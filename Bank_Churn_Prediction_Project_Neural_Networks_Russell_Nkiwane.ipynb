{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: \n",
    "Given a Bank customer, build a neural network-based classifier that can determine whether they will leave or not in the next 6 months.\n",
    "## Context: \n",
    "Businesses like banks that provide service have to worry about the problem of 'Churn' i.e. customers leaving and joining another service provider. It is important to understand which aspects of the service influence a customer's decision in this regard. Management can concentrate efforts on the improvement of service, keeping in mind these priorities. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages to use in EDA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data into pandas dataframe\n",
    "data_og = pd.read_csv('bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check number of columns in dataframe, 13 are dependent variables with 1 dependent variable \"Exited\"\n",
    "# Check number of records in the data, which is 10000\n",
    "data_og.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first 5 rows of the data\n",
    "data_og.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowNumber number of unique values is 10000\n",
      "CustomerId number of unique values is 10000\n",
      "Surname number of unique values is 2932\n",
      "CreditScore number of unique values is 460\n",
      "Geography number of unique values is 3\n",
      "Gender number of unique values is 2\n",
      "Age number of unique values is 70\n",
      "Tenure number of unique values is 11\n",
      "Balance number of unique values is 6382\n",
      "NumOfProducts number of unique values is 4\n",
      "HasCrCard number of unique values is 2\n",
      "IsActiveMember number of unique values is 2\n",
      "EstimatedSalary number of unique values is 9999\n",
      "Exited number of unique values is 2\n"
     ]
    }
   ],
   "source": [
    "for i in data_og.columns:\n",
    "    print('{} number of unique values is {}'.format(data_og[i].name, data_og[i].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns RowNumber & CustomerId which are unique identifiers for the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_og = data_og.drop(['RowNumber', 'CustomerId','Surname'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
       "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
       "       'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_og.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NULL values, which there are none\n",
    "data_og.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate records, which there are none\n",
    "data_og.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore           Age        Tenure        Balance  NumOfProducts  \\\n",
       "count  10000.000000  10000.000000  10000.000000   10000.000000   10000.000000   \n",
       "mean     650.528800     38.921800      5.012800   76485.889288       1.530200   \n",
       "std       96.653299     10.487806      2.892174   62397.405202       0.581654   \n",
       "min      350.000000     18.000000      0.000000       0.000000       1.000000   \n",
       "25%      584.000000     32.000000      3.000000       0.000000       1.000000   \n",
       "50%      652.000000     37.000000      5.000000   97198.540000       1.000000   \n",
       "75%      718.000000     44.000000      7.000000  127644.240000       2.000000   \n",
       "max      850.000000     92.000000     10.000000  250898.090000       4.000000   \n",
       "\n",
       "         HasCrCard  IsActiveMember  EstimatedSalary        Exited  \n",
       "count  10000.00000    10000.000000     10000.000000  10000.000000  \n",
       "mean       0.70550        0.515100    100090.239881      0.203700  \n",
       "std        0.45584        0.499797     57510.492818      0.402769  \n",
       "min        0.00000        0.000000        11.580000      0.000000  \n",
       "25%        0.00000        0.000000     51002.110000      0.000000  \n",
       "50%        1.00000        1.000000    100193.915000      0.000000  \n",
       "75%        1.00000        1.000000    149388.247500      0.000000  \n",
       "max        1.00000        1.000000    199992.480000      1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive Stats of the variables\n",
    "data_og.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: Exited, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "France     0.5014\n",
      "Germany    0.2509\n",
      "Spain      0.2477\n",
      "Name: Geography, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAIuCAYAAABZzclzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXhU5dk/8O99zmzZ9xBCCIEESICwgyiyiFrXarXaarW1Km6l1qqtpa6jVev7Vn9drVtd4tvaVhFFwQ0TCGFfwxogCQkhZCVkXybJzPP7YwKiAlnmnPPMmdyf68olSSbnfEUzc8+z3SSEAGOMMcZYoFJkB2CMMcYY0xMXO4wxxhgLaFzsMMYYYyygcbHDGGOMsYDGxQ5jjDHGAhoXO4wxxhgLaFzsMMYYYyygcbHDGGOMsYDGxQ5jjDHGAhoXO4wxxhgLaFzsMMYYYyygcbHDGGOMsYDGxQ5jjDHGAhoXO4wxxhgLaFzsMMYYYyygcbHDGGOMsYDGxQ5jjDHGAhoXO4wxxhgLaFzsMMYYYyygcbHDGGOMsYDGxQ5jjDHGAhoXO4wxxhgLaFzsMMYYYyygcbHDGGOMsYDGxQ5jjDHGAhoXO4wxxhgLaFzsMMYYYyygcbHDGGOMsYDGxQ5jjDHGAhoXO4wxxhgLaFzsMMYYYyygcbHDGGOMsYDGxQ5jjDHGAhoXO4wxxhgLaFzsMMZ8QkQOItpMRDuJaC8RPdnz9d8R0S4iyieiL4goUXZWxtjgREII2RkYYyZGRAQgRAjRQkRWAGsB3AdgnxCiqecxvwAwTghxt8SojLFByiI7AGPM3IT3HVNLz6fWng9xotDpEQKA31kxxqTgYocx5jMiUgFsA5AG4EUhxKaerz8D4CcAGgFcIC8hY2ww42ksxphmiCgSwAcA7hVC7Dnl678F4BBCPCEtHGNs0OIFyowxzQghGgCsBnDpN771DoDvGx6IMcbAxQ5jzEdEFNczogMiCgJwEYD9RDT6lIddBWC/jHyMMcZrdhhjvhoKIKtn3Y4C4F0hxHIiep+IxgLwADgMgHdifQMROQCsAWCH9/l4yalTfUT0KwB/ABAnhDgmJyVj5sdrdhhjTJIzbdsXQmwkouEA/gEgHcA0LnYYGziexmKMMUmE17e27fd8/kcAD4G37DPmMy52GGNMIiJSiSgfQA2AlUKITUR0FYCjQoidkuMxFhC42GFMAz0vWDuIaHnP59FEtJKICnv+GSU7I/NPQgi3EGIygCQAM4loIoBHADwuNxljgYOLHca0cR+AglM+XwwgWwgxGkB2z+eMndEp2/avBjASwE4iKoW3CNpORAny0jFmblzsMOYjIkoCcAW8i0lPuBpAVs+fswB8z+hczP+dYdv+DiFEvBAiRQiRAqAcwFQhRJXEqIyZGm89Z8x3f4J3IWnYKV8bIoSoBAAhRCURxUtJxvzdabftS87EWMDhYocxHxDRlQBqhBDbiGi+7DzMXIQQuwBM6eUxKcakYSxwcbHDmG9mA7iKiC4H4AAQTkT/BFBNREN7RnWGwrvThjHGmAS8ZocxHwghfiuESOp5930DgBwhxM0APgJwS8/DbgGwTFJExhgb9LjYYUwfzwG4mIgKAVzc8zljjDEJuF0EY4wxxgIaj+wwxhhjLKBxscMYY4yxgMbFDmOMMcYCGhc7jDHGGAtoXOwwxhhjLKBxscMYY4yxgMYnKDPGdPHCD68MBhAKIOQ0/7QDsPV8WL/xTwLQAaC956PtDH/+2ucP/ne5x6B/NcaYyfA5O4yxPnvhh1cSgFgAwwAknvLPb/45DsaPHLsAtMDbmqPqGx+VIPtRR+SiKgCHF728oNXgbIwxibjYYYyd9MIPr7QAGA0gA0AagCR8vZhJgHf0xYTUIkfUfWk9nxwHUHbKx2EAJQD2Aihc9PICt5yMjDE9cLHD2CBUvjjPWtl2aMya6vcmAhgHb3EzDt4Cxyo1nF4oeJsj8u5pfXhkB4B9AHb3fOwCsHvRywuq9IzHGNMPr9lhLMCVL86LAjAZwKRT/jluSNCIWnhHawYFUkLa+/hQB4CpPR8nvXh3Ti1OKX56PvYsenlBX6/LGJOEix3GAkz54rwxAOYCmAfgfAApp3scQUm0kK25W3SGGRhPGlIiun28RByABT0fJ3hevDunGEA+gHUA8gDs5GkwxvwLT2MxZmLli/MI3umnefAWOHMBDO3rz6+u/O+e6o7SCTrF8yuqffoaa/DcuQbcqhnAengLnzwAmxa9vMBlwH0ZY2fAIzuMmUj54jwFwER4i5t5AObAuztqQOKDhtdXd5RqE87PkRrtMOhWYQAu6fkAANeLd+dsBJAN4EsAWxa9vMDXUSbTIyIHgDXwHkNgAbBECPFEz/fuBfBzAN0AVgghHpIWlAUELnYY83Pli/PGA7gMX01LRWp17Vh70qAZ2lXUqHBJt7bjq+L0KQBNL96dk4ue4mfRywv2SsolmwvAAiFECxFZAawlok8BBAG4GsBEIYSLiOKlpmQBgYsdxvxM+eI8C7wjNlcB+C6AVL3uFW6LHRTrdQCAlMgY2Rl6hMP73/W7APDi3TnlAJYCeB/A2kUvLxgUhyMK7xqKlp5PrT0fAsA9AJ4TQrh6HlcjJyELJLxmhzE/UL44LxTe0ZurAVwOIMqI+woh6t4t/V9/KQL01GmPvN9KRCQ7SC+qAHwAYAmA3EBf6ExEKoBt8B558KIQ4jdElA9gGYBL4T0G4FdCiC0SY7IAwMUOY5KUL84Lg/fd/fXwPrEbtabka5aV/a22w90aJ+PexqFyR9T9SbJT9NMxAB/CW/hkB/I6HyKKhLfIuxfAfwDkALgPwAwA/wUwSvCLFfMBFztMN2dagEhEkwC8DG+fpFIANwkhmqQFNVD54rwIeKenroN3AatdbiJgXfWHO8rbDkyRnUNXZN/tiFyUKTuGD+oBfARv4fPFopcXdErOozkiegJAK4CL4J3GWt3z9WIAs4QQtRLjMZPjYofppmfKIOTUBYjwvlv7K7xD07lEdBuAkUKIx2Rm1VPP9vCLACyEd5pKeoFzqsKm7bnb61bOk51DT6REbrBH3Hau7BwaaQLwMbyFzydmLXyIKA5AlxCigYiCAHwB4H/Q06JECPE4EY2BdyF3Mo/sMF/wAmWmm7MsQBwL74gPAKwE8DmAgCt2yhfnJQK4FcDtAEZKjnNGMfZEVXYGvZESZsqC4AzCAdzU83Hsxbtz3gbw2qKXF+yXG6vfhgLI6lm3owB4VwixnIhsAN4goj0AOgHcwoUO8xUXO0xXp1mAuKnnSewqeBchXg9guMSImipfnKfCu9D4DgBXAPD7QiLMGmXIYmiZSNFst76/iQXwAIAHXrw7Zy2A1wC8Z4YWFkKIXQC+NX0qhOgEcLPxiVggU2QHYIFNCOEWQkyGd2h6JhFNAHAbgEVEtA3eA9hM/667fHHeiPLFeU/B2z37Y3iLOb8vdADAQrYUeEfcAhapUYHZ3PTrzgeQBaDy5YWfPF+QnmHmNUqMaYpHdpgheublVwO4VAjxPIDvAEDPnPwVMrMNVPniPCu8Rc0dAC6GSd88EFFImCWqrLm7Pll2Fr2QGh0iO4OBIkJbymcAeLAgPWMNgL8B+CBjf0HA7uZirDdc7DDdnGYB4kUA/oeI4oUQNUSkAHgU3p1ZplG+OG8YvFtkbwUQEKe7xjmGVzW3BHCxo0QG/FTdqcYULUns+eOJfmlHC9IzXgXwSsb+gmp5yRiTw5TvRJlpDAWwioh2AdgCYKUQYjmAG4noIID9ACoAvCkxY5+VL84bV7447y0AJQB+gwApdAAgLii5TXYGPZESHjD/rXpj6WrdFdZyJO0bXx4G4EkAZQXpGe8UpGdMkxCNMWl4ZIfp5iwLEP8M4M/GJxqY8sV5cwA8BO90m7+fwDsg0bYEv9oOr7HjRJZo2SGMMqLsi5azfNsG4EYANxakZ3wK4MmM/QWbjEnGmDxc7DB2Gk6nk1LccZdc1DXxcQCBcj7LGYVYwgP4BGXLMQCDo9gRnrrh5av7OmpzGYDLCtIzvoC36FmvYzLGpOJih7FTOJ1OBcD3ATxaqtRmNFF7TbgIkh1LdwpZRihQOj3w2GRn0RzZB8Xp3AAQfbxgjyK6+3tA5HcAfKcgPSMH3qJnTW8/wJjZcLHDGACn06kCuAHAIwAyAAAE5Fr3FX+3c9owmdmMQETWCFt8YX1n1WjZWbRGSqjfnzmjCSHE6KL3U3y4wgIACwrSM3IBPJWxvyBHm2CMycfFDhvUeoqcHwN4GMC3XuirqWFGG1y1wbAH8DSPV3xQcm1gFjsRHtkZjGDrat4R0l49VYNLzQOQXZCesRbA7zL2F3yhwTUZk4p3Y7FBy+l0XgogH97dYKd/kScErbXu32dkLlniHMNNf7jj6ZAaNSie51JKP+nS+JLnA/i8ID1jQ0F6xmUaX5sxQ/HIDht0nE7nBADPw9t1vFdlyrHJLnQ12mGN0DeZXFG2+IA8eE9RogN/0ZXwVCVWrtNrO/ksAJ8UpGdsAfBwxv6CL3W6D2O64WKHDRpOp3MIgN/B266i760cCBEbrAdXz+8aP1+naH7BoYYMlZ1BD6RGhsvOoLe4Yzv3K8IzX+fbzACwsiA9YzmABzP2FxzU+X6MaYaLHRbwnE5nEIAH4T0IMHQg1yhSqsafj/R2C9SAHSUgKMMsZGvuFp1hsrNoiZSIWNkZdCWEO61o6VgD73glgEsK0jP+Du/urXoD783YgAyKuWw2ODmdTnI6nT8GcBDeEZ0BFToAAELcFkvxFq2y+SMiohj70MOyc2isg5TggD5jx+46vi3IddzoUTkrgPsAFBakZ/y8ID2D3zgzv8bFDgtITqdzHrwtKt6Gt+O6z/ap5akeeLReBOpX4oOSA+xdulIjO4HeUg99LPN5PAbAXwHsLEjPuFBiDsbOiqtxFlCcTmcavIuPr9b62oLEsJ3q4XVT3CNna31tfxFrTwqsbdpkqwcQuA1OPe4jQ2q2arHd3FfjAHxZkJ7xLoAHMvYXHJUdiLFTcbHDAoLT6bQCWAzvoYC69XnaYSkZOtmd4iFQQI6KhttiA2rHGVFQq+wMehpSs+UQQQyXneMUPwBweUF6xlMA/pSxvyCgR0KZeQTkEzYbXJxO57kAdgB4CjoWOgDgITGqQD26Wc97yGRXgjSZ8vMXpIQH7outEF2pxR+Okx3jNEIB/C+A/IL0jAtkh2EM4JEdZmJOpzMcwO8B3A0DC/fNlqKIce6AqglOIqJYhxpS2+FuDYgTo0mNlB1BN0HtNVvsXc3nyc5xFuMA5BSkZ/wLwL28a4vJxCM7zJScTufVAPYB+BkM/v+4m9wZxUrVNiPvaaRYe1K57AxaISU68Bqb9kgr/sAsh0DeBGBPQXrGpbKDsMGLR3aYqTidzhO7P26UmWO99aCa6kqQGUE38UHJTeVtB2TH0ASpUQM/bsCPkafrUFzd7kmyc/RDIoBPC9IzXoH3QMKAXkvF/A+P7DDTcDqd3wOwF5ILHQBwUdfkcqVut+wceoixJ/b9dGk/R0pklOwMekisXG/W0be74N2mHrA7Gpl/4pEd5vd6RnP+BuAG2VlOlWct6LjRdb7sGJoLs0YFSoEgSAkbIjuE5oRoH1WyfKLsGD5IBbCmID3jBQCPZewvcMkOxAIfj+wwv9azNmcv/KzQAYBWcs2oocaA6w9kIVsKACE7hwaOEalW2SG0Ftp6dLu1u83sK68VAL8GsKUgPcNM03HMpLjYYX7J6XTanE7nXwF8CMBv353nWvcdk51Ba0QUEmaJOiI7h++sdbIT6CGt6H2zFzqnyoS34HmkID0jYKZPmf/hYof5HafTOQrAOgA/l52lN43Udk4DtQZaPynEOYZXyc7gM3I0yY6gNcXt2h/dcHC87BwaswJ4GsDagvSM0bLDsMDExQ7zK06n8/sAtgOYLjtLnxDU1da9ZbJjaC0uKLlNdgZfkRLaITuD1oaXr66VnUFHs+A9iHBRQXoGyQ7DAgsvUGZ+wel02gG8AGCR7Cz9dYyaz2lBR1UoHAGzFz3alqDrSdRGICUisPp8CdE8ouzzKbJj6CwY3s0IVxSkZ9ycsb/guOxALDDwyA6Tzul0pgJYDxMWOgAAgm2NdV9gHEzTI8QSbvoTlBU1KqDezIU3leRb3K6APDfoNC4DsK0gPWOa7CAsMHCxw6RyOp3XwTtt5Q+dmwesQqmf3oHOgDkOXyHLCAVKp+wcviA1Kkh2Bi2NKVritwv1dZICYF1BesZC2UGY+QXUOx9mHj3TVv8P3nYP5kcIWWvdv/WironzZEfRAhFZI2zxhfWdVaZdMEpKVMB0cLd0t+0Obz6cKTuHBHYArxWkZ5wLYFHG/oKAW4fFjMEjO8xwp0xbBUah06NUqZ3Uhe4W2Tm0Eh+UbOrFsKREmH4q7oTksi8DbmdZP90G7yhPiuwgzJy42GGGcjqdVyEApq1OixC50VIYMA1C4xzDzTyN1UqKIzBGdoSoH16ePejXrggg7aHb1PczszIXyM7CzIeLHWYYp9P5EIAPAITLzqKXg2pFuhuegDj+PsoWb5au2qeh1MhOoJWohgO7VE+3Q3YOmQQgXrpc2V86hKYC+DwzK/Ne2ZmYufCaHaY7p9NpA/AygFtlZ9GbIAzZZjm0ZmZ32lzZWXzlUEOGys4wYGRvkB1BK6MLlyTLziDbxnRas3qScmI9nAXAXzKzMicCWLT7lt1+NQJJRA4Aa+Bdb2QBsEQI8QQROQHcAeDE9PDDQohP5KQcfHhkh+mqp4nnSgyCQueEPWpZigfCLTuHrwjKMAvZmmXnGAiiYNMfiggA1s7m/NC2ypGyc8h0LByb//g95XRvHhYCyMnMyow3OlMvXAAWCCEmAZgM4FIimtXzvT8KISb3fHChYyAudphunE5nBoDNAEw/ytEfHhLJu9WyTbJz+IqIKMY+1JStMEgJ75KdQQsphz9rl51Bpi4VJQ/erqaD6EwnKs8GsDUzK9NvDlsUXic2Klh7PgKhsa6pcbHjx4jIQUSbiWgnEe0loid7vv4HItpPRLuI6AMi8rvGgNk5qRecM+u914jcSbKzyLDdcihOQJj+CS4+KNmUZweRGmn+dgPCUzOsYo052qboQADND9+ietod1Nsav+EA1mZmZV5iRK6+ICKViPIB1ABYKYQ48ebn5z3P228QUZTEiIMOFzv+7UzDoSsBTBBCTARwEMBvJWb8luyc1JsAfGazdcyeMnXFFtl5ZHCTZ/RBtdL0/+6x9iRTtlwgNdr07S5i6/YUKMJjlZ1DBgGI1y5R9h4eQql9/JFgAB9nZmX+UM9cfSWEcAshJgNIAjCTiCYAeAlAKrzP5ZXwtsdhBuFix4+daThUCPGFEKK75+sb4f2F8gvZOam/BfB/AGwAEBLSODs9Y02u3FRybLQcNPFuJq9wW6wpt2+TEhUmO4NPhPCMLnq/ry/0AWfLaFrz5VRlVu+P/BorgHcyszLv1iPTQAghGgCsBnCpEKK6pwjyAHgNwEyp4QYZLnb83FmGQ0+4DcCnxif7uuycVDU7J/UlAM8C+NoUQlzc4XlJw3evk5NMni5yjy9VanbIzuELuxLkN4V0fyhKZIzsDL6wdzZsC+o4Zsq/e1/VhWLLC99X5gzwxxUAL2VmZT6iZab+IKK4E0sLiCgIwEUA9hPRqbsbrwGwR0a+wYqLHT93huFQAAARPQKgG8C/ZOUDgOyc1CAAHwI44zuqlJT8GdHR5TuNS+Uf1lkPmHrdDhHFOtSQY7Jz9JMbSqipT08eWbJcdgQpuhUc/tVCdYwg8vW16enMrMwXMrMyZazdGgpgFRHtArAF3jepywH8LxHt7vn6BQDul5Bt0OJixyROHQ4FACK6BcCVAG4SQt5C2Oyc1BAAn/RkOSMi2MaNX5UcHNxQYkwy/9BOnVMrqX6f7By+iLUPK5OdoX+olkhRZacYKPK4jw6t2jToTkwWQMsjt6hdrUGk1dTpAwBez8zKNPT/BSHELiHEFCHERCHEBCHEUz1f/7EQIrPn61cJISqNzDXYcbHjx84yHHopgN8AuEoIIe08keyc1DAAnwGY35fHEyFqytQVisXScVzXYH5mjXWfKc+qOSE+aITJ+n1ZTP3/V3zt9kKCGHTPzW9crOwuSaA0jS97K4AlmVmZpl+wznwz6H6hTOZMw6F/AxAGYCUR5RPRy0YHy85JDQfwOYDz+/NziuIZMX3GsnIid0C0VOiLZuqYWUfNxbJzDFSMPdFU27hJCTJvcSlEd1rxB+NkxzDa9lTK/Xy6cq5Ol/8egE8yszLNvWid+YSLHT92luHQNCHE8FNO4jR090F2TmokgC8BDOjJyWrtnDh12vJtCIBzaPqEQKute007ZB1mjYqWnaFfKNS0hXRQx7Gt9s5GfzsRWFf1Idj6P9cPeEFyXy2A97TlWJ3vw/wUFzusX7JzUqMB5ACY4ct1goObzssYl7tGm1T+r55aZzVRW7nsHANhIdsImOgEWFIjTXk2EACkHlo2qKZbuhWUPXiHmqbBguS+mA5gTWZW5qDc5TbYcbHD+iw7JzUWwCoAmhzNHht7ZN7w5F1rtbiW3yNYcq37DsmOMRBEFBpmiTJNoaYoUaZscEye7tK42h2TZecwigDaHvux2tESZOgJ8BkA1mVmZY4x8J7MD3Cxw/okOyd1CLy7wSZqed0RI3bOjI45kq/lNf1VNTXObIOrtvdH+p9Yx3DTTMORGm3KwxyHVm08TN84oyqQvX2hkl+cSDKKjmR4R3i44BlEuNhhvcrOSR0Kb6EzXutrE8E2btzqlODg+sDfkk5w5FkLTLkNPT4o2TQNKUmN9Ltecb0SomNUyUeZsmMYZedIyl0xUzlPYoQhALIzszJTJGZgBuJih51Vdk5qEoBcAOl63YMIkVOmrlCt1vY6ve7hL44odVNc6GqUnaO/om0JpunRREqE6Q4UDGmr3GbrajXXQvABagzG9t//QOnXLk6dJAH4MjMrM1F2EKY/LnbYGWXnpA6Ht9AZrfe9FEUkT5+xrCLgt6QTwtdbD5iuhUSIJdwsO4SaiGyhskP0V1rR0t46eweEbgXlD9yhpngU8pdDH1PhLXh4l1aA42KHnVZ2TmoMgC8AjDLqnhZLV+Zg2JJerFRP6IJb2mGQA6GQZQRB6ZKdo3eq6dZEKe7Owpj6goCfwhJAu/MmtaU5mPxtBCsDwBeZWZnmm/5kfcbFDvuW7JzUUHhbQOg2dXUmwcFN540btzqwt6QTYrdYirbKjtEfRGSNtMWXys7RK7KbbopwWEWeaRZ/++Kd+cr2g0lk+HNKH00B8GlmVqbpRgVZ33Cxw74mOyfVBmApgJmyMsTEls9LTt4Z0FvSC9TyNA88Jhgp+Uq8Y7jfj5qQEmyqETMI0Tqy9JOA326+J5nWLDtXmS07Ry9mAViamZVpmvVprO+42GEnZeekKgCyAFwsO0vyiF3nxMSUmW5tS18JQuIOS+km2Tn6Iy4ouVN2ht6QEt4tO0N/hDWXbbe4OwJ6vU5TEPKfvlHqzqv+uBhAlqRu6UxHXOywU/0ZwA2yQwAAEawZ43JHhYTUm/Igvr7YqZYOExCmOe03yhbv9+fXkBJlque00UVLAnphrJtw9ME71CSPQmY66PFGAH+UHYJpy1RPDEw/2TmpvwXwc9k5TkWEiMlTVlit1na/nz4ZCA+JkfvUctOM7jjUkKGyM/SG1GiH7Ax9pXZ37ItsOpQhO4deBNDx5E1qU2MImbGguy8zK3Ox7BBMO1zsMGTnpP4IwDOyc5yOoojh02csqyalu0N2Fj1ssRRFyc7QVwRlmIVsft1RXFGiTNPZenh59nHZGfT037nK1v3DyczF3O8zszJ/KjsE0wYXO4Ncdk7qfABvwo+PqbdYuiZMm7Z8RyBuSe8mT3qRUmWKnVlERDH2oYdl5zgbUiNjZGfoEyEaR5R9OVV2DL0UDMeapbP94uBAX72WmZV5pewQzHdc7Axi2Tmp4wB8AMAmO0tvgoKazx03flVAbknfYD3g93//J8QHJdfLznAW3aAQU0yZRDYW7VQ9ncGyc+ih2YGdT/5INcuC5N5YAPwnMysz4M9BCnRc7AxSPf2uPgVgmoO0YmKOzhsxIj9Pdg6tuah74hHl2C7ZOfoi1p7kxwuqqYaITPGcNrpoyTDZGfTgJlQ+cIeaaLIFyb0JAfBBZlamaaac2beZ4omBaSs7J9UB4GN4u/+ayvDk3efGxh7eLjuH1vKs+03RJiPcFhshO8MZkdUUa2AsXa07w1rKU2Xn0JoAXE/fqBxvDCXT9Sbrg1QA/87MyuTXTJPi/3CD098BTJMdYiCIYEnPWJMaEnK8WHYWLbWRa0YNNR6QnaM3diUoSXaGMyEKapGdoS9SDn/WKjuDHpacT5v3jlDGy86ho0vgpxs5WO+42BlksnNS7wJwq+wcvvBuSf/EHmhb0ldb9/r9yAQRxTrUkGOyc5yWEub3hx5CeI4lHc2dLjuG1g4mIu+9Oeoc2TkMsDgzK/N62SFY/3GxM4hk56TOBPAX2Tm0oCgiafqMZTWK0t0uO4tWmqj9nHpqKZWdozex9mFlsjOcjqJE+vF6Iq/o4wV7FeE2zYL0vmixY9cTN6uzZOcw0JuZWZkTZIdg/cPFziCRnZMaB2AJTLDzqq8slq7xU6d9vDNgtqQTlFzrvnLZMXoTHzTCL6eLSI3y755GQogxRUtGyo6hJTeh6sE71AS3Sv79d6+tEAAf8oJlc+FiZxDIzklVAfwHwHDZWbQWFNQya/yEnIDZkn6Mmmc2o92vu2DH2BMHdCaTxyPw/77Iw+t5WwAAy3cW4IXP1+Dfm/JPPmZbaTnyDpYMKBcp0X7dzsLW2bQ9uL3GdJsCzkQAnc/+UKmtD6N42Vkk4AXLJsP/oQaHZwEskB1CL9HRFfNGpOwIjC3pBNsaa8FB2THOJswaFT2Qn8srLMGQ8FAAQHtnFw7X1ePBS+bCIwQqG5rQ1e3GltJynJc2YkC5SI3063faI0tXmKpJaW+WzaJNu0cqg/n8GV6wbCJc7AS47JzUawE8JDuH3oYP33NubGzpNtk5tFCp1E9vR2ed7BxnYiHbCAD9mjpsaGtHQbKhevcAACAASURBVGUNZo70Di4SEbo9AkIIdLndUBUFqw4cwvmjU6AqA3taIiXcf0cYhKcysXJ9wCxMLhqKvHcuGBQLknvDC5ZNgoudAJadkzoWwFuycxjBuyU9b3RIaF2R7Cw+I4Sste7fIzvGmRBRaJglql9ri5bl78OVEzNA5J0Bc1gtmJiUgD+uXIvokGA4rBYcOd6ACcMSBhqrgcga1J8f8HjceG7JXXjp04cBAB9ufBXPvrcQb+c8d/Ixmw+uxKrd7w8000nxtfkHCUL1+UJ+oNWOPY//WD1Hdg4/wguWTYCLnQCVnZMaCm8rCNM0RvQVEcInT/7UYbO11cjO4qvDSu3kTnT7bdPNWMfwPq8r2ldRjVC7DUnRXz+P8IL0VDzwnTm4avI4fLbnIC6dMAabDpXh7fXb8eW+wn4msvT7GIJVe5ZiSJR3CU27qwUl1Xvx8PX/gEd4cLTuEDq7Xdh44HPMHXd1fy/9dUK404qXjvHtIv7BQ6j51UI1tlulgNnooAFesGwCXOwErjcAmLnj8IAoikiaNn3ZMUXpbpOdxSeEiI2Wg357UnR8UHKft/yXHqvHvooaPLM8B//auANFNcfwzsYdJ79/tL4RABAbFoKtpUfxk/OmoqqxGbXN/Th7j+xNfX8wUN9Si72HN+G89Mu9P04Kuj3d3mm1bhdUxYLsnf/F/MxroKq+dT5wuI5vc7jqh/p0ET8ggK7nrleq6sJpwMNvASwVwL8yszL9tqHyYMfFTgDKzkm9H8CgnUe2WLrHTZ328S5A+P25K2dTqFZmdMPd4cs13B43Ln3zdvx0yW8AAM+ufgkXv/FT/HL5V+sq39/zOV7f+l6/rhttS+jzVuPLJ6bjse9eiEeuXICbZk1BWnwsfjRrysnvf7bnIC6ZMAaenjU8gHdNT5fb3ec8pIT0q7h9f/2L+N6sO7+aVrMFY/LIOXju/bsQE56AIFsIDtccwMSU2f257GmNOvRRQExfLZ9JG/JTlYmyc/ixywDcJzsEOz0udgJMdk7qJADP9frAABcU1DJrQma2qXdoCUL8Nsuhzb5c4/WtS5AW493d1ORqwdaje7HytrfgFm4U1BajvcuF9/Z8ip9MuaZf1w2xaLMYeM/RKgyPjkBEkANBNitGxETi+c+9JwkkRob3+TqkRPS5Mtp9eAPCgqKQHPf1maWLJ9+A3173Kq499x4s3/omrpjxU6wvWIHXVz6Fz7b/s89ZvpbL4z4ypGbr1AH9sB8pGYK1/3ehOld2DhP4Pa/f8U9c7ASQ7JxUO4B/IoAODvRFVFTlvJSR2019Bs8e9chIDzwD2rJc2VSDnEMbcOOkKwAAChR0ubsghEBHtwtWxYJXNv8bt077Pqz9nKpRyDKCoHT1N1NafAxunzPj5OcThiXgO+O/Kjq+O3kcfnXJXNx0yshPX5Aa1efRk0NVe7H78Ho8/q8f4c0vn8bBinxkZT978vtHjnnXC8VHJGHTwZW4/eLHUXG8BDWN/T/vMaF6czEBpp7aaLdh3yM/UWf0/kgGwAHvdJZddhD2dVzsBJbfA+B3FadIStp7XlxcyVbZOQZKkBi+Sy3bNJCfdWb/FQ/PvwcKeX/NQ+3BuHzsPFz61u0YHjEUYfYQ7Kzcj0tG938HMRFZI23xpQPJpQdFiXL09bFXn7MQT9/8Xzx10zu49aJHMSZxMm658OGT31++5U1cMf2ncHvcED0zoUQKOrv72ZheiM7UQ8tM/fvoIdQ+uFCN6rYQv3j33UTw+Tt+h4udAJGdk3ohgF/KzuFviGAZm752TGjosf5u7/EbOywlCaKfLTG+LFqPmJAoTEwY+7Wv33POj/D5rW/g8QU/x/N5r+PBObfh3zuX454Pn8Cf12f1K1e8Y7jfNGIlNarvc15nsbNkLUbEpSMyJBbB9lCkDBmHZ95bCAIhKSa1X9cKbqveautqjtUilwwC6P7D95WjxyLI9IurJXggMyszYA9yNSMSAdJWaDDLzkmNArALQJLsLP5KCKrYvOlatbMzeIjsLANxflf65nT3sJl9ffxzua/g/T1fwKKocLk70exqxWVj5uIv330MALCn+iCytn+AJy/8BX783q/x/k1/w8+WOfHrObdjZHTfuoocbSvMXVu9dN7A/o20ZY+46xgpIX5VWEzc/fLO2Lrdk2TnGKhPp9GaN7/D63R8UA4gc/ctuxtkB2E8shMQ3sAdiz1Q+N3XWRCJxOkzlh0365b0TZbCfvV9WjzvLmxZ9D423PMuXrzqCcweMfVkoQPAO6pz/u3o8nTD0zNVo5CC9n5M1UTahvTrED8ddYKCY2SHOJXi6So2c6FTFod1XOj4xuYRrlcra56UnYN5cbFjcgmr8q/JpksfuhNZ+48geWAdFAcJVe3OmDb9o91m3JLeRe7xJUrNjt4f2bvPDuZhUkI6EsJiEeEIw9TE8bjo9VtABIyLT+vzdYLUkEQt8vhOqaETe8j9RGLFuqOyMwxUhxUFD9+imn4HmTRCeGa1d+SuLzsy7NyOjl/AGeHjqZRMCzyNZWIJq/JjAOwF4J2aEaL9Yny6+Ra8PtfsO0D0VF+fkLtn98V+Mf3SHw5h3XGza27/tinpSAghlh7+Y2u36AqVGoTsuxyRi/zn/Bch2uas+3WXtbs9ovcH+xcPUHff3Wp7dRTxlPgAWIQ48qfq2uPz2jtOHdWrAjAezsbjsnIxHtkxu7/iRKEDAERBK+nyeXfjzZ1VSOj/PtlBIiqqat7IkdtMtyW9g7qmVCjH98rOcQIRUbQ98bD8HMEtsjOcKrSlfLsZCx0BuF+4VinjQmdgxrtceWsPl0d9o9ABgAQAf5GRiX2Fix2TSliVfw2AG0/3vRYKn/wg/hbxHm4w9aF6ehqWtG92XPwh021JX2Mt6EcPBf3FO5Klv1slJazf5/3oaXTx+9GyMwzEyim0dstYxW9GDs1CEaL6mdpjW/5TUT0nRIgzjXLeBGfEVYYGY1/DxY4J9UxfvXTWBxGFfUjXz7kXr2w5juhqY5KZBxHUsWPXjQ0NO3ZQdpb+aEHHjGPU5Ded3eMcSdLnwUmJlB3hJNXtKohqKBzXn5+5qLgIV5eU4JrSElxfWgoAeKG2Bt8rKcHiyoqTj/uosRH/V69PbVkeg3X/uFQ13dSubCmdXRtyy47armpp68uhi6/AGcHNQiXhYsecnsep01dncZxiZ9yLV22f4sr1OmcyHSKETZ78WZjN1lolO0ufESjXus9vitdwW2yY7AykRvW5T5fekspXHxvIz701fDg+SBmJ91JS0Ox2Y0d7Oz4cORJuARx0daDD48EHTY24IVL718oOKw4svpUXJPcHCVH/UF39+o+PVp4b6fH09T8KT2dJxMWOySSsyj8XwC39+iGiqH/Srec9iL9uaEKY9GkHf0Ikhk6f8VG9onT51fTQ2dRT6zmN1HZEdg4AsCtBfTuUR0ekRstdIH2CEE0jyj73eRpIIaBLeJuiuoQHFhDeOH4cN0dGwarxpjMPcPzXt6khnVbyl2ME/F58d/eWlUcqOn/c1HzeAH78ZjgjLtQ8FOsVFzsmkrAqXwHwNwxwp1UVJZ77M7zRvQbzt2ibzNx6tqTvNc2WdIIl17q3VHYMACCiWIcaIvUkZVJ0GO4YgIimQ/kWt6vfhRcRYWH5EVxXWoJ3GxoQoqj4TmgYrj1cimFWK8JUFXs62nFhmLaDaAJw/+l7Sml1NC9I7hMhmu+sb8zLPlIxY4jb7cvhpH+CM6LPvdyYNrjY+QYichDRZiLaSUR7iejJnq9f3/O5h4imS4p3JwCfhpsFKfGv0L0zHsEf1rYjqFmjXKbncLTNzJy4UvMF3R6PB6+88greeecdAMDKlSvx0ksv4YMPPjj5mJ07d2Ljxo39um4NNc1shatG07ADFGsfJnPnnyAlTJMO7L4aXbRkQAd7/is5Ge+njMQrScPx74Z6bG1rw+0xMfggZSR+Ez8EfzlWi5/HxmFJQwPurziKl+sGNFP2Lasm0tqNGQpPX/VBhNudv6K8svHehsb+N5L7tgkA7tbgOqwfuNj5NheABUKISQAmA7iUiGYB2APgWgBStiz3LErWrLlcKY06/05kNW7FTE0OqgsEkZHV80aN2pKr5TU3bdqE2FhvF4OOjg6Ul5fjnnvugRAC1dXV6Orqws6dOzFjRj+bShPsedZ9BVpmHaj4oOQmibevI7JIb1Jp6WrbHd5cNnogPxtv8S45irFYcGFoKHZ1tJ/83r6ODgBAis2GZU2N+GPiMBS6XCjt7PQpb0UUNrx8BS9I7pUQHT9sas7NKzs6Kbm7W8sRsKfgjDDlrj2z4mLnG4TXiXM7rD0fQghRIIQ4IDHaMwA0/eXwkJr0Rzw0+Xd4KtcFW3vvPxH4EoftPz8+vliTab6mpiYUFhZi6lTvm2cigtvthhACXV1dUFUV69evx8yZM6Gq/R/VLleOT+1Al/S+OzH2YRKH5C118u79leQjKwdU8LV5PGj1uE/+eX1rG0bbv6rd/nqsFvfGxqJbCHh69r0pIHR4Bj7j6rKg8De3qf5zCKOfCvZ4Ct6rqDr6aF39PB0OaY0G8JTG12RnwcXOaRCRSkT5AGoArBRCbJKZJ2FV/lQAd+hycSLaT+Pn3Ym3q/Zigt8cWCcLEdQxY9dnhIXV+lzYfvbZZ7joootwopOB3W5HRkYGXnnlFURGRsJut6OiogLp6ekDDIuw9dYD+b7m9FWYNUremhlyyBxV8hLi+PDynGkD+dG67m7cXFaGa0pL8MPDpZgbGoI5Id5lP182N2OCIwjxFivCVRWTgoJwdYm3I0y6wzGwqEDDb25TbS4b9avX2qAiRPclLa2r1x0uH53e2dW/Vvf9czecERN0vD47hUV2AH8khHADmExEkQA+IKIJQog9MrIkrMoneBcl61qYdpN15LPC6Z6KLbn34fnzLHD7zXZeoxEhdNLkz8O3bL6m0uUKGdA6jIMHDyIkJASJiYko7Tk7BQBmz56N2bNnAwA++ugjzJ8/H9u3b0dxcTGGDBmCuXP713vxkFI9cQ7SW62wSHvxspBtBAABCS1KSAntMPqe3xRVf2C36uke0JTQcJsNH6SMPO33LgoLw0WnLEp+KN63pUkC8Pz1KqWoIkbamkO/Z/OI4lerajqnuVzzDbidCuBPAC4y4F6DHo/snIUQogHAagCXSozxEwDnGnInInU7zZx3B94+VIzUQkPu6aeIxNBp05c1qWrXgFoRlJWV4cCBA/jTn/6EJUuWoKSkBEuXLj35/crKSgBATEwMdu7cieuvvx41NTWoq+vnrAwherOlSOpJ0EQUGmaJkrJImZRwt4z7niSEGF20JFlqhj5aM4Hy1o5XuNA5nVOad05zuTIMvPOFcEZcY+D9zrYJZzIRbSSifCLaSkQzjcylNy52voGI4npGdEBEQfBW3ftlZElYlR8O4H+Mvm8nOcY+jv8Z8TJ+nuuBIvfFRCJVdY+dNv2jAsDT77+Diy66CA888AB++ctf4rrrrsPIkSNx7bXXnvz+qlWrcMEFF8Dj8eBEM14iQldX/zsf7FePjnHD49uKVR/FOoZXyrgvqdFSt/Bau1p2hLZVnn5oxo9URWLji9/lBcmnYxHiyN+qa3e/VlUzzy4wsPlB3zwPZ4SRi+zPtAnnfwE8KYSYDODxns8DBhc73zYUwCoi2gVgC7xrdpYT0TVEVA7vKMsKIvrcgCxPoo8nJWuOyJZHF8y7C2/tK0dSqZQMfsBub5sxcdLKtVpec//+/UhMTERYWBgcDgeSkpLw0ksvgYiQkJDQ7+sJwtAdlpLNWmbsr/igZCkL3BUlSupheCNLP5FaZPZFp4rih25XeW3IaZyleaeRRgF4wKibnWkTTs9HeM/XIwBUnObHTYtOvKtk/iVhVf54APnwh3VVQrRdihVbb8abc3TYlWAKFUfHrikuntm/BTUGUgSV3uq6IJlAUt7ANHXWrf/06D8GcqKsT2xhPypULAkD2vLtM+Gpnr/mvhhFeOT/jp6BABofXKjWl8dRiuws/kQRovp3x+rK+tjTyggtAMbC2WhIgUFEKoBtANIAvCiE+A0RZQD4HN7neAXAeUKIw0bkMQKP7PivP8AfCh0AIAr+jK6c+zO8saMG8Udlx5FhaOKB84cMKZI6enI2HhIpe9Uj0nYNhljCpRzsR0pEnIz7AkDssd37/bzQEX+/UjnIhc7X9bN5p1FCATxn1M2EEO6e6aokADOJaAKAewDcL4QYDuB+AK8blccIXOz4oYRV+XMAXCY7xzc1UcTU+/H3sKW4XtNpHTMggjJ6zIbx4eE1fnGQ3+lstRRLO6RMIcsIgtL/BUe+aSclSE7LcyE8o4vfT5Ny7z5an0FrcjMVf3pBl2qAzTuNdDOcEecYecNvbMK5BcCJXRTvAeAFykx3z8oOcEZE4e/TDef/Ai9vrkek1J5IRiNCyMRJX0TZ7S1SFuP2pps8YwuVSil9z4jIGmmLLzX2roq0dhl2V8O2oI66YbLu35vacGz689WK3067Gs3H5p1GIQB/gTNC16UCZ9mEUwHgxCL2BQACakcuFzt+JmFV/mUAzpedozd1FDfzXrymfIHLNsjOYiQikTBt+kfNqtrll33FNlgPSmudEO8YbmzxS7Z6Q+93ilElH8u6da+6VBz61e1qxsnTLAcz7Zp3GmUmgOt1vsdpN+HAe3DtC0S0E9433HfqnMNQvEDZj/QcILgVPjb7NFqiKF//BB4ZF4oWOVMKErhcQVs3b7p2CqD4Xffi73RO2pXsiTW8HcDRtsLctdVLDdveTEr0OnvET2cbdb+T9/W4y+evuS+RIPzuzaIAmn59u1pXFk9+vx1ebxFud/47FdWxGve0MsJeAJlwNvKLs4b87pd1kLsOJit0AKCCks67G290rMVcqYfbGclub58+adIX62TnOJ211gIp26EjbUMM3QZOSrjRa4QAAPE124r9tNARr1ymFAz6Qke/5p1GGQ/9R3cGHb/7hR2sElblK/Ceq2NKgtSEl+i+6Y/hubx2OAZ06rDZhEfUzk1N26Rpl3QttFHn9GpqMPwgzCA1JNHI+5Eaafw0jRBdaYc+NPKE3T7bPJbW5ExWDF3g6m90bt5ppMf0Xrsz2HCx4z9+AMAvn0T74xCNnnMXsuq3Y9pO2VmMMHTowTkJCYVSG8WeTq51n+Hd0AnKMAtZDSt0SYmyGXWvE4Laa7fZOxulbLM/m7owbHnhmkG8INm45p1GmQDvSD/TCBc7fqBnVOcx2Tm04ibL8Bfw28xn8XhuJ6zSGzXqiQhK2uiNmeHh1X61Jb2J2mcep5YSI+9JRBRtTzTsEDJSo8N6f5S2Ug8tk7YA/Ey6VJQ8uFAdM1gXJNs8ovityprC52vr5lv85WwybTzOozva4WLHP1wHYJzsEJoiUvbSpHl34u2jBRi3T3YcPREheOKkldF2e4v/HK9OUHKtew0/ADLekXzcqHuREmnouULk6S6JO5Y/2ch79kYAzQ/fonraHBQhO4vhhPCc294uo3mnUXh0R0Nc7EjWswPrcdk59NJFttSn8dSYP+HXq7uhSllQagQiMWTa9I9a/WlLeh21nNNM7YYWYHGOJKN2kHhICTN0Omlo5YYyf1oHIgDx2iXK3sNDKBCmbfrlRPPOV6tqZTXvNErAjPjLxsWOfNfBu/o+cBFZttCs+Xciq6gEI4tkx9GLqrpHT5++7ADg6ZadBQBAsOZa9xl6MFi4LdagqSU6RqQYN2UhREdqyceGb+c/m62jac2XU5VZA/nZAw8eQOGjhSh6rAhFTu+vZNW7VSh8tBDlr5affFz9unoc++KYNoE14ifNO42SCWfEFbJDBAIuduR7RHYAo7goKONR/GH4q/hZrgfkkZ1HDzZ7+/RJkz9fLzvHCVXUMKMdnYa9WtmVoOHG3MlSZ8x9vEJaK7ZZu1v9psXA8VBsff77yhxfrjHyNyOR9rs0pDnT4G5zo62oDaOfHg3hEeg40gFPpwcNaxsQsyBGq9g+UYSofqb22Jb/VFTPCREiVHYeAy2WHSAQcLEjUcKq/PkABsO7k68Q2XPpwnl34a09FTBuMes3ud0Cd91VjkcergIAvPZqHe5YWI7nnvuqA8HKlc1Y+n5jv68dHn5sbtrojf6xJZ0QnGct2GvY7YhiHWqI/icpKw5DpwvTipf6zZqYbgWHH1yojhakYYd7AkS3gBACokuAVMKxT48h5uIYkEX+zJ2fNu80yvlwRhh+eGag4WJHrvtkB5CljUIn/hp/iX0HP14j4/4fLG1EcrIVANDS4sHevS689o8keDzAoUOdcLk8+OLzZlx1dfiArp+QUDgnYejBjVpmHqgy5djkTnQ3GXW/WPuw8t4f5RuiUMN2+SnuzoMx9fsnGHW/sxFA66M/UTtbg3xckExA6fOlKHqiCMdXH4capCJ8ejiKHy+GNdYKJVhB+6F2hE8d2P//WjFB806j8OiOj7jYkSRhVf5IAFfJziEVUcgK+t7cn+Ef22oRZ1hzzdrabmza1IbLL/c+kSsK0N3zrrbT5YHFArz730Z875oIWAb4rpYISlrapokREVXyd6IRIjZYDu4w6nbxQcm6F1akRhg2DTrs6Joqo+7VmzcvVnYdGkqjfb3OqEdGIe3JNKQ8mILj2cfReqAVcZfHIe13aRh641DULK1B/LXxOJ57HGUvlqHmI+N7rpqkeadRroAzwi8KbrPiYkeen4P//gEAjRQ17Zd4KXgZrjWk/cLfX6zDHXfG4MSpJMHBCubMCcHddx1FQoIVISEKDhxwYfbsEJ/uQ4TgzIkr4xyOZt1HOnpTqFaO64bbkNGQGPsw3fuFKUq0Ve97AACEaBl5+JMphtyrFztGUe5n05VztbiWNcr712cJtyBsahjaD7Wf/F77Ye+f7Ql2NKxrQPKiZLjKXXBVubS4de/M17zTCATgN7JDmBm/2EqQsCo/BMDtsnP4FaKId+mm2b/E3zc2IFK3BbUbN7QiMkrFmDFfPxvuhzdE4pVXk3D3PTF468163PLTKHyyoglPPVWNf/5z4M21iRA3ddrHHaraadg00umDIG6rpXizEbcKs0bpPt1AarQhfbjCmw/vsLhdhh9e+E31Idj23A98W5B8gsflgbvdffLPLXtbYB/21e9DzdIaxF8TD9EtgBPjZwrg6dR/MC3C7c5fUV7ZeG9Doyb/rgHmBjgjRsgOYVZc7MhxCwC/WfDoT2ppyKyf4zVk4zu6rHfZs9eFDetbcdOPyvDM0zXIz2/H75/9aoi+sND77jUpyYqVK1vw+ONDUFrSifLygR8RpKrutOkzlhXK3pK+Vy0f5TEgg4VsIwDoet4OKZGG/P6MLloivTVEt4IjDy5UR2m1ILm7sRslz5ag6LEiFD9ZjLCJYQib6K3nmrY1IWhkEKxRVqghKoLSglD4qPf0gqBkHetL8zfvNIIFwB2yQ5gVCcFd5I3Uc4hgAYCxsrP4uyRRtu5xPDohBK26vLDl57fjvXcb8cyzCSe/9sjDVbj/gVg4HIRHHq7Cn/8yDM88U40bbohEaqpvnQKam2Py8ndcLvUd6/SuUWsnu0eer/d9Vhx59UhLd71u29DtkYuaiOy6rp5Vu9v3zlv7K6lnYAmg7ZGfqEeKhlHAPl8EezwFWZXVtgDpaaW3CgDJcDa6ZQcxGx7ZMd4l4EKnT8opefbdeLNtA2ZvM+J+69a2Ymy6HbGxFoSGqhg3zoGFC4+AiHwudAAgLKxuzugx66VuSd9hKR0qoP87nDjHcD0XnLfoXegAQPKR7IHPX2rk/xYo+QFb6ARe804jJALgQwYHgEd2DJawKv9TAJfKzmE2aeJA3m/x5FQHXL6tGpZMCIjiopmbKivHDujkWy3M7hq7KcOddI6e9yht2bN6U+2K+fpcXS1xRN03Up9r9xCicV7e/TbV02XI2qDT2ZVCuU/fqM6TdX892Tyi+NWqms4A7Wmlt+VwNn5Xdgiz4ZEdAyWsyh8L78gO66ciGjvnTrx9LB9TdsnO4gsiUGra5kkREVWGHfT3TZstRbovuI22DbXpdnGyNeh27R6RDYX5MgudxmBsf/aHiu7TjYYL/OadRrgMzohhskOYDRc7xroXftRI0GzcZBnxBzwy4Tk8mtsFi0H7YLVHhKDMiSvjHY4mKVvSu8g97pBSvV3PewRbwuP0ujZRcJte1z5hTNF7BrW9+Da3gvIHF6ojPArpvoXfSIOoeafeVAC3yg5hNlzsGCRhVX4EvLuwmC+IlN00Zd4d+L8jB5BeIDvOQBEhbtr0j12q2tn/fhQaWGc9oOvvvkqWFIKiS5d7UsN13VFm7WrZGdpaMUrPe5yJANqfuEltaQoh/2hIpZFB1rzTCLfDGcFvnPuBix3j3ARgMDWv01UX2dKewtNpf8X9q91Q/KPLeD8piid1+oxlxTK2pLuoa/JR5fgeva5PRNZIW1ypLtdWonR9kh9x+HPdR47O5J35yvaDSZQu6/5aG8TNO/WWAuBi2SHMhIsd4/CojtaIrBvp/Pl34u2Dh5FSLDvOQNhsHVMnT/l0g4x7r7Hu0/VFPd6RrEtDUFKjfd8adybCU5t0NHeabtc/i73JWLPsXCVgGj4O8uadRuAzd/qBix0DJKzKTwcwU3aOQNVBQeMexvPDXsdduR6QYT2TtBIWdnzOmDHrDN+S3grXjFpqKtTr+nGO4Z16XFdRonRbYB1zfN8+Rbj1W1x9Bs1ByP/djWpA9IDi5p2GuRrOCOmHXpoFFzvG4FEdvRE5cug78+7Bm7srMfSI7Dj9FT/k0NzExP3GjvAQKNe6V7cOj5H2+GA9rktqZLQe14UQntFFSwxfq+MmVDywUB3mUchi9L21xs07DWUFv7b0GRc7OktYla8A+LHsHINFC4VN+hX+GvUf3JQnO0t/EIFGpW6ZEhlZqds6mtNpoLZZDdRapse1g9TQoTpc1g0K0WWnPHcjfQAAIABJREFUl62zcXtwe62hu7AE0PHUj9SGxlDSbfeaIbh5pyzcY7GPuNjR30UA+EwEIxGFfkzXzlmE17bWIaZKdpy+IoJjQuaXQxxBTcaNTBHUXOu+w/pcWkmykLVF46vWECm6bMkeVbrC8CnQd+coWwuSaZzR99USN++UaiycEXNlhzADLnZ0ZilouJBau6WcpzLYNVD09F/gFcdyXL1Odpa+IkLctGkfd1osLsO2pNdS08xWdFRrfV0iomj7UI0LKetxba/XQ7grh1ZuMHRh8v5hWPP++SY+OJCbd/oLXqjcB1zs6Chl8YpgS1nrz2xrq4fZsyt2WQ425qHTo/vpr+wURJH/pp/MfgB/29CE8DrZcfpCUTyp06YvO0Tk0eWcmm8h2NdYC/brcel4xwhNixNSHBqPFHnF1+YfJAjDDvFrdmDnkzep5xp1P60FezwF71VUHX20rn4e8UGpsl0HZwQvBO8FFzv6+i6AUAKIusVES0nLHPuqymDbmqpNalnLRriFaU8BNptqGnruz/C6ZxUu3Cw7S1/YbK4pk6d8ssmo+x1Vjk/rQKfmjS/jHEnaNt9Twjo0vR4ACNGdVrzUsGabbkLlg3eoiW6VrEbdUzPcvNMfOQBcIzuEv+NiR183fvMLBNiUdvc51oLGWfYvKzpsG2rylJr2neCOrLoTpMT9g34287d4YW0rgqWcXNwfoaH1548Zu9aYLemE0HXWA5r3HQu3xWq6TVxRIjX/PXF01G1zuBoStL7u6QjA9cwNyvEGEy5ItnlE8VuVNYXP19bNtwCm3zkWYL4vO4C/42JHJymLV0QCuOxsjyEgQmnqmmPbcXySfWVFhXV7XS41dZrycDwzKaOU8+/GW62bMUvX/lBaiI8vmZs4rGC9EfcqUWomdqFb02kiuxKk6e4mUqM0Hw1JPfSRYS/c78+mzXtSlPFG3U8T3LzTDC6CMyJCdgh/xsWOfq4F0OfDyUhgmFrbMc++oTbV/mXFAcve+lx0uDVfNMq8PKQm/hm/mvIknl7jgl1ae4DeEIFGjdo6NTKqYrf+N0PUJkvRNk0vSRTrUEM0O0mZlGhNz+4hT/fh+NptU7W85pkUJiLv3bmqqXYscfNO07ABuFJ2CH/GxY5+fjDQHyS3GGspb5tnz62Ks6+q3K4WN61Dt6dZy3AMABEdpIy5dyKrZjcm6l9MDBARHBMmZCcGBTXqskX8VAfUo2Pd8Gh68nGsfZhmuxFJjYzU6loAkFC9udSIBbatdux+4mb1HL3voyVu3mk618oO4M+42NFByuIVoQAu8PU6BCjU6ZlqLWqebc+uVG1rq9crR1u3wCNM2fjSX3WTNeU5PD7uD/jt6m5YdGlx4CsixEydttxjsbh03c0nCAnbLYc0XRgdH5TcpNW1SAnX7nh8ITpTDy2boNn1zsBDqH5woRrfrZLhbSgGgpt3mtalcEbocmp5IOBiRx8Xox9TWH1BQLDS2n2ebU/DDPvKigbbpto1Sl3HXi3vMagRqfk0ff4dePtwIcYckB3ndBTFM3L6jGWlem9J362WJXsg3FpdL8Y+TKst3Y1EthCNroXgtuqttq6WGK2udzoC6Hz2B0rN8XAyxanC3LzT1ILRyzrRwYyLHX3oOndKQKzS0DnXtrVuvP2Lo6XWncdzqaVL9ymOwaCT7KOdeHbUi7gv1wNFsxd8rVitrsmTp6zQdUu6h8SIvWqZZvcIs0ZpdAaIekyb63ilFX+g+6jFR7No065RSqbe9/EVN+80PyHQVewZaqo1YUbiYkdjKYtXEIDLjbofCaSoVe3z7OtqRtizK/ZY9jeugcttisPz+ku43ai78wbUP/wLAEDzq39G3cIfoPH3j558TPsXy9H2/ju+3YjIup7mzrsTWfuPILnEt4tpLzS04fyx6Xm6bknfajkUJ6DNcQgWso0A4Pu1yK7ZFJ7i7iyKPb5nolbXO53iBOT96wL/X5DMzTvNSwg0H/IkbHi260frJrlebbuw84WfpCxewccCnAYXO9qbDsCQMzu+ibrFBMvhlrn21VXh9tVVW9TSlvVwi3YZWfTQtvQdWJJHAgA8Lc3o2rsTMf94F/B40HWoEMLVgY7PP0bQ1ddrcr92Ch6/GP8v4S3cniu0eLHWUHx86bxhw/bptiXdTZ7RhWrlFi2uRUShoZYonxcpkxKi2f/LiZVrK7S61um02bD3sR+rM/W8h8+4eacpuQVVbfekrbmvc9HWMa637Qs6/9+5r7qvnN2E0AgAUQBmy87oj7gC1N4VsgMQYIXLPcN6oBGWA43NIsyyrntUeLBniGMSiExZ4Lprq9G5cS1CbrodrUv+CSgKRFcXhBAQLhfIYkHrf7MQdO0N+P/snXd4XFeZ/7/vuffOjKaod8kqttyb3OIay+lxChBIlrD50UIILLsQSgADIQTYZcOGZYFll93sprPsUhJIwCQkgVjuvXdZlmzJktXb9HvPeX9/zMglLmozap7P88wzmlvOee9oZs5730p6DEuxECW9hTsqtvCKvd/BmswcNI2aHkClE3ct8PtT9nd0FMTFQrFVr0qaIvNjMlaWY0Kj19sxpJo7JFJiE5jP7C+t+WPcMowUoeVLD2nplk72eM0xVFKk3PuLhqbMIsuKqeWp5Ec98NgJGgG6AHY+7MZX3wri9RMWynM1vHhPEgDgpX1htAcYjywZtW/RqCLIxokNanb9M3J19lY1YzpAV7uhvhPA8BQjHUOMyYVvlDOqah0Q4BE91nLbvvZ59jcbmo2drZXUGT4+0nINlJ5/ewruTz0CiMhHVjhdcKy8Ce0P3w8tLx/kcsM8ehiO5UNOgrssXkou/yL+LeU3+OCGuEwwCIhgnznrLwXxSkkPkzX7lGjZF4uxspMmDLmWEYnUmPxeub11uw0ZiEsBNgbM798rGtpSKC8e4w+ZYWje+c5Hndj7aTd2PuxGV5CxuV5i/9+4IZlxoEkiYDKe32fiM4vGRHLaiMAM1cmufb+wbqy8KfTUqWmhF8o+aT66aquaOQOgvkoljKo1aLQwbiw7RKQB2AngDDPfRUT3AXgCwHQA1zHzznjLULJmbR6AYSlQNhgIyNXaQrlaWwtYoErmOhtkmWcyJ+mxuX2PE6Et6yFS02FMmYHw3vP/Rtf9H4Pr/o8BALp+8G24P/438K99BeGdW6FPnAz3h2PcDJjI81v81fWVfOOOb+NrReloH3HTfzQlvXvb1g90WJYj5oGlG42jVnFo6J0N0m15Q17ZSEuPSVG7ySdeTo/FOJdj7SLasqdMrIzX+EPBqdSRFxqbbNPCZsVwzSkICEsGMyNgAoYGPLU5jM9dZ4OhJfqHXggzAmeQuf9XVoX5c3nz9HakDNb6OL1kzdqJtU/eeTKmAo5xxpNl5xEARy54fRCRIkvrh1GGOzFGOgCTwmS9wV9hW9+UZ/9L4z69qnsjTDUq+0WFD+5FaHMlWj50B7q+uwbhPTvQ9b1vnNtvVkUaduuFxQi++QekfuufYNWegFUfnwS1dspc9Fk8bXsddw1LG4e+iKaknyaSMa8RFKDwgrPUeaTvI6+OU08essYktLQh99nSrOCRtK4TM4Y6zuWozcbGF2/WRp+iM4zNO4mAW1/yY8HTXjy9KwyPnfCB6Qbm/acPpakCKXbCjgaJ904bez1Q44Fiaj2kijd+1Xxo+/TQc1gR+snin8gPrGhHylBLIiSsO+9iXFh2iKgQEUXjHwB8EQCY+Uh033CKMuLxOgOFAIKp5uone6Cd7AlykrZVlnqELHCWQ4yOImieT34Onk9GMrDCe3fC96sXkfL1fzi33/vcvyP5i4+BpQUoBQAgEuBQ7Btkn4Mo7ef4+LK3+bYt38LXpyajJ27Wgv5gGOG58+b/cdPuXXfHPDix0jjc9cHw0BJ1NNJLCMJkqEGvciRSMockBIAJ9e/ENH29l4ANh7/xUW1hPMYeCjbF1U+fbQ4vCIVWDcd8mx50Id8j0OxTuOUlP6ZlCnxluR1fWR6JzXnotQC+s8qO/94dxpvVFubkaHhs5bUVtxNm7dRWNaP2Wbk6rVLNmcUQK+IwzZ0AfhKHcccs48Wy8yMAXwGgRkqAkjVr7QBuHqn5YwEBDhGQS4zDndfZ32rw2bY2bxAtwQOjuSN7cOM7MKbOhJaZDeH2wJgxB22fuA8ggjFpatznP0v5Sz+DZ631WBWTzKWh4HJ1Lp82fX3MAxN7KLC4jXqGZBInIiPVllU7hCFMkGtoyg5zV/HpN2PuZlZA66Of0FJNnUZP76gRat6Z74ksKdkugXum6dh+5nypqj2Nkb+nZAi8uM/Er+5z4mCzRFXbqCtnFVOYwT2cdOgVuaLyjtD3qqeEXir+iPm1inWqfA73BiHGnoqSNWsT1ZQvYMxbdojoLgDNzLyLiFaNoCgrAIyb0uoEpFGXeb1tdxuYUKeyHCetsuQi9hilIymXrXwhbOXnb6AdK24AVpwPSvb8zReHXSYmkf2f+Gz2n/iODY/hW+VJCAzZ3TJYsrJOVXh7Dm6qr58VOwsPgSqNw43vDy+eOJRhsh1FLR3hpsmDFKIpasEdNCld1fs0FY6pm4kB6wcfEPUtqVQey3GHgs5c96OmlvaKQHDYYnMAwBdmKAY8doIvzHizWuLxivNWm2++E8LTdztgKkBGb58EAf641gMfGZgRbkbq/lfk9f4XrVunNCJjuDvd2wFcB2DdMM87ahnzyg4iNQXeQ0R3AHAASCainzPz/xtmOVYN83zDBjEmaM3BCVpzEKzREZnvbLEmeabDrg09cnUcUUuTrn+YX6j/PJ6qXoAdI7b4lZTuWeTzp+7raC+MWXp1O3kXd5O/Ppmdg1Y4shwTwse6B2kAI1sHgCEpO5NP/CbmGVJ/mk+bd04ZPQHJM0OhDc80Ns9zMQ8pzX8wNPkY9/wyknRnKeCvZxm4vSyyxPzuqIlF+do5y8/SQg2zf+bFnByBubmx6iYysjCjq4oLDv6PvEn8RlbM8iFppN2ay5BQds5Bo9hDMWCilp1HmfmuC7ati26LazZWyZq16wGM+mqpsYIBCbvYaxW5Q7LINRe6iFnPojEPM0/HoQ1fxj8ssiOcNDIioH33rru7/f7UkliNmaNSKu8OLxy0tcBndW3/Q91/DKrQHonULfaUB5cOdm7d9B9YuenLMW3bUJeJTV/6pD4qCrgJ5qbvtradTvS0Gl4sFmd28ZQTz1m3ed5SC+dIaKPJgPDH2ifvHHNxpPFivMTsXAIR3UNE9QCWAlhLRH+K11zReJ3RXS01xhCgUUgtMKq6l9n/3AjbxqbNosG/Cxy7BpJjFiI6QrNWPowXzx7CrBFp1kqE9Hnz15KuB9tjNWYTdV3nR6hlsOcnae5BW1ZIeIaUaVZ8+s2eoZz/boIGjn7tY9qoKDORaN45vPjZfmytXLzu/aEnjpaFfl7wwfDjFW+oxfNHmaIDAEuj7YsSYJxZdkaKkjVrVyJRsRIAwECLSrcdsSYlZ3G6fdgCI0ctzHI+dmx8BD9YpkMOe76tadr2b9t671RmLSYpL0Uyc92t5txVgzmXmfmVU//is9gccGybZptdabhuGZxVibl91frPuwRbMXkPFND+yKc1f1Pa0GKIhgoxd3y5vfNIoqdVfGGG1Q7Pgdfksu7n5O2TTnPOqKmi3g9m1j555+GRFmI0MNo00bHKsAYCjmYIyNLaw1laeytY4KTKSaqzJiVPYpc+ln4gYgeRthvXVXySXzz2GB4Xk1A9yADdwWEY4Tnz5q/dtHvXe2LibjktWueFYHbZYQy4AjERUbo971Rz8PSAgzVJSxu0opjeceSAYCsm31EG5L/cI2qb0mhErTrZlrXjFw1NRTlSJhSdOMAM7ynOOfB/8gb1v/LGmV1wzxtpmQbJcgAJZQcJZSdWXDOxOgOBFCZqjYGJojHA0OmALHR1WqXuWbBpMa/0O9oJk2Pq4/z98PVYt+5h/Pv1AmrYojJdrq7l06ZXVh49UjH0BZ+QssU4XrnKnDmosbIdxR3NwdMDn1akDy4mjJknn/hNyaDOvQx/LqeN26aJkbu5Ye55uLN772c7uxK/OTFGMjUf4InHXrBuTVqrlswOwxh0jNgoYjmA/xppIUYDCWVniJSsWSsALBlpOUYzBBAsnq3XeqHVesNwaNutUreSBa550EZvs8SYQ2TbgBtW7eLrDnwLX/cUor5kuKbOyjpd4fUe2FRfN3vIFp4T4uzMFZgW0KENOPg6y1EwqJgu0lIHpSAbZs8el78pJlaYMxnY/PRqbcQUnXg177yWCbFRvVHNqntWrs7aFOk7lT3SMsWYURFAPxoYtwHKw8gsACNWV2WsQYCNgvI640jXEvvbDUHbluaNojmwbzQXLow1fnLN/ip+lP0SPr6egWG77pKSvYvS0+v2DnkgQuYOvXpQOeTJtszkQU0pkge1CJXW/jEmLTRCOo599ePayJQTGIbmndcKzFBd7Nz/f9aqdbeGvl8zNfTCpE+YX161Sc2a2Y8Gm2ORspI1a8ebAjcoEpadoTMeTJ0jAgEp1G2usO1pBxMaVIa9ypqcXMDJtrKRli3uEDnfwF0rN/P1u7+NNTnZaC6I/5SwzZi5rnj3rrtr/P7UIRWHPKzVT1pslZkCYkCxNHaRNJjFup1IH3g7DlZN+Y2bhlzrhIGOL39Cc4YNGvaKtCPRvHO8wYxgAzL2/0auDL9k3TK1FalzRlqmYWYZgN+NtBAjTcKyM3QSyk4MIEa+1hqqsG9pKbO/1XBcP9RRiaB1dqTlijfdlDL/C/h3zyu4b+NwzEeEtHnz1wrDCLYNZRwmLtirndo28PlFlkNzDbA/lT6oflaZrfuPClZDuqFjQP7ofeLk2XQa3iJ9w9i8czyimNqPqKKNXzcf3DYj9JxaHvrX6/7Fum9FK1KvxUKoCVcWEpadWJDIhogxpHiKXu+fotX7FWxij1Xk8sti9xzoYny6C4mSX8b9K9bxTdu/jTWlaeiM6w+yEKp4wcJX92/beq97KCnpe/Wa/HmyRBFoQDdNGfaCujP+4/3vc0X27gELxywnV7885My3dXNo45bpwxuQPNzNO8cLJmunt6tpNc/I1anrVPksFZ8Gm2ORxBqFRJ2dIVGyZm06gCHdISfoHwwE2KnvlRPdusxzzoOgcamoE6u2j+DZ47fi9bhbDP3+5M27dr5n6VBiFZaaU7bOlBMGFKBf1bVr/e72t/vdYoG0nA325AcGFJRrD7ZvX771m0Mq9NmYhi2PfFofPssts1oaDG7416aWxXbG6GkqOkphBvvgOPKWWtD8rLW64ABPHNayDmOIEICU2ifvDI20ICPJuFwwhpFrzfc7YhCQRH5rqTjYCf1gZxun2g5ZZZ50leGYNdKyxRImkfECHlr6Ft+26Vt4bKYb3tR4zeV0di+bPqOy8sjhVYO2XOzQq1NmyoF5eDIc+QNSrkgkDziDa2LN74fkog/pqPrKg9qwfb9HqnnnWIMZ4RakHPitXOF7wbptcgMyZwCYMdJyjXLsABYC2DTSgowkCWVnaMS0106C/kFABnWGV9p2toEJp1S2o8YqSy5lt1E80rLFigaasPzT/OzZT+OnO1dgfdwaCmZm1lVMKNq/se70nEGZ/C2S06vF2V2TVO6C/p7jNtIHFGxMWtqAahKRkvW5TTsGnW7OQOdXH9RsIRsNS7+3kWzeORZgRlc15x36hbwZv5IVs7xw9vuzluAcy5BQdhIMgXFlVRiLEKNYawoWa01BsE6HZL6zzZromQG71v+YkFEKk5b7MzyS+ye+Y8PX8cS8JAQH3GahPxQX71vs96XuaWsrGlSV2M3GMX1SKLffxxtkK0Yk5b5fFh4h0gdUzyeneWc1gQeVos2A+und4kRDBsW9Y/UFzTsTdXPehcWicQ+XVT1v3e76k1o4x4KeiDsZGnGtBUdEDgDrEbEi6QB+w8zfIqJfApgaPSwVQCczj0gJh4SyMzQSlp1RBFk8Uz/tg3baZ8EudlglblNOcM+DRiPSeTxWnKTJ13+KX6j7PP6pej52zY31+EQwps+oLN2z+66TPl/axIGeHyJrbr1oO1CoMvr1fSAit1tPq/daHf1SSEhL639tHmZz0snfDdqtsWEmbdgwK/4BySVhc8tLjU3TUpVKNO+MEmBbVaWae+YZa3XODp42HcCgG8cmuIR435iHANzIzF4iMgBsJKLXmfmDvQcQ0T8D6IqzHFckkXo+NBKWnVEIATqF1CLjWPcy+9sNlm1T0yZx1r8bzGqkZRsskvQJ/4yvzf4eHq8MwwjGenwipJbPW6sbRmBQad4bjCMDkinLUdjQ32NJpPTbSpcUaNlpD3cPKputKRVbf3q36Hfg9GAg5vavtHVs+f2ZxqWpSl1zbVMuhBmynT17X7RuqVwV+ue66aHnJ3/a/MKqqKKTILZMKlmz1havwTmCN/rSiD7OZT8REQH4KwD/Gy8Z+iJh2RkkJWvWFiNROXnUQ4CHvNZy274OMDrOqgz7MWuSJ5fT7FP7PnuUQSQOYW7Fw/xi9Vfx3dB0HI5pYKYQXLRw0asHtm69181KH1A2kI9Ci5qp61g2p/Trfc12FAVqvAf6c2iQhLPfMT5lJ387KCteWEP1lz+hzQLFr4puTqR5Z3G2lNdsbS5m+Oo4+8Av5SrrF/LGGR1IHpmq1NceGiLupH596QYDEWkAdgEoA/BvzHxhHa7rATQxc1W85u+LhLIzeBIurDEGAblaWyhXawuBBU6oXOcZa5KnjJ163KsXxxKTbJP+nr9jLcLWdX+Hf1muQw66I/i70XVz9vz5aweVkl5pHG67L9y/dTzdntdPmUUzgKL+HEnKrMlq3T/gxZOBrjUf10TQRnGJibrWm3dKppZDXHL0RXmr4/dy6ewQbIlegiPDDMRR2WFmCaCciFIB/JaIZjHzwejuD2EErTpAQtkZCgkX1hiGFMq0Bn+ZaPAzDLFPTnB1WyXuOTBEykjL1i+I9B1YuuphLj/yTXzTKEVNzFpsOJ3dy2bMXFd5+NANA4pd6SL/4g7ynUpjV59ZcU49uX+uJrJ1oJ/KTn7jltMABtQGgwH+2Z3iWH0WDakmz5W4Vpt3hliv2axmnnpWrs7cqGbNYIhr6vpHKcOSos/MnUS0DsDtAA4SkQ7g/QBGNIsuoewMnoRlJ0awkmh84QvQPRnIvvdb6Fj3HAInd8GWXYrMu74EAPAe/AtUsAfJC98b07kJIJhqrn6yB9rJnhAnaVtlqYdkgXMeBMXNxx0rQpQ0/TF+KlSBv1Q+hJ9dL8AxicPLyKivKCret+H0qbn9X6QIWqVx6PT7wtf1qexopJcQhMlQV7XwECX5+jU3c3Bize8HHLy9ZRqtXzcnDgHJzMEP9ni3faOtYyX1M+tsLMMM7oHz4BtyUfszcnXRMS4qxQAVzwRxJ27KDhFlATCjik4SgJsBfD+6+2YAR5m5Pl7z94eEsjN4EpadGNGz8zUYGRPAYT9UyIfQmSPIf/CnaPn9Uwi31EJPzYPv4NvIvu87cZWDADsF5BJxuBP64c5OTjG2WZOSU1SmfXY8YzmGDJG9EjdV7ODF+7+Nr6XkoyEm9YaKivYv8XnTBpSS3ko9i70InnXDcdVcdCIyUm1ZVR3hpqtWvSXhMfszr8vXsMuw/APqAdSSjO0/el/sA5KvleadzAieRfqBl+X1wRetW6c1Iy1xAzi6iadlJw/AC9G4HQHgV8z8h+i++zHCLiwgoewMipI1a3UA00ZajvGA1d2KwMkdSF76QfTs+B0AAksLzAy2wiChoXv7K/AseA9IG76PKwGp1GVeb9vdBibUq0xHtTU5eQJ7jAGnZg8XfnLP+TL/xHcnXl3/13hpyIt4NCV94p7dd1b7fOn9a0ZJsK03Dh+7w5zfZ+GdbEdRS5/Kjta/hKXJ1a8MyP1oaqh59BPatJgqsczWbT7/xidb2lbo4/S3VTE6jvOEwz+XN2uvyOtn++FIpM6PHSaXrFmr1T5554ArkvcFM+8HcNmbImb+WKznGwzj8gs5DEwBMOpdHGOBjj8/jdRVD4LDfgCAsDvhnLoMjc9/Do7iuSC7C+HG40hd/qERk5EYhVpLsFBrCYI1OirznU3WRM90OLTsERPqShC51uJ9Kzdyxa5v42v5WWgZUq0SIqSUz/tj9/ZtH2gxzaR+xdk0iI6FAYTbk2C7ahZVlmNC+Fj3jqvPL9L7/J4JGTqW3nG035ZWBnq+9jGNAw7qf/2ePhjPzTtN1up3qqknn5W3J/9FzZsloSW6aI9NDADFAE6OtCAjQULZGRyJhnMxwH9iO4QrFfbcMgRP7z+3PWXxvUhZfC8AoO31nyD1+v+Hnn1/QrBmD4zsEqQuu3+kRAZJnqbX+aZpdT4Jm9hlFbuDsshVDl0MS2uB/tJFaQs+zz/r+iv8YtN78cqQFicheMLCRa8e2rb1XrdSet+p3QTXJuPozpvNOVd146Tas519DqWl9ZkhVXimshnnq7ReFQb46dvF4dPZtLg/x/c94Phs3ulj+9E/q/lnn7FW5+/jsikABlWROsGoYxISyk6CAVAy0gKMB0JnDiNQtQ311TvBMgwOBdD6+x8g8+5HAQDhpmoAgJ5WgPa3n0buA99Hy6vfh9l+Bkb6yGaLE6AhrBYYVd3Qq7p97NI3WxM9NpWXNA8Rv/XIQ5TyKzyw/B2+eesT+HpZKjoH3UJD182Z8xf8YcvOHe9d0p+U9FrRMteE5TWgX1FZSdLcfVqdSKRe3Y/F7C059Ua/Y4q2T6H1f54Xm4Dk8dS8kxlmK1IOvCqXe5+Xt5XVc9Y0JFz145EyAG+NtBAjQULZGRwlIy3AeCCt4mNIq/gYACB4ej+6t//2nKIDAJ0bfo702/4OUBbQW/yYBNgKjYC0V4YAF/msZbYDHeADHS2cZjtiliVncrp9VHRjbqGcJX/H/9X6cfzX1pvw5qBrnCQl9SydOfOdykOHbuxsezywAAAgAElEQVR7cSekbtWrKq+3pl/xWIIo1MnwWmxeSSFiEp6cq02T3FO7R5ehfmWMtXmw44fvj00K9Hho3smM7hrOO/i/8kb8n1w1sweuQTdPTTBm6F/s3TgkoewMjkRKZZzxH98CW+5k6J4MAIA9fxoanvlbGNklsGWP2hhhEJBFHeEs+45WMKFG5SSdtsqSJ7JLH9FFkUlkPotPZb7Jqzc9jsdmueAbVD2h9IwzFcXFezecOlXep9JwXGuYtsyaGtIg7JfbT0SUbs871Rw8PfMKQ7QSaVeNE5p84uV+xU2ZArVfekibwkRDSs0f6807JYvGvTyp6nnrNucb6ro5ZqLB5rVGzOpxjTWImfs+KsFFlKxZuxdAzBsyJhi/sE4HZKGr0yp1z4KtnylGcUKwbPwMftywFJsGVeSLGdbRIyv3t7YW92kJmGMVb7jOKruiYnCoY/PGg50bVlx+r3HUkfbZK7pSNCtwqGLjo1dSlM7LC3jXfFw7W5NLQ/qhv6B555jqaRVko2q9mnPmGWt19jaePn2glbETjCsO1j555zVZIiBh2RkcJSMtQIKxBVk8W6/1Qqv1mnBo260St5KFrnJoNOxBrYq0vJ/ii3l/4jvXr8G3FzgQGlBwNRH0adPXT9qz544TPm/GVRWIg9rp4oXWJClw+TimLEfBldNgyd59tbGL6t7u6I+8z9wqDtbk0qDdd8Tc/uX2zmMf7u4ZEz2tmCE74T64Vi7ufFauLjnJ+ZORSKpIEGFiyZq1VPvkndeclSOh7AyUJ1I8J+zC74ejrpVTuus4y6zmfFRxQdJxVZhcw7lZ7UjJGGkxE4xOCDAQlNcZR7ugH+3qYo+x05rkcatsx9zhLlxYRVNXPswvnvoS/rF6LvbOGci5REgpL3+9Z/v297eYYecVXU2KuOiAdnrzXFl8WXdJsi3ziunfJNxXDs5i7iyqe3thX3LuLKN1by4Qq/o67kqMleadzPDXc+aBX8tV5s/lTdPbkTImLM/1P3sQwpYECAESGvI++qNhraB+DeIEkAugcaQFGW4Sys7AKdBJ5SXDn5dMfkxEIyqw/6IDmBEwoZ/thrOzidN8pzhHVnGBdlxNSKrm/PRTnJMTgL3PtNsE4xsCUqjHXGHb2w4mNKgMe5VVlpzPKbZhuwuXpBf/Ez+mZmNv5Zfw5BID1mXjay6HEFy4cOFrfaak79ZPZs2RRUyXcZ/YRdIVU5pJpF7R6pPWeXyfpqyrBkq3u7HzqXsHWSF5DDTvVEyth7n4yIvyFvtrctnsIOyxSacfZnI+9D1ozkgI2UhWUL+GyEJC2UnQD/qsN0GEJBus0kx0I5O6MROnLjlGMTqCsDd3wN3VwJnBkypXVXGh7TgXums4L/MMZ+YoiNGRwpwg7hAjX2sN5WutLWBBx2VeUqM1yTMFSfqQigL2b3ISBzCv4pP80omv4dvmVByd3t9TIynpv9+6c8f7Fl8pFkSSmnxca9w+VeZf0myTSGQ5NFdrUPouSYsXWtoVf58mn/jNVZuDWgKnHn1IKxtMQPJobt4ZZr12i5px6hm5Om2Dmj1r/DXYHB0V1Mc516TnIfHpGTgxKfAiCGlOhNKcCKGA2rBIHLtoPzOkhGj0wdHayik9EXdZAY5zQVKVKkyu5dzsdiRftUJtgrEJKZ6in/FP0c74FWxijzXB5ZPF7jkwRMwq/l4Ok2xl3+G/N5dg07rP4McrNKh+/T4kJXmXzJr158qDB2++oqVlq37cNVXmX3Zfhr2g7oz/+CXKDmlpl7UWGWHvXrevofxKczHg++ZHtLA3iVL7If4FJ46+5p3MYC+SDr+pFrb+t3VH4REunoTxFDNIhOZfPQ4AcJevhqf89lFXQX0cMuh6W2OZhLIzcIalmh0RNB0qLwX+vBTyYxIasepSd5nfhN7UBVdH1F2mqrhAVKlC1wnOTzudcJeNaQgQCKt5RnUP9OqeIDu1LbLUo8t8ZzkEXbVb+OAnJWMrVqzaywsOP47H7MWo7VddjrT0xoqSkj0bamvnXdbSYJKcWSua95ao7EuUlBxHUc8Z//FLRRFpl02PLzn9RuBqsjx/s9hfnUcDirEZTc07mRFqQtqBV+T1gRetW6ecRXqfGWdjldwH/gm6JwPS14mmXz4GI6NwVFdQHyckLDsJ+sXIlu69ACI4bbBKs9BVmkVdmIXaS45RTO1B2Fra4elq4IxAjcrDcS40qrjAc5LzMxo4I+EuGwMQ4CC/XCoOdUI/1NnGqbZD1iRPusp09Lsn1EAIUtKMr/MPgjfhzcqP4b+uF+A+3UGFEw4u9frSdrW2lFw2pX2jcVSVhC4ti5PhyL+sFYVEyqWBz6xaCs5UXjEwec9Eqnx90QAqJI+S5p3M6KrigkM/lzfTy3LlbB+S+gy+Hg/01tHSXKlwTlmKUMNxOCZEPtKjuYL6GCeh7CToF/1qhjhaEMTpToTSnQihkFpx3eXdZQ0+OFpbOMVbx9nhas4Xx7nQcUIVpNRwbnYHksdUXZHxDgEZ1BleadvVBiacUlmOWmtycjG7jZLYTkSOP+O2im28bN8T+Fp6HhqvWhiRCPq0aRsm7w14qrzejEuCrINkzm+kjsN5nHZRZWm3kX45d6yfhOMSy05G28HDgtVllZlOF3Z9/z5xhZo9lzLSzTstFmd28ZTqZ63bPW+rBbMltGuqwJ8KBwFWEHYnVDiIYM0epFzgrhorFdTHIAllJ0G/GFgcwCgn6i7LT4E/P4X8KEMjbsC+i45hhj8MvakbrvYmTgvUco51ggv042qCs5rz0k5xTm4Q9r4bRCaIOcQo1pqDxVpzEKzRYVngbLUmembArsXML+8lz9xH+V+978ErGz6IX1w1IJYIyeXzXu/Zvu39zeGw8xIzTqVxuPv+8MV9SQ2yFQNgXBQnI5rx7tgUZjW5+uXLutUsgbovPqRNVKIffclGsHmnn+3H/qLKG5+x7sjbw5OnYhRZiocb6e9Eyyt/H3mhFFwzKpA0MWIUHKsV1McI12TMTqKC8kB5ImUbgEuySq51FFNbALaWjoi7LHRS5akqLrQf50LPSZWX0YiM7IS7bHhgwIJd7LWK3WFZ5CqHJmIWt5XK7Tu/gzWFGWjLvdpxlqUf3rb1vhKl9IvnZvA94etOZrDnIqVlbd3T9V6r43ymIyXtdaT+zUXxPbZQ584VW75xiXuHAf83PqLVnSigPjufX9C8c1jq0DDDakPygdfksu7n5W2TTnNOont4gpHmj7VP3nnnSAsx3CQsOwNnXFl2YoUgznAhlOG6srvMkhBnfEhqbzmfXUbHucBRpQpTazg3qxOehLssBhCgI6QWGse7oR/v9rJb32RN9CSp3KRyDLE3VCelL/wc/2fnh/DSprvw6vIrHafr1owFC1/btmP7PYuAC+Yk0Drj0NkPhJdcpOxkOQobvN7zyg6R0/fuMSfW/EFdbq6f3yD2niigPl1Aw9W8kxk9tZxz8P/kjer/5A0zu+Dud1f2BAmGgYQbK0G/GFQDxWsdIug6VEEKfAUp5EMZGi7nLvNF3WWdZznNd4pz1XFVoB3nQufJSDHG3BBsw95eYSxDgJu81nLb/g7w/o4mlW4/apV5cjjNfsWeU30PSqn/i48s/wvfsuUJfH1KMrov++PpcPgWz5r9duXBA7dcFGPTQb7FXeSvT2HnOeUm21EUqPEeOD+FSDYvGoxlQ97ZrZcEPh8opsrfL7l6QPJwNO+UTE37eeKxF6zbnH9Ui2eHYYzqissJrmkSyk6CfpGw7MQJIrjssCZmoQtZ1IXZqAXe5fiKusuaO+DpOcOZwZMqj88VY1S5WQ3IyGaIIVkvxisE5GjtoRxtewgsUK1ykuqtsuRJ7NQH5Vpporyln+FnWj6B/9h+A/58WdduWtrZitLSXetrahacr2RM0Ncbh0/eHV54bt50e95FqfSkpV6UoZXdvKeKwBcV6ulOwp5/uP/qAckXNO9cNIBL6xdBNqo3qll1z8rVWZvVzBkA5cR6jgQJ4kAiZidBHzyRYgcQHGkxElyZqLusyYuktlZO8Z7mbPME51MVF0aLMebkdMKTUFijMMAw6IAsdHVZpZ45MMSgLJdFXLPxm3h8jhP+SwofMkMeO7piT0tL6fl4G0bwr0MrepywZwGApcyql0/98FwGl+68aatun7skOoC1bOtjrY5Q57k4IUk486nPao5uF132LjUezTuZobrgOvi6vK7jWbm6uIoLS2I1doIEwwgDMGqfvPPKTXjHIQnLzsBIuLBGOb3uslT4ClKj7rIbsfeiY3rdZV1wdZzldH8t56oTEXeZq5rz005z9jXjLiOAYPIcvcYLrcYb4iRtmyxxQxa65kGQrb/jnKbSFZ/i5898Fj88cR22zr9oDoI2ddrGqYGg57i3J3NKdGLHBuPI1tvM8lUAoJFeQhAmQxkAQCLN03u+I9i60xHqPNe1nIHgEw9o3d0uumwmUyybdzIj0ICMA7+WFaGfWzdPa0XqgBqmJkgwCiEA6QBaRlqQ4SSh7AyMhEVgHNDrLstGF7KpC3NQczl3WWsA9pZ29nSfQWbwpMpDFRfYqs5ll6XnjDd3GQF2CsjF4kgX9CNdnZxsbLMmeVJUlmN2fzqyK9IKfsyP5k/B0fVr8N2FdoTOZWIRwVNe/kbP9m3vbwqHnTkAUCfa5odgdtlhpBCRkWrLOtERbioDACFSz9XemXTytYuUrv+tELuOTaBLg6Nj1LxTMbUd5QlHXpK32H4nV8wKwJ7Ivkww3shAQtlJcBUSlp1rBEGc6UIw00VBTEALlogjF+1nhikhGr1Iam3hVN/pi4sxptZwbk4X3GP280JAKnWb19v2tIMJ9SrTUW2VeQo52Xb19hFEdBzTVz7ML9Q+iu/1zMb+2ed3cf7CRa8e2brlXrdShguE5M3GscobzFkVAJDlmNAcVXYUhDsLAEhZp7Jbdp/LZjo8Aet/t+zSTuZDbd5psnZqq5pe+6xcnVqp5s5S6H9xwgQJxiDXXJByQtkZGAnLTgIAABGMC91lk3EGN2HPRccwwxuGEXWXpQVqOVdWqQLjOBc6qzk//TTn5IZh2EfoEvoNMQq1lmCh1hIEa3RU5jubrIme6XBol/Z+iGKRUfIkPy7LsWvdF/DUMh2WDQA0zZq+YOHvt+/Yfs9CgES1aJq1AtP9BjRntqPIPN69EwC1EIkcAMg9u62WgGIA6HFg33f++l1VhgfZvJMZ7IPjyFtqQct/W3cUHOLSMkTnSZDgGiCh7CS4KmP2Tj3B8EMEtx2mOxudyKbOS9xlzGAGtfhhb21nT1cDMsMnVR4f50JbFRcmn1R5GWeRNqqyy0jyNL3ON02r80nYxG6r2B2QRa650IX70oNJ24uFqz7JL1Z9A99SZaiaCgAOh++62bPfrjxw4JYKEDJ26CfWL7Omrky1Z0ercOttAHLAHJpU89osAJCExi9+UstXgs79Zg20eSczwi1I3f9buSLwvHXb5EZkzOj7rAQJxiXXXMX7PpUdIsoB8D0A+cy8mohmAFjKzM/EXbrRxzURtJpgeCACETjLjWCWm4IouoK7zILW4IWjvYVTe+o42zrBBeK4KnSc4ILUGs7J7h4BdxkBGsJqvlHVDb2q288ufbM10WNTuUnluEAhAYAw2Sd/i//RXI4N6z6Nf71eQGmpaWcrSifuXF9zcuHKI1r95CXWZDNJc+cBAImkHgBw+s/utJne5QyEvvshraPLTTOib0q/m3cyo6ua8w/9j7yJfi0rZnrhvCYabCZI0AfXnKGjPxf8PIDnAHwj+vo4gF8CGFZlh4gmAHgRQC4ABeBpZv4xEc0F8B8A3ABqATzAzN1xEuOa+4DEkqDFWPmcDyEJWAq4d7qOb9/gwFffCuL1ExbKczW8eE/khuOlfWG0BxiPLBn1Xp64QgTDgCxMg68wjXyYcnl3WU8IRnMXXJ2R7LIcVaUK9ai7LKOOs3Pi6S4jwEk+a5ntQAf4QEcLp9mOWGXJmSrdft5yQmRswspVu3nhoW/hG84JOF1aUHBkuc+bvqO5eeKiPXrthvlm6QqdDK8kdwgAJle/kgwAv14hdhwuphVA/5p3WiwadvPkquet2z1vqgWzLejXVIPNBAn6wTXXuqc/i3cmM/+KiL4GAMxsEdFI5OdbAL7EzLuJyANgFxG9BeC/ATzKzJVE9CCALwP4ZpxkSCg7Q8CuAX/5qAtuG8GUjBXP+XBjqYXN9RL7/8aNB17x40CTRFm6wPP7TLzxQMxaOo1riOBxwPQ40Ikc6sRcnLycu6zVD3tzO3t6znBWqJrzuIoL7VVc4KlReZmNSM8G+s646lMWIIs6wlm2Ha1gQo3KSTptlXlK2WUUAUCAnDPX8A8Dt+D1yo/SMyunTN00PRDwHNvXTYXzrVJOt+edalVuJWS4KqP98OxjBVj/m+vFyr6adwbYdvwdVd7wrLU6ZydPnQ4g/xLhEoxKGp79LMyWGgAA6TYUfekVnHrqvYCKLDPFX/0DAKDupx8GmyEUfeFXIybrOCKuyg4RHQAwM/oyAKAUwC4AhYjU+ZEA/paZn46nHBfSn8XbR0QZiAgIIloCoCuuUl0GZm4E0Bj9u4eIjiDSMXgqgPXRw94C8CcklJ1RCRHBHU0iNhVgRlXmsGQwMwImYGjAU5vD+Nx1NhjakNfeBDjnLst0I5jZ6y5bisMXHRN1lzV5kdTWwim+05xjnuB8Oq4Kk05wQWot5+R0w31JwcCrzsso1c4GSrWzAbBOB2Whq90qdc+CTUt/C3dUbOEVe79DazLnlv8pefu2e+iQVb8t21FktQdZL2jY2Oi1I/DEA9rSC5p3novNYYbVDs+BP8il3c/K2yed4twpAKbE5h1LMFyY/u5zig4AsBVGy+9/cE7RAYCWP/wQyde9H8rXAdg8lxsmwcCJ21pGRLcDmHXBJieA3yGi4DAiiQQ6gK8DGFXKzhcBvAZgEhFtApAF4N64StUHRFQCYB6AbQAOAngPgFcB3Acgnk3+EsrOEJGKseBpH060K/ztIhsqSnR8YLqBef/pw02lOlLshB0NEo9XXNvuq+HmvLvMW5hGXkzBGdyM3Rcdc4G7rKORMwJRd5lWxYXuE5yfVs9ZV8wuI4tn6bVeaLVeEw5tu1Xilt5Cz7wvin8z76Ff771n0cuZu7Y4nLc6pnZSqMs+4fSvsx75lOaZZoW39jbvZIbvNGcf+KW8Qf5C3jijE55Eg80xTuur/3jJNv+R9Re9DjfX4OyLnwcAGAWTLzk+waCIp2VndfS5FoAPEQvPZAAeACFEYl8V4rtWX0Kfi3fUbVSBiAWFABxjZrOP0+IGEbkBvAzg88zcHXVd/YSIHkdEKQvHcfprzs8ZazRB2PtpNzqDjHt+6cfBZomvLLfjK8sja+RDrwXwnVV2/PfuMN6stjAnR8NjKxOKz2jg3e6yclRf4i5ToJYA7C1tnNx9hjNDJzkPvdllNSov8yzSshGU1xlHu6Af7epmj7H/1Ul3eyqzVnU/Ov8p/+nKXF+Kr8X70/cF1aPBjvY7WwLTDnLpnhetWx1/UEtmh2BbcmUJE4w1wo1VAADhyQBIh+puAvji5vYMAqQFAHAWzR12Gccp8VzLeks4lFywLQkRfaN3XoGIwjNs9Ccb6/3v2jSFiLoAHGDm5viIdUVZDEQUnf9h5lcAgJmPArg1un8KgDuHU6YEgyPVQVhVrOONExZmZUc+/3saI6brKRkCj7wRxPqPu3D/b/yoapOYnJHQM0c7RCDtguyyYjRj2aXusnCvu6yZU32ng9nWiYMFPTWUZ72dcbtvYkmDN9V7TNygFdp/1f6R3M+pWZkAxa1beYIRxorcm5LQcaUySbLl5Lm/uyqfQ9fG/0Hxo68Mh3TjmXh6KbYBeO+7tgmcV3R6XVnDWlKjPxf8CQBLAbwTfb0KwFZElJ7vMPNLcZLtIihSrv4ZAEeY+YcXbM9m5mYiEgAeQyQzK14kuqYOgRafgqERUh2EgMl4u8bCV5ef7wTwzXdCePpuB0wFyOg7LQjwj5gdMUEsMQGzydBa63W9q9ZAsMbwyTqjDo16A02pgXnzjolWc3G55Xd7WusC2WdncNXJcvPkJrYZwtSgLJiaYl2zmybbYBJDZwkbdLYRhGBLF2QJUkRKg84ApMYCzBCARkISpNAiK6oFImYLkhQzGJIUBDEAhoQAgQEoJggNxMQqYmFgCMUMkCJiFlAKYAgARIqFipghIARH/iCWEKxYMDMxQzCDGCCoyDMzBCuAIvsAQChE5mdFkRVB9f4AsoCE6K2eyCCAmaBAABMzARBEgCAwIuMxEaj3FlqBRGRWYnBkVoAoMpuIHgMmQESlII4cH+0aC4AIDCImAjGIOLJ4UeQ8gEWvfEyRvUSIbGOiyArHgGASX2B1LwAtyez2AoAXcCFyeb0LYi8WIusVQ4Yp87dfPPLgnXfsZ0BRRDYRGb/3f4foZZ0vNcnRlieRa4juZyZFInIV0bM4GqfPF8brE0cvTlywCETGZopE9qtzVxbZTnR+wWASvW8JEyDOzdH7sYq8Mb3XTByVJyorRa8HF44a+Qdf8DZdMGTvGej913CvKJF9epha4mgXuC363PuxEwB6zfNVAIpwsZVnWOiPsqMATGfmJuBc3Z2fAViMSGDwsCg7AJYD+DCAA0TU29nx6wAmE9HfRl+/gkiafLxIKDtDoNHL+Ojv/JAKUAz81UwDd00xAAC/O2piUb6GfE/kB3dpoYbZP/NiTo7A3NyEVWe00yFEe72ut54y9O5awwicMnRZr+tai67Zu4VIDhJlMpABonwA+cSs5p/gA3dtV11FLalpR6d8MORI9muVJU7bzfubs45lsyr0puDsBCHQ2UxZLUQpnAw9yaDWrGxucjiINAlDNFOr3glLBmHvsmDvlHCFIZLCOmyskU0pmFJwWBrCVAKaJcihbEhiB9nJQaQ7WOhJRLpBStOhBBOTZBBDCQkmRUxMSkgITbGmM6ArFoZioUuQrhB9FiQsIt0iJSwOC3BYA8KCOCyITAGYJBAWAqYQZAmCSUJYQkAKDRZpHH2GFBpZpEGRIMkECdGr0pBkDQpEzESSBaTSWbKApTSWrEMqwYoFpNJIsmClNChFEFDQIioOCWYIpSDAIMUQYKGxYgEWIqKQkc4W6yxZZwmdLaWzBZuyoEMqnS3oLKGxZLDkiNtJgSABZiZIJigwR7ZF1lkLxAqABEGBoUBQAMEEQwuEQzahwUSvokOAIFJKce/dvwVA1w1hWaYyqlpP5Z3I31Md0agiyiKgwFGFlVlBMLNgJgKzYEURxRJMYBKR/SCOHE/MJBRYIKJmRNRBpuj7AeCcinhOAwSgIh43IsXRy2REVD6O/MYBIHBU4Yss/cxMiIoZUQV7Va3zmhFduI34nH5DvXMwRT4TFB2fSVCvQgrWCHROQY2ql0QAWLAAQOxzsC1+eTyYGH0+BqAMEWWnV3O8KOiKiHKZ+Wy8BLmQ/ig7Jb2KTpRmAFOYuZ2Ihu2em5k34srl4H88XGIM0zzjkjk5GvZ86tJCuwDwvmkG3jft/Osf3OrAD4ZJrgRXJkgUaNC1ljpd76gxDF+tYZj1ho6zumbrEMLtFyLVArJBlI5IJ+UroksOLz2s9t+xUwVKmzCNyZhydMqHt29bUCo85nqHNaHYrNFToAJntDJeqnbknVVz9nuRkjqZqhZIcUhKOHpqUVa7HZMC2fAGUpBH+UJ3l1HAEYKW1g4xwUcNyU6uddi5WdqpO5wElxWgtKCf08NeYuUl5nYOU48Ae5Hi9yPFH4DbbwotQFDhJA5zCpmcIgSnwFAeGMoDwU4BRUIpwNIEW5pgiwQswSRJCUVSU7A0sIROhtJJsCE0GKTBQ4IM0sggg3ShabowyCbsyhAOJUhnFkIpEVlulQArIlKCWBGTIpAkEoqYJLFQxGRCskmSJJlKCT+zCDM0k6GFwcJkaCYgTIIwQZpFECZBs4iEBRKWICGF0CULzWJNWCw0CSEsCCEp8lCQJKIPDZbQYZGAJB0mdIps18kinSRpJKGRRZqwoEOSAROGCsNgM6IecRg2NmGwBQNm5MEWDFjQYeT+2TQbWxzSUjZp4byZV2jRyB0JECk4nQI+HyxTGQAQLJ6LX8/4XglHTHfETAIKFNVtIpYMhiTFEc2KmaGgoFgRs4KKakTnnqO2LsUc3QZEjH5MinsNfQCDhZKsQcJgi3UoRBXDqAKooLMFHZI1lojuR+/fGlvQWUGDJAOy91horEiDgg6LNFbQIUmDIo0lNKhzf+tQpJNkHREZdCjWIRF5WKyTioyH3ufI34zIRShiAJJbkBrPtewIIsHH0y/YFsRlqjYPl6ID9E/Z2UBEfwDw6+jrDwBYT0QuAJ1xk2x0klB2EowLFKBaNK2lztDbTum6t9YwgqcMXTXout6maUk9glLCRJlMlIqI2bloMPPYw+xbtZ/337ZbcUEbZhGwkAE+PeGWzdUT7y6VZk2K5v+trXzCXzuOlP00VN/+JS2UXEXu6uVq+gqX2l6epmYffxtFf1lB03MyyDe9nf58wx1oP5uKlZ2bRRX+hPy6Tg60TYetsYwgiZxJAiucHnIbdhG0AyG7h0VamFRyj/S5u6g+KYW6HWVo52Q6EnKjzZsmvV4XpYa9oshs5tLwGRRZZ3W3aifTqFMhw6cCelD4jLDwkRQcICX8Quo+AcMnhN0P4fSTluwXyibdrLOHNfawII8g8ggmtzBtboRsbvYabjaFnaRQQpKlKZJQsDRFFjGHFHPAggoo5iDAQTCHBDikM5sGYNmJla6TrulCJ10YQiebsgt7yBD2sCEclk04LUPYpRFRptgQNjKEDbqwCZ1sQiddJ9I0RYAChBRMEkySFEliYZFSJqS0SFomLCuqWEkTFpskoUMqE5IskiSgSEIKCaVppDQdrDOkgLCIIg8hRBAkvERCCaFZSmjS0oRlCSGlpoYXXTgAACAASURBVFnymM2Up971mdE0KE1jhMOKAMDlJFMIP/dccMx9M2u6HhAPmUSsESmdiHUi1gE2iNgWUd90ktCFJI0tGJYF3bSgWyZsMvJsyN6HBUOGYaiIgmYoM/Lg8882RF/DhCEsGGxCJwsGWdARmctOYejCD40kNCGhawoaSQhNQWgKmqZAQkHoDKEzSGOQziCDQToi67ENgAGiy8ezcMTrCoYFZgsKEsxWZBsrYkgoljj/rMAsSUVNbYoVFBQE6P7BfKH7x+MAbsHFxokfA/gqrmywiDv9UXb+FsD7AfR2Ad4OII+ZfQBuiJdgo5RhjR5PkGAwdAvqOqPrrXW63lVjM/yndEPWGxo1abq9SxPuAFG6ilhjcgDkxHp+d4A7b93Nh27aq4zMbsyhSMwfAKA1fea+QzMeNKTuWG4GNm7g0K7yuyb8Xe3Lju2mM8vmNOtFqK6IxfRT0pxyuEz1rNiltlt3qVldz9GEg6uA9hzxwYw06iw5yCdn20Wl+Wnucbrp/3X+UXM53uFGdJHjpM0SrfnClOUUNjKp2xZiq96rZ+o5Ms8+TZ9mz6KgXVPdutS6bB1SJu+1yNMAI73ZCCQZqsmehUNGvmikBdQSyDC7fMmix+cUIZ9N0wJhUWSdRTE1iuKksyLf0SyKM5uQRe0U1APwGk3Uo58RzTpEg65ZjbrObaQJChLb/SSSfCSS/KB0L6n0brbSvUCKj5U7AENXDg3CozO5BGtuMm3JVsiWHA7bks2w4QmZNrffNFzC0pNsUrM7pDCSTLDNj7CdEWZwKMAyEGIrEAYHTFZdFjjIzAEwhxQ4ROAwM5sEthyAdADKCbALkQr0giBMXRh+g2wBXdiCRkSRChnCbrqFwzKE3TKEXUUsU05lCJvSyWZFlClD04Sua6TrgjSbgGYIEnYCJQHkUFA2SRy2IIMWybAFFS7UqsQp7Ljo82OQnZmZiEwwM0M64LJ7wj1oOldMUvXcEDi4pdyUUKzAFHFgsVDROBYGDAAOEOyAkkKosBAyTEKGNSHDQkghhDSFsGBokh3CUkJIaJqPRcTaxVpk2+UsYIieT0IoIUgKEkojUoJIaRcoYMaFChgiiowNgJ3o6vEqiklZ0E0JPWxBt6IP04JhWaRLkwzLhGFZmq7CsEnrvOLGJmzyUmXtvMJmQYcH3eELvpaxphMRD1DvbwsDaEWkzk6vS6s3LmvY6E/qORNRNSIxOn8FoAaRjKhrkcBIC5Dg2sUEzLO63lRn6J21ut5TazPCp3UdZ3Vdb9OEyydEqglkgSgFw9y0Nr2bm+7YoY6tPMjuFD/mUCTG7hw+Z86pfbM/0xhMylzCzMrs+XWlsuoqVhc8tLnG1m64c4+ILdrSAAWkI9dmhdw9B7im3csT95WjZ+lBtengI+rmpT+klC25OGu+RyR1pGBF3WLKyzoCY9Iuqpy9jLY03a/sdQHxQM4bxuLCTbTf87I4HLKHcqp0bXKdBw7MMdpSMlGT1I0gdejSqkOypjuy7FnISbrJ8tgybX5DafmaXzaJrrDX1sbCU22zuZs1l6dNObK6tQ5bqmjSsrV6UWTuw1TrTVmBbr8LAZ8dpl9owmcp8ltw+ILaBKtJL+RmMR3NspQaw8XUpPK1NpGZ3OUIpoa1Tp1FqyHkGV0LHNb1cIMeVk2aT2vXNFsPkdMWgsPlI5Hsh0zvgT+jG6GMHpZpXfCnejnkCcDvDCHJbsIplOaUuivF0l3BsM3jN22eQMiWgrAtWYZtuTJsuMk03GzZnGxpdqGETSihG0yaA4A7ErZqesEhH6ug3+JgwORgyM/+MFTAYitoMQcA1QXmEIFDOiNsgC0jqjglAewE2I1IEbnLIkhjnWymIWykk41Nq00CQIrDGdaE4Ha/104As2Jac8OHjzz5zkszNCaUefKDZ9ubkpMMhwxbplgiy5zvDSwxiMhBEPbonEnRRJZzMJglVETBggpZJEMmZNiCNE2SpglpmWRJC9IKQ/5/9t47To6zShd+zltvVXXuST05KuecJUuy8QVjYwy2SSaYJXkN7ILhLml3Qftxl4VlWd8FloX9SDa2ccQEY4KTJFu2ZGWNRqM0mjzT0z2dc4X3vX/UjDSSR8m2bGD1/H76Y6p7uo6me6ZOnfMEYZIlTNjSIluasGGMTbEsCGbDViwIJkhwG1IVEFxAqhJSk5C6dBoZFwA36HxKo0kbMHOsAbPOnIAxZgmm2GK8AXMplvQyQzKlcMYK8iUNmDJZA2ZZqnT0PK8+pJRHiGgunAbHgrPCehgOxzYIp+GRcBqi1wxnbXbGZNzvBvAeADE4eVgkpfyfNs2ZiOzrXcBl/OVBAjLOWHxQ5aM9DsG32Me5PaByJaoorjRjgRJR5RjBtxGO5frrjvqY7L1+h+hZdVhWeEqYR5NMiUzuSR6c+5H9ibIZq0HUImUpU0rddRgyu2F16K1bPFrZyuf4luiKtr2R7+JWNxlmYKphZjOsU1rsGrU5yUoj7T4eWzpgPLzrH8Xfrdyk7Bj8MVZ1XSvb7V7WFFepJvZRJevrtK6eeicbWRZwPSJvLn67/33k74uxd5pPu29sfJJGZvS5fhGIZRLxbTTnCMnFx7miKLN4vHJRKUptap+dcdv2zqIw+6QGM1DlqjNb3K3pqsRc7uH+ijQzlKiSTmRYsuiijGx1xfUZ3j1uXyCW9/tiwh1M6QhZ/iirZgPUnO1Fa74PrXIflmhbDa9u5rku8tJiWatAOStDBYtTUfg82by3HqO+ForkW2kku5SGzWaKFOspZldS2uNDIWiS7YuVKaXhKiU1xHlugPPSIZWLEUUpjSqKTClM5AjMpFyZq5T1BPMRXpEFVWQkKtMwKjJSVGSAsriUgTzgKQEuAwq3oTIJNwCyFVfGVH1pQ/PlDTWQN7RAydACZkkL2Ibmh6lWwVK9qqW6VFvRXUJRPYIUH0BBEJ0W3yGlsCGNrJSlHGQxL2WxAFkwpCiYUhYsWxZsSzhruqIQbgDIlAoqxlYcjAlm24J945mfzZVSojqg6x3Rw9UEgCtSsYTEvsQfm83e/Wd+3KRCak5lWoGTWlSZPj6ZMsf+WRpz2WNrPqhMl16n6SLO3Aqn8akUVxkpGiPmIoxPpuAhogs2/BIQpgVRsGAbFtnFCQ2WYcG2nCbLtk1Ytkm2MGFJE7YwyYYFmyzYsEgwCzYrQTCbhGJDuASkMt5gCUgNTpOlw2mwtPMWNqHEN19zEc++eGg4paBT4MS3jCvtMPZYgIhISvmaTHjONdk5DOBZANdLKY8DABHd8VoU9SeMzPmfchmXcQoFovwQVyJ9qprqUXm2R1XNfs7ZCFfUBFN8eUYVtjONqQRQ+XrXez5MHZbHrt8uhpYel3W6hRk4ZSB2GgQx89i0m18YrF8/H44pKYSdGDDSPysA1vIZgWXPN/tmb3hKbd/s9iZaFdVYGENVTreHZJtpRn88jYwFo5a5y3jBs9Z7s6Yfv78wuLyhuGn71+mHoc/zbzT/Vrn90ZDomvoR9A48bc32tSiVuU96RvXO4l81P8zLm7r9v2t9S/ru0jvdP+y5ueAdTNDbM8+5v6D83gpOH6771RLv8G89B2x/uMO77qDMLT0BjZSW8mjV4kSscl46pngqI8UhYae3ZYU1lGWyUF+uV8tad2t0rqvFDhYWaWpKb06HC5kRlgqHKVkYZWkrS4Uy1ZUqW+TvU67w78n4fHHD7UlzNVAMFYKuwDA1RHvRmuxFW3EATckoqo2jsrGso8iCrGArlLUylDVLlLcsKthFMoQGW/p9KAQaKWq2UMRso2FrEYVFM42gluKooKTiRVHlsL02gccUpTTClfxQiLPBOi4HuIKjnCOqKCyhMDXLmKtEFBBABYg03ZC5spyZKcsmMpWZeKEig2Kls2ITZVnJKmPg3iJcLhMe1UKASZTRhOmNIF4yVW/KUH1ZU/PnSk6jVHKmSgFpqD6YqlexeBW3Fd1nK5pLEvdJYoGy4KAfAz1w1EIEwIamliu2zALSAEkbQqkzvK68TOS79bxhSc5UEQisaFdcNRmH31QAZJGkNEhIQy0KQwXyGqyMGxDlE9Z0r0jWSSCbk5pXmFZQmVZQ6eSKz1KZbmpMt1TmsjWmS850oTINKtNpfMXnIq4wcnGFFI2R4iFiLgKNN1NeInpF3jcSUlgQRRt2yYIojjVWE6ZYlmWSbZmwbQ52qcKyx/F1OFugEIBNcEjLA3AmOk0AjsNpfqoARC9xLQDO3ezcBGey8wwR/R7A/XgdyUV/Irg82bkMAIAN2BFFiQ6oPN6j8kyPqpb6+BjBlyueDLGgQQiBKIDTnUT/vCClnN8jO97yoozN75GtXGA6zpCPnonBunU7jk5/R41kfP34MdvsPmBmH60H0Fjjajm4qOKqJUnK9XWzyKr5017ccYRm52DJJgKCTaZFu2aQ5/q9T8ZHZ6zOZtO9adfgOvnB0L3says/x9/3wp3iV5nP4vPvj8ibf/N1u05cx47qtX7Re79YVrnB9pT+qnJrb2dqQajT+7apn7BPzGitvG/mrfG7M++surfr2hE9msV1xR36/+GPF2ZRT9P2ZfrIvVf5E/t4r2tmd59/Y/svUyv7pElUFYqGFpWiVVcXsv6GfEbmPKlSD+/MPl8S9gggi6qPlynV7hZMcbdimTZbdXNfGZVYXTpdGI5Qyg6zZG6IpUtpKuQsMgNuT1pv9MXY7MBm+HxxcrmyXFVLHrhkXdJdFhuoaJa9aLP70GoOosGMoaqUh7cQs5k7XmxR2nOWpKwpWc6SlLMUKtkqTOGFQDkBriCyqUaKZlppJNdGw4U2FrbmU4RqkNDKKeXzoFSuQIRobAqQYiw5oiiJYa6kBzy8MBTgxhDnco+ikENUZ94CI7/lTBVPSik1UxYCeSTLs8hUZES2Mp0pVWbSZkUGsiwrEcxDrYrD4zLgVW34FYEychqO0/D08LAAQCHOLQkmR02bW6WUJYTNbp//lsP/3f7YrGiiV06rmpkaRE81Z6okIvL7l7aorhYviC54miGlkXcmTsU8RLEgZbEoZcGEM3GyIQtSyiKkLBIc8wBVSlODtHRAuCWEx5SG17SNUNF+9a+FDMxUHL5Unp+cSmmmynRDYy5TZbo9NpmSzj8NnHTiTFU4qUxhKleIqwopGoeieUjVCVSGU5Opias169Wufxzk/M3bAKAOTqLB/VLKJBEdBrAEwKfh/A35CJxV12sCOt8EaUx19TY466yrANwF4FEp5R8vfXl/YtgUXADgJbPTy/jLQsoh+Eb7VDXdo/J8j6paA5yziKLoKYX5iw7BNwSiv0gDICaktfyobL/uRZGZPoQZikTthXxfMji188C82wxL9Z7m6W8VdjxnFbctB6B7ednAdY0f1YlY6Of6cy8WlNy8NWt/bv6APrnvufTaen17dHq3fou5sK0pe+837MKWK/5DWunvmze0fJLudW8tLFj9i/xnlO9AbMsUHre/IH9ck7fTPS7Ph56q8uxbeEchLzoKqnmwfk31WweZq6xus3YoUvL1V0+fsX1Y8edm/ZpuOvIE3lxlxmDy4+mkkirOeSPb3f9R/nhmMR2bOaIy8ZDfd/xxr1dPWaxp+VH0bzgoC9OHZAPBUzlaNf94JLQklwpMqTQVfaoU0UHb7BoRZo+UdqwGsKaoTM+F9MaeWndbqsrVyPxqeUghtY2ItAwK4QhLD4VZMhtlKUpTocyA1cQUS/d4kgN+fyzm94+WvN4k013ZIOdGHRFCNpgVQc3wAJpHe9Ga7UOrPYw6NYmKQAHuWkksBFOkKG9FKGsmWdYqUs6yKW9pZNg+WLICEjUEqICUlUjHmygaa6Vwuo0NF1spbDdRlFVTUi9D1ueGUcGcpujkZ7xIVIgoSmyYn1ynGUMqt8KKwkYVhacU5s4RC5iEMulMjU5rCLgtjUAOifIc0hUZmatIo/DQAydm9kWLFUFNKb2hKhD+9XCimUlIGyAPYzCkpMW6C0dKRWSkxIGZs/CGruP4++oaXOX3w2ZawVQ9KVP15wzVlzP0YLGkBUxDC1iG6oep+cemSm7NVnTNZppHkuKVxAIgelmpolJKAVnKQho5KYt5KQtFyGJRioIJWbCkLNhSFgFRPMVvkqYKmBqkrQO2xyGGwweH4/OaQCFeVEjNq0wrMFLe8bF77n7hUpyHiG4AcB+c6Z9jruQQhEIA7oDD2bEBhKWUr1k+1nmbndOe7HhpvAPAu6SUV12yqv5UsSk4BUDX613GZbw8GEBpmPNov8rjPaqa61G50c85hjlX4wrz5Bgrt5wm5qwEy79UqJYsruuQB968SxjNEcxh5/HMmYiCXjF8YP7tJ3LeujUTL3BSSmnmfrlFmN0bAYCTlrmh+ZNhztTpR5Shnc+qnctbWvc+29x88Irb8aM9uUHVVjuSy7v1W4wVrY3d3/yBSAy0fcaI8mNytqecVVTOqXjK92xw5sqnzE/J75vKc/H4vfZXSwNlvfp/qWU13/iJSEbqbsj2NqxtM3K/7PYzq2FdzU0RW9PqnlE7+lJadMbUaTsPh0I9sw/TnNF7cWus254yVxnKH1N6spIVzEUb2IFjtymPxVeww9MEidBmj7vjwYA/vcelN/uy8K7rkMfWHhKiJYo2gFclymYeiVQvTcbLZ3oNLThdwlKFNdAljK64sPo1KVKNgGgiMLNcr+mucbVGatzNdlCrDurM3UJE5QCQQzESYenBMEtmoixFKcoHSrAaQahUFCPt9SUG/b5Ywh8YNT2eJNf1XLmiWA1EDhG9BD0/jPrhPrTEe9Ga70czIqh1pRAsM6DXgSgAKQVKdoTlrBhlrTRlTYNyFqhou8gQAdiyipwLEgCAIEQ1kqPNFIm3snCmjcLFVgqLRoqyECVdQeQDLhiVBFlJdPqkwwbsmKLEwlxJDnGeGeS8ODimTosoippQmJ6R5Nv1ic4ZMMHUChVm0gSNmf3W3FiDyC8jIEYItLlL6a4cZ6Ax12nIv13bvG+py5ML5iX3FaC6DXg0Ez4uUAYgSBewhZAg22mUfFlD9WcNLVAwHPWbZWgBYWg+aao+xeQexVZcuq3obsG4RxLzj3GVXnHkgpS2CVka5zcVpCwWIYolKQumlHkLong2GwIN0nY7TZMYX9NdTD2LPvvAY5fkxp2IlsFJWXgazkboO3DSD8oBHALwDTg0mWopZdmlqGHSul4jbtBfBjYFQ3iNGeSXcX5IQMYUNjrAeaxHVTO9Ki/2qqoY5AqLOqN4h+Dr8GIuYwzuksxctV8efOMegdoE5k+2ZjgXLEXPHpr1gV2jVQtXgug0wzApjZyRvrtdivQqwOE7vKXp9r0e7l9mwS7epW+JSpJNa9bed0Qo1PpB3C/44dRO3pdb363fYvyv5vr9N/yR8gsGFwTb57yv2Uj9QLup5TMjv9cPDFi1e7z+Wd2hz8s7Ne3ZyMC/i//MTffsqL21ptrzN7+W3Qt6q1r3LP5svEgJzcz+itW46u011W8TBS7Kn1EP9sRYcnFT88F9jU0dNYai1f4SN+19Am+uKZlqNe/OHlQGckGy5PyVdKjzNv5YZB1rb9PIbunhvO/BgK/nD16PJ6Ioc+vjiGxoF30rD0tem8AMApVn/M3HR6qXhmMVc3neE2oDKXVS5GPC7Om2zRM5YQ16IXNtGONneXlwqNrVPFDjbi1U6nW6hwfqCaxpXFVUgBGLsNRAmCXTEZaWKcr5SzAbJKEaAFS1MOrzxYd9/ljK74/ZHk9K07R8JWN2I9EpXk0G/sQgGsN9aE32oM0YRCONotqTha/SAq/HOPnWlkUqWCOUsxKUNbMsa9mUtxgVbTcsUQ6BmjM/JxyWVUuJaBNF4m00nG2jcKmVRmQ9jSohSrr9yAd0mFWMUD7x+17ot3DTg3mMZAHGAIVBairZuZJUysqVfDYntIop7sRod7HCO82VTXcWgsSdtmrqV6ZCr52cL8yEtP0FJIM5pCoyMleRQb4qLc2KDKzyLCiYk8xfgO4uwaVb8Cs2AgSU00VmNVmKnjVVb8ZplgIFQ/MXS3rQMLSAMFS/MDUfM/kpqwDBVLdg3A+QH87G5FWFlGbxtMZJFEpSFkuQBUuKgg1n4kRSFonIdesd9/xHz6tdA+C4IsPJx/LBiZv6KoA+AOsBDMJZbSUBrJRSvmYpz5ebnYvBpqAbQP71LuN/EvJEuSHOI70qT47FEBj9nNMIV/QEU7wFh+BbDSck9jLOg0BOxq7ZLTqvPCD1igwW0KnMmguGBInu1uu29bS8aSaIVb/kcTs9XEr/NA1YM8ePXVn7nq3V7ub1APCU2r6lW4lsKC8fPDBv/tMLdmHFvjvp84vUXaNblFhpQ7d+S+l99TU7aFAt+9KDcu4zG76dLGXuO9TmqdMWVV097259a3z23Ke7hqoqKr9u/2OT/uzI8b8TPy+8S/vNjBsa60dmHYd9x6OitnvKjcf6Gq5cZBW37rNLexZO8S88sqTy6lCOmdpm9eCJCKVXVIV6OqZM3SU0rbD0MM3pvBe3xroxdQnlrRg/njnBRgqtJNG6iI4f/Wv+m6GNbF+Ti8ypRaLCE153x0N+X75d19ssoHH6EI5tPCCGlx6X3vIsZhPgLbiqBiKhxX3R0EI7622oE0ydCiISdrxfmN0Dwuw2hD1SAVmahjGHWZW0dJWrsafG3ZoIuZoUv1pRyZ012MmVRxFmMsrS/SMsmRyhlEiynK8Io14S6sbeBanrubDPFx/x+0fTPn9Metxpj6oVq4hEIxFO/r5IQMZQFR5AU7QXbZletJrDaOBxVPrz8IQEWO1pJneGSFHeGmE5M0VZq0A5U1De1siwvbBk1di67CVTBg1mqZ5Go80USbRRONez97nAfX/YO5MI7ImPVB969z2RmYkiuKYAU8oZSraEygijeYEp5YQDIxLpLwbQdGdG/v213tiShe6RQc7zg5wXhzgXYa4gqihqSmGePJHPICqXQPlZDfomgKQU3gJSZTmkyrMyU5lGsTIzJvXPQJblpOIrQPWU4NFNeLlAkByi9sua7ghipsW9KUP1ZSZYBZiGs4ITY1YBzOJu1eIuTTDNLRj3SlL8AIIX8n86D0Kf+P5VrzpfhohmwlFuTwPQD2AqHDLybwF8DE7j8004WRVfllJejILsldV2udm5SGwKWniNA8z+EmEBVsSJIYj3qmqmW+WlPlXFMFeUmKJ4soyVGUDVGMH3Ml4BqlJy+C0vimPrOmTQX8A8egWf35HQkt2ds94fEIo2KUnZNvs7zOzDIUCebIIWVly5dVZwxXoASFKu72FtezUIrqXLfvW8x5Necyc+t3kXrdyobQ1vZwV7Vbd+S/FL1ZXb/+DyrLrnm7aya8nntqc8Wo2R+fmMtzd/qn1ATRlPawcWrVr18IFntKuKd9kfWqg/O3L4/fYfjH/kP5n7/obafUOWOvtff2T36KK6eteS/50wFdQb2UeOwI6tXFC+YfvM4PJZWSpZm7WOYyOUWun1xQemz3hh2OeLLy+S2zg57SHXTBYrdvDjmRgljbkEVM6ivhO38d/0vYntqvVQaRYAHFXV7gcCvr4nvZ5AnLG5igDN75GdGw/I+PweWe4rYg4Bqsm9iajD+8mnA20VFnfPBJEmpbCkHT5hmydGhNlD0o7XANYUjL1XBLLKtOqeGndrpNrVYpbr1X6deVrojGmlASs9ytL9YUomRljKTrCcpwCjTkI2nAyUhLDd7syAzx+L+v2jOZ8vTm53xsd5qZpI1tMZHjEWuBFG7XA/WkZ70ZrrQ4sYQZ2eRFmwBFetJHb6ylNKgaIdYXlrdExdZrCcBZxal4UIqEo9fz9SL/4S0sjjZHImJJjukbrbY9m5FAnbpHmtVdF8NuvqGskFAy6yPRz49bs95pJ65SXxAy/5PDrrtPiIoiQGVZ4Z5Lw0yBVz2FGnKQmFubKMeYtEZcIhYV/4xVdK6S0iE8wjUZ6R2coM8pUZGONmkWU5Sf48NE8JLt2EV7URIIlywkVJxF96WkCOWQVkDNU3vn47aRVgan5pqD6yVK9qKWNWAUz1CHaaVYD2ie9fdcninohoEZzV1RIAm+EYE48AKMG5wXoawKrLa6w/ZWwKJgC8Zm/QnyOSjCUHOY/2qjw1FkPgEHy54koz5i8SVQqnkXmldyeXcRY0RmX3DdtF34qjMuQyMPtCOAznQsbX2LV//u0JQy9bdrbnWMXdz1uFLUswgXTZ5J21e3XorQvHZbU/1597MUelFZqWj6xY+Ug5EdSP4u6DefLO058c6iRbzu7Wbyn+sCyw+9sVZWvv+pZ1KF22NN8x50PLisnv7atzNdD62psX/kLb8VzWFZmxYuUj+CHdfmizuGqFvmXk6DX2DnxfvXPq16rK99zv8679+ONy2/p2ufr4tHdsH2jYsMy2uo+Z2cc8nKhuReja3Y2emctyVMps1jqOhim5QtUKmanTdh6qquqdS4SqQ5h76D7cGu/GlMWQ0JSh/F6lO2NT3l5MgKuNhvpuUx47cZ2yI+RDYQ4RKEeU/Z3Pc+gRv690SNOmCaI63ZC55cdk54Z2mZs5IGt1EzMIIJvxYqJs1tFI9ZLEOO9nzBQSUho5YQ50CbMr4fB/0s2AaJj4M/co/nC1u7m/xt2Wr9TrNA8P1DEoLWea65mwcqOU6RthyfgIS1lxlnUXYNQKyMaJBnhEdsnjSQ34/aMxf2C04PUmmMuVDXBu1hLJSd22C3BnhtAw3IfWRA9aiwNoRhTV7jSCFSbU+kk5cLYsZv7724X8w3eX+2++7Vj+iYcb7eSom7l9JnGdmMvH7GyCMZcHSrAGxvAx+OZfjWz7E3A1zkP1zV+GD/lMI42OttBIqo2G820UNpspQrUUVyso4/OgWMZhh4gunAScYpSKKDw+zJX0AOf5QZWbQ5yLEUVR4oqiph11WsByCNgvi+DsLslMMIdUeRbpiowsVDpSf7siA1GWk8yfh+otAZbAkgAAIABJREFUweUy4OE2gmNS/1eNyCyIx+d2tl/ylT4RfQXAp6WU5WNfZ+CInX4EJ3L9F1LKmed4iVe3nsvNzkViU7AffyKmbq81SoTisMIjfSpP9qpqtlvlZr/KEVa4mlCYL8dYcCwU8rx3XJfx6mNmvzx8/YsivKhLNmk2pr4ar2mo/tED8z7WmQ60rTmb+swhIj+2RZjHNk48XqZVd72x/oNVNHbxHiclA8DMWc9urq7u2ViAO/MR/MwNIq7/YTBOQEW3fkvhGa/7yKdqQou+co+1ZfYAW7N5/bfzlnHgsJV/auX1TR/fybhr+r36VqO8qn9ozpzN8zfR17Ydt6cv1beEu1bYneoD2ldDv/e5ez4fqpy+oFv2ffFBUVF015q7F382bXLXHCv/1DbbaF/qUnz5ddVvP1Kh163JkxHbonZ0DrHEclIs1tzcvrOx8VA9Y2JqHp70L3HT/idxTXWJXDNhihTvyR5Q+nN+mGIhAdSA6PBH+ONH36ZsKytDdv74hKRd0449EPANbfa4y1OMzQERD+RkbE2nPHpFhzDbwmjhwvErkiCR9rccj1QvCccq5/K8u7oNxOpO/qxFLmqbPT3C7MoLa9gHmZsCnM6F4aRmK10NPbXutnjI1UQBtaKCkzaFJvm9tGAXY5TtG2HJ0RGWNOOUdeWoVC0gm0Cnr2gUxcx6vYkBnz8W9/tHTa83yXU9V6YoZgPR2W8AkyiLDqIx0ou2VC9ajUE0KjGEvEM//OmU3P13lbGaOoAYRCwCpbEZMpkEBctgD/RBnTk/y1y+gnFgRzkLVBZJSFb51s8O6LUzPZCovZA1UhkyyUaKjrbSSHpcjt9EUapBXC+nrM99So5/UavwIlEh6qjT0kOcZwc5Nwa5YoU5p7F1mjtP5DeIxtVpL/vmTjdk3pkgIVORlbkxN22zIgOUZSUCToOkuwx4VQt+5kyQzia0GJh9uPOSqaDIydP7IYC3wkkduAbACgD/DCANh6/2MwBxKeXnLlUdL6nrcrNzkdgU7AAw5/Uu49WEAMSoosQGuDLaq6qZHlUt9arcHuKcjyrMlWZsPBSy/PyvdhmvFUhKsfCE7Lh+h4zP7pdTuXj1mnCb8eKRGe/ZHq5ZueRcq0QpzYKRvmevFIk1E4/rzDP61uaPFxgpTYBzUR0nJQPCWnfFfVEiWbcVG3f+gP5mOSyRcz017AWAbv2WQo/GI29trG+57kXx/K1PiTU7ln1pW9Zbt6qU/PZwhVaTv7r+/dM6+eCLz6tHVs2c9eyWquq+dX+LH+xN2GUz9S3hnpl2n+9x7YvqCU0x391QC72Asm/8xD5WlaZlR6a/69mh+nUrpcwkjMzDPVIkV5dp1V3ram6MeXlwRR6l6Fb1UMcAiy8HSU+ounv3lCm7maYVlwDAIcw9dC9ujfVgyhIQeSlvDfDj6S42Umgk4TSZ1UhEP8R/13mzstVXifQCGmscUoxSv/F5Dz3q84ljmjpDEoUAoDopB9e3y+7VhwU1xDCdSZxcA+ZdVYPR0OLeaGihlfU2NgjGp0xUvQk71ufwf05Ywo6O839OmwQQyA5qod4aV0u42t1ilms1PpfiaSZiIUwCG8KIU7ZvhKWiIyxpxCij5agUsiGaJ3Pq5bwY9/niQ35/LOnzx2yvJ6lpeqGCMauRCJOSce/5WQJ33ZVAeZVm21KxM8kSd1VX5o2ixSXjzM7nuTZvEZO2DXP/bqcRKuRQ/s3vgze2nFqX5awoZa0s5UyD5SxCwdbJFMExdVnV2T67p0PKKqRiTRSNn5Ljj4zJ8RN6EDm/G6UKBll1vlyryX+esOMKi4cVnhhSeXaQK4VBzsfVaTyhMD3LmK9EVGZf7DrtLFAtWQzmkCzLIlWZkfkxs0gzUMDA7Q8deu8rff2zgYjuArATwLcBzIVDRu4E8CkAH4DjwZMFMEVKGb9UdbykrsvNzkViU/AZABtf7zIuFFmijOMZw1M9qpofWylhhHM9qTB/gah8jOD7imWUl3HpodjSXHlEHrjuRZGfGsYsJjHpxerlQgKyv/ENL3RNuaFZMuWczZMUmZFS6q5RwJg78TiDUrqh+ZNHNMW1YPzYOCkZAOrqD2+fNm3nKgD4Gr6ypYMWbKC00aW/EJ0KAN36LXmToCxtbdJqkhj6zvfthqHaVS8envX+FWbuiS220b7hmoYPbQtqobUPaNu2Z1hh5YqVj+wWOmZ+HD8cMiytTt8SHmiwo+VP65/NlRQrdEND/fEYV5Z+6A/21jftkaty3vrB3Ys/k7O5e55tHNlt5n5XAYi2OveU/aur38pVps8twIhtVQ+197PYMhB8Pv/o0enTt0e93sRyImhj0559T+CaGoNcMwGAEqVOfjwdZXFj9riMuxzp+AeUJw69mz+j1yK+cNzQTwJyt64ffiDgizzncVdliWaP3/23hmXXxnYxuPyodFWlMZMmZJ2N8X6ORUJLCulgW6WluGdMvDhKaZvSDnfZRldUWL0k7XgtYE/BJGojl+KLVrua+mrdbdlKvV7zqsHasTXYpFMIAWElKdc/wlKRMEsWY5RRs1SsspwmaNJVi6blwj6/Q5T2+2LC7Um7NK1Q9bOfjbbce0+S33V3E6qqOG6+qQfV1Ry6zvCd79bjne/oxdRpLpv5vLn23Wl3+YzGZGIo46n7wue7rLlrtJIjqT93BpwtC5S3RihnxSlr5lnOsihv8TPUZResjGIQdg0So02n5PglR44/qoQo6QogF3DBrJhMjn8xSDFKRxUeG+JKepDzwqDqmD2OOGaPepoxd4FR8GWu055qv7X96pdb27kwZii4H45x4CeklG8kovkAdgFIwRH4NMHJy5oqpQxfijomre1ys3OR2BT8ORxn6dcVJmCOcCU6wHm8R1WzPQ7BVw5zRR0n+I6FQl6UnPgy/vSgmTK/oV22X7NbWI2jmEeXKOQzVj67/eDcDzObu+ee77nCGjpsZB4IArLuzMeuafjwtqBWdTIIdCIpGQBWrX5wn6qWFgHAX+HeIwa5ZrLB/E7tYGI5AHTrt+SI4F3Q2hSVRKH7v25FAB7cvP7/GlKWRCn1Pe7jZYlrGz9WnScj+XP9OZ2rRXvV6odLMarEHfgehEUefUt4qNxO127V7xjwUn7OR2qrt+1yu9bP6pedX77P9iiCGg/PvOW54drVqyQEmfk/Pi+MzpUA3NMDS7YvrLiqTiGlpQAj/pza2d7LRheDENC0fGTqtBc7Kyv75xM5fkSHMLfjXnww0YO2xSDyQkiLhQv7+ImMQTlr0fhKwY9c6hbl6YPvVZ5Umii6kAgnV0txxmKP+n1HfuXzokfls8cnqUxIe06fPLzxgIwu7JbBQB5zJqrobMaLifJZR0ZCS5OJ8hmn8X7GIaWRFWZflzBPJIXVrzv8H1k/2XurEM9X6vXdY2swBLTKcpX0NjqHXFpCihTlByZEZ/AMFSss2M04y2Tn0Ud/IQ4caGeMkdQ0xQ4GWalQsDUiyUolqdTVqWhtU9HTbSASsRCq5sjnBP71m/VobHQ2Tln4UoNoHOpDa6oXraUBNNEoqj0Z+Coshy90fq6LYScob0dZ1kxS1ipSzhRUsDUq2X7YJ80YL+pmkMMy6ygebaZIopXC2TYaHpfj8xCl3H7kA5ojx3/F/M8SoRhReCzMldQg57kxTyM7zDkbVRSedNZp4+q0ChA90H5r+y2v9LyTYYKh4PjPi+AYCs6EM9WRY49tkFI+eylqOGttl5udi8Sm4J1wutZLhgRj8QHOY30qT3U7cmsxyDmNEXwDRScUsupMh9LL+MuBtyBTV++TB6/eK3h1CvPPsX9/xci7q/v2z799qOCpXnUhz7dK+7db+afmY5I74lWh67e0+OZsmHjs5/pzO3NUWg4AXl/s+JIlj08DgDQCsdvx4woQET+S2sp7suuBU83OypbGzjxjs7/zPWt7TQqrti//x+fz3to1pfTPt0p7eP2Vte/ZUu1u3rCbn3h2L+++oqxsqH3e/KdmddH0E1/Bv9TDFJa+ZSTqEcXGzfodh2oouew7ZcFn/7sssMpdQuFffmp31CewOuNr7Nqz6I6SzV1zhJ0cMLIPD0KkVxKYuajiyhemB5bOJaLKIszkc2rn/h4WXQxCgDEr39Kyf3d9w+FGxkQbAEw27YElMkpvdj/vy3lgiEXjfi4eFHM3K1sO3Kr8EVNoeD7RKf8aG7C3u12H7vf74jvcrtoCYyeJnKoli0uOy0Mb2mV6Tp8MuQ3MmqiwG+P9HItULx2JVc5V8+5Q60Tez8nniWzENrt7hHmi4PB/8tNw9kZaBNSq3hp3S7jG3WKUa7Vet+JtImKTkpZP1SJlmgqDEUoNh1kyH2VpJUOF8pIwm7/179/ym6aJj33sY3jooYeQy+UghMDnPvc5PPLIwyKVGjX8fsolEmmtVDLVqVO14siI4fv7f6jmU6ee3zFBAjKOypEBNEV60ZbpQ4s5hEYeQ6U/D2+VAKu7IB6NlPbYumzcjNFkeYuoYOtw1mUhepm5djqMYh3Fos0USbZRONdGw0YLjch6ivFKSnv8yAc1WFVEeFVUqTZgpxn7VvmXE59/NV7vTEwwFMzBickZgENIbgZwr5TyISLKAxiVUjZfihrOWtvlZucisSn4eTghZxeNIlFhmCuRPs6TYw6+Zr+qIswVLcGYN3/Kwfc1sxC/jD8dlGVl9Nqd4vCGdukpy2GBY+1/6WByd6pjzof3xctnrb5QjoCR+/1mYRzagEnUXdMDS19YXPGGVROVQBNJyQCwcOHvtwaC0fUA8Adc+8Ld9OHVAKDuHt2ijJY2AEC3fkuWCL43NdbvGFL5yr/+rb3lqgNyw0D9+u1HZ7xrlbAiXUbmnqk684ze0PxJnYj89+hb9xTJXDJt+vYtdXXHNmzDFbu+h08tgiGS+tZwUhVWy++0L7w4nQ2t3ep27f9kTahBElXd8oz97A3b5XKA1M5Z738uXLNiNYg0q9TxopV/og4QTSpp6ZXVb9lb7562gojcJZipbeqRfSfYyEIQygApa2q6drVN2aOOT6wAoAPzOu7DraemPQBQsIZ5V+aoMlyoJyFPyvd1GMUblG0HPqT83phJ/fPHnZHHEVaU8CN+3/HHfB4+wPmciTwqb0GmVh2WR9YfFIWpw2icjJyed4cGIqHFvaNVC0XW21B/Ju8HcIjmUsR6hHFiyLa6bWlFKwFjGs7hxeRSvNGQq6mvxt2ardIbVB8vq2GktNJ5olR2Dx7E3z72VWsoHWFCSmKMpNfrs/KFvFpWVkbZbBZTpkxBLBZDY2Mj2tvbEQwGUSqV8IEPvDvf0qL0+/2xhN8/WvJ4E4rLlStTFLOO6MKbDguKGUHNUD9aYo6kvlUMo05NoTxYhKtGErtAvg/G12VhyllJypo5lrPssewyN0wxPh162TcsHhRz9Y7ybLwpMpspgjqKqZWU8XpRKFMd5dmFnOOL2JR6Wdew82HMUHC7lLKViN4I4FtwDAXXASiTUkoiejuAB6WUr6k32uVm52KxKXgrgJ9OPCQAEVUcz5g+lWe6Hbm1HOZcGVUUd4ZRwCAKSYelfhmXcRI1cTlw/Yuia02nrPAWMfdiXVxfDgQx6/jUtz8/0HDlPDgRMOeFlFbJSN+7S4rY2sker3Y1d2ysffdpip/TScmAopiZ1WvuBxH8APBl/MuzXTTjCgDQng2/wPL2agDo1m/JEMH/wdrqLbvdrg2Lj4v9X3xILLSZlt9yxb8DRJ5i8vt7IPNLVofeurnZN3tjivL9D2kvVILgWb7iFztcrtzK+/Herb+hG9ejZEf1reEMCdn2gPbVrSvZ4Q39nA/c2FCbLzI2Y+qQPPr/3WNz1caUtK/p2N7Fd1i2os+W0iyYud/tEObx1QB0j+IfXldzU1eZVr2GiJgBK/O8emT3cRZegLF1ViAQ6Zw2fXvC40ktH1f35OFJP4qb9z2JN52a9gCgpHGEH0+HWaw0k3Aqf4zDMq9lOw58hD+en0c9cxjJ0y7gJmBu9bg7HvT7UrtcrkaD0WnNTWVahtd1yK61h4RsimKKIvGSdZWheuOjlQuOR0KLC+lgW4WlOH4/L33fbUNaQ8dt88SosHoVaSfqALsN57AyYKQUK/X6E7Xu1ljI1SyDalW5yvRWmsAt+U3n0/jfv/sGgi4/fv6uf8d77r8DObMAt6oj4PJbWTNvcU01GWeWRUKVkK6PfvSj/JFHHsHatWtRWzt5XBvnpaTXFx/0+2NJvy9mebxJVdfzFYxZDeOfuwtFAa6sE8HRmuhFW7EfzTKCGncGgXIDWt1FUwScdVmEZc3U2LpMUsFWqWT7YJ80Y3xFHm5+5NJnyPGtZhahWsS1csp4PSiV22Bfcv3T6M9eyXnOBiL6MYD3AegB8Bycz3UEwLvguCcn4fgM+aWUbZeihrPWdrnZuTj81/9t2viC2/VPEYVrYwTfcc+YywTfi4AwBLr/pRvSkpC2RGB5ADVvr0H4wTAyBzJwN7vR+DGHH5vYloCds1H1xgu/0fpTRltYdl2/QwwsOyZrXCZmvZbnHqpd/eKRGe8KSaZe8B8aKXLRUvqnYcjS/Mke9/Lg4HWNH9POVPZMJCUDQNuUXVsbGztPJqHfivt7LFJbAUB/cqiDbDkXONXsfLmqYsujft8GzZSFn/2bzQlQn1+5aXvRHVrlTF7+sIKTmr2x5dMFIhbaxg9v6eSDGzgvpVaueijFmGz+Bv5hywFavAFFe0TfGs6TRNt31G9vvl7ZvjFHlL2xoa5jSOUrdUPm/s/d9t6WKNYJYtahWbc+F6leuhZEqrBjvUbm4ShkbhkAlGu1x9bV3JjycP8yADBhZZ/nR3cdU4bnY2yyoOu54WnTdhwprxhcPHFKMzbtifegbelJ/xkpBRsp7OVdmSJlrYUT4xgYhH01233go/y3mSV0bKYyiddNP+cDD/p93b/3eVxhRZl7pq9NY1T2bDgo+lYelmp1EjMnyz2zmVpIlM86OhJaMs77mXE2FZ6UpbQw+7pssystrQGXFJkWQJ4vLFb61cr+GlfLUI27pfjD7Y9P+3Xn5rp/e/PnlU1PfQcj2VEEdD9q/VX49fu/jxvu+WtkS3msbFoERoTnenYjWUzLOY0zkp9+518fnCw643zQtHzE54uH/f7RlM8fEx53Wle1QtVYtMZFT9PTCMQG0DTSi7bkBEm9Jwtvle1EcFzc5EJKm4p2hHLWKGWt7LgZIxVtN0wRgC2r6SIy686BN/Z8/bonXoXXeQmIaD2AegA/gTOZfgLOZPC3AG4B0AbAD8dQcPelqOGstV1udi4O8++aPxtOmNllvAJIKSFKAopLgbQkTnztBGrfWYuRX4xgypemoP/7/QhdF4JWo6H3zl60frYVxP98KUpzeuWh618U0QXdslm18Zre0QBAMtB2uH3ebQVT8y++mO8T1sgxI3OfG5CTKrPGwj2HOVNnnHa+M0jJALB23b1djImpABBFaOjT9P2TEwf9D4Oj4zLhbv2WNBECPw34n/9WZfkaALjrW9Yht4E5fY1veP74tBvXSCllKfkffYBoWVzxhi0zgss2SEhxt76l0yR7biAw0rlg4R+ngKB9Ft/dPkJ1q1GwhvVnRwySaPkiv3frx5TfrgOBPlVdteUZr2cjANy4TWx711axiABvyt96ZO+iv4VQ9JkAYBX3bbcKz7SMk7IbPDP2rgxd51KZNhtwjPu282O7jihDc0COEosxM9faum93Xf3RFsZEy/j/99S055pag/RTPztL5JT+3D7ek9VhiMWn3+lLuZ4dOHib8lh8Jeucykm85D0xgNKTXs/Bh/y+3D6X3mIRtUx8nKQUMwZwZGO7GFlyXPrKcpgz2XpFgkQ60HI8EloaHq2cywvu0BQQO2tDI0U6bJvdvcI8URRWOABZmAqcnWdy/4592NM3hHKPR1wxZU54IJFWu0aHgkRMsYWtXDV1NYQUODrajZxZxLbb7sfHf7UJf3fFh9FWcbpFzPmjM84HKVyu7JDPF4v4/bGszx+D2532qGopRCQaiC4+EkKAxChC4X40R3rRlu1DizWMejWBSn8B7moBVvOyOJe2yFPeHqGcmWBZK0dZS1DeYlSyvTBF+QWuy+b2fP26S3YNI6JWAFsAHBlTY/0BwI/h2CH8PYC9Usp3Xarzn7Wuy83OxWH+XfN9ADKvdx1/SRAlgRNfO4G699Qh/GAYU/5xCvq/24+am2qQ2pmCq8mFwJI/r9QIJqS95Lg8+JYXRWrmAKZNtkp4LVDUy8IH5t9+POttWHOxpmZ2qWOnmf/DLOCs439xfdPtuz08sPzMByaSkgGgsrJv75y5W042Wo/i5m0P03uclZgtC64nh06uv7r1W1JECD7rdh34eG31AgD4p3usrbP7sd5S9MzWdd/SQKSb+ae32KV9GxiYcVPrZ0YYKU1RSh/7lbazFQS1rW331samQ+sNqMVP4EfH8uSdT3lrUHtuRJJE418pv3vhy/xnS4mg3R3wP//NirLFIHI3R+SJf77LtnUL0wUxs2P2h56PhhatBRGX0siZ2cd2CqtnLZw7VzkruOKF+eXrmxk5Un0LdmEHP/biYWVw9qmpgxS1dcdebG3d61VV47QJ2aTTHgAo2hF+ItOpDOVryJYvmQCuoM5Dt/HHIlew9laNrNbJ3qAulfc+4Pf3PuH1eEcVNu9k4OcYuC2NBSdk58Z2mZjXIyu8Jcw5m/JonPcTrVoocr6GekEv5f2MQ0oppR3tFuaJYdvssaUdrQLMaQA0IST+6ddPwLQFPv2/1uHu53cjZxgQQuKf3vZG3PvCPpHKG8UydzAXy+ZcJdvUF9XOoZ7kgPofb/kHzKmeNtkpX4Lx6IxhlkxEKGUnWM47Fp1RjwuUhRMJ0+1OD/j8sVG/fzTv88WZy5XxqapRA8i6lysvN6AWR1A33OfwhfL9aBFh1LlSCAZLcNXhlVAeDDtOOSvKclaKsmaBchYob6tk2H7YspIkZvd8/br0y379c2DMUPA+AG+CEw9xE4AaAA/C+X0pAlgmpey4FOc/Z22Xm52Lx/y75idxieS//5MghUTXV7pgRAxUvKECte+sRfTxKFIvpOCd40XVm6sw9JMhtNzRcv4X+xMAt6Wx5pDcf+1OUWodwWz2MhUarwZspuUOzXr/zmho8YpJ7frPAzP35BbbOHAFzsEh2lj77i017pYNZx4/qgy9uFXtXDHx2LLlj253u7Mn1V6fx79vG6CWtQBAGfOE/nxkyvhj45Odfs4Hrm2qbwSA67eLbe9/RqwFgG2rvrqz5KpYLmUpXUr+JwHwzwqu3LawYuNaAHhSPbClR4luAIDx/K00ArFP4v/P2sRbKGcNaNtGiCQarmPbd39X/fZMIvh2ufRDH66tLhdEdaoli5vusXdOH8YVAJAMTOnct/Bv+HgmmLAiXUb24QxkcRHgeAstrrx6+1T/woVjf/BhwS7u5MdfPKQMTJ84ZQgGwx3Tpu9Iu93p5ROnBjl4Uo/iHfufwptOn/YAoLRxnB9PD7DR0gyapHFeSF3HbuO/GbyK7W10kTlpN1Agyv/e6+l42O8rdujaFJuo4cznuAyZXXFEdm5ol/kZg7JOszD9bFEjJ3k/1UsKqUBbpa24Zp5rdSOlVRLW0PFDvX80f7Xzd1MlbM0WQs8ZBjyqCksI/MNbrsJ3ntqGcq8Ho5kcNs6agt/sPwyPpqJo2PZXrnnvwZUNy5MVep3brfjqxxvMi8GFRmecD4xZBY8nOeD3x2L+wGjJ600oup4Lcm7UEr0y/6scPKkhJ6U+0YO20gCaKIpqdxb+8QiOl+tSnwpfueiScUfHDAWPAdgEh69jATgCp4HOwwm79QP4iZTyry9VHZPWdrnZuXjMv2t+O4B5r3cdfymwczb6vtOHuvfVwdV4anU++ONBVLyhAoWeArIHs3A1uVD91gtaz79mcBkye+V+2f7GPULWxzGPzjG6fy3gJJK/+fmeljdPO9fa4azfL23TyNy/XdojV5zreQvKN2ydXbZq/ZnHLdjFu/UtEUGnZKW6nh1evuLR6onOs+/Hg8OClDoAYEP53Vp7Yun4Y+OTHQuwFrc2MRCx2rjs//YP7CYA6G655rnutuvXAUAp88BWaQ2uByBvavnMUc7UmTaEcbe+pc8mMU1RzOyq1Q9GGRNt/Wjq/gLuLANROWXNXm1bRCOgbhXr6LhP/VodI1kxoigjNzTWjeYYmwsA1zoOzvMICAhSjINzP/LCaOX8dePRGVZx5/NW4blp48GnGnMlV4Wu31/rbltFY1MUG6K0i3ftOKj0TZN0qlFxuTKD06bvOF5WNrz4TGlxB+Z13ItbE71oW3JasyqlZJHift6VyVDGXDjZ520m9XXfxh/rfRPbWeOl0uyzvYeHNLXrgYB/4GmPO5hkbO5kjUowJ0fXdsij6w4Ju3UELVzgrHJhm6mFePmsI5HqpalE2QyfoQWmT8b7+c2OH2HzwUdh2gY2zLu+VObmw7/e9YtmlTEBgrKirYmGk2mkiyUsbW7AoeEIPvmGNbh3+15cOWsq6stOvaTGXMkqV2NvrbstFdIbFZ9aHlKIt9HF8mVwcdEZ54OiGCmvLzHo948m/f6Y6fUkuabnyhXFajhTaXexkIBMojw6gKaRHrRl+tBqDKFRiaHSl4M3JKDUnS3aBcCB8JWLFr6S858NEwwFrwTwmJRy3thxCYCNKbGaAPRIKV/zMO3Lzc7LwPy75j8O4M2vdx1/SYj8MgKmM1S92SEhF3oLiD8VR91769DzrR6Hx/O9flTfWA299vweG5cSvrxMvGmP7Lhqv9Cq0ljwaob0vRJEqhbtOTT7A95xjsnFQopCopT+Se/4tOJsaPTM3LOm+oYFNAkp/0xSMgDMnrN5c1VV/8bxr/vR3P0FuvMkb4kfST3Le7Inm6sT+i3JcbO1ha1NYeHIWXH/160okwiZ3JN8du2/eh3y8GgBf9AhAAAgAElEQVS3kb67FQC1eOfsWlV9/TIAGGTxg79T984Bgfl8sWOLFj/eSAT3XizZ/2/40iwQ6ZQ1e7RtETcBNbOo78Rj2pdcnER9iVB8V33d7i5NXQsA9THZ+y8/sfNuE7MBIBGcdmj/gk/qQlGnOj+3YsrI/XqftAbWYYxj4+VlA1fU3NgbUKvWjEvxbQhjNz+xvV3pmyLpFAdKUcxMa9uePbW1x6Yydjo36lzTHtiyoPTn9vHerIKivWSy9VMrDfc7QaXbK/0ozD3b2iVDlP6tz3voF36fdURTpwuiSf1zauJyYMNB0b36sFTq4ph+LgdvCbLTgdbjI9VLRmIVc9WCO9QmpKz9+3veiWl1C7F8+hvwoye+Cl11wRYWvvWhx/DTp76G+vL61AtHfs8ZLLGstTG540RXQ9G02PSaKrx31fkpZwRmlus13bWu1mi1u8Uq00JBjblb6WWuhi42OuN8UNXCqM8XHx4jStseT0rXtELlGFH6FecK2mBWBDXD/WiJjknq7TDqtATKAzaUA31XrbokURFjSef/DUdqfh2Ae+FEREQB/LOU8p+J6L8AfOxys/Nngvl3zf8ugE+83nX8OcNKWyCFoHgVCEOg5996UHVtFQKLnLu23jt7Uf/BejCNoffOXkz5B4e0XHVtFdzNr33OaGVahq/dKY6uPyj9gTzmX6yj6qVE1lt/Yv/8j4+WXOUrzv/sySGs6Akjc68CiHPuDINq6MSbGv6qkiax6Z+MlExkG2vX3ZeaONa/Fx/Y+jjdcHIqpO4Z3axESxvHv57Y7KxqaewYn7L8539aO0JprASA51Z/bZehB5cBQDH5g13jSqm3Nf/NPl3xLAKA36p7tg4rifX/j73vDo+jvL4+78zszlb13i3L3SvbcpO7wUAIodeA6YFQk1ATAiGhJPQkhISEJDSTUAymQ+hYkiXZki3L6r13rdr2MuX9/lhJ7Gp31Sxj+H0+z8PDszOzM3dnrZ373nvuOQCQklKWn5pWvhkAPsI5Ba/jio0ghBCL0Kws7NcTIDqJGLu/Ut7p5ImYDgD3R0XkvKfTbgUhDCdR931vSAeWtWMrAMiEc1Usv/7AYMSy8SqPLHbXua3vuEG/4eRE8om1m2PPs6tYbdb4vYYsHOZaDpSxbWljY/mje6SEhPri1LQjIRwn+KlYV8JQ9RquGm5DWpZfa9IlDXDNliq2yx5NJBrQuy8Rxp6fcJ/Un8fmh4bBmkmCtGwoQMt4Zf0bIfrePLU6wsKQpQErBZTS+b1o3FYud69poOpIC5aQ4PwuAEC+pOz7Q0+XRqEOE+8479mhT8reml/fVYq+kQ48vPN1PP/5A1i74BR8VvoqTllxCfKq3sdtZ/9Z/tenv7KfnrmhNk7vdFBpIBoQ5mOGOlRaLrQrRpXaFadOc0Tw8SoNp08gYJImOsRPFxOtMwZGrTOkSawzJgelPG/r0ekH+/T6QYtON0g1arNaoXRGEyInzdSoNAj+suPkpmMiiksIuQDAHgASviHWVwH4EsDP4GmJ9wPgKaXfugzLiWRnFjDsMtwK4K/HO47vM5wdTnT+uxNUpgAFQteFIuYcT4vKXGKGs8OJmHM9r3ve6PG0sZJUSL7xmJn1+iFxgLadVSS3ZtfSKLUbS4NxF44X3ArdYMXyn1aZQtI3Ho30gccb6uPJ1HMBADyjGTw75WYbQ9iArYyJpGQASEyqKkxPP+xjEno7nj3QT+LG+TvK/L5CxiaOH9PMXzbMEI+T9xlJ8fs7FIoNAHDTR1LOSRV0OwA0zTtrX1vq6Vs88dceEmz/WwN49H5Oir90GeDhZrzC5w2NJRSrsj7K1+mGNwPAs/hFbiHZug3w8GGU+43hBIgMh3koj7+9R08cywDgPZ22+P6oiCVj/kMnH5GLbvhEXkTgScaGwhZWlWXerKaMIh3wEHNF5/58yXlgKbw4WynaJSVro36o955akyGLR9jWA0e41mSZUJ8kMyy8uzIjo8iqUlnXTjSe9Kr2xLsJvwATQCxCC9dobmOMzgxCA5vDxmDYeA33ac2FbJ42CqYVk00cjTDM8Ps6bc27ei1tVigWU0ICctEYmYrL2mjNSeV0MLOFhukdWErgW/n4zGJGntWKgw4HXkxKRp5Lsv65r1u1Oimrp36kK3pJynpl91ALAwr85LTf4blP7sUd5z6Dl776A05d+WMkRXokhSgVnbLY1SgLTUOy0M5ReSRxqkQ9EBQMb4riE1vj1PNMUaokRq+IiOKIYh6ZQOSeCWRQyURsnX2Mqa+PGXEMEAtnIc7IUeuMWQoLyqJabenS6weNev2ATasbImq1RcdxrhhCaEKwxDUAfr7j5KZj8uyaICjIwpPYlMFTGJAB/BMec9B7KKWzXpjNOr4Tyc7MYdhlOAUe/YAT+D+GjC5af3aR3LOqiSbwIvweJN8FyIRz1S28eH9P3MZVUxohTgHBnpMnuQ5vxBSVKgaM++yUW2t4Vh2w3x+IlAwAGza+UcFxwnilQwaRr8BbJoz6PgEA/1V3JRHpOAfOO9m5Li4mt0it2gYAWQ1y2T175BUA4FboB/I3PhoOQljPGPozLaNml/hR0g0HdIqwbABoZvpKvlZWrgY8hNLsDW92sqy0AADuxVP5bWTeZsAj8KcsMsYQIFwLhzWXv70+ipg9LudKRePOhDhe9PANEDNCux5/URrSumAAPN5UFctvLBoKX7xlbOKNyo5ht/XdSir1bsI3JG95adjG/cvCNqUzXvYNMqhUzrYeOMy1JMjEV2hNpTZ3LFhwoCU0tC/L205iDJUwVL6Kq0baA1V7KKXMgKuCazKbiEnIDOapFgbL8JXs51WXTjAqDQQZkItVfM3uEP1AoVoVbfeYlwZcBCgF6ljTQGu2VVDz4g4aqxKw6DOLmXl7ZAQNLjeGJBEKQrCA57FWo8E+qw16lpUHwLmuXX1p1QcdFWm1fZWRDGHIosTVuHrHvcHC8nxc2TEsi23NkrvJIotdWlBrGjBzojABEcOUsS2x6tT+WFWqGMbHhPCMJpVMU4AzaHxBrDMETxI0UzPPb+JlRKdGY/IQpfUDDq12mFOprCGjROmJJMczdpzc9MnRfI5JYyFkH4DrAKQCeB7AbgBPUkr7CSE58NhIvE0pffFYxRA0thPJzsxh2GVIAtBxvOM4gTkApdTQSivPKqJDy9toGifjOz361ZG4fX/j/POTKMMeVYmLUll0W94spFK3H8k4EH6QeE1+mDJmc6B9gUjJAKDXG+tWrvrUhz9Uh8W1D5E/+IxR85919RN886PczO8cYgiNAIDfR4bn7g7RbwM8hqj/eUpSjrUQ9218rHRMN0iw5+ZJrpKtwHirLXXMsuAdZVH+EGPdDAAazUhL1uoPowiBXgQr/Az/qjCTsCzA41iuLB5IIECoAqL7c+XdJfOYvg2Ax6/u7KT49hGW9UxfyVT81VtywcpmunWs4jcYvqSi3HCjnjJc2thnkYSOKsH6HgMI40RhhrDONZE/KErTLV/p3Q6UQaUKtr2ohGuKkwkdn04DPITX9PSSI7FxTQsI8TfwtEFjegcXl32N0wJWeyBRF9tlK2VbrIQ4pVUTKy5j0MFuvoz9uuJy9ks2mfSvmIpDYmQZ49t6Xf2HOi3T7rGxCJp86xx0JP4Tc+eHH3YufTs9rSuVVSaf0tSIH+j1qHG58N+UVPy0owMqhuDB2Dic3tKMfRkLpVv7h+wXGM6pCUk7WXKoo9IxhR+XN2RppEsWmttlocUtS33hoM75mIHLuTc0bEhvjDqlI1adZovkE1QaLiSeAZMy2zaYNyzE0dNPTN29zIjVyJgZM3GEuSGm4CjJzCwrWLTa4U4PUXrAzXLCtRdduK/5aOMNhlHezvMA0uF5Rm6HxwD0FgBJ8IygX0OPQ+JxItmZJQy7DBbAf6V1At99MDIV19XTih8Vy5aMbixkKWY8tfRtYyhsUWXl8uuoyGkCqhjPBFR2mlzmlxtB7aunPhpYH/2jnDTd8u3B9gciJQPAylUf79Prh3ymup7Hjbl7yanfHCtRF/9lt9K7RdjM7xwcs0h4Ta/b/2hUxIaxfa88JdaoRonCDfPPz+tI3rEV8Lh6u0b+JmG0enFqwlX7Ivi4LYBHdO5VPs89pnmTmFhdmD6/ZCPgSRJuwQtGgSgzAIAMuaqVBwcSCRBKIMt7lA/mr2YatgIem4ar42P3l6v48QRxc5V86NYP5DRmVBBRYhSOcsNNxcNhC7+p8lAqi468fMlVsgJe1RUlox7aGHNOZYwqJZt4WTVQULmS7Sg6xDVFS0SeMEYui4lJNcWpqeXhLCsGnLSqQGbla7hypB1pqwOOKLulYa7FWsF22iK8K2oToYbLfhGbW34V+5k8alQ6afVBBMQCtap6d4h+uFjFJ7gYxi/pstXb0PpkKxY8sgCxDNtz6N76yOwQzUCv2R29JzVNsa2pEX+MT0C+zYYvrVZ8nJ6Ou7u78ZOICCxWeWgwdnVMx6jeD7XqEhLHWojTAaWyRKW+Zklo7pOFVkqlwVhATMcsOXgcUVijVEktceq04WhVMtErIiI5opxHZj8a7gMbnP39jLmrlxmxGBkTMRF7iAtiEmbgAeYFAYDmgQceEOciNm+M2kScCU/rKgtAN4CLADwCz3OyFZ7W7+2U0kNzff1pxXgi2ZkdDLsMhwBM62FxAscfCpE6t1TS8h8ekoUUI5YSIHzqdx1/2NVRneWGmzvsmtgNUx89NWRpsM1t/q801vKZChn6rP1ZkadkB1u9BiIlAwDHuUzZG95UTDQmvAX/PjRCItaMvSYWoZUv7E/zPsY72SlS8VXXxceOk3Uf+o+Yt7jTQxJ2KsP6Cjf8PmasjeK27MmVxfZtAKDhQnrOTLoxnIya6laznQcKFXXjPCFvQ9J+xHTdgWc5OloxYAadlYpDg6ljZNu/K57OOYMt3j723icjwvJeCdGP86QizbT3iRelXr0D41NsAxHLyiqW/zSMMtx4pZDKNqPb+nYdlQY2wSu503Ph7VviLuzSceE+95mC0mq280Ax1xglEdkvcYiI6Cyfn1Hs4Hnb2kCcDRu0pndw0ZGvcFqCEKjaA4BYhTau0dLC9DvmERq8qqmE4DqHLSjzGJW2Lx8jkE+Gbo7teUuva/yfVst3c+zSzhe7dOaDZlBKoQhTgMoUhCUQLSKUUUpgWBTDGNb+Q61+MNdoTtmq1bEFNhsW8jyeTAiuyelW6AYHojIb+6OznKaQtCiJVS2ciVUDpYJdFjubZHfTkCx2KKlsSgLkWVdOCYgUqoxujVWn9cWqUoUwZYxOxWpSJtqpHA0ccA/2M6bOXmbEPGad4YSQhMn1fWofeOCBoFIER4NRmwgrgFfgUUm+BZ7f2LsopbmEkGsB/BbAhSeSne8ZDLsM/wVwTEb4TmBuoHZS8ylHaOWppTKJHUEmmWX5+nhAZFXmyqXXlg5FLM2eqHo7W0juxiOC7YNUTDPRi1YlVZ8Ud9mkq9RApGQAyMgoyo1PqPep9ohghauw2z3uAA6A6bEfVpYPZ3kf18zvHGAIjQKAHpbtPS0lcbzyds5+uXBnjjxOZs7b9GS5qNBkAoAsDXe4zS8lYpQjszX2opx4Tfr2sWN3KwsOWBhnNgAQIrk2bHyzeaw6UoslNQ/j4ZSx2Bijs1xxeHD+2L+Z33Kv5F7Dfrp1bHT7S4269I6YqDQ6yj1iZCrd9p6cv76Obhkzc5UYpf1I5i2HTKHzt3jzWiShpVywfqgGRJ8EJEaVUrUx5hxhbJpsDBSU1rJdRUVcQ7hIZD9ZAY1mpDVjwYH2kBDjmmCu11NWe+BJ8rhGyxAZcS+fzIOJgyj8kCkuv477n91AWpaMfVeTwQ24n+xg2nZ3gq3aZ05b+o+ljGSX0PRQE3TLdJBs0rg9TP3d9Uj9ebKsP+TodR62KLIoL9wXHhNOML2xbIlR2ociFtf3R2eN6f0shJcJ6XRAZfugLLS2SEKzzcP/sc3DUYqEqlldf4wqpT1WnWaLUiUqNVxIHAM2lcxQ2XwyOOEeNjLmzl5mZKSfmKmXdUYcgPceeOCB8+bqWhMxahPxEYBKAJ8B+AuAUC99nVoA204kO98zGHYZfgPg4eMdxwn4ItRGB04/JNecVE7V4VZkBuMmfFchE0ZsSj+nsCPp5KUgzJw5nwqOgn2Ssygb0xzX1XCh3Wcm/ZQlk/AjgpGSAUo3bX6t3dsLCgCOYFX5k+Q3md7buAbTPq7Z6tPqauZ3GhlCowEPIXZFWrI8VkVJGKRtT/9LGj9v3YJLcrsSt44nVU7Tv4shW9YBHsG5c1N+TsZ4MTa4+l/n8/kxHoRKbe5Ys+b9kDGRt73YUfw8bloz1n5i+h1HFKVDC8e8hq5nPy68l3t13M28WcG1XZQQL3q7jq+tk0vvfFdOYCjG75sxMvNI5bLrIr15VpTKoujYWyC5yrIwYVx7ns5wcHXkaREsw/m4mQNAHdtdvJ+r14tE8luhc5xzOH1+SXlMTMsiQgIbc3qqPReXfYVT44NVeyBTge22l7LNFok4pCziMXIMCAaytIM5XHE997FpNalfxAa57hjeqRFw5bsOVP42ov1lTtPxyCM9a8NPiSDOdpci9oJYDHwxAHefG6m/SPXR14o/O9qdbVdWby+npmXtNFLjwpLpOoRTEMkUMq+hPyar36P3MzPez/htkYY6ZKGlc5T/EwHqysA0E7BgYAlnj+QTW+LUaUMxqhTolZERCk8bbJZTW4HhhmgeJrZHVz965mNzeV5vjCY7H8OjnJwO4BMAj8OT/L8ETwu3H8ARSukPjlUcQeM7kezMDoZdhgsBvHW84zgBIHqEdp9ZLDdurqKhOieWT/dH8LuGntj1B+sWXRohMwq/h9xsQSmVBevb+8baO9MBRxTWc1J+1sUxiqDihMFIyQAQHd1yaPGS/DUTtz+DO3KLyCafOBSHB3NZo9Nnm3dlBwBWpiV3eVsbvPGoODDGkXGoIrv2Zz80vk9yN5QKtg/HlefWRZ2RM09v2D72uoRr3lfKtYwnV3FxDUULFh5YP/b6FVyT+xk5czweptdxWFE2tGSsqnAOU3DoacWzS8cqKBZCzOcmxdf1c9x4dSvUSo1PvCi1h9u+aXOLLG89knlrqTlk3mbvKg+VLb1uy54WKg/7tCkJiLQ8fHPhktDshYESzgam52Chok4jEMlPj4cQWUhKqipOTqmIYlkp6HdYgcyK13CVuR2pWUHtBwTZxLVay9kOawgEmjm5/AKlW5iKqhvYjwazmeqARqWNQxKWPmtD3a06JIYQpD1thZYHnTdf1a87O6blg8c612U8nMFMpa+ldlLz+jpau62SOjK6Zz45aVPHthujV3UYozNlqzYhiTKKGZvzUiqLVOod4/8QKg2N8X+O9vdHDlVEtcWq03pj1anucGWsVsVqUwhhjlY+fmfSY1teO8pzBISXJ9YOAM0ArgUwDOBdeJzOzQD0lNJvXyRtLMYTyc7sYNhlWA6g4njH8f8rkvtpy9lFcvu6Ohozpmz7fYVZn1pfZrjRKihDsqY+evqg1GVxmXbVglr92kyTQD4z+aZDWi5kUh2MrxQVOS1s//ZA+9ate7uYV9n93n8DXi6zEr3P6PpEjR0AaOJ3GtnRyg4AbExJKrewzHhF6NlnxeJoM8bPn7v5j9USpxoX0nMOP9Mw1iJiCec4P/V2E+NlnfFfPu+wkwjj93q54Yvc8PDe8QTn93gwt4Ys/ybh6bGXKMqHl49VODYzFRWvKB5NHuOtyIB8U2z0vkKN+pukjVJ688dy3rYKuslbgLI/etXhqiXXxFKG9fGlktz1hwXbJ+GA5PPQZQlnXxv1w4Mp2iVZJEArppHpLSlU1CndRAxIXI+MbD8yP+OgoFTa1wRTT55WtQcAsYmdXJO5ielzJBMZU3K+1pLamhu4D/u2MhWpN35gmfdRvYgwFeASAZ4jMNpk8BzBafM5vHKeGqe8YoNMAUbNWFsp6+i1U40oQaNKVpGp9LXCrNS4uYo2bK6WpZR+zOPkwPpCweBW6AaNUSua+qNXOcyz4P2MgVK3TRY6m2ShadjD/zGnALKfB9lsoGK1xmhVckecOs0SxScqtFxYLEPYMU2b6WBF0mNbyucilokY9cSqBnAFPARlDYBV8PB3fgTPKPoblNI5/Y2bUYwnkp3ZwbDLwMOjGfC9rCJ8H7G4g9aeVST3rWimSUoJc1b9OF5wKsP6yg03NFh1yTN2JJ8KsjTc6Tb/xzGRFzIVtsVdkhunTpu0CmQi9o63lPujA6nEqlTmzjVr3/cTOXOBt1+LVzl4TR0BAP9VdzkRqU9rq4nf2c8SOr6KPSsxvrBVqRhPiG75UMrdVknHY6xZdHluT/yG8deCI3+f5Cwer94YwrfuWxq2Yfz1aPyR3wi8yeKGjW/WjOkBySDy7fj7wQESM17xYbrtBxUVwyvG2qLLSEvjB8r7tSyRx/Vy/hUakv/X8NC13hyrzGa54tdvypHervciy1tKV/ziiCUk1ad9R6nkFuxfFMru6nWAL/dGxWqNG2POrYniEzcGsuloZvoO5ytqOTcRMyfuAwCtdrg5Y8H+Lr1+cM1k4+TlWFH5Oq4caUdqUG4P4JlaUzSajWTYvYyMVtkmQ1zrx53nKg/2/vODkkytkigLrtXizNft2HeNFjvfseOcRRz+1yChdUSCJBPsu1aLH++x456TVLbGNH3V23qdq1qpzJAJiZ/qWgAQP0jbt1fIbetrKRc3jIUzNeUd4/30Ra8eGQlfGOJW6BfMlPczBirbjJLQ2ioLTXZZ7NGB2tIxRwMSLOEcEXx8S5w6bTBalUJDFVHhCoafRwiZOCksANAmPbZFmIvremMST6z34RHf/RrAywByjoe+znicJ5Kd2cOwy1ADYPGUB57ArEAolVc20YqziunIkg46n53hau27ColR2msW7TzYH7N6jTdZd87OL7RWCNZ34jGNh5A3DOFb9i0N2zipASgQnJQMAMuWf5UTEdG9feL2QmwueZbc7je9yH/W1UvgO/o/Mdm5MTY6p0CjHj/nmnr5yC/flsdJvDZ1bFvR+t9+M/VEBYdr5K9OjD5QCIh4QdodHSzhxqsm+Vxtbi3XNZ4gjZqVKsnoSK8LvP1mPN/qJJrxihHbaSvmqkZWkVHeUwrp6/xSebegJOL4eQtVqoob46LjKCHjlSmdnQ4//pLU4F2NAoC+6NUlVUuvSsCoIeoYZGmkU7Du6aKyeT0mIEQR1bIl9oJ+nSLMbx8AtDL9pfsUtYyLCAHFHxUK52D6/IOV0dGtSydz5rZBa3obFx/5Gqcljo3lB4RMRabXUco1WQRiF1dNRiIWTX3o230/lEQS/n5N5oE//vfrtWU3aFQXvOnAkINiTQKLVXEM/n5IQMG1Wlz2th2/2sRjRdw368kKpbJhd4iuO0ejDjcxzNJpKYdTSjO6Ub+9Qu5d3UA1EVYsITOUDRnl/dT3x6w2DkYsVY7yfmbdVpKlwXYP/6dZlCXjGP9nrjz2aIgisj1Gldodq051R/BxGiWjtqU9cfJJc3R+H4xq63wFz3evhsfd/C54qjpqeBJ3I4ALKKUHj0UM04rzRLIze5yYyJp7sBIVsmtp+Y8Oyvb0XiyezGjw+wYK0LaU0wub5/0oHV4KunMJ0VFUIDoL1mASUmkgJGkWHt4Yc25Ac09vBCcle5RcN2163U6I/yTPE7gvp4xkbffZKFM3/0U3R+BbBWrid/axhI7zVB6LCMt9NTTkm8TETW2v/FFSeXOzcrb8qc7bANVteSdXFlvH35Ohz9q/OurUcV4MBZVf4XNrvDkv0dEthxYtzl891u4ZRpjx5/inSybcN6ad7dYDXI1pzVhrKhKmgTz+dqOWOMdbqV0c231eYrzZwTA+C6FrP5PyfnCYZnuT5gVWbSpd+YsKqz7ZT7BRclUfFOyfxwKyHy8qVp1WsTH6HChZVcD2VTszUJanqJadRAjonEmI5EpOqTyYlFQVO6YoHQzlWFHxGq40d0zG7QEAQTazbdZyrt2mhSCvmPi99r/9EBxNhwBCwGrCoExcBDLYKqRoXOYNUXa53yJEf3SZBnd97sRnTSIyYxm8en5wnq6JIaYPddrqd3U6uUGpWOidYE4GVqLC8lZas72CDmW20HCdE0tmM8hgU8e29ces6hyIWkGt2vjE2fB+xkCpJFCpt0lyNxllsY1QaShuVB5iriq+/7lz90dXztG5fEAIWQPgAIBNlNIiQshf4OHonAdPVecXANbCo6acfjwEBYETyc5RwbDLcBuAPx/vOL7vUArUvr2clp9eIsuJg1gWTNb++wxjZOaR6qVX8xLLHxN+EaWUCrb3c2WheftM3xuqiGr5QeK1EYHMPb0xGSkZAJJTyvPT0soCqiz/BP+tcRK1z2cnVqGNL+j303Zp4nf2ek/1vKXXFj0UFelTyXjlKbFOJWA8ualacnVuX+za8eRGlkxdbvMLcfBKiM5Pva1awfDjlRojMTe8rzyYBi+DxSVLc3KjojrGz9OKeU334ckob2VgttVayNWZ1o8lW1o4LHn8bY2RxDKeWDgIsV+YGFfWPurrNX7+dlp9/+uSjpPhcw97YtcdrFl8RTK8uEWAxwNKsH1SJAsN2QiQwM7XryxaFbkjxrtq5Y0OZrA8T1EtOIg7qCZYVHRryfz5B6FUOifVDZt2tQcAHGIP12SpH/7HA6ucbWUhrCYUMRf+Dv17HoR6/lo4mkugjJmHqDPvBAD0vnYPwmLirFtC+7tN7XUxW5IQev82ftrKxBSgJTxfuztE17dPo462eWwsppUo8G5qW+uxtbAt6qSxvIBFs/HBcyv0A6O8H6c5JDVKYlWLjsazjlKXRRY6mmShySSLnTyVzakAne0i6Y47d390TJ5V3p5Yo6+3ALgHnr+PxyilOaPbmwBkU0qNxyKOKeM8kezMHoZdhi0A8o53HN9HaB3UdJqtr68AACAASURBVFoprdxxRFZEm2CYrobG9w1WTXxLWeZNRpcq8pgZ31HqtrnNr1RQ2Zw99dG+UDLqobNTbrGwhJ3SJmMyUjIAbNj4ejXHiX6O21boRm7AyyETHz5Mr6NUWTbkV3lo4i/vZYk8/tAv4fmaqxNifRKlh18R8xZ1YVzJ2KJNbDq49l4fHpfL9MIBKpvG70miZmHp5tjzfK73paI8t5U1enGUZCk7e0+5QukaP+4g1pc+jbuXexNW2RZLAVdv3jBWvVBCcH2hvLs0lekfvx4F6C+jI3M/1Wq2eU9gqZ3U/NjLUlX8MHwSIYFTmw6vvL3SpkvcNPGeyNJgm9uyxzjm7u4NAiJmRmwvXBSyZkkw4bouZqgyV1HltBO33/vHoNUNNi5ccKBXqxtaS8jklcEyrKx4HVdMWe1xl5WAONFqevL+mJgLH7Ib334wilWHIG7nEzB++CRCsy+C7HZg4L1HEH/tP2B852HE7XwcpncfdN20Nab8toRyJnoKo9JAGGSYgXf1urr3dVrSpuCWUC8vtqmgt9OhjdW0bkuVLMzrRYpCRtpMrj0GiVHaByOW1PdHZ5lGwhfq3Qr9QvhzaWYEKlv6JKG1TRaaHbLYowe1z8f0Fofb7tz90TF5Vo1OYjUAsABwASiAZxKrCcAFAE4BkA2PI3rKicrO9xCGXQYdABPmrtT4fxrhFtp/xiG5dlsF1YXaYCDT1Hz5PkLgtMMVy6+vGAnN2DCbqY7pgkrmHpd5lwkQZswdm8rc0xuTkZIBIDS0typzxRd+Y9AA8BVOLXqR3OjHMeEazflck8WvEtTEX97jTfwdYBnjSSlJPg/xcwvlgstyZZ+kIGfr003eY/uSu7lcsL3nQ9g9O/mWEjWnG69gSJDdr/C57d62DEqlvX/d+rfhbaL4Li7M30Mu9YmVbTLnc42WTWNVAAJZfk/524IVTLMP7+kNve7AHyLDMycade7cK+07+wBdSyZwNbrjsotrF+1MC8QJEV1lB0T71ymAvz8WR5SW9dFnlCRqFq4LptPSQ4arc5RVVhtxBU2+FQqHMSOjuCoyqt1AprAlsEI38g4uLv8apyYEq/ZIvd0YvvfnCP/D09Lw7TcIDBRi3NV/IwPvPaIN33ol+t9+GCHZF0G7cAP69zyIuMufhPGDJxGafQGUMekIhXXEY1T6tSLeY1Q6oxatBEj71arq3XrdUJFaFedgmKDj+IEQM0K7tlbSlg01MkkcRIa3htJMQEEkU2h6Q390Vv9g5DKFQxU5/2h4P4CnokvlwVbZ3dwtiS0SFY2RgDsDvlVAGUDYnbs/shzNtYJhdBKrFZ6pKx5AO4DL4eHM5cPDHayBxyri62MRw3TwvU52RqXg8+C5wRyAPZTS34260+4GkAbPl3AxpXT4WMRg2GWoAuC3mj0BD+KGaMdZRXLzxhoaoXFh2cQ+/v81yIR112dctL87YfMKeFY8x+5aQke127onEqCz+vE9LeHq/HA+NmDbaSJe5/OLJ3tAZmV9mK/VjQQ810N4OLeOLPWb8FKUDuaw/c7tE7dPrOxQgGamJbu9p5wSB2jbn/8t+VSjypddnzsQvdLnOs7hZ+oAcfzhFskn1u6I37nI25ahixmq/ERRuhReE2QRkR1Hli7NMRDyTRvsadydc5Bk+8TLNZj3sc2Wzd5tj+cVT+acwpb6HFfGK+uuio/VeesFAcD8blr/0H8lhUKCTxtK4LTDJatur7Fr433G8gFPJU+wfnxQFls2IcCCQc3q+jbHnl8frozbGGwsuZeM1OQoqyxWONciyEg6YURnSkrFwaSk6kSGkaccNfdUe640dSBlDUZtOgBPsjN4/SUgvAqyaQREpQJRqym/aG0Pr01yWw9+lJr40395eFJfvwBHy2EoYtIQfdbdftfQwmHxGJV+waSQ/sxgitGToZdle9/W6xo/0mm4To95achM3p/WS5u2V8ida+upKsqMxUfTdrdpYtv7o1d1DEStGNX7CdyOnAkoldxU7G6UhOYBWWxjqWR23rn7nVOO9ryB4DWJ5cfFIYTsgUd4930AayilA8cihuni+57sEABaSqmVeFbP+fCQoc4HMEQpfYwQcg+AcErpr45FDIZdhpcAXH0szv19RXoPbTyrSO5a3UjjVQIWHu94vi10Jmw90JBxQby3H9KxgugsKRQduaswy/bfuqgzcufpDdMSGpyMlAx4JnzWZ7+lC7bivhqvNwlE6ScVoCzoK2Csol/LppG/vIfzquwAwKq05HaREB+eyxuPioPeI8UmfVpdyeq7fVbtomN/vujc75OE/TDxusIQZaRPEvGx4nBeDzvs4wC/aFF+bkxsi889+iWeLugiyT4xc3WmPK7V6vPeh7kXcy9nv9zqrW0zwDLGsxMTei0s40Mq5t3U9odXpCMpRvjdi674zQfqFl4yHwHaU7LY3+S2vm0GdQQkIYcpY5q2xF4wpOFCguos9RNT3V5F1bCFONYHS3oASmNiWg7NSz/EKb3ae8FghW7kbVxcthenJglEOX+sshP14h6/Y01PPQjNaecNinsLBt1VR+L5+IX6sI0/nuoSADxGpReyeeVXsZ/J80n3lEalgSAAQp5GXfWmXmc6pFIleathTweMTKUlHbR2ezk1rmymISF2LJ1YqZsJRnk/jf0xq1xmfVq0xPILj4b3M4pdtzx38tVHeY6AGJ3E+hc8GjsrAJTA8wzeAWAHpfQXhJBWnEh25g6jZdt8ADfBY0a2nVLaQzy6DDmU0hmVLqcLwy7DDQCeOxbn/t6AUrqsjVafXUQHlrfS1Nn2uL+vGA5bUFWx7HpJVGgDapzMNdzWD3NkoWH7bN8/X7/ywOrI09YHM/f0xlSkZABYuLAgNzauOWDiNISIvp+RfwesPPFfd5cTgfrds0b+8m6OyD5tms0piUdMLOvjGfX3v4nFURbfce69W//S5mO+SUWXa+QZC7zG8PWKiLYfJl6XQLzaiwJE2yt83hAl1Eu9jtJ1698u4XnHOM9FBOe+Bf+utpIQn1i4mpFcrt3mcw9uZt8vuJvbvd6bb+IG3DsT4opreaVfFeyCfLng4n3yyokebm6FbrBk1R31jiBmsKLzUKHo2JcB0IAtkQRNxpHs6DOV3uTsiTASc8NeReWA2ZP0BK2+6vXGugULDgxotCNrCQk+wfTkk/0oOmAHp1U7Y37/eGXdA39azW/YStzFBeDmL0Tor38PoaEWlmefAp+9Ga79eYj4y4sY+dUvLKGbL6tWKZNSCDBtMq4SgutstrDsWvYT9+JpGpUGQgfHdb6p17V8qtOoell22cTW41RQiNSZ1Uirt1VQ89J2Gq12Y/HRKLqP8n7q+mNWm4fDFuiF2fF+brrluZOPyTMqyCSWG8BWAKdRSk0nkp05wmiZtgRABoBnKaW/IoSMUErDvI4ZppQeE5drwy7DCgBHjsW5v8tgZCqtbqDlZx6ULQs7sYCl0/9hmg5csowrO9rhphQipThNr8fPoqLxR2M/9lltWKzi8Vi853n4gckEkyzhivCg3oXHBA5VZFeZ4aZWuyZuI6aROBwtKBWdbvN/DlN52K+1MV1E8Uk1J8dfljpd752pSMkAlTdtfrWbYWhADaQPcW7BG+QKv4oFAPCfd3UTL7G9MQRKds5NjCtoUip9znPrB1LO1irqE9sRw825Q5HLfJIOt/X9HFlo8jluR/zOvChVkk81ppnpK/laWekzkcRxzqHsDXuchHzDkbFCN3IL/j0kEqVPa4erGs7lOu0+176QzS1+kvunYaKQ30OR4blv6XWbMaHNlNpHm37/iiQHsj/oTNy6vz7jogWBPNModZkF6/ulsti5GYEfrnRhyJoDKyK2JzKEDZq4DhBL015FZZ+J2LMnS3qUSltvxoLiuoiIzkxC/AXyyssdUKsYPP54P37/hzj88ld9skMVadH+872BgUcemK+59BpY//U0qN2O0If+CNP9dyDiry/D9PtfQ3Pp1VCkL5SZfmc512SxEouwgmD6VRsWkjhqVGrLJM2LGS817pnADbi+1Goq39LrbEdUfKpIyIwrthonNWXX0tqtlbIzoxtHLYY6yvup74tZbRyKWKoc5f1M9flW3vLcyWVHc91gIIQsBFAKoAMAhcf880F4jGQpPLQFdnT/Okpp77GIYzr43ic7YxhlhL8L4GcA8r/FZIcFMIIZilR9H8GJ1LW5mpb98JDsTu3Dkpmqks4ElFLYKYWWYSBQisvb23BXdAz+MmDEf1NScXd3N66PjECKQombujrxr6RkKI59vgHAo4BbteSaksHI5dne3IRjCSpb+12ml42AOyAJeDrQsPqeHyXfSJgJ483BMBUpGQBi4xqKFy48ELTFdS+ezG8j6f5cHpmK/BfdJNCqt5G/vIsjvhL7t8ZG5eRqNNu9t62rk4/c9Y7sU2EZDl1QXbrqNp8KBpUtvS7Tv6PgZdugYrXGs5Nv0ZAJoo7vKIvyhxirT7xhYd0Vyw1fLSZeI+o9SGi/G3/R0AmJB1cxnMN1233i3MqUle9SPJ46Zjg6ho+1mkP3REcuwISRf6VAHQ+8Kh3K6IGfwKNboR8oybqz0aGODjh5J4s9dW7rO25QV0D9HQaMe2XkjgMZ+lXLR7mNATFErC17FZXdw8SWDRK8MsEwoj01texQQmJtCsPIad77ensF3PDTTvA8A5NJAiHAz38RhY9zGZNl+Y4B4+G6eZqLLmdUm06C5R9/gvvQfnDpCxB63yO+F5Gog+2wlnKtVgVc8ipv+42pQCDLJzOl5T/lPjatIfUL2Qnt0ZmgScG17dbr277QarQDLLPcm0M2XUSYad+WKtq0qVqWk41IZwMk+zOFTRPb1h+d1WGMyoRNm5A4gfdjARB+y3MnS0d7nUAYJSdvAHAWgBYADwFgKaV3j+7/Izw+WQtOVHbmEISQ38Fj4XA9vqU2FgAYdhn2Ath+rM5/PKFyU+vJR2jFaaUy4oewfCYrrLmCQ5ZxeXsb7omJxVPGfryRkopfdHfhtqhofGqxYBHPY4f+2IdFQaSm9LML2pNPWTKN1dScQRa769yW3SFHobEBlihs56bc2sExymlPbU1FSgaA9dlvlUymz3IF3uyUCetX9SE2sZPP7wtYDWrkL++caCL5x/CwvJfDQnwqMSo3te76o6SemDDt3fpM10TvKZfppcKJFbFNMeflJGkXbvfe5oQw8iqf56Zek1gAkJFRlBufUO9TtamEofJR/G7+xNFrRdlQLtvr8Dk2kzQ1vKv8bYi3WCIA1CkUzZcmxjGCxzHaBz8qlguv/Eo2BPqba086eX/j/PMXIUDCQimlkvNAgejcvxhBVLQVDG/Kjj7rSLw6fT2ZJGEfJtbWvYqqriFiXY9Jx7+pHBvXeGjevMO8QuFeAXiSnd/c14vnX/B0Bne/MYKvv7Zi1So1Lro4FI8/NSwse/Se/XtxSmIgTldAuCQj12ypZrvs0USiMxwMoXQzUzluVKog0qwV2e2E2D7Taqr36HXOKl6ZPpF4Pl0kGWnrtkq5fX0tVcSMYBEDf0HOmcKl0BuN0SubjdErnXZNXPt1L51/rMQEx8jJ5wF4Hh5hxmYA11BKh0fb5O3wkPdXnkh2jgLEo5gpUEpHiOcH53N4LOW3ARj0IihHUEp/eaziMOwyPAjgt8fq/N829HY6dHqJXH1SGVVGWrCCzFCNd64gUYoL21rR7nbjsvBw3BkdgxcGB/GRxYxsjQbXRkTid709+HvS5CaBc4HemDWHahftDJPZKcTU5hieUeOvDJjA45gh5DOTbjyoVYQGtBgIhKlIyQCg0Yy0Zq3+MDWYwWQ3EtruJn8NWPpn+hxHlEeGVgbaF6iy855OW3x/tL9W0X+eFOt4ET4LmdIVP88dDl/kk2xIQlulYH17ufc2BVGaz0u9TSCE+FQoq9iOA/sV9X6Vk7Xr3ilSqWw+9/ALnH7gZVy3fmIbM9CkWRrp6fhc+UtZSXynyEwMM3J2UnzzEMv6mSQmDtC2R1+W7KoAZrcuZYixZNVdzU51ZMDvlcqOEbf1vXIq9WxGkClIDRfavSXm/JZQZfQGMokI3wixte1VVHUMEkv2ZEnP+++/j/r6GikkhLqefCpWef9vern16zUoLnZgfoYS99zjySHvuL0bixbxSE5W4FCJA2x8Yp/5+icaO5GyerrVUmIRmrlGcztjdGYQOnMrmTWkruZG7sP+rUx5irflx2xQrVQ07Q7Rd36tUYeOMMyy2chNEErpgi7UbS+X+1Y3Ul2YDUsIZj5tNgG/XVJb8/BRniMggpGTKaW20f1bAfyJUhpU2+nbxPc92ckEsAuelR0D4E1K6UOjP15vAkiBJ7O8iFI6dKziMOwybAWQe6zO/20g0kR7zjwo12+ppKF6BwxHQ6qba5glCT/v6sJ9sbFYwH+Td93f24NLw8JR7XSiwG7DIp7HjZEzsoOa+tq65IZyw01mNx86qbrssYDb9mmu7K7eilmouXpja+xFOfGa9O3TPX46pGQAMGR+nhsW1hd0oms3Ltv3AbkgoNcW22TOVzT6a+wAQAN/RefEVXc5r6zbmRDnV539/S4xb2E3fCo+g+FLystW3OpHfHYO/7UaEHyqAasjT83NCMny+wy7lQUHLIzTJ+FhWbcpe8ObJobxvS/P48bcveRU/9H6wwM5rNG13XtbDIaNOfwdQxri8p0aA8Tr4mIKStQqv/NwEnX/5nXpwNIO3885hrbkUwub0s9ZGkzqwCNR8B4mfnZvRCjj6zfHnm/x1iAKBBOxd+5VVLYMeJIevwd6W1sblEol3n33XVx55dn9r7zyX110NPhn/prIPvJIP3784zA4nRIefKAfL7yYhPt/04c/P52A3z/ch6uviUBYUvjIHlxSloNTkqZd7aGUMkZnBddkMRGzkDmbUXADaW64gfuwawdTmqgm7hmZ506EhRDzxzpt9Tt6nVinVCyQCZmVNAQnUXdmM63ZXkGHl7fSCK0LS2fSwhvFSUtqa3Jmc/2pEMwmglJ6/+j+fwBopJT+8Vhcf6Y42pG24wpKaTk8NvITtw/CM/r2beEAPO2zOTd1PJZIMtLWs4rltvW1NErtxtKZTD98mwhhWazVaLDPZh1PdqqdTgBAmlKJR/v78J+UVNzZ3YVWtxtpyhnb3PjBpQwxli+/odaiT904kUR6rEGp5HZbXi2m0sC0RsMnw/KwzftmkugAQK6iukgmdNJrM4xgCw3tC1iZGUMxsoNzPSziZBwCvxVYiiAGnDQ6nMGwC7tln20RwzUGULl3ovUCp14/LDryfY4tHfw6O12/soshjE8l6Uz36nmv8wUmePFsJEkZWlF+Wnfmis9c3mP21+G5bZ00Ja+BLPJJRoSsqO04NJDLDrrG72U/wqPXu/6mzONvLwsn1nExRw7gXu7t3/aX8NB9z4eGZHtXBkSWKB+4nNu6o1Qu+umn8iIC30mj1I4vNsb2Hewrybqr2KUK96t+MYrkpXzYrbLo2LdPch0yAP6TSkPunoUfdDyLJM2iw+ujz9AEa3eGUk3Sue51SWbi6MpRVDX1E1M2vKayUlNTMTIy4olb1MVQqsfIiELu7FyUZ7X0ruU4qJ94fABXX+OhUMqy56smDOByydDBGnY1Xth2NV7AEbqq/HVcaelE8uTVHkKIHKPOdMeoAYm62C7bfq7FysIpjZu2ToUKmr7gVuEXCwBgAelsvZH7sO105mCMt+fZdKGnNOTHFmv2jy1WUIAe4ZW1b4To+/ap1ZEWhiydro2FyBLl4QVkxeHR1EvlptZ1dbRmayW1L+qkcUoRC6ewtXDB82w6VugE0EkpLRp9vQcemwiMeuydD+BbXyQGw/e6svNdgmGX4RMApx/vOKbCgi5af3aR3LOqiSYqRXyrLZmZYEgUwRGCEJaFU5ZxXWcHrouIxHadhwd+U2cHHoyLg4owuKmzE6+mekjLP4mIwGLV7DnDEqNw1C68rLgvdm0WCPnW+UlUtg24zC93g7qOeow9UbOgdFPMecvJDErq0yElA0BaWum+5JTKoA7pFKBX4K0BGoTbpCzsK2As/ho7ANDAX9GhIJJfb9KQlmyfOAqcZKQtf3pe8mtBlKy6I88UOt8n+aBUcrtGnhmZOKK9NGxDviF8q1+VqYRrzi/lWvy2z5tXsi8pudrns8tgpJ/jucPDJNJP00ZRbMxlh90+ySMPt/Mr/q6yJDLg14LKVavKfhYbnUQntNcAIHaYdj72kjSidWH5xH0A0JJ6ekFL2pnLJ5Kex0Bl24Db+k4tlYybEPxBSReHri80hG9Nm5gEToQFjp4cZVV9nyfp4QFgZGQEzz33HBQKBex2OxQKBXiex9KlS2lSkqt5376KpFdfS+EB4J/PDeLgITvS03nce29gMWEL9MNv45KKHOyYPrcHANzSENdirWQ7bRFEpAHv11RIJb2d17MfN53F7o8IgX15sJbtdDHMMEPv6bW17+u0aFYoFgX6jqeLUBsd2FRFGzZXy2JaH1In+q0ByFtSW3PUC6ZAIIQkwyPxsh5AF4C/waOYHAlgMTxCuxp4xAaPiaDvTHEi2ZkjGHYZ7gLw5PGOww+U0hUttPLMIjq0rJ3OC/AH8Z1EndOJX/f2QKaADIrT9SG4OcrTovrSYkGdy4VbRl8/0d+PApsNC3keTybMbriBArQ9+dTCpvSz5oGwRz0hMRvIYl+D2/K6GpBnTZwcQ4giqvX0xGvDyAxVnKdDSgaAjZteq2dZKahgZBPmN/yWPBG0HcB/3XOECHLAylADf0W7gkh+/06z0pJbBEL8Eps3HhWHJhI7jVGZpRXLb/Cr+rqtH+XIQv32CZvlC1LvaOIYhV+8/+XzDjuJ4MelWb3m/UKNxuxDeHZAZb0FL3S5iMqv3aYsMuYxI26f5IuBLH2ovG//MqbNL6Fq57jO8xPjHC6G8YuJkan4q7fk/JXNdFuglb2TD+85lHVXl5sPC8qVkISWcsH6oQoQg36HDFhXVtSpB9J1mSunMom1wtmbq6iq62FG1o2YRtSvvfYabr75Zr/jPvjgA6xduxb9/RXd7e2VvCGTC7/iivBpq6qXIqv8DVwxdbVnAohVaOMazS1Mv3MeoZiV6Gc8Bnt/wv2v/nw2PyQcFh917dlABuRiFV+zO0Q/UKhWxdgJWXw0EhaxQ7RzW6XcsqGWsvFDWMBQPLuktubBo4kxGEYHf+LhsaJ4EcAyeHTuKgH0wJPwhAKoP1aCvjPFiWRnjmDYZVgJj97AcQcrUWF9Ha0446BszejBotl6ufz/goGIZWVVS69VSJzquNl+SK6qg4L9s8WYg2k3JaMaPjvlVhNL2LSZvG86pGQACA/vKl9u+HrSytNLuC73S/LDoKtK/vOuzmCk0gb+ijbFBBIvAGxLSTwciMT7j7+JByMt8KmoUBBp77Znhidq0lDZanSZ/hUK+ArizdMZitdFn+H32UcrXZGYYEvAsoI1e8ObRoaRfZKvQUT23oZ/UJmwvi1hSqnygDGfMQt+1bBdisdytrHl2ydutxFiPS8pvrqH4wJ+J5ur5EO3fiCnMUEmrprTfpTfmvrDzGB2CJTKoujYWyC5yrIwyb87JaMa3hBzTnmsKjWbBBm3vvN/j+GrpkKEqvTSlRfvPPTsnhfWLVi4gDQ2NiIuLg7nnXceenp68NlnnyEjIwMNDQ245ppr8NZbrzquuVZbsXKlZTEhmLZtgwX64T24pDwXO6bP7RkFM+Cs4Botw8TkNhD4awRNB5EwDVzDfVpzMZurjsbIChKAvzRTGFnG+LZeV/+hTsu0e2wsZm1DAQCxw3TTl7dVFh5tXNMBIeR9eKo7f8O3OAk9E/yf9in6llEG4LiN1ikF6thRKhc/9bxY8NoTku229+Wshd3YeiLRCQ6bJratcP2DReWZN684nomOYP8qV7B/thpzkOgQMMIZSde3zTTRESE587naaenvpM8/ZJ3qmMNYG3yKhFIJFEGvRYO0V2JEyR5oe00ysU3cRkBZvaWjxm87o4smTOTBidtbrBXr3JKzYuL2UKpJXiwl+h0vSQpd2ZHTRUrhE1MkBuMewL0WUOprukgIcWdHb5b1Cl/SEICrhHu2vyGe5DfgoKVU91lH99ptdnvA4Yf8ZcyaW25hRYs6sKhpeuvHmzcU/daqdJtLAu0nhOEUmh3b+NDr7YQJD/pQdMvO8Nze3dv+1/kvo8k9UBjItfoiw+n4z0VPgmM49jSsWq+VeLmjqc1004032Sil6Ovrw9dffw1ZlrFq1SqMnYJhVOrGhux1+wsvQU/3glxKSVewOLyhhyX8Gjy/7WVcOv8u+ofyJNpeAEqd03mvHKUyuLOjt7pOTdAKS8OKZTV7gHr4LdPGIEKjnhIv2bLO9fc1K13/sj0lXFTQRSOLKZ3ZebwRLcnRN46YN33c2bOhtLVD+7fe/vItdkcuL8sNszidtS+c+P27PRYgHtmEVQCKAMRSSnsAYPT/R2V0Opc4UdmZQxh2GXYDuPjbup7GSU2nHKFVp5bKTMwIMudgTPH/CwicZqRy2XVlw2ELNx5LR/KpQKkkuC1vHKBSX1Duy0xxasJV+yL4uBmf7ytFRW4L2z9lf3/UETx8spWsDEa6Am/aglUUiF3s4vf1BeWC1PNXtE0czwaA22Oicr/UavxiXF8rH77zXdmv4tMXs/pQ1dJr/Vo5stBZ7ba+6ZfcxqnnlW+Lu9ivYkVB5Vf43BqBSH6Cjskp5flpaWV+bahCbD70LG5b6edrRKmsLOzfH8gT7OfsO/m3c3s2BGqPvBSqL/hTeFjA1g0jU+m29+T89XV0SzCj3aZ5Z+9rSzlt5WQ8NMndUCrY/hcKSJOafkbxiTWbYs93qliNT5uww9SDH7x4LdQKHkMOEwgI7jvlFusb9Z84UxfN09XV1anWr1+PxYsX4/PPP0dTUxNiY2Nx/vnne51FlhIS64pTU8tCOE6YkYCmp9rz5BnjIgAAIABJREFU4/JcnDzjag8E2cS1WMrZTlsIBJo5BfE3KLRwWH7M7q24gv2CpJK+FbMxKg2Ebo7teUuva/yfVst3c+zSaVhGfFhxVcXZc3HtyUA8ceQC+AOl9J1v071gpjiR7MwhDLsMPwXwz2N5jVArNZ5xSK7dXk41YTYYCIL705yAL2TCCA0ZF+7vSthqACHH9Q+Qyo5hl/mlNlDnpBNNM8HaqNNz0vUrts/0fdMlJQPA4sV5udExbZMmRZUwVD1KHgj6oGL6HeXK0qGgbbBgyc4z4aH7/h0W6pfIqV3U8vKfJO3EB71MGCFn6zO2QCPZzpFnK0FdfqTVM5NvKtZyIX5tIyMxN7yvPJgWaNx6VdZH+TrdsF/C8yYu3fc+udA/8aRUUhb0FzE20c/248fs10WPcs+vIAG+i4Mqvvq6uJgImZCAVbF1dXLpHe/KCcGquQ5VVOehrLuMglIf1MyTUkkQ7F8UyO7qdZhi8ZSqXXpoTdTpoWNcpw5TD67ecw+++skuAMA/il7De9VfYlNqFq5ae/7ItR/dJ1169eUKTLNdFR7eVTE/o9imUlnXkUmsKwKhFFllr+MKWxeSs2aqck5sYifXZG5keh2phMKPIzZdqOByXMDuK7+a/VTM8BiVzshdPRjcgDtHo656M0RvPqziUwLx2ADcWnFVxbNzcb1gGB18+AjAZ5TSP41uq8N3tI11ItmZQxh2GdIBNM31eWOHaeePiuWmTdU0XOfE8mCrtxMIjq74zUX1Cy6KpQyXdrxjkSVji9v8KgPIc+aOnq5fUbQm8gdrJxOGC4bpkpIBWdy85bUBQuik7a6/4+c5BWTb9mD72WZLgaLBHHASCwDq+StblURMm7j9Y63m0D0xUQFJt/95UmwI5CdVvObX+VZdkl8iMuoa75dshCtjG05NuGp+oPv4paI8t5U1+iV6DCM6sje82cmykt/1n8C9OWVk9Xa/gGUqKvP7DjIOyc/ccwdTcuR5xR/TAz0ce1m299yk+CEbwwRsu4ZaqfGJF6X2cFvgkV8K0Mb08/Z1JO9YjQlWGT7hSaYuwfpWB5XNAW0pvA9dFrapcGnYxvld5r5472THG3d/8jiuyjoPB7srHbsbPrVGJcfqt5+0fVpJiFptal+w4EBrSGh/FiEzs+UZq/bk4OTkiV5m0wEZclUrGs1GMuxeRoJwo6YDJQTXWcz+8mu5T1xLSNsyJoCf2GzRynHtb4boWj/TajT9HvNSNYCMiqsq5vxZBIxbMz0P4FQAEoAfATgDwDkA4uCxT9oO4EocY0HfmeBEsjPHMOwyNAOzXw2MIa2XNp1VLHesqadxagHTlvg/AV+MhM6vKV9+g1tUaFdMffSxh+SuKxFsH2dgFsJnwRDJJ9buiN+ZPNHnaTqYLikZAOITavdnZBwM6LztjZvwYqmZhAatHijKhnLYXsf2oDHxV7YEUrStVioaL0mMDyiX8MjL4r5AXlLdcdnFtYuv8Pt8lMqia+QvxkAWHD9IuCY/jI/xS5AkyO5X+Nx2ich+MWg0Iy1Zqz+MIsSXd0UBehf+eqCXJPjfN5kK/L6+w8Qp+Y2fryINdXuUD0SwAUwsXQTOixLiD7coFYENYSmlt3wk522tpJuCidDZ1THtJVl3DgkK3aSVRclVc0iwfxYdKDHfXVyG6p5+6Hgl7vnhDkcUs6L8Z+8+vS5OH0WWxSzA02feBwD4S8EufNW8H29c8mdc8dbdeHvn33D9e78RNm3dXCrGKxZgmg9+jnOZ5qWXlMbGNi8iZObWKaVYXf46rrB0IWnNjH2tZCqyPfZSttkqELuYRTB1FTQYWEji6czBsuu4j20rSPOS2RqVBoKTEMenWs0X597Vfc5cnXMiRv2wegD8Cp7pK8CjjXUPPLydQgCx8CgqH1NB35ngRIVg7vHxbN+4pJ3W/PItKffVJ8TmJ16S5m+pottPJDqzg4OP6Clae1/B4ZW3L/6uJDqCPTdPsH28AnOY6KhZfe/J8ZeFzibRmQkpGQBSU8vVUx3jhsJpRsikQmzEJs5KzDQ5iLAgAJRkMAE5FnF9h1b4kYXhIecyysX1gd6T3//OPEqpH9GUBaM8TVjhBIU8cZ/dHjavuWlN5cTtBCCP4o5VGmrzIz+DIQrXlthVlGf8iKSldMGi09xP2AXKdkzcx1OoPujq2XiWxZqDQKtVQsizZ7HbHrmYqZYIugN9Ro2jP2Vzwa9WJHXuzQOlAYnfAMDyS9bwYbfGMoqFOQB8CMBr5iXh+q2ePFKiorp0YO96m2Ajr176UJ4oi3KNsQkOwYUXSt7C389+AIIsQqaeW8czSsU6MWPdla5tXIYUlwuKKR+IosiHNtRv3F6Qf1lUS3NWoSRxfgT0ybAKJZlP4LZNz+Ea+yn001yOupun/WaGcFKidq17S+xG18nxbnG+Pp8qmFIaQABzKkhguY/l7NXnuR/eOt/1n8hr3XeVFcmL8yTK9Mz0XBOholR9rtU2/c81Q4z6YW0F8GtKKaGUGkb/y6SU/m9U0PdlAK9TSnd8VxId4ERlZ85h2GU4BcAX0zmWUCpnNdKKM4tl0+IOzGcpZmUmdwLfQGR5a/Xiq0oGojLXTTRoPF6gVJbcljcLqNQdUO5/tmAJZz8n5WdtCkY5Y5VXYPqkZADQ6gYbs7L+N6UI5UGsL32a/DJoVQcA+L09pcQtBz2mjr+yhQ/iVWRISzYHIj6n9NOWp17wFxfE/2PvvMOjqvI3/p57p2fSe28ESAgQkhDSE0TFgl2sWBBUrOvqFl1XF3/rqivq6q69l3V117a2FcRV0oAkEBJKKiW9t0mbmdvO749JIMKUO5MEosvneXwwue1kMpn7vee83/cFsHPpQ9vH3IJOmAWh0lif2fCyG6w8pecHXVkQqI2y+tp8rawo7GAHrP4uFy3eXOjp2XPCtiF49N2J10ZEojhx6VKkZnVh5z7CSScs0QWhv+sH9b1DtiIMPtW7lf3Bz8emYFU/RgeefEts8BuCzdm7UV1g0+4l9xkEpZtdOwFJ7G/ihj/qAR09Os7+0TG8UVSOYE8PHOzuxYiZg6dWAzeVhvvrqoer3634OgmgeOHCjQCAP37/AgqOlCE+IBZ/u+BYnCAPYWSHon53PduxAET+cpGPT0tV7Jxys1o9utQVw78KpFR9iOtG2xCW4kqKOTEK7ezB4Qa2cyyUSFM1aaU0izlw4Fb2y74MpjrGmrGmTM7ERsN/pzYW69jLwyKE/AmWpSsDgOWU0p6ZGIOrnC52ppmF7yxUAOiBFUt2wJJ3klFN9563SzJGd2E+Q3HS0rN/zlAQ6UjU+SWNkSvngTCzpt2RSiaDeejtg6Bj022bTs8Pu7VUr/RypKmwijOiZABYvHhzoYeVm/jxPI3fFlSQNLsFlPrbtmZCbZtb1qmvP6wmglV9RWpk2EEzw5x4U6GU/vMJ0XB8lAIAtIbk7Kyfe5XV18k89F4xFXtOWLJSMdr+iyPuUhArhRUPYfRddeEAJfTENHcicukZ/zqoUAgnaGpaEdZ4P/7iQQlzYrK1SE3qws5qwp3YVeaBEUOh+pdNXmTUajFyQKVqWBMSqBEsrrZWWbdFLDi7gmbaik+gIFJ93BVFbSE5Dh8SLOG034cDNHSi2Pn1OZZf+Q+1h7CnuR1zAnyRPy8GH5fXDn+x5s3DalYra3aVhzhWqqgvr2XbE0DkfzbqdIONcXE7m909elJd6YAagnv/J7hqn6vaHgAgA+ZaxcHhLqbfHE+moeU6mdTX3qb4siuXqYqwVfxbwQDAHxsN/FSvbw1HeVjj+zwAQEMp/cNMjMFVThc7M8DCdxa+D+Caia/VHB3N30v3rqyQaGgfEgmmR5V/Ggtd/sm7a+Zf5yGxqikF+E03ktjfxA29Jzpq5XWFnMDLC0J0sS5bwcsXJQMsyw1lZP6TkSMOXY939xuJm21rfkol9bftor3MInvFzhnhIbt6FAqrIuWX/ybs8hnBCdtERjVWkPMMjo+aAABJ6Kjjhj+w2i2S7n/Btkh9Qr61bYeZrt3fq/ZbLWA12qGW1NTPPQg5cbmyEkv2bsKD86zOIojUqC7orLPmLK2B2fi9+r59IaTf6u+sn2H6LgwLbjWwrM2iIqGJVv/+Q1Fvz0V9RBd8pCL53hFBoVtoax8AoJQf40e/KusdPJD1RlG5cqLYmcy/yvcia04kWgcMONgx2p8Zno778zacWOhZQYBoLFUcLKtlW+dTIt8rTKEw9cfG7trnH9A4nxDqksdYBVKrPsQal2d7QKnIdBr3KA4Nm8mosGQ6LEEWkCMHNyi+bD2TqQjREs6m6zWAD7DRcI2d7VOCWDoBd1JKo8a/zgFwP6X0/En7RAL4mlLXIjpmitOanZnhc72RDl5aIpW88IJQ9u7TIrtuq5QR1ofM04XO9DGsDztUnPGnXQcWrEuZbYWOyB2q5Ibedp+JQifBK7N4KoVOPdsuu9ABgMjIqj1yCp0x6IaM0NlfUjOJ3Y7DGYnNJ7AAUTTa2lYdQayaHbISp9Oaevda28YogueBaKqsbSvv3byUUqnb2rYYKTDFR9KfYBAIACajR3hDQ3qdtW1J2LPoGry726rWhiVac25gHFWSE8ZjglqbY34uuU4KK7F2Xh9J8v2huS0h0WwusrYdAKojScL6X7CeHd7YYWsf/VhHdE7xbxYEt5cUWDPp+/u2Tbj/ncvw2EcbdCr9Jfms9qKOIaNZeHpLIT4oPeZtuPVAPToNw/Bzd8OuxjZcmxXvU9z2g/fXhz4tt/WaTkYBVpslzMu7wZzvuUAILyAUsvQsgqDxqavLzispvtq7sXFxiSiyVn8P9kjGrsVP4p7Ml7B2dAXdUqCg/BGnTkAIKwXrUrnswCzzimCJj/MooSpmN8WJWi+5HKDRc+7i786PN7899yzzk40fCbkFI1RTbWXXz129hiPGu7CeBxBACDlECMkA8ASAdEJILSHks/F9LgRQO1PjcJXTxc4MsH6z+PUbz4rsVYVSlv8Q0qai3D/NiZiV7j27lvyqsDzl/ih7+T+nCt64vYgf/XwBjstrmg5CdHMqE72yT+jekYuzomQACA6pl5XVVY5ltY4S4pkRweE6vr255gjedlp6+VzrJoYAENpWaPNGo9BkWi2gRMq71Q3tsvmhfR6XnEgorN64uzrj0gYGgq06H5+PLzKzUGh1GxSMmzk3KJYqyAmCZhGsYiX358wScYHVY5WA8oP2rpw1hqECUCpY22dMQzx/sUGR8fkyUkSPExxPQECZ+Pp/5C3d9XgbKxgPTN6WPncl7jjv8aNfC1QXIVBG8duLH9rOi5KpY3AIvCCiqKER12UsgSTRY27JhJD6od1LP2l61q15pKaAUurQiVsBVpMhzM270bzcZ6EQUUiodcH18VDKqlqaF2VtL7lmXnV1boXZrN1FqXNiYg8M+9yEV/PewVXR99HHq0JoSwmsCNft/wCMXoxxzzIvD04x5wV2C2G6AsoQpwuwyTTQsKhfCxvyEs1vJuSa/9L6nnBmgYHq9o67ebvcICOD5wBsBpAJS3v5a+PfnwfgAIBsAPUAzgbwixkch0ucXsaaIWrmx38OS4V7mmlCZBSmurlX7+wMXJZsy533VEIplfiRT4okoXlGkobdlb5N54aucyeEuFxEOSNKBgBf3+Y9CQsK7AqOJ/gTNhZUk4V2z80eGS5R1tv22AGAWvUNhzSEt+qA+7KXR/EL3l4naGwAQGuiQ2//RdRb86ESWPVwYfbTKmvLEpRKonnwuQ7AigYHDH951L3tDGGteiIdYFt27lDW29BNSUJG5r9qFAre6pLQg3iyqJHEWne75qUhdUFnCxGpVXPGp5UvbbuMLcq3fl3gW5224lcBfjHUThDsnDZa98j7okop2rbKoCBizbw1xZ1By9InXru+4U68/M2DCPGJRn17JYaNA/By84Ob2kO8Im1JxfcHtqcQgFmTYZEffVlZjbquXgR7uuPa9GNvJQ2r784OuKTORx2cQY53mraBCImrUBwu3cs2R1vTTNnDza3/UNzcne16fd9Sa6aNchiCe//HuHpfAc6IEIjSZYsRYuAaFAeH2phe8zxiCdScMn4wfLjriWuuno5zHc+4dq0KlhRzq0UDIeQSAJdTSq+diTFMldMzOzPHx6d6AD8XKECbw1ZsL8x+prczKD1/dhY65mGz4bXdM1XoqBjN4MrQG6WpFDoGMtZyhOl2alYoOma37CfZg5jrMC2eGeatzjgch80nsBiOt9lib9QQD05h3dRTIZrd1eYBq8tVhDAsq1pg9TgKSVnVv81mXtMCMTzdXdLstL6VUVTsXuVHKfqsbf0/3J/hSQet5lZByXiY84LCKEustlffx9+W/7xwURGlsDrTdfaYMfmzto5BFaU225APhpJ56+5h/Vv8YHVpDLBkjCXUvZe3dPefW1jB9KOxrD3z93j8+o9x0bKb4abxxLywZNbP78qlJtHHuCYz4+iy4QVJCfjVytwfFToAYBJHAr7reC9nS9tbzaO8oczWGCbDglEtFebkrDXnByYJUcWEkhNa820xOuoTW7nnvJzSnZeP9PREFlAKp7uFJs/23Esfrwyhrdudnu0BQD1VcXyKX7757JBAbrFPhaRXFFPA4UyXPXrh+c1UjndADCyNN28RQvYQQl63YndxE4CZHMOUOD2zM0PUzI/3BNCN03EOU6LPO37f/gXrGFGhtZuTwwscnv3iHggiD5GKWBKdi/OX3oh/73wV1S1lCPOdg+vPuB8AUFa/FaPmISxfeNm0jFESB1u5oXeNgDAjuiECIlwYcee+47OInMUZUTIAqNUj7UvTPgu0ltV0PAZ49t6ON3xBiN32X9WO7iJryd+TqVXf0KAhvNXXsl6pPHJZWLDNJ+rH3xKKYjtPNBcEgMaIc0oOx1xgdVaJSsZBs+ElFayLSemlkb+stdXiPwpT1wfqEg2sCJIBwN//yK5584uTrUUejEE3dDte7+KJ2vp7hxMH1AVd3USybrm/ht2684+Kt5YQAqtC2iGGGC4ODW6wJeqe4PJiqXh1kZRsT0wrEUaomX99SbUmNOPlLQ+pHrzijRP2eb/gKeQuuAjN3fV0z6Ev+8K9oFuZOFeWQDdIG7M3I+ACRsVoZAtbJUhCJdu4s1LRGC4R6pQjOSGiOTxiX3lYWHUQy4out40PwaP/I1y9rxDLpzTbA1EaY5tHKxVNIyqYpSUEjv/uJmEGENj4xPkGl69vB0ddWISQBwGkArjU1szPqeb0zM4MEV9bYwDw3akex0+VMW1A845lG3dULb5zoaNCBwAUrBJ3X/A0Hlj9Gh647FVUt5ajob0KR7oO4HerX4dEJbT1HQYnmLGzbgtyE6bHYFTkG/dxQ2+qZ6rQAYAVIdftmGqhU890lDtT6ABAbGx5vZxCBwC2I7vBUaEDAMQkOrzx2fukDBcEux02FXNsDyG0vSARlFptySWM1ouwQdZnWQBS3vuNTeM9N2gCl4jRJ5oGjtPTE53a1xduVTisw5jHJvzCjVCpy+rBKtbbnBvoRxlYTb7+u3hW+gb+lzWU4gTjRADwkKjndy3tyRlGo3WN0DgfZzPZv7mJ7TArTrzOgx0dyD7YgIsPH1QsqHk7L2H/K62G0V7xsY/W493vnzi63ze730NHfyMCPMNQ1rCV3HnBy349xgBlx5CqHDLEuZ3Gw4s+a3oucXfv1p0iFZsc7Q8ADBhFshiTfaN5eVgqH1vCUCJbTEwpq25uSsreXnLNnNqa7F0cp6mQe+xkPDDksw6vjM/2PFHl6mwPWEYnRrtnmvODU835Qf1ChFuBrZk9K2yeqUJnnFYArZTS0vGvPwaQDACEkBsArAJw7WwtdIDTxc5M889TPYCfGrxCa6hcdGfBzrSHg4xaf4fRBBMQQqBWWuxBREmAKFlWSwRJAKUUvGAGyyjw36p/In/hJWBZl0x8f4RgKivhRz6dC8ycV1KK78oCX3XwlFLRBYimYmWNU224hIicj2+r7NTp7ciRszwF8JKvjKvb3KKlVEcoHbC1vWwuY3MpTSkYPVXckNWlLABQ6lbY1E60jNammMSxPba2pwgx2RqqtHmzrKnOy+E4tdXj/dET8hAe6gelo1YPVrO+5twgL8pYX6LbIi1NuoJ7uFWipNfadgZgXu3sybtjYLAYlHK2xtgUSGLX3cOGHQrCjwqzSzw98WrYMQsfxXBrjMSPss/m3V4gSoI08RCxbd+nuGnFQxAlEXTcKZll1Uql/tylKv0VtYDSWvfQCRwcrkj/pPGZkDpDeSGl1OrPdOLPSNgkMSprrXl5ZBo/p4SljFO5UD090amlO1cn76k4r2FkxLuYUjhfrABIQfniTfhF5ku4aeQM+q3znVwTqFl/Id4rz3xmSLw5w/+Q6K/ZRglsLqcC+NCl68iEUtoJoIUQMjHDuAJANSHkHFhiIy6kdpy4ZwOni52Z5RNMcR32fwWJMEL9nMsKi7I2if0+8XkgxOnlP0kS8fjHt+D+dy/D/NAUxIUsRlJ0Dp745Fb4egRBq3JDU3cdFkXZ1cc6hFJKuZF/FwjG4izA+vLBdBCtX1QW6754SoUOABQoq0slQm16q1gjJLS2nDhh6taEaMfnp5SCyhJj2n06VFNqs3W5KQAx1NIpYpXgzh02W9cZReAcEK3NgmV797/t/q4v4FL9YemIsQJhKipWhVEb3VvzUBt/C144AEqtd5upWX9zTpA7JbB68yyn8+NXcn8eESjTamt8GwaHsl/u6qkjdpxtOSXRPrBWkfPuGcx2CstsUapOB0/Wcqv4VXsb1re2wEQp7vrygbz+tjKOkfjG97dtwvywFPh4BEKn1iMqMAF/+mg9CAjCfGPBKMMS1F53zmfVSwsB2CxWJ6CQlJX93+d+2vSsunW0vkDujZSAMIvEyKwbzfnR6XzcDpYyVmfEbDEy4hu3p2JVdmnpZUO9veEFtvRWjvDAkK+V2R6bhaY9qIcqlk/2zTefFRLCLfGplDyUxdRiHjjBKIAvXTm3k9wF4H1CyF4ASQAeg6UV3R3AVkJIJSHk5ZMwDpc4rdmZYWrmx78JYO2pHsdspj0oo6xu7pX+lJnCevckxswjeO3bh7E66y6E+Bw75YSeoKWnHjWtuxHqG4Nzktc4dW5K+TFu6N29VDK45FwsF191SN2K4DVhrmReTcZZp+QJMjI/3Geri+h4uhDYei950XFnjEns0hR0OpxhqlHfWG/POO3M8JCyLoXC5pLcK38VdttK/eaU+r7izCe8bLXIC+Z9ZcLYVpvnPi/slh3uSm+bM47FitqCWkWbTZG6j09LZcKCbQttLQ++hxsLNpMLbIvcjUKHuqiLIxRW9Skh6O34Xn3fqIbwNjUobQq2/eLQ4GETw1jVAU0Q2kubHn9bHNPwiG/jOdzW2oovoi22UW/09eGr4SGk63S4wcefu31QGL7zslc9IaOrikpjfdzIp9VU7M6GvWm8SWhZ987swEsbvFWBmcSBvcGPrgVKq9nW0jLFQR+RSPbM+KzCMIIxImLvrtCwmjCGkab0+TQEj76PcPX+KWt7AECkJrZ1dI+icYSFSTzQ9MT5N03pfDYgFlfud2FJM5cAvEopfY4QshrARgDxANIopbtm4vrTyemZnZnn7VM9gNnKoEd0bVHmE3tq569Jm65CBwB0aj3igpNQ3XIsX7Gl1/KAF+AZhtL6rVh31sNo7z+CboPNB+EToOJQh3nw5eaZLnS0rL7rjOBrPaZa6ADAf1QVHc4WOu7uPXVyCx0AKEZuo5z9mBFeVveLo3DFIEG06g8zQU04sapfAQAVP+Kr5EesGgwCAKtKTAWYZlvbi7s+DaI2PGwAIEuYl6Ok7AFb2/v7w5O6u6OtmhECwHV4Oy+B7rOtr9EqgrmcQCUlsNqF1A6/4HTz875DVGdTQxQqiCGFzW3h4Txv01wQANr8SORNv2Rjq8NRePy2db6++CwqGr8NCMQLvV2qR/WS78HNd/e88s3vRjZX/N3eaUEYna/aY02OUn/pfkAhy3PGKA4HbW1/J2dr+zuHx4ThE4JTbV4LhCwQw9NvNOfHZfHzShWUccrsTpIU2sbG5JyS4mui6uoyyzlOXen4KOscN9tTGTyF2R6wRCNG6jPMeUFp5pWhM7mEJQC4j1IaDyAdwB2EkARY0s4vBU58b8xWThc7M08RYH2t/X8Vk9qrsyz1gZKKJffN5VXuUxLeTjBsHMSY2bJiyAlm1LXtRqDXMZ3BV+Vv4fzUG3+kJyCEASfIW5qX+JZq89AbDMDPaAo9SxTGc8Nu7mMIM2XvDVdEyQAQO6fMqZbcUmTK+hwhI/yQzFPafdqP4Hm7YteyecTd3vagrjKbxRAhhGHVC23qLIb43uh+rsNmkUBAmPO4ZBUobGYT1ddl5ZrNWptPwg/gkRw/2l1qazvVKkK47EBiS8MxCHfvZeYXYruol81raCnVfd3akX7W6NgJyemtb7Si5q4aNDzYAIElqo1rFLl3sD1dzTyP+zuOefp9YTBgU7dFVx2lUqGo50jwB7pRZUvzjp7uwRab5o8TsMqohWqvO+ew6qRCALLeGwNcV9yXLS8uLe76dA8vcbJTzwkIiRfDlt1oXj4/h48vU1JWln5o0hlId1fs0tKdVyRV7jmnbnTUq4Ta+R07IgXlSU9ZtD3Dy+lW17U9QAeAGQn9BABKaQeltGL8/4cB1AAIpZTWUEqnZI54sjld7Mww8bU1FMA7p3ocswGRUY3uS1hfsD39UY8RfVgWCJm299/QWB/++uV9eOyj9dj06e2YH5aChZGW1YaqI8WI9J8PLzc/q3oCRwimih3cyEfRgGtZO05AV4beVKlkVCeESDqLK6JkAFAozIN6fb9ToaXtCHP8IgJghgWZT7G24yIAIJYX7MZNVMaQOfZmh8Jbvp9nNa5hHIUmKwl2tHYlXf+Oo5Ta1P74U4+4KMl/u+0RElL3WlPfAAAgAElEQVSxe1UMpcSqGzADyjyJexZq6ZjNGSKqU4RxWQEihfUYBSPUuizzXxc3SCF2PHRAnunuzX+gb2AnJmlivLO9EXVf1NH9xDERzQIfqPBXCgZIhnqzCSZJwmdDBhzkONzl5weBUkgUYKigDhtr9w/b/3ojI/EOH/IIYVil7oxctefNRsL42Bzr8bSNNSz5tOkv8yv7vt8uUVG21w4AzBND0m4w5yfkcQnl9mbhbDE87D+vYvcFWWWll/b19YUWUGpbI+YIDwz5rsfLee/gquhf0j9XBtM2Z2d73utcnuSwsJwOCCFRAJYAsFmIz2ZOa3ZOAjXz4yMANELm+vTPDUsi+bnbGyPPnQPCOBVVcKrhRr7aJvH1eTgJv7vsgEu3hbrF5U/Hub5X7tt2mO12+lxz5uwsCA5pkG2M2ISoQ78jT8sqdlQ7u4sYg32PHQCoVq+t1RGzzRm0bTpt5V2B/ieEZU7m708Kh1QibI6rMGvTPkFpO+zSPPRhIRXbbaa85wReti1ENyff1nYREveuuqBFJJLNMXh5dexPXPjdPEKsZ4UNwqvnLrxilojCph6KjPCNqpJuDbFoKqxA6T9VfyxcxtTa/Z1WqlW1NwYHeoiEhAAA18Oh6dkmxP0pDs3PN2Noj2XihTAE54R6HYkZZqPMkkTUDIM7/PwAAE92d6NkdBRz1WpsCgmByChM+xJvLe33js+R+2Ajcgf38KNfewCirPcUADBguCTfFTvmuC9ZRAjxlnvcBIeYzt0lyjoVRwTZS7c/uj7Dj0ZGVe0OCamLZBjJKa8fawzBo+9fuGZ/EfIjBaKMcrB7fOfypBnPoSKE6AEUAPgTpfTTSd/fBuBXpzU7pwEAxNfWNAP44VSP41TQ7ZdUUZDzdENj1PnZP6VCh1LBZDa8tV3i6/NxEgqdeM+M4ukqdAxkrOWwk07JFigNDDoU5cwRhci31w77I+R47AAOBDsAojjeoYt0q7/9DKXA7vJ+e9uVbivC7Q1lZ89XSyilNp/oWTCqs/nFRlDb/jKDg8GJHR1zbc4AeWHQ/1H81gxKbfqnUL0yissMMFLYcgMm5Eru4bwvxIxtts4BAElmbv7WljalXpRO0PpE3BmBwMsCoQnRwOcMHxy+JyD6M93Y0D0BAX0ThQ4A/CYgAJ9HR2NTiKX7n5UETdLeF/KS9j5/gEiCrGUaVjVnidrrzghWtWAbLF1GDpEgqSr6tuZ91vwc0zF2aBu1EmBqj1gpKOV6c97CFVziHjVV2LQmsHl9Sel25HBqbknxNeEN9cvKeF5lUxMmh0mzPVEOZnt2nKRCRwlLZ/H7kwudnxqni52Tx9unegAnkxG3kMMl6Y+W7U+8OVli1Xa7PmYbVBrpNg++fIhKA5kn43rB2piqhd45TmtrbDEuStY6e5y/f+NuZ59MdyNNvkUAJ8mNurBb74QIQqC9ZSgAqIi1X59GtPzXrmMuw/pHg7jZMhkEL5k9j4zstStWDZV8EoMlb5tiZAA4dHBZnsmotxE3AUSiMfaXePKwLTNEAKDuymguw99AAZueNHfzd+W/LKwqpHaKL39R8i9obp0718ydMGb/8/wx549zEHx1MLo/7YZ2fbDnxQsNivXtLYMv99m3wvEZqF2YW/yrIO+B2oKjgjk7EMIqlW4r81Ue6wyE8bT52hwPL5k9C7s+zv+69ZW+Qa6nhMq41mSipcAl15nzFp/JLapUU6ULQmTCdHbOTdu548pFVVVnV4+NeWynFPL8p2yQirKkp3B35otYN5RPvytQUL5x0ubXp3JuORCLUegbAGoopc/M9PVmktPFzsnjE8gU4f2U4ZT6vt1L7i0sS/1dhFnjPW038JOFJLTXmQ2vCQAn21BvKrgrfZpyAi8PJy74ClnDVVEyAERHVzh1c5BApB4EyBdsU1tLLcdjv1BRAWpi58YOAOV2zAUBQGvqC2UFk12RqlJrcxULALC7b2u6RCWrmpkJzuYXpRBK7Lb8VVScHy9JxGYHWCrKlqzGB3Z1EtRDNYdb5t9PAZszVk8I1+RuFK4vpRQ2NSEqQP1Je2f2mQMjVq9nbLJIldRBarTvNXiOPBfl/j1j7DnCcXbfO6zEa5dU/S1v8b4X9xNJkOeOzHqGqD3XpSt15+4CGFnHAMCoYAjd0vZm1n87/t5gFEZtFqy2iJL8k64z5yadzS2usmcUaY8hQ2DC7l0XZZaXXdI90B9cQCmm5G7sCYPfzXgp721cFflL+uc9wbTtB8ygkSAhxIsQ8jEs8ovrAKwihBwhhBgJIRIh5FeEkFYAGQC+JoRsmamxTBeni52TRHxtzRh+xo7KElGYa+ZdW1Cc+YTC4BmbK8dvY7YhmPeWcsMfhgHUYaDldKBk1IaVoWvFqYR7TsZVUTIAaLRDLSr1mN38pOOpx/w62EnV/hFmsZdA3myTHBWh1oGz7pFAxBxnvHYCAT0VNs0JAYBRzU8BGJvLLxIVNTWDOw7aO4cSCrfl/ALrURDjiKLKc9/es0ftufZejE+y0+gOu5EP1Es1l0vz67ZnqviOeE7Gnfzd+yg9JsC+6XMjAjYNI/HFY5pscXPPMrHTTFtebjk6ozRQMoDWV1oRcEkAqEABCZAYwrbEKPxfypHqJWLdMHEyvv3Vi3KLf+3vNdhQ6Gh2bgJWHZ+q9roziFHO3QZA9hJVn7l93hctz6ds7/68QpB4pzuHIiS/xWvMuckruaS9WqpyumgCALNZH7J//5l5O7Zfxba3zSuQJPnBpdYgAElF2ZKncHdN5/KkmXQsfg7AZkppJCzGqakAzoPFTLAQwDZKaRilVE0pDaSUrpzBsUwLp4udk8tLp3oAM0FLaP6OgpxnujuCM/NAiNUwxNkOP7q5QBj7Lg3AlL1t5EBAhPPCbj7EEkXMdJ2zUFm901mn5AliY8sPWQuqtHs9LHd4c5uAGRHs3vCPw+FN0EuU7M+SEkIG3WC3EIlo/s6utxMhhLDqJJszLgBwYLAkU5QEu11HMVJgio+kt7ucNTQUEN/ausDu7M0v8FReGG2y27FEvdXzuaV+7fYKva+l9JSr+QebJEr6AeDGJCU2rzkmp7r8X2N4s5IHKIhpl0HR/a+OQYmT0PtNLzxSPaD0VoJ1Y6Gdo0XD7y3+VY1n6OffeidLBt3gsChgJU6XXPls7sL9r1QRSV4nFSEKtUq/Kl/lcWM3iF62zw4AtIzWJn/S9Ezc3v7CYolKdrVc1giXfBdda85JOZdbsl9H1S4JcUVRqT90KC2vpPiakIMHl+4UBOV+V84ziVemeLxNCCEeAHJhWb4CpZSjlA7+FNvNJ3O62DmJxNfW7AEgu71yttPvNW9/YfamfQ1xqzMow4Y7PmL2QanImYfeLRa56pPScTXBiuA12zWsW/J0nc91UTJAGMHk7d2+yNnjqpAsuzB0wmNHFsGC4PAJvy6M2I1qcTN2RTKiud7ePgptZgrsLD9TUHZP/38d+hKdxyUnEhtRERM0HknOHRv1tPv58Cf8ZqmeDtnVk1AfdQKf6tsyEfdgjZ3SggXncY8PCpRpz41UwEd77K3/1kVaLAlmwP3eHefNUZDPozky9ElnR+ClgQi89NjEYfBVwYh7NA7hGyx/+gY98b/lLja5IJEUUMBhO7R/376k3OJf+XgaDsme5WFYnwiN1y1LFbqzSgH7y4PHH1pj2JH9SdMzPoeH9xZQO6JvW4RKPonXmLNTzzcnV7tRdZmzx48Pg+1on5++Y/tVifv2nrnfaHTfQanj1+o4SlaccWhKImgHxMAieH+LELKHEPL6dBicnmpOFzsnn+dP9QCmypjWr3VH2sPbK5PuThQUttt3ZztUGu01G16uo2Jv9sm8brLvWQW+mhD7ghAn+Y9qj0uiZAAIC6veRQicWkoToOAG4SXbD4gM8645xdogUhAc3hzL5jn+gPbv3Wv3SZ8QlZ5RhNsMAAWAQ8OV6ZxksvukroHSK12Ye9jReCorz10sSYzN/RQQVM/gzmgF5eyeS/LVJPIpvkeoHb+gWhoRk8/9BWaq+NG53NUEl8UrseSVUUR7MYhUU89Fh4eC8hJUjt1yCSEvXMDmPX4Fc0Ak1j2AJsNKnFvKnmdyEw+8VkkkUXbxolAvXKb2utOHUcZsA2xrkI5HoqKmvPebvH83/03sMjYVUBccjIOpd8LV5uy0C8wptXpJUwoqa+X1BAYHgxN3lV+csav8oo7BgaACW8n1Vpjpe4gClkTzlyilS2Dpirt/hq8545wudk4+n8CGEdhsh2e1hsqFt2/bmbbR36gLPCmdSjOFJHQdNBteM4KaT2qxFqVPLJvjvmTK4Z6TsYiSTS6LwcPCDjitGdqHxbUgRFYrOQAwo4LsWTPqwFQQAGI53qGge08MiXMUPRHRvNXhjKRCtyIKsN3FBAClPV877LpZIIanu0sau91FoqjUV1WeI1KbgaKAG0Y9n8C9SkIluzNKkp9mEb/E5xCF7XO1Uv+QdPPzXgOC+kczXL/JUqNygx5Pr9TgoR/MeHS5muR+3ZrLP36wp/vzLoczEZWxzKJb7mbVve6QNQMS0Fu1JKfk154eQ41Fjve2QIhSp9JfnK/yuK7NXoCrNTjJ6LOt88O8/7S+1jXE9W2nLhjOBVKv+VdxWcsu5FLr3SXtTleLHpPJI2zfvrPydmy/knZ0xBVQSuzZOXTAcg+ZSVoBtFJKJ5ZVP4al+PlJc7rYOcnE19bwAGZtMqw1JMIIDbGXFBZlP8n3+y7IByEzlvR9MhDN1eXc8PuBgHRSl958VMH1aX7nJZBpdI6eiigZADw9Ow8oFILTjs2FyLfrU3M8xCi4NOtkixie1zvaZ1RLPHkWdmdA3EfbYh05/TKsTySIu10tSvvYwaQxYdihnmMVlxINB505IyO+cU1Ni+3evIPREf47bOyGHSdnAJACtIv5JJ86ChgBoPc/z6Llb9ei/Y3bj+5zeNsnPun/UM1pNBxLXH+visNzO83Y02H51lxfBu9W8ai9SuUfU2MY5tpNDl2Dh3XE5/Y7FWnfLiEFFI6jFRSi2T21YlPOggNv7AYVZWtrGNY/WuN1W7JCm7cdIJ1yjwOAEWEg/Ju21zN/6PxHjVkccyn3KoB6zruSy0y/iFt60EPS7rDnrWQPUVR5HGxIzysuuibw8KGUHYKgsNYt+PKKMw65HFMhB0ppJ4AWQsiEZcgKAE7Ga8w+Thc7p4aX4URXwamkI3BZeWHOM00t4WfmgjB+jo+Y3fBj/y3gxzanADian8SLIp77rhhPbynEps0F2LLf8pD7VVUNnt5SiA9Kj30G7m5sRVG98zE2GlbfvSJkjdu4E+m0MRVRMgDEzil3yer+ABY6NxvEy/bYkUUUz/vK2a/Nz/Esqm/fAYciWaUuz2HSdkn3Z+6OZgjcoAlcIkbbDOmcoKV5UfbIsI9dUXMCDixYi9eqHHnXSIHaJfwi72oKmPULz0TA6keObTOPwtxWA/8rH2WM0LKfNntWGXmKt6t43L5UhYd+MOP/lqvBS4A4/pNFKySvp5q7TWpJanD0cwDA6+eweY9cwzYIjPXw0uMJ7KlIyS3+jV4/3Gz35z8ehSYlU+11uxujiCgAnPO36TG1Jvy7+W9JpT1fl4sSb1fYbgt/6hF3BZeZcTGXdsRL0m13tegBGEVbW0LGju1XJ+zfv3yvyeRWOu6PZMLJa3K5C8D7hJC9sHRgPUYIueSn1m4+mdPFzikgvramG8D7p3oc9hhyj6wvyny8oib++qUSo5Rt3T5boVTkzUPvF4nmqjwc975XMAw25KXjvpW5uPfsHNR29uBQdx+a+gZw38pcSJSiY3AIvCCivLEVmXOcc4RnicJ4Xtj6HoYwodP5M01FlAwASqWxV6cbdKrdHABMUI+OQh/v1EGSXI8dx6nnABAkiIFyDOr2xDpeEoto3urQaoBVzU0GWLszQP3mjnlDfJ+dTCwLKUJMthz/lqqqlSmiyNoVUJ+JLelnYKvDpR8pWJfCL/Tepw5P5Fjt5JxUAr63BR3v/QoSZ8Tqfw4vznmf9t2dpsLXDQKWhrAIcWfgpSHICGOx8KUREAJcEIigbc1tQUGCIGuZqjqSJKz/BevR6QW7SesTKESTR9ruP2cn1Ly9Cw68jCZDiNpd5X55nsr9miMgGqfdkBtH9i/9pOkv0QcGthdLVHJqlmgCP+oeezmXkXkpt6zJW3IrgfMC5KMM9IctKi+7dNnuXRe29PZEPL3ijENOhfQ6w4S3DiGkFsAHsBQ8+bB0qJYBuB3Awp9Su/lkThc7p45Z6UZpUnl1laXcX7Qr+ddzeJXHT36dFgCoZBwwG17dT8Uuq1oZQgjUSostkChRSJLlHipIFJRS8KIIlmHwQ91hZMdFgWWc+rOhK0PXVioZ9bSbFE5FlAwA0dEV+wmB00uSu5FWA4uFvDzMYh+Z5pZ+BaBgAIft7GVzHUeUeA43zpVjdMeqkx1GYxR3fRohR/S6ikvxgx1dDgBIkkJbuec8pSPh6jq8khdHax2Kh6UQXaqwwKtyclo3o9bBI/0ysG5ecF96EYLX/hXVinhfZVzWtovnK/GH/GNvj6fO1mDfbXq8f6lFqqWn1H1LS3tq7phxm6NrA8CYhnjefZsi44s0Ukhh21NoMkFd5ak5Jb/R6UdanZrlYRRBcRqv2xcrNFnFsBmlYR0Kyu4fLMr+tOkvHk0jBwrG076dxofqoy/j0rMu49JbfSR9Mabgpmw0ekbU1OT9w9XjZTLhrTMfwGJYEs7vB/BfSmkcLOnqP1mh8v90sUMIYcdb674a/3oTIaSWELKXEPIZkWuY5gLxtTXVAGbNNKDIqMb2x68t2J7xqH7EPVx2cN9sRxJ7jpgNrwyBGpfY3U+ieObbImz8YiviAv0QG+CLRWFB+MvWYvi46aBRKtDSP4jEUOfivbICLil0V/pkTOmHsMJURckAlfwDjtiNTLBFEfJkZRZNQEYF2X4840fIEnrqKO1ztM+RIMRSGc7lPgO1DtcmFdr0VNgx7AMsGpAeU6vD2Qsv6hYxXwx16BczNuYVffhQqkNPlofxUJYP7XV4PjHMLY2PUv/ofJ7LLkfI2r/B54z1MBT9HV45a3Ddrvj8xHe1PX8sMNv9XTAA80JXT/4v+wdKIDOT6u8r2NwHr2cbeRay1oOVgtEzbdfj2fG175WBSs74NUGhXZat9rxdRdiQQjgQmR+PSAXdzp6v8j5vft7cY2oppHYiO+zhTd0iL+WWZV/Opbf7Se7FoI71S1bYvHHjxhnTzdjy1gFwEYB3xnd7B8DFMzWGmeZncUObAr+ApXqdYCuARErpIgD1AB6Y4es/PcPndwgFaGPEOSUFOU8bugNT8/Az8FOYQOTqK7ih93wAx3lPDENw79k5eGjVCrT0D6LDMIzl82Nx79k5uDApAZv31+OcxLkoPdyMd7dX4Ltqx3KF+Z7LSsLc5spOEJfLVEXJABAYdHAXw1Cbadr2qMf8AGf2Z0Z4pzxN5La0eIuiXR8dAKCEMAadfXNBAIho3urwZyJEqWMUkQ6XRnb0fJ5AKXU4tixhXo6Ssgcc7dfeHp9hMPjbnblhILGbcHeCmpqOBkMantyI7kvPQO9Nlx/db/jV59D/4u+XCMM94oQXzsj+7zG063NwXZZVOoV3KEb3f4+RK97wf68lsK+uV3R4c77JMJz1Rmf3IYZSWcXIwVAyb909rH+Ln3zfseDOnWk5Jb9Vu412OFwqnAxhNJ5qj6tyVfor6gCVw9f7eMzSmN/3Hf/I3dz2RtswPyA7q+t4vKhbxMVcWvZqLqPLX/Iogp3YDiv82dXrysSWt04gpbQDAMb/depvfzbxP1vsEELCAJyPSWFqlNJvKaUTU407Abh0M5BLfG3NVkBea+ZM0OO7qLIw55nawzEXZIEwwadqHDMBP1ZQyI9+tQiAU47OWpUSsQG+qOs4NhnRNmC5V/u5u2FXYxuuz0xGp2EYPcO2JziCtNF7F3nnOa2HkcNURckAEBVV6VKcxzDcB8zQOBXsSoZ5WUsWzhIiiLLOWxdGHM7seBsOJsjxeVHoVsTCgWGeSRz1bx2rc9iZRUCY87hklZwn/X17z0q30Z1zFA3Mbptwtxcz3smkXXkBvJ944eh2aWQY/IEqeP/5BUDBsmNsy16RN0uj+7+D+5LzMVj0d3hmXwtIAjAuh2pTRfs9NHxZvb1W+AnSTOYFm1vaJZ0kyZqBMKmI/r6bFVn/ymGK7bXHT0YpjHktK380c17dP0rhoPX+eBhlWLza6454VpNWBGDAmWMBYIjvi/pP66vp2zr+uY8TTS6b+nlSXdhF3NKcK7jMngDJsxB2YkLGKd24caPdqJBp4GfprTOZ/9liB8CzAH4D21ObNwH45iSM4xHHu0wvI7rgIyXp/1e2b+GtSSKrdk5oOsuhVBLNwx8WiubdubD8ATtkxGSGkbPcb3hBRENXLwI8jjVNbd5fj5WJcyGNa3gAi86HF63f8/QK75bcwNUhZAZa9KcqSgYAnW7wiFJpsrusZ4tSZNY5u8TpjMfOOLImd6J4easBZfPkdcB5GQ7aFSADAMN6hRHGw2EhU9bzTQp1kN8FWDp4oiR/hzMVlLKqPRXnezgKlPRFX9BGPDAKSodUi1PAeEyq9RkGQuNh9N95A+jYKPpfenBJ99d/HNAnXyAZD5VDFRQHhbsvGI0e6pD5aH/jDoAAZcFXLFjD/+6wRB0XCMGiGFzQ3BYdzfGyZ18+zmayf7uW7TArIKu7CwBCO0qWZW+/n9WNdjo3y0MIo9Rm56g9N0iEDSiC/InEo3SZGhd+1vzcovLezWUiFZxvzRzHg2pDL+RSc680Z/YHSl6FoDY7dB939RpOYMtbp4sQEgwA4/86uSQ9e/ifLHYIIasAdFNKrXpnEEIehKV1ccY7puJra/4DwKmsF1fhlG79FUn3FJYtfTDMrPH9ySWSO4JKJoPZ8GolFdqdciceMpnx0radeHpLIZ79rhhxgf5ICLGsEu1v60S4jyc8tRpoVUpE+nrhqS2WFYUQL48TzqVk1IZzQm/iCCEz0qY/VVEyAMTOKWsmxLVojGLkOu04S4yiU+OlMocWI8NYEAD2xJBYOR1eEc1bZbXHK7TLHRaxAuXcG4Z2y1oyWc4nZrCUcVhomUweYQ0N6Q6ziWJxKO5O/KUBx2apAQCMzg1uV98IxtsHusuvhc+rHwLeHr7qc84u0c7NoF7Z1xzd1/uMdQhZ9wL8L/g1AKBESkxcxT3WL1LGYWeUhlLtF20dmatGRrfJjYFoDCKx6+5hww4FQbapoIof9Ukv/2Pm3Pp/7gSVHBaWkyGMzlftsSZHqb9sP6BwKe/p8HBV2ieNz4TXDpYWUSdnmSbjDm3wBVxK7tXmLEOw6F0IisneSfsBfOHqueVix1vnCwA3jH/vBgCfz/RYZgrignHkTx5CyOOwxNYLADQAPAB8SildQwi5AcAGACsopTOZKnuUmvnxqwB8OVPnlwjL1cet3tEenJ30Uw3qdIQk9jdxQ+8JgHjK2uQJiHBB+O1VWoU+ZSbOX890lBeqqpdO5RwMw49mZn0oEOLc8t4EN+DDIwJR2g3QPB711rYGIiFO7v6V6pv3epFRh1ldpRr1gfXBgbK63N5/UjiiFGF33BSgP+T9rQvEcQeXaeCvdYBgdzmPAcNdFnVvF0Mc58a1Mf37v1HuSYCMMNbExO8KvH06HGrBPsJVRZ90ZeUM/O5u+L358QnbDU89At1FV4Kvrwb3n809Gr95/l6ZV9k9ZwTpav1O9WteRQRZ74GP3N1K/8/XZwGc8JdaVSptv+57aSGZ5IXlCE7p3rs7+b4Go9bf6WYASiVRMBaUiOY9SbDcC5xGQZQjaf7n7Q7TzUudao7UGMw9Bcrq6jamfykIbtq4ceM/p3I+uRBCkmCRdagAHAawFpYJkX8BiADQDGA1pdQpQ9HZwv/kzA6l9IHxePooAFcB+H680DkHwG8BXHiyCh0AiK+t+QpwnBbsCq0huTsLcp7paA/J+ckmkjtC5A5VckNvu5/KQgcAzgi+dvtMFToiJHOxsmbK4sCIiP0VrhY6ffDtdLbQAeCUx844sp7AInlBlrEgALT5wmHbOAGI59ARu742E7CaVIdP8hIk1b6BIrup6ROESj6JwZK3rPbq/fvPyOJ51V4A2LSpG5df1oj164759b32ah9uXt+KQ0/8NWeeafdOADB++xXGPjnWucw3WHTMirBImL79Cl4vvOpv6qvr4fvtv0zNNDAsw/w391GqqbG74zirh0eXfdDe1cFSKjv36qtlTOa9N7P9JiVqHe9tQcUP+2WUbsyIO/jxDjh5MyaEYZW65blqz1tMhPFxKahZoLx+e/fneV+0vDjaZ2ovopS67K2jg9r/XH5J3tXmrCoAH7l6HmehlFZSSlMppYsopRdTSgcopX2U0hWU0rjxf3+ShQ7wP1rs2OF5WJ4mthJCKgkhJzPW4Y/TebIBr7gDhVlP7q2fe2U6ZRTOueD9hOCN24v40c8XAM4FWU43S3xWFPppQqc13HMyBRZR8pR/jyGhrndxlSDX4VLLCXDioDNP6ID8ZawAUQyAzHbgyhh57ewRLd/JerJXaNJSAThsfa81lGYIEi+rgDqbX5RCqJwkb0axp2KVP6XoW7nSHY8/fqy3YGREwoEDZrz2ehgkCTiv64VlrHnEaNryJbQXrT6231svQn/jbaCiAIz7SpEgX39Ob3aoR+qDp1+a+YWwPupuNyB1gkSOi/tvc5vGUxRlm/y1+ZHIm+5ho2vC4Th8dBLhrT9kZO34nagx9pU63vvHEEYfoPa8MUvpdmGlIwNJW5jEkYDvOt7L+bb97cZRwTCl5hM3aJ7fuHGjiy7MjiGENBJC9o3f63aNf28xIWTH+Pe/HG9J/1nwP1/sUEq3UUpXjf//HEppOKU0afy/DSdxKF8AcCmbZTJGjW/bzqW/L9mz+N0WoV4AACAASURBVBcJgtLN4VLATxVKqcQNf1wgmnbmAJBvcDcDROoXlMd5pGTN1PktouSuKWusvH1a97KsONfV43cgy+k1bzIquORCKwcGYFgZxoIAUDqPkVXk+fXuWyhH/0GIQsMoYxz63wBgdvVtkdV6r4TCbTm/QNbPYza7BdfVZh9ZuFAruXsc+xhnGEAQLEL6vVVGPPlED+E7u7RCfbVo+vYrAICp+Aco5y0A6xcARu8OZcIi9K1bDRAC9oKcVCFUt83R9Uehdc8wP5/QJAXIasX2lSS/H5rbEhaYzbI1OYKCqP+wRpH76kpmJ4V9YfZk1NyQf2bpw8tiD31WAkqd7rpiVXOS1F53RrCqxG2wdCU5zSDXHftVy8tphZ0fV/GS2el2dwC1AD505dpOsnz8XjfROfo6gPsppQsBfAbg1ydhDCeF//liZ7YQX1tDAfyfq8cLrHq4KnFDwY5lj/iOuQVngRCXBKg/BSg1D5sNr+2ShOZp97BxFm9VYMMyv/PnE0IcZie5ynSIkgEgJma3Q+8Xe7QiwuklLGZEcCV7S3ZR5SZJsqbVDwdjDoV9J2IAIKCs+3CLrCUapfaMuZCRwdQ0cmCpWTTKmtWIkQJTfCS9rOWsnp7o1L6+8B/NfOh0DHJy3LDh1jbk5+vx6mthWLZMh4+/iDXoz13VBACa7OXQ33Dr0WPcb7sXvm98BM8HHwMACIne+WKwdpuj63NQqvO5Z9KqpBhZBYwSUH7Y3pVzjWG4EE4s83yXzKTffSs7PKaCU0VDZMt3WVk7HuTVpn6nZ1gIYZVKt7Pz1R7rhwjjKSviwhodxkOLP216dkFF33c7JCo6dOmexMNhT+TM2KyOHeYBR2fTtgK47BSMYUY4XezMLv4NwCn/BgoiHoy5qKgw+ylTn9/CPBCimaGxzQokcbDVPPhKJ+jIKe8m07BuPWeGXKclhDi1TOMMU3dKtqBSjXVrtUMui5vbENokEdbpbC9XPHbkLmMBgK8oySrgKCHMkE5ea3NE6391cvYjrEcwYbxkdVLu6P5C9mfteVxyIqi8iIOa6rzcsTHlj4qAK6/ywiuvhmHDbb54+60B3HCjN4q/bvMJ/P25/iNvvWg3JX0CfpFPvhio2eZoPwqGuYh7NGermOxw3wke6B/I3dTTVwlKZc/WdPmQsHX3sHMro0mBnM66CdScISBr50NpMYe/KHHmehMQ1iNY7bkuQ+l23i6AaXT2+AkahnZnfNz4TEi9YVchdez8XQlL6/dMQwF8SwjZTQi5Zfx7+wFcOP7/qwE4FNf/VDhd7Mwixmd3NsrdvzMgdVdBzjNHmiPOzgFh/GduZLMDkW/cxw29qQYE2Z09MwVDWNO5Yeu7GMKGAYBJMGPVu7fg7DfXYsXr1+PpojcBAI9tewlnvXkj7vnqT0eP/WT/Fryxy7HucLpEyQAQE7OrmhDXl/uKkO/MU+lRmBF+RmcYQwVBdit8XSiRlXHk37NnESxW+Q5R6M6Q1WXUZWpcOMobZOlINFB6ZQhzZWpGCFNbuyJIFE+cYWposNSZYWFKbN06gk2PeuoiG740C82Nsl4zPsk3X/R3XPAAwM38r/LfFc4qoFReIXLO6FjKZ22d/UpKZfvUiCxRPnYVm/fCKmaXJEMvNZmo5i1ZmTsfMqrNgy7ZfLCq+alqrzuDGeW8AgCyCsbjoZCUe/r/m/tZ07PKtrGD2yilts7z+7Anck5Gm3QWpTQZwLkA7iCE5MLiL3cHIWQ3LFo7p60mZiuni51ZRnxtzWcA7BplDenDG4ozHttdnbA2VWJVLuUb/dQQTGUl/MincwHMhqKOrgxZW6FiNIkT31CzKvzzqmfx7U1vYfPaN7HtSCl2NFdiV9sBbL3pbYhURE3PIRh5Mz7a/w2uX3KJw4tMlygZkAQ//+b5UzlDGdJdKpSIUXTaWNGZJ/conpf9GVY+j8iasWGopNSPtslaMmGVUQsBpaxlr+LuT/3kduksEMPT9ZJmJwB8/vnn2LRpE1588cWj27du3YqXXnoJn332GURB52s0aoVvvx2WPv3k2OTFxKyOKFJIkuUlDdQNe5019I9quf43fLJvvuirluXe+7CwNm+TcOV2KjPwcg7PR//Q3OrjJ4gORdGTKVzILL3jdpYb1sCpVHONeSAoa8eDS6Mavy52aZaHKNQq/fl5Ko+1vSB6l8XHPOU8irs+yf+q9eXBAXNXMaV08nJVcdgTOV+7em5noJS2j//bDYs+J41SWkspPZtSmgJL8rlLQu3ZyOliZ3ZiVRRmVnn0lCf/pmhXym9jOLXnjLQ4zzYopZQb+fc2wVicBTif0D0TZAZcVOih8s2c/D1CCNxUlnupIAkQJMvnPS/yoJTCJJihZBR4pewDrE25DErWvrmzgYy1TocoGQCCQ+rLCaHOtn8fhQK0G0GuCZs5yduFo2TPBsXwvOz3REUskW1NEN76g+ziTqFJk6UbGuS6Ywe5btn6jwu4lGhQGJKSkrBmzZqj3zeZTGhtbcVtt92GpqYmvPbaa+jvH9E8/VQvUaktL11J8SjmzVfDz08BvZ5FQoIG69e3gBCC9Qt2J+Vgm+wuJz7VL0/0UckqeF4UL8r6tXBrBaXyZj88Jer5XUvbkmVGk1NxCH2eJPjmX7CJpXNJAXUy4DOm8T/ZGaUPj6rMBpfsPhjWO1zjdUuaQndWGcDIbqk/njFhKPjb9rezt7a/e8goDE8UfL9x9XzOQAhxm1h+H/cFOhvAfkJIwPj3GAC/B3AyO5JnlNPFziwkvrZmO4BPJ74WGaXxQPwN20oyHtMOe0TmYAbFsLMJSvkxbujNUok/nH+qxzLBPM+0knC3+VaF0aIkYuVbNyHpbxchJyoVGRFJOG9eHs55ex3CPYPhrnZDVUctVsblOLzON6o97dMhSgaAyMi9smY0bHEIcQ2UMLI9bX6E5FKRJXtmJ4YTZLfGDuuID8+iUc6+gV27FoNSWcterCZ1KUBkaWyKuz+LoTLTwd2gCVwiRu+LjIyEVnvsrUAIgSiKoJQiODgYa9euRW5uLi6/fDXOOiuwHACyst1w/fXH6sxbN/ji9dfD8bvfWVZFN+D5vGh6UHZnFL/UP0/yUskqkD4W89Ju4H/b4CjaYgIWYF/v7M67fWCwGJTKXjaRGMI+fRmb98wlTKVEnIsx0Jr6Q7J3/C4lsmlzkdzf8/Eo1AvT1F53+DLK2G2YwnLPANcZ90XLi6nFXZ++FPZEjstiaCcJBFBMCKmCJZ/xa0rpZgBXE0LqYekGawfw1kkaz4xzutiZvdxPAa4p/KySgpynB7oC0/KdcSH9qUOloQ7z4MtNVDKkn+qxTBCoidq32DvfZrgny7DYsvZNlN3+MSo7alHbcxi3LbsGW9a+iYfPuBNPFb2B+3JuwgdVX+G2f/8Bz21/x+p56pmO8pFpECUDgF7f16BUmhdP5RxFyHcYEWAVXjIQFxxpKeR54gBApMA7FcvR7gNZT+IMFdS6sa59cvYlhFUxyjmywi/HBENIl6lRtgdMihCTraHKisnfU6vViI+PxyuvvAIvLy+o1Wq0t7dj/vx4UrF71RxKiUMDRQB4BA9keNIB2bMbXJpfjuSplFUgFUqLF13E/bFbpERWKz0A3DY4lP1SV08todSp6IXS+UzyhjtZMqhDheO9f0zskS9zMkr/MKTkhp0+FgAIUWpV+ovyVR7Xt4HopmIMy7eNNfxlCsc7ZLKvDoB/UUoXwxIBMQxg9bjXzg5K6dzx/+6nP6OIhdPFziwlvramYXv6o5sOxV6cBcKGnOrxnEwkvrXabHiDAfhZE1KqV3i15gWtDpIT7umpcUdGeBK2HT52T9vfZfGVi/EOx8f7N+Olix9BXc8RHOlv+dGx0ylKBoDYOWWuFSqTqECqSzNDZFSQfaM7/lC5O/qKkh8old3xVRlLZC95hLVtk/35qNQtjwccp5cDwI7uLxZRJzQjq7gUPyr9WMyalZWFDRs2YOXKlfjhhx+Qn5+PiooKfPDBl96PP6ZXUBlJ6iwkxVO4O05FzfICOAkh3DL/bMldXsGzl8bGreCe4jjKyha3ZxtNi/7T2s5pJMmpvKpBPfG/9W42qXABKaAOUumPR2vqC83efv+SiOatRaDUJXsGhvWL1nhtSFFo83cAxJW/uZfv++dXsoNQp8DxvjpPAniEUpoE4OHxr3+WnC52ZjFmjfczgOOk4Z8TgmnPDm7kX9EAddnpd7pREtXQOaE3mYidjre+sUEYTJbZcCNvRlHTbszxPaYtfqroDdyXvQ68JEAa1yMyhIFR+PF9evpEyQDLckPu7r3JUzmHCEboh69L4mZmhHfFYwdwYhmLAEQByDYuLJ0rz1wQAII7SxdBZmwMYfQBhPGRJVrlJJN30+iBo+7D9/3nCST97UKseOOGo/tM7uLzom4REZzvXpPJhJ07f+zh19Fhua/6+vqiqqoKq1evRleXEFhaGiTL3ViHMY8n8Qs3QiV5hSkhhMvwz5L0ClleQI00ODzb/FfdGFXLLl7CBDG0oLktLIwXZBkWTkAJYZ6/kM17/ArmgEjgVMFBADLn8L9z0sseGVByIy6buyo0yRlqrzvcGUVEAWR4MI0zACe6cKcZimOzr56wLF39LDld7Mxi7nj5jH4Aj5zqcZwsuJGvCgTjD+nA9GhVpgMCIp4btr6eZZR2u966R/pw5Qf34Kw3b8Sqd29BblQqzpxj0TBvri/C4qD5CHL3g6fGHckhC3DmGzeAECAh4Nhpp1OUDACRkVV7CMGUlj6rkVgDF32EyDDvYouu/GUsANBLkuwHgnFzQVlP76zE6bSmXtm+V0rdCtli7F29W9LoeIGxeuE5eG/1pqPbhswjJ3TxLRGilxqNRun/2Tvz8KjKs/9/njNL9oXsJJOQhbAj+04ChLrh0tZuvt20LhWlWpVWu9mmr13yVm3fttpStbW2dkF/1daXLooLu+wh7LKGJSGBAAlZZ86c8/z+mAQDJDBnmUnA+VwXlzCZ85wnEWbuuZ/v/f1OmnSuVdK7777LnDlz0HX97ICVEIIjh0dPbm+PD6pYSOdE9nf5zumguxpCKL7pGdP1OOdFp0a7OM6A9MneZwaelvFBFxGxUsb962jtlI+0thkSLgNsKVKu+vIDjqiGBAxPTMW2n8iduebRMZ6j76wIttA9HyHc8e6ET85yJ3zuICI6mImx8oWLl4Qjc6onX50HgSeEEEeAJ4FvhmEffUKk2On/PAPBB+Jdjkjp7/A2vbBGV/fMwsARRjiYM/C/VsU4E3rV6XQxPKOI/3zptyy94/e8feeLPDjj9rNfu25ICQ/N/NLZPz9WtoC37nyRX9703XPWsFOUDDAwe4/H6hormGP6RVi0BPvB9sJLjTw5TdOCtvTXFeFojgnOXBAgp2ZF0Mdeiit3BMIdTIQEmvTH7m5a/z7A1NyxJMd8IG1SUM6Z4qtY9htu/sM9iq7pys9//nM2bw7IS3bv3k12djYJCQlER0fj8Xj49a9/jRCCrKwsKjffMFzXlaCOkIbw/rB7eHpX0M7GQii+GRlT9BhHUILaFmITp3qfHnZUpgWtVxIgfna8YdajJ0+/R++eND3SHCtS7lvgmPTmOLFcBnm82P2+Q/b9rXTK+sdPONVWQ+Pt3VGcmcXRyfeNcUbPWH0RAftO4Fe9fM1uevLVuRd4SEqZCzwE/DZMewk7kWKnn7NgUZkfeLiv9xEqpN5y3Nu4aL/UT0+/9LPDy9iUshXp0blhiaTYa6MoGSA17VClouiWU+C3McZ0EKBo95ty8zbiswPgUf2G3sze94ig9TLZx1aPNqIJckZPPRPsc7edXjFdk1r1+Y/HR8WeM8X3k+sfYVreOA49soxffPXHy8ePD5xMDhs2jNmzZ5+97pprruHee+/llltuAUDT3Elbt17dLiVB7b+UZZPm8Xrwqd9COHwzMyfp0Y6gChgv7uhS7/9O3KEPCuoIrIvPn2me9uKx+mpFSmNaGCHE89c5Zv33Z5U9foUjl77gXOLa6weVrH50dE7N8hVGi63uOGOmzIhKutctnDnLuVBP9ODCxUtMfyowQk++OgQEyl2Tv690PnZFEil2LgMWLCr7N91G0a8UdH/t+96m5/zgG9nXezmfvLjhG4ckTgxZuGd3NHTvSteujKamJl588UWeeeYZfvWrX53VZ3Q3kOuiqqrqAv1GdwoLNhuOaTgfL+72ZhJHmL1e+PQkk1caKnYKVL+h17ENxSIu2Oc6NW9ClPd00J/uHVHjJoEISkMkkc6qU+/2+Abe2xTfy6+8UvLu2+8E3W1rPpMx7OjRkUEf53yOP5SOlFXBHx0pwukryRwnox1B3UNHcdzg+/HM5dpVy4K+BzDe6xu+9EitI17Xg+qcdWfHIGXkXV91JNYlY0gDBCCQytC9L5dO3vDDOqfaFtR0Xo/rKNFJUQmfmeVOuHUvuLsMK19duHjJUrNrGrp/L746BDQ6XR/oyiD4ruflRqTYuXx4gCCCDC8X/N5t63zNf/WA7HeTZgPcmfumpt80JJThnt3pEiUrisI111zDggULuPPOO9mwYQN1dXVnDeSklNTX16OqKlVVVZyv3+giKqqlNiq6xXQOVhdbmLCbIKbPekUzJzKXBo+xilTV0NFf5WBhKNA0p3ZV0B4qQjhcimto0MfOe89smqrqvl4dmM+f4nv2Y48rel2H42TDyaCP16oPji9pa00KumPzDR4vSZd1wRcGinB7Z2aOkVFK0E7It6nfmP1X/xxDepwMTctYfuhocbHPZ6gzBNAWLZIeuNc59fXJYoUkuE5Xd+LbjhWUrH5kZHbtquUE6ZPUE4oze1hU8oIRjqiJbxE4NgoXvfnq3A081fn4j4AvX2SNy5pIsXOZsGBRWQ0BR8vLHrX1jWX+tqWTgaA/YYeLKCW24SPZX4gWQpg+vjFCd1FyQkICAwcODOwjKor09HSamprOGsipqorD4WDNmjVMnjwZh6PnWqyoaMMeIbBcqK1klmFL/bP49WYBZtyTweAxVqFPNdRBaooTaX6FoMehc2pXjEbKoI/KXLGzRgHexeur+N4/lvLEfz54T19StYun3ljBX9ad1eqKH6z8Uczirf/qca2epvhSXUlJ0S2KIV+Yysrrx+q6EpT1v4JU/oeHxsTItuBTxh0iyluSNUq6laC9Zr7hv3vWT9VPrpIy+FFxN0S9WlM385bmlmWcG7MQFC/NdZR+54uOatVB0JlcXQikMmzPX2ZN3vijWoe/3VAC+znrCCFcsaVvLVy85LDZNYwipTwgpRzT+WuklPKHnY+vklJO6Hx8ipTSildQvyZS7FxePA0YypHpT0ip+bxn/rBK8+2YTT8TIgMoOLzzPHcf6wr3DAe9iZIbGxs5duwY+fn5vRjI9TwNLoTmS0k9asux4G5Gms4hE63+oMfBz8dI6jlArt9v2JeoNjU4c0EAl789ye1rCvooSyhxacKRvmFigYe7Sz+QQLT7VA6dPM3Ca0vRpeRY4xlUv8bLlavyX6x8zX/g1GEmPfMJ/lq1BLj4FN99WR8bLqQI+nvQdVfcli3XSSkJasIoCl/Mk9yf4ZD+4LUuDhHtLc0aIV1KUGPvAL/Qbpn5qP/uTVJiqFvy/YZTs3/QcGoTUgatkepib44YeueDjvQjaQSvT+pGfGttYemqrw8beOy9ZUb0XN3YCfzUzL2DpbuBYKdZYNfj9wsh3hdC7BBCXLGeOj0hriCDxA8Fz8x/ZzyBNuRlFRkh9baT3jMv1CC9V/X1Xnrjupw7Vye508Ki04GAKHm5e+cFx00+n4/f//73lJSUMHz4ub6Kr7/+OpMmTeLYsWPs37+fzMxMSktLz349x7NjdWHhZsvfQyuxTV/mD/Fmo0kcNa3rXdsbTYkd10Yt2JglTl9yAq47o/Nz2xDBBX0CfP5tbcXN62XppZ8Z4ED+jSur86+/dM5HJ7q/drev+a/DTrW28duVG/j6dbPoUP38Zvk6Hpg7nRfXbGLe6GFsOXKM7OQEZhdO3FU28LPDhBBBV3oHlPpN77i3G8rIy83dtiq/YMvMYJ9/mEEHvslTKQiRHPRN/Hpr1Iq6fUKVQTt3lymbq37rejJfCAx16Xa5Xfs/m53l9AthypvqUyu1VZ9cJccLMGWc2Rzv2b957ENezRkdrLZNAiULFpWZKrSCRQhRDUyUUjZ0e2wO8G3gBimlVwiR0SlW/lAQ6excZixYVLYZ+GVf78MIur9+n7fp2bb+XOhMS795WTgLnS5R8gWPaxovv/wyo0ePvqDQ6clA7vjx45w8efLsc/LytpkUBZ/Leqa9byWDTTSrpnUNGDzGAnCBIbfm9UMVQ90gT82yEUGPZRPQZiCizvHoiXY5ucqTxc+WriIlLpZol5MjpxoZlZNFg/fo8Bb/aUMC2kI9c0KKHm9Iv3LkyOiZzc0pQWdi5XGo8GH+p9pIZhVOJc5bmlUknSJoQe87+vgxt/i+X6fJ4DLGuhjuU4vePVyTOEDTgu4mdeeVEsfMR7/kOOZzss/M9QktR4tKVn99SGbd+uVB/oyeDXWhcxHuBSpkZzfqw1ToQKTYuVx5DIJvw/clmnfXRl/znzJAz+3rvfTGkMSJa/Lih88O5z17ckqWUvL666+TlpbGtGnTLrimNwM5VQ3ISRISj+92OtVRduxvNaVWihVEi990y9jMhQkGjAUB9mVTLCFofx632pLqUlu2vrTsCb7x4if44ct3nv3a39c+y49euYs/vFNx9rH1e5by1u6WC3Rfc4YV8fA1Jdw8dgT/2b6H60YNYd2Bw/xhzWa+9sZjw6SUhsaQ5/nGj0JiqECoqrp2kqY5gnY0nsCGsZ/mzxuM3AOnEu8tzRoknSJobUulLB56te+JNlU6DI2JJ+v6gHcO14we0+ENOsm9O9VZouiOBx05+7MwLHwGUKTuHLn7xVkTN//kkKJ5LyZOrwUeNXMPE/RkIDgEKBFCrBNCLBdCWB5iuJyIFDuXIQsWlbUA9/f1Pi6F2vb2crXt3+MwEQYZLjKi83aMTSmzFKlglN6cko8cOcLWrVs5ePAgixYtYtGiRezdG5gEvZSBHEBR0QZDb3oXYx/FA61cL9r8bgtXG74iw68ZcrvtNBc09Gk+q35d89Qh17Jg3o/PPtbubeFg/Q6+9ann0aVOzckD+Pxe1r7/BtdNfChXlz13nGpOB7TfaQlxbKyu4YvTx1N7pmHAe0ffM9ShiMaVPM0/JCjhcRdSd0ZvqZwXJWXw050f5dUZU+TqZUbug0tJ9JZmeaRD9Dptdj4HZPagEu/P3e3SbWgE2gnOl47Vl97eeGYlBgtGAJ9LxHzzS86Zf5yjrJYmp14Tmw8Xl6762uCM+o3LexG037dgUZl50b8xejIQdBIYGpgKfB142cix6eVOpNi5TFmwqOzv9FPvHSk11Xvmzys1b9Us+rG2KM6ZfHR21mcyhBCmzO/M0psoOS8vj+9973vce++9zJ8/n/nz51NcXAxc2kDO6fQ2xsefmnj8uJ+FD9dyx5eOcOcdR3j1b4HX1ueePcnddx2louKDzvXSpc1nv96dRpJPqCKq2Mr3aN5jx7ipIIDH7zf8Brc3WxjqBuUeeXfo4IGj9djoD2p3IRT8uj8wLef34lCcvF21mNmjP47T6XbgKOxx6uc/2/dw7agh6Lo8p0u3+eTbhdJgTMFILXdqvB5t6AisrS05/8D+iYY8ax7gp7Nz5SFj3Q+XkuQtzRooHSLoTlIdKZlTvE9nNMq4oKM6ulh4urHk58cbtgspTTl//99UZcbCuxwnO1zmXOsVqTtH7Xph1oTKpw4omm9Pty8tXrCo7B9m1jRDLwaCR4FXZYD1gA6khWtPfU2k2Lm8mQ/GWtihRurtp71Nz26XWl3QYs6+wCnczdfl3NF+sXDPUGC3U3IX+fmVVUIQ43DA/Pmp/O6FXH75dA7/+McZ9u/3smOHl+ee96DrcOCAD69X5803mrn5oxc23dZQYt1YzKTHTgDjnzYLfarhonr90OAFzQDRvsZMp7/tnAIh2h3L2IISKv52D6mJWcS44zh0/H2uyp/BC2/9gGfe+tuUE82tPP5/b7PuQGDSeHtNHbkpSSTFRBPjdjEoNZkn3wicwKQnuVNr2/YZznS6yTehAImhrkFt7fBpTU3pho5+fsDXpyTIJmP6GLeS7C3JTJNK8IZ1Z4hPmup9urhWBheu2p2ytvaxrx891uLWpaGOVxdH00X+HQ86CnZ5MHUsBpB05uDQ0lULC9JPVC5HyhrgK2bXMspFDAT/TsA4ECHEEMANNPS2zpVGpNi5jFmwqOwEAdFZv0DXThz0Nv2mCdk+rq/3cjE6wz13OxWXpe6FUXoTJVtHysys/fkAqalOiocEfABjYxXyBrk4Xu/H7w90EHxeHacTXl7cxMc+noTTeWFdsYaZQQtxe0TT2wSkmr3cTGfHqLEgwObBovCYqnL74cPcePAANx08wB9PBxoCT504zscOHuQbxz4IgX69qYl3Vj55QYF09dhb+eYnn+WWafeyZOML3DDpdtbs+ie61Jk16uPiiVu/tPKxm+YypTAPgFE5WVwzcsjZ628aO4KvXVvK56YG/tmsa/jnOCmloa5THNGZ47QCww6/27ZePdXvd+4M9vlONNdT3F/okj5jhUSUI9VbmpUsFYK+roOomBLvz8fv1nMNa2ny/f685YePZmT6/YaLJQC/U0R97wvO0ueuVdZKjBWRXShSd43e8fysaeu+d9+CRWXhLCp6MxD8HVAohNgO/BW4TX6IxrEjxc5lzoJFZX8D/tzX+9B8ezb7zvwxBfT8vt7LpZiddevqWGdC2MV5y1073ztflGwH6RkHNymKfsG6dXUq+/Z5uWpMDCUlccy/p4asLBdxcQrvv+9lxoyePR0Pk29pj6LVbyzDyAYKVNWwgWFTnEjTFGoeychgSUEhfx00iD+fPs3ujg4q/xwxMgAAIABJREFU29v5e0EBmoQ93g46dJ3XzjTxcLQvll7eII40BBoXGUke1u1Zyp1Xf5faUwdp8A4zJM5XdW/SgeYqw0c4E/yFM6Oly5DZoJQOd+XmGxKlpDHYa+JoTargoSghdWNd5ShHurckK0GK4A39NBzO63wVM1Zpowynn8dLmfDmkdqJM9vaDV/bxdLxytQH7nE0t7kxayL45/FbVr1u9v5muIiBoE9K+Xkp5Sgp5Xgp5Tvh3FdfEyl2rgy+AtT01c3VthUr1NYlV4Exj4y+YMyA2SsyYvKC9lexi05R8pRQrF1QUHnBm297u873y+u577404uIUPnNrMr951sP8e1P5/Qunue32Afzrn2f47/+u56WXPmgi1JF11HeiIe/Uw3fTcPstNHzpE7T9LVBLNz/7c07e9WmafvyBkXf7m0vOfr0L0eI31JU4H6OmggC5qnFjQQCZ6aoeER2QbMUpDgqjojjmV1FloBPmlTpOBL87dYrPJw8g0deYLdXWHo9jlmx4gRsm3o6ma2fNfYVQkEpyPiJmS0/X9Mbmk29N1aVee+lnnsuNvglpBGkc2EVHR6Jn755pe6QMvqOWRZ3nW5QfNxyQGe3I8JZmxkgRvIM1CPF59Vuz/p9WuszQvQAFlF/Xn5j14KnG1SYNAKlPEZ47H3QMqSoQyw12HWu5DAZJPixEip0rgAWLyk4Dt2Nuatc0Uuqat3nxCs27sUvp36/JjRu2aWjS5D5JV+9NlGyV6JgzR9zutnOM5fx+SXl5PXPnxlNScm73Zu/ewOu9x+Ni6dIWvvvdTKoP+jh6NDA8sopZ1TgcJMx/mLTfv0rKM3+g7R+LUfe/j7qjitTnXwZdRz2wF+ntoOON/yPmo5865x5Ks2rozbYHDP89jpcywXfCe+ZgxUH2fnMve7+1l4Y3AycHdS/Xsfc7ezn67AduDadXn6bhzQaqCsTZI7sa1ceujg4mxcRyTXwCtxyqJsflIsHhYHtHO3MTEvhabQ1P/uPB/PqmI3znpc+wZncg5qHq4CoGpQ8jOS6N2Kh48jNH8MNX7kIg8KQW4YyZaeiNVkeL2tm45oDRn0OyjMsbpuUYGxMH6usHT248PdCQRmUEO0bewbNVhmMbop1ZvpJMlxTGksi/ps6f/Uv/x1YaiZfo4s6mMzOerzu+TzHpLaM5hOuHtzpm/epGZaMOwYifJXD78N27TAmlg6Unp2QhxONCiK2dj70phOh3+YN9QaTYuUJYsKjsLeAX4bqf1DuavE3PVUp/Tdi7JGZIdmfsn5Z+82AhRNiLslCJkgGKijbsF+KDf8dSSp588gSD8lx88lMXmt52dXU0TaLrnVNACni9gferdUwTjtR0XEMChoZKbBzOvAL0+jqkqiKlRHq9CKeT1sUvEnPLrQin65x7iBZV+s+coO4v36TmufnUPn8fZzYGBlFOL3uB2t99hYYlT519fsv2d85+HeDgSdU958VWhj/TwshftfDztYE64dGlHVz16xa++NoHzYQ/VvnOfj1KcDLr1iyKf1xM4WOFnHr7FO2H22nb10bxD4qRuqTjSAe6T6dxVSOpZalnzQVbdZ2v1tTwzYxM4h0O7kxN5bX8Ah7NyOQXDSf4Slo6/6+xEQ34VEp62y/ufpMffH4x04fNA2BMwUzmTfzi2X3dMm0+3/7U89w+91sAONyjJoFi6M19Z+OaaZruNyyyne4fOtMlHYaPXbZvL5uhqm5Dx2dzeXPqR3gjaJPCLmSMM9s3M1NIYcwv7Cn/p0se839pg5TGwzyndHhH/vtorRar60GPwp/P8tHKpAX3ObzN0VwqPuSXw3fvCkuiOTBHSjlWStnlOv6ElPIqKeVYYAnw3TDto18TKXauLL4Bps+Wg0bXTh3yNv2mAdlqyNK/r4hSYk9enf1FlxAi7MdsoRMlg1D8HQMG1J7jSr19u5e3lrZQWdnBPV8+yj1fPsq6dYFGy+pVrQwdFkVampP4eAcjRkRz111HEEJQVBQQNR8j5xzRtlZXi7rvfVxjJhBdOpdTX74Vx8BsRFw86u6dRM+Yc+G+2jQ3ioMBc+4k5+5FZH3hSZo3/xPf8QN4a3aRfcfTSKnjO1GNrnpp3f4WCeNuOHu9UxHyqWui2bUgnrV3xvHMBpWqOo01RzW23huPJiXb6jXaVcnvq1TumxSw9ElLdpyMyQ80zxwxDqKyo1BPqshOcbZUJcIhaPh3A6lXpyKcgj05DPZJ2fZgTQ03JiZxdULCOd/Lzo6At2K+280/zjTxs+wc6tpOJ9c17DHUdRFCKA73SEPXSKRj88mlhoWtCsIxzzfejSTo8NLOK52Vm29Ml9LYhM6XeG7WULnTsC5Gxjo9vhkZugRDGq+XtKunzlcf2mXEJ6iLbL82cPnhmvxBqrrG6LVdnEwSA+/+qmPU+mKxXAbGt89nG/CI2fWtIs/NC4sjzB3//kqk2LmCWLCorAP4HBj/1BMsmu9Ale/M7xNAKwrVPeykM9yzRhGOvL64f6hEyQC5nh0bhSCl+2OjR0fz1tuFPPe8h988G/g1ZUpggGjGzDi++MUPdLz3zE/l+edz+da3ArVYNQX7pfggRkFvb6Pxe18j4b6vocTFE3fr7aQ+t5iEexfS8sKviP/SvbT981Uav/8ILX987uy6wqslOuNTiMoaDIASFYsrNRf/mRNILeBJI/0+hOLgzPpXSZhwM8LxQcMtJ9nlGz8wMEmeECUYnq5wuEnHpwWKlnYVXA54Yo2PBya7cTkCGp8MTTvb8vGd8NFxqIO4YXEkTkxk/3f340pzocQqtB9oJ3F8YOReEzgfrK/xFka5uT3lnB8lAL9sOMH9aWn4paSzEYaCIOp4leHjCWdMyVgMuDYDHGjZOsWndRieskqXicX5errhWAKvN27g7l0lh6Ts8U28V77D92amyAbDk08yzpXnm5Hhk2AoOPYNfdLYT/u+e1SXwnAxGC1lzJKjx6bPa2ld3pvY/FLoinA8+UnHrJ99TNmii3PsPzqAzw7fvStkr8Hn0ZNTMkKIHwohjhB4P4h0dogUO1ccCxaVVQEPhmJttX3NSrX178OBC98V+ilX59y20e2I7pNMrlCKkgE8uTtNj3f3xApmnz1SkH6Vpu99jeiPXE906dxznqfuDfitOT2D6HhzCcnf+wn+6n34j3ZqTjV5TifL31SPr/4A0bmjiR06nWO/fwBnUiYiKg7fsT3EFk89bycfCJSrG3Uqj2nMynfyieEuxv2mlYJkhaQowYZajY8O++AILU/1awBah8bhpw+T9dksHDEO0uelM/jxwQz8r4Ecf/U4GbdkcGr5KQ4/c5iaF2pY1tQyYF1rGx+vPsjHqw+yvKUFgLeamxkVHUOG00Wiw8GYmBg+ejAwSHRt6x7D/waEEp0kHAM3Gb1u7Yn/M6aJ6WSOOmq6QyqGj8EaGvInnGzIM3Q0paA7nuCBkVGy3fARkYx3DfJNz2iXYEhPs0EOG36t739a/FIxFZ3zPydOznrs5Ol1SGmoAO3O2uHK+PlfcdAYS9cU3IPDd+8yZNZokZ6ckpFSfltKmQv8iTB6/PRnIsXOFciCRWWLsHEcXUqp+5r/tlzrWFtCwIjqsmBq+o3Lk93pYQv3PJ9/uytrQiFKBkhKPrbD4fAPv/Qzg2cTk2MgoPs588T3ceYVEPepL1zwvJYXfkX87fciNT/o3aaOvB2gyQ4BZ40adV87J177ESlz70aJiiVpyifJ/tIvSSm7i6aVL5Fc8nmaq97gxN8raFzzV+CDnnuLT/KJl9v43+uiSYwSPDIjii3z43nq2mgee9fLf8+O4vnNPj79Shs/WOGlUFWd0i858vQRkqclkzTx3FPL9kOBxk9UVhSNqxvJW5CH7JB87nOFVX8vKOC1/MCvWfHxAHwkIYEFaR8YzD6SkcE/Cgp4Ijub+NbaQkVTDRcSrtiPeDB4rHCs/cCYNv8Zw6JjB4r7GnVMOwa7NAC7dpWW+HzRhsbYo/HGPckDKYrUDE+GygRXgW9aerM0aHK3V3ryS7w/d3ZIl6kgz083t0z907H6ow4pTWcNNsaL9HsecIx9Y5z46fDdu35jdh0z9OKU3J0/A58I5576K5Fi58rly4BpIV4XUvpavE3Pb9T9h2bZsKewUZw4/r28uBF9Jp7uFCWHrKtTVLQxaF+UYNBRtAbShwKo27fQsfSf+LZs4OTdn+Hk3Z/BuzbwQb9j1bu4ho7EkZaBEp+Aa8RVnLzzUyAErqKhiLYPPHak5ufEaz8ibsRsYoeeOwTnqw/UCc4BObRuf4f0j30D9cQh1FOB90lVCxQ6nxvt4pbh5wqgK48FhnGGpCr8oUrl5U/Fsv24hjjUOqDmdzVEDYwi7boLXfCPv3qcjI9nIP3dlBYK7MjB1BFn6qntht8gFWd6ISLWUBEBsKr+tWRpdOoJyNFTRg3Ukw0LiEEomzfdmCulMJQmn8KpzO/zjTbO1Y0EhUx0F/mmpJ+SwU07neUYqVlTvM+knZGxho/7AK7y+oa+fbgmOlHTDHsbdSGFOPjb6xzfN3u9GXpzShZCdNfd3Qzmoi+uNCLFTogQQjiEEJVCiCWdfw7rOOCCRWWtwCcxqBHojq41HvU2LjqGbA7JJFGoyIjO2zEu5SNj+yrkLpSiZACXq70hNrbRVnH4+wx7n04Bt3v0ODLfqST1+ZdJfW4xqc8tJmpqIP0jeuYc4m+75+x1Cfc+TOpvXyHp2z8CQLSoJyHQHTr575/jSs0lcfLHL7hf48qXSJr5OdD90PUeLhSk34suJXe+3sHwNAcPT4u64NrH3vXy33OiUHXQunQ0Aur2+zIa1zTSsquFfY/tY99j+2iuCmhYz2w6Q0xBDK4BLhxxDmIGx7D3OwG7HP+I2AF+xdgYNMCgw0tNhaW6YkoMFy2nfXXFTWrDe2bud406ZqKQwnBhpqox6Tt3zK4zOupdyIHi+/npXjOBnDLZPcQ3Oe24JHiTQ4Am4pOneJ8pqpMDNhq9J0Cqrqe9e7hm2HCvz0RhiA/4zLbbthku8CzSm1NyhRBiuxBiK4EC6Kth3le/JFLshI6vcm5nJezjgAsWle0kkJ9lGE09tM135ndR4A9rpIJVYp1JtbOzPpMuhAjJ8VEwhFKUDFBQsHm7EFxYBVhgBXNM+Y+cj9KstgN4a3bSuuNdOg5vpfaF+6l94X7a9wdOYtr2vIc7qxhnQipKdDxR2cOo/e0CEODOKGT5/vb4P25Veeegn7GLWhi7qIV/7Q0MFv19t8qkbAfZCQrJ0YJpHgejf92CEPDoBGf8qN+PovgHxQx+fDCDHx9MwpjAdFXihEQyPvZB/Tnw1oEU/6CY3PkBc+O6AcaLncTmQ0OE7jdgjtf5M3KPmAhKtdHrVte/OkhK6TN6nQtn3Bx1pKEOTRenTnnGHD9eaDiuYSprJnycV0wVZ3JA1DDfpLRaozEN7UTFzvT+fMxePduwMBvADe6Xa+tKbj3TvAIpjRR4D2y7bZthLZZVLuKU/IlOl+SrpJQ3yUA214ce8SGKxggbQggP8CLwQ+BhKeWN5339m0CelDIsuVbPzH/nNwSOtYLC37F+tb991USw9w011DiFq+WjeffXOhXXkEs/OzQ0ibajr7jfSw2VVgd0bcbMPx9TFOmxc9X7+O2mJpE84dLPvDiuzSeXO050WDryfNf90HsFSv00M9delZ97SgphWDx8+1Jt+byN0vC+q0bfu/xk6ijD16lt767QvJWGj1nnZN26PCNmkKmf76vudatOKS0zjV8p5eQpf9sYFdVuOGLlSb6xvFJMMrVf5WTHDtfGk7kCLkyrvShSLnY/vmKKstv038N/x8VueiQ9dTCXtqt4cdtt2243e59gEUJUA82ABvillBOFEIuBoZ1PSQYaOz9MR+iBSGcnNPwvAZ+Fc9rVfTgO+ABwyaRiKaX0tfx9mb991Qwus0IH0K/33LWzLwsdCK0oGSAra/9GuwsdP05fE0kj7FhLtPldl37WJVcxfWWUlMbymjpZN1RJv/SzLiTv8FJT1zljpo8DDB97rDn++kgppWF/GYB5vvGjkJj4+QixedONg6UUhjsEC6koHShrTHna6KnRI9UJqYcktBi7UojP+L4763Vt2jIz9wW4vrVtwqs1dadcUl4sx6uS8AYxn2MeKKX8TOefxwJ/A14N414uOyLFjs0IIW4EjkspL2hr9tU44IJFZV4C+p1ez8GlVNt8Z363TlcPzA7XvuxkdtZnVsY6E/tUWxRqUTLAoPwttjtAVzF2JzYd+wmvZvBT+IVY6TUn67qphOo9ORRLMJbzBAxo2jdC6JphPYwQUQnC6TGUlwXg1dvSjrTuNnVkEo0reZp/iOEJMgC/P3rAtm1zG6VBo0IB4sc8PCFOtpgS/+pp0aPVcSn7JcbyvgAeUO+fvch/4wqjnkFdFKtqwbuHj6ak+bWeft6ngFu23bbN8N8Zu+nUJn4a+Etf76U/Eyl27GcGcHNn2/GvQJkQ4qXznhP2ccAFi8oOALfChWJDqZ855m1cdEjqTecbnlwWXDVg1orMmPw+nRYLtSgZIDa28aDL1THe7nVXMsdUgdAjfmmq03EuwnS9k+nXOsxcpzmEqzWaHgM+L0Vy015TBYQrdu4gTNR2Gxr+PVEaTRzvZKSWOzVej15r5tqmxoEjj9UONazDceGPepKveJxSrTZzXz0jZow6NuV9M8Vohf+zpeX+L66TEsNaJ4AkXSa9daRm7KT2ju65YRpw67bbtlWbWdMkPZoHdlIC1EspTf39/bAQKXZsRkr5TSmlR0qZT6C4eEdK+fn+MA64YFHZG8DXuz+mq0d3ept+K0C11bMlXHhih24eljSlT8I9u7PctXNtKEXJAEWD1x8WwsIZTy/sYNSASz8rCDTpBSwXfNLCOVaeqpr6FA+wb6AwFdqYd/gtUyabiiN1ECLe8PSQX6rxe85s2mnmngA3+SYUII2Jf7vYv39yaXt7vOFiKZHmlB+xUAipnzRzXz0zZpw6ZsBOGXAoNsSL2nXTFqhf3S6l0eOwAA5w/K7ueOk9p5tWEhCIf33bbdvClXvVRY/mgZ38F5GuziWJFDvho1+MAy5YVPYz4AUAf0fle76WlwtAZvXFXqyS5Eo/MD3jo0V9Ee7ZnU6n5JAeoSmK2pqUVG+7+LCd6JY24mwpdEW7v05YEdx8gOnOTpFqXjO0foiINnNdyuldo5C6obiDLlyxsxxmrqs6tWy6LrXDZq6NIzpznJZv2lOmcvMNw3VdMTyFlkPNoEf4QS1Smuq+6VmxE9TRA7ZLE3E4/9KnjL/V953DuhSmii2ArzQ2lSyqP/GLbbdt+5nZNczSm3lg52vfLcDicO/pciNS7IQQKeWyrkmsfjYOOF9tfet3/vZ3p0LoxLShxK3EnLom5zZHX4R7nk+oRckAeXnbNguB7d/rJibvRggbRMUfeOxYRVqol4pUNc7stZsHiwIz1wkQSU0H3jdzrcM9dDw4DB+DSXTX1tMrDI/LdzHBX1QSLV2XHFroCU1zJ23denW7lMa7LFdRNfoLvFBpOpMqO3aif2RylcRoyCmskyNGzPP9uMkvlVoz9wZWzWjv+LbJa03Tm3lg55c/AuyWFhygPyxEip0PIQsWlfk039ZvABebNOi3KCi+eZ67jyjCEdJjo2AIhygZIDtnd0i6byuZbdp08nyUZr9ta5kl36eazm07lSgyNQVTbxp5R942XYg6osaZevN9v2n9dL/uM1VkAdzom5CKNC78BWg+kzHs6JGRhiMsAK7jn9NKeddwSnoXmidusn940iYJhk0Ld8u8wtm+n+GVTkMJ9EA1cAvlTaa0PxbpzTwQAlKJyBFWEESKnQ8pCxcvOQHciEGn0v7A1dm3rY9yxIzp632EQ5QMMCDlaJXDoYXE3HEvQ20rokSLeb1Md6SFY6xsvz/LbNcAoC4ZU0dDaSe3jcakaNgZM3U8Bg30OhEbGt4wNYYOkCzj8oZpOaYKFoDq6vElra1Jpgz87uGZ2YVynxm3YgC0vPip/mFJG2QPAxeX4qhMz57qfTq5WcbsCPKSRmAe5U2m/v9apTfzwM6v3S6lXNQX+7rciBQ7H2IWLl6yi8BIuuFPSH3F5LQbliVHZZgwRrOfcIiSAQoLN4WkY3KGhFNeomzzJRKtdnjsWDvGcoNbGAyT7M7WAmH4eARAIB0JzYdNDR0I4Y5TnHmGx9ABDrfunOjV2kxdCzDdP3SmSzqCfdO/gC2V14/VdePJ6gDlfHNasjxtKt4BQBsUP80/JHGtxPho+WkSU6Z6nx50QiZdaoxfBT5BeZPlnMFLIYSoFkJs64wU2tj5WLkQoqbzsS1CiHmh3seVSqTY+ZCzcPGSt4G7+3ofwTA4Ydza/PiR/SKQNByiZAC3u+14TMwZw861wbCWGXuwMT9MeLUEu5aycnGMSWNBgPVDhenR+bwj78SavdYZO7cIE2/aAGuO/8N0kakgHPN8490Y9M/pQtddcVsqr0eaOA5zoDuf5P6hbundY+beAFpBwgz/4MQ1ZgqeVmLip3t/OfqAnnWxcfo7KG96x+z+THCOcWAnP+syD5RS/iuMe7miiBQ7EVi4eMnvgUf7eh8XIz3as3N86tVj+irc83zCIUoGKCzcuFMIbOmYnM8aSu3VH/jlhVHjJpAWfHYABmi66UDG3R5RbGa8GSC9oXIMUp42c63iGOARSqKpI6XjHYdHtqiNprxzANJlYnG+nm7qOAqgtTWl6FD1WMNJ7gAxtCf8hK8mCKmZmmYD0IoSZmpFCavNHH+qON1zfU9O2aQXr+jhy9+mvOl8j7QIlymRYicCAAsXL/kJ8GRf76MnYp2Jx+Zk/VdqX4Z7didcomTQ/Wnph4eFavWDFObatpguVQJCyj5noN9veDS5C80hXK1RmOo0KFJ3xrfWmD4ScsbMNh3Rsqr+1QxpLLzyHOaoo6Y7pLnjKIAjR0bPbG5OMRwYCpDOiYHf4ztNSGnKBwfAPzixRCuIX2mm4JEoyid83y/9pzZlWbeHn6G86Udm92OS3owDvyKE2CqE+J0Qwh5PrA8hkWInQnceIRBg2m9wCFfr9Tl3nhFC6RdvpOESJQNkZ+/ZIERoPJBOkH7ML1ymRq17QrT5jwmbXk+saHYABqnWJGj7s4Wp7gxA7tF33WavdbgHjwWnKRfcJvVE4WlfnakMKgAHivsadUw7JqMVAKqqrp2oaQ5T02HF7Bk6n1/uMpg2fg7+IUml2qB406LnBepXZ//Wf/1yKVlMIE8w3PRkHPhroAgYCxwDnuqDfV0RRIqdCGdZuHiJBO4ClvT1XjrRr/fcucOpuIde+qnhIVyiZIC8QVtD1slaTanpT/E9IVr9tnjsdGLpGKtIVS0d+20oFqY7LJn1G8cgpeljNEf0BNPHOavrXxsspTSd1ZSjp4waqCebLhak7ozeUjkvSkrjAacAJSyfdAP/MH2cBuAfllTqz40zPdb+uP8LaoH3z1+kvMmWyUIj9GQcKKWsl1JqUkodeI5OM8EIxokUOxHOYeHiJX4CoXKWXnTsYFbmp1fGOZP6zT/ucImSAeLjT+51uby2OyZ3sZbptmqflGbVtokxK3ERAAWqakkovalY5Ju9VpH+qNi2um1mr3dGT55IIGTSMG1a88C69gPrzN4b4Bp1zEQhhWmDura25PwD+yeZPsr7LH8sHS23mC5WAPwjkmf5c2KXmbh0PfDx6oobwu6l05txoBBiYLenfZwPzAQjGCRS7ES4gIWLl7QDN9GH/7BGJZeszIot6BeTV138211ZGw5RMkDR4PXHQrl+DbmFdq4nmlXTxw89rGaps5OvmjcWBDiZKLI0gWmHc0/NclMREABCuGIUV4HpKIe1J5aMlVKaDnZ14Yybo46sN3s9QG3tsGlNTRk9CX6D4lEeL82QdaYF1wD+UQNmawNjlhm4ZBtwfXXFDaZ1QxbpzTjwJ53j6FuBOcBDfbS/y55IsROhRxYuXnKawKcL02OhZsmJHVI5Inlav0pg7xQlh6Wr43D4ziQkNNiebt7FEXIP6sIx8NLPDB7R5jf9Bn8+liodIMuvZRJo+5umfoA5c0GAgXVrxyCl6U6XM6ZsCCa9r3x6R/LBlm2mYiC6KNQzJ6To8ZY6u9u2fmSq3+80FVYqQFTw0JgY2Wa6QwSgXpUyW8uMXhbEU98Hrq6uuMFUR80OejMOlFJ+QUo5ujNm6GYpZUg/BF3JRIqdCL2ycPGSY0AZYKu+42IkudIOzsj4WIGwKa/JDsIpSgYYlF9VKQTxoVp/JbNtz9ERXt0ujx3LAmUnOBWw1J3Ymi9MH2U4dDUmpqPBdHdGcSRlCyXZtNne5pNLp+hSt/SmOM83fiQS035FUjrclZtvSJTSnEN7FL6YJ7k/wyH9potOAHVs6mwt/aIFzwFgbnXFDZb+vkTo/0SKnQgXZeHiJTUECp7qUN/LrUSfvjrndkUIkRzqexkhnKJkgIED99g3Et4DG5lif0q8X7fFY8cuYqW0JJheP1RY+n5yakyf4gDgjJ1j2qBQk/6Y3U1r91m5fzSu5Gn+IZbW6OhI9OzdM22PlOaadck0pv+AR/xIaSnSRh2fOltLjVrWw5eqgTnVFTeEPJRZCJErhHhXCLFLCLFDCPHVzsefEELs7hwtf62/vfZdSUSKnQiXZOHiJYcJnBcfCtU9BIo6z3P3IUc/CPfsTjhFyQCpaYc2K4puq56mOxLkcTLtnW7TpR+JbSPyVk0FAVI0zXRmFMDuXFEswbRfT/ax1aOR0pQ5IYDDVXAVuExHFGw/vWq6Jv2Wgn5HarnT4vVoS9qZ+vrBk0+fzjZd+eVxqPBhKqqR0pJoWJ2YNltLcXcXPh8CyqorbrDUOTKAH1gopRwOTCUwWj4CWAqMklJeRUAy8M0w7edDR6TYiRAUCxcvqQZmEaIOz9XZX1wX5YgN2fSRWcIpSgYoLNgc0klQ39uAAAAgAElEQVSQfQzZI4ViScB7PqJDqxdgm2YHi9NYANl+zdLP0e8Q7jaT5oIATs0bH+U9bfooC8AZPcl0d0oiHVtOvmP5aOYm34QCpKmQ0rPs2D5nhqq6Tf8sJrBx7K28ZDqwtAt1UvosPdm9nMBr2KzqihssFYNGkFIek1Ju7vx9M7ALyJFSviml7NJnrQU84drTh41IsRMhaBYuXnKIQMFzwM51J6Vdv3xAVGa/CPfszj7l2MZwiZIBoqJaaqOiW0KSg9XFCuaY9nHpDdGimg7e7Akrqedd5Kumop7OYf9AYUmwmlO7ytImHNETJ4F53cy+5sqpqu61JPKNIzpznJZvqWgDxVm5+cZ0Kc0HtN7E32dMlassjaQD+Can5WgZ0aXVFTeErEt9KYQQ+cA44HybgDuAf4d7Px8WIsVOBEN0HmnNBiyd53dRlDB2bUH86FI71rITDd27wrXLdCikGYqKNuwVwtYOyQVUMiHO7jVFs2rpyOh8rAqUAYp8qmljwC42FAvTbsgAObUrRiGl6YJHCGeU4hpsaqKpi3Un/mm5UzjBX1QSLV2WJry83riBu3eVHJIWHJrv52ez8uRBU5EUnbyPELOPPDz3iIU1LCGEiAf+Bjwou5lPCiG+TeCo6099tbcrnUixE8EwCxcvOQLMBLZYWSctKmfXhNRrruov4Z7dCbcoWQjNl5J6dEQo7+HHoZ4mxfasLaXFb6PHjj0UWjQWBNhULCzFabj87UluX1OVpTVi5wwDc4nkADVte8e1+1tMT3Z1caNvQiomks2709CQP6GhIc+0QzPA4zw6JUE2mSm8tgOz6uaMDbkYuTc6J0z/BvxJSvlqt8dvA24EPieltNzVjNAzkWIngikWLl5ST6DDY+rFK9aRcGzOwM8OEEKYnjoJFeEWJQPk5OzaIAQh7STtYPRuAp8sbUW02uexA/Z0dgapfsvTYQ1JIksTWBrhzj72nmmRMoBQEjKFkmJJr7L6+GsJVt9Ek2Vc3jAtx7JuZveu0hKfL9pUQjqAE831FF8pdEmfETuMdQQKnT4bL+/8QPdbYJeU8qfdHr8OeBS4WUppqZiMcHEixU4E0yxcvKQJuBaDWVoO4Wq93nNXkyKUkIRcWiXcomSA3LztiaG+x0pm25lfdRbRodlaQNlR7KRrWrqVI6QujidbE+R7apYNtxJuCeCMLUuycv1Jb+3QZvXUe1bWAJjuHzrTJR2WNEAglM2bbsyVUpguPOJoS/ofHowSUg9Gz/QWMLduztg+MwzsZAbwBaBMCLGl89c84GkgAVja+diiPt3lFUyk2Ilgic5oiY8DfwzyEnl9zh3bnYrb9uMUOwi3KBkgIfH4bqdTHR3q+2xjzICQLOzXU0OyrgUUUBwWjQUBtlkwFwRwqy2pLrXFksDX4cobCW5LRcaq46/mSIvFn4JwzPONdyPNH6sBqGpM+s4ds+ukxHQRmEm951uUn+Di3ZCXgRvq5oy1LbfNLFLKVVJK0emEPLbz17+klIOllLndHpvf13u9UokUOxEs0xkeehvwv5d6bmnmJ5fHuZKnhH5XxukLUTJAUdEG0xM3weLF3d5Cgv0FppSanR47YM80FkCcrlv+NL9uqLA8pp9Vt86ygNsZM8XS+HezempQg7fGcncnXSYW5+vplkOCT53yjDleX2hFbMwIdoy4i0XbeokGeQb4r7o5Y8MW6imEqO7MsdoihNh43te+JoSQQlgzq4xgnkixE8EWFi5eIhcuXvIQ8FhvzxmZPGPlwNii2eHblTFWuHa+F05RMoDT6W2Mjz81MdT3qWTiToSwPKF0PqJdqxdgc7SHPYL1VE23HOq4K1cMkWDpDTPv6DvDrGZ1OaLGTwLzRz8Aa47/fbi0kNnVxRx11HSHVCxHyOzZM73U6421pAOaw1tTruY/5xdN36mbM/YrdXPGWvqZm91SZ4fm7L9pIUQucDWYz1uLYJ1IsRPBVhYuXvID4EucN0GSHTt4y8jkGf0q3LM7Z0Tb0f1Kfdg7TvkFlVUiDPqglcwOSZqzaPXb3pWyq7OT4/db/lTvd4ooK+aCAFG+pgynv227lTWEcLgU15DdVtbo0FrTa9r2WBYZO1Dc16hj2rEwRh5AiM2bbhgspbA0IXU7z5cOkzuWE3jN+ULdnLE/tLYv2/kZ8Ag2/b2OYI5IsXMZc5G8lbFCiLVd7VQhRFg1KAsXL/k9cB0EQgATXanVMzNuGdSfwj3P5199IEoGKTMz9+eH4067GR6S4znRrNpeRNkhUAbIV1VbFjqYJSwLuzPrN5y2uoYrdvYILERYAKw78a8J0mJuGECOnjIqSyZbOoYC8PujB2zbNrdRWtQBfZvvjSqUe+fWzRn7ktU9WUACbwohNgkhvgwghLgZqJFSWrIgiGCdSLFzedNb3spPgO9LKccC3+38c1hZuHjJO8C0KCVmyzU5t0shRGjEsTbQF6JkgPSMg5sURQ/5sVkrcU0dxNibh9WJ0qz6L/2svqHIp0bbsY5Vc0GAvKNvF2Nx/FsocenCkWbJM8cvfQn7mistdZm6uNY3ZoKQ4qjVdZoaB448VjvUip7ooIIsWVP2KUsePjYwQ0o5HriewGtxKfBtAq/BEfqYSLFzGdNb3gqBTxhdo8xJQG1f7G/h4iW7PzbogasdwtlnjqWXoq9EyQAFBZVhaWuvZ9puhAiJM7No89v+GmJXZ6dQVW0Z599YLCwXpDEdp7IdWoclN2QAV+xcy4LpLSffmapLzXKR4sIZN0cdaYt3zf79k0vb2+PNhI6+B0yZW7bfdGiqXUgpazv/exx4jUC0TgFQJYSoJpB7tVkI0S8tN650IsXOFcJ5eSsPAk8IIY4AT9KHSbqeipIG4CPAs321h4vRF6JkgOiYM0fc7rYJ4bjXKkotGdtdDLs9dsA+YcMg1W9LEXsiWWRbNRcEyDix2bK+SXHmDEdEWRpl19Gitp9eXW11LwCFeuaEFD3e8nQWQOXmG0boumIks+oFYM7csv0hn2a8FEKIOCFEQtfvgWuADVLKDCllvpQyHzgKjJdS2p5PF+HSRIqdK4Ae8lbuBR6SUuYCDxFw7uwzPBUlqqei5B7gfgJHb/2CvhIlAwwuWn9AiPD8+9tPceiSlNVQeOzY09lJ1fU0pLSl0DuRhOXgyEGH3yq0Yy/O6GmWJ6p2Nb033a+re+3Yzzzf+JFI84GlXWiaO3Fr1TUdUnKp/2ca8PDcsv13zC3bb0nDZCOZwCohRBWwHvinlPI/fbynCN2IFDuXOb3krdwGdP3+FSDsepSe8FSUPE1AuNzXbqYA/MtVWRN+UTIoir89ecCxq8Jxr9MMOK4Kd1FIFpdS2u2xA/ZNYwE4bTAWBNiWLyy/qca2H89TNO/7VtdxRI2dBMJqp0nZdPJNy6JpgGhcydP8Q2wJBm5uTh965Mioi02MnQSum1u2/2d23M8upJQHpJRjOn+NlFJeMBHW2eExnfwewRqRYucypre8FQIanVmdvy8DbPkEZweeipK3CRRflvULVtinHNvYonT0SVfH49mxSQjCItheTYktb0I90qHVC7As3j0fuzQ7AAk2GAuCPeaCAOkNVZaPw4RQnIp7uKVxeIDqlu2TfVq7pSOxLkZqudPi9WgzmpsLOFQ9rqS1Namno7EqYOLcsv1v2XGfCB8uIsXO5U1veSt3A091tlR/BHy5Lzd5Pp6Kkv3ANOD1vrh/X4qSATy5O8MWr/AeM0OWSK6EwGOnE9uqnTRNsyVccVeeKLZqLggw6PDSPDv244opHQ2XPO65JGtOvG7bz/om34QCJJacnrvYUnn9WF0/x7jwj8D0uWX7q+1YP1guYu/xuBBia+dr7ptCiOxw7iuCcSLFzmXMRfJWVkkpJ3S2VKdIKTf19V7Px1NRcsZTUfJRApqisFm6Q9+JkgGSko/tcDj8w8N1v8MMKgjV2qJZPROKdSXCtmOsHNVvOQwUQHWK6Ha39Q5pfGttoaKplt2HhRKbIhwZlg0C69urR7f6m9ZbXQcgjujMcVq+LZ0iXXfFbam8Hik5Bdwzt2z/F+eW7e+LVPDe7D2e6HrdJRCEHBkv7+dEip0IfYqnouR/gelA6I5butGXomSAoqKNjeG61zEGHtGFM2Ti5FB57FhzozmXAtW+0fiDWcIWvUXqqe22WDG4Yudm2rHO6vrXUqTFOIsuJviLSqKlq9KOtVpbU9i+be7cuWX7+2ySszd7j85BkC7iiLgj93sixU6EPsdTUbIJGA/8JdT36itRMoDL1d4QG9sY8hysLlYxqzqU64tW+z12Ole27WilSFVt+3+90QZzQYBBh5facuShOAcOQURvsbrOaV/94Ebf8TV27AngRt+EVCRWuzCvAOMffPBZy9+fXZxn74EQ4oed9h6fI9LZ6fdEip0I/QJPRUmzp6Lks8CdYPmFskf6UpQMUFC4ebsQ2B7G2RvrmBYSI8EuRIcWF4p17ZzGKvSpSXattbFY5NqxTmLzoSFC91fbsZYzZoYto9erj79WIKW0Za1kGZc3TMsxe8TWASwoLy//dHl5eUiOSc3Qg70HUspvd9p7/An4Sl/uL8KliRQ7EfoVnoqS3wETgW12rtvXomTQtYyMg8XhvGMd2aG9n6r32wiQLvL8/gy71qofIDy6sGeUPeX0rmo71nG4R08ExbIbcqu/Kae+45At01QA0/1DZ7qkY4fBy7YCE8vLy39l1z7soBd7j+78GfhEeHcVwSiRYidCv8NTUbILmAT8FJs+5felKBkgK2v/RiFkTrjud4DCfVIooSvuAh47A0OytI2j50m6noyUlk34ujiRxEE71hl0+C1b9DZCKA6He6RlwTPAe8dfH32eFsU0CsIxzzfeTXABnxL4X2ByeXm50QIppPRm7yGE6P5B4mbAUiJ9hNATKXYi9Es8FSVeT0XJQmAucNjKWn0tSgYYlL/FGc77rWR2TUhv4NVPCLAlaPN87Cx2ANw2GQsCbB9k3VwQILlp33ChW8+nAnDGlIwFLBd0Pr095VDrzs02bAmAdJlYnK+nX0oLdBS4try8/KHy8vL+4obcnd7sPSqEENuFEFsJREN8tU93GeGSRIqdCP0aT0XJu8BVwEtm1+hLUTJAbOzpgy5Xx/hw3nMTk0P6/Sqt6vFQrW33WEuCptviFAywbqiw7eguuXGvLR0ZoUQnCcdAW+wlNjb8Z7KUum3/b+eoo6Y5pNLb9/lnYHR5eflSu+5nNxex9/iElHJU5+M3SSlD++EigmUixU6Efo+noqTJU1HyBeDTGIya6GtRMkDR4A2HhbC5XXERdBTtJGlDQ3kP0exvDuHqtq6WYZOxIMCOQWKIJKijmUuSd2SpbeaSrti5thyRatIf+37TBtuOZBwo7mvUMe1Iuo+2nwA+XV5e/rny8vKwWTFE+HATKXYiXDZ4KkpeAUYDQQXs9b0oGRRFbU1Kqh8bznvuZvhuhLBtCqknRLMaMiNIuzs7Hr/fNhdp1SmiO2wwFwRIOb17JFK3HB8BoDgzihCxthxBbT29fLomNcvBp13k6CmjsmTyqs4//gUYUV5e/opd6xtFCFEthNjWeSS1sfOxJ4QQuztdkV8TQiT31f4ihIZIsRPhssJTUVLrqSi5Hvg8l9BirHDtXNuXomSAvLxtm4QgpIXH+axgTsjDBpVWNWSdKrs1OwU+1Va91MFM6wnfAAJEUtMByxlXXThjSmwxeZRI59ZTy2w9lrnGN2agQyo3l5eXf7a8vLw/hGHO6TyS6vK9WgqMklJeBewBvtl3W4sQCiLFToTLEk9FyZ+AYcAiemgGdIqS+zztPTtnd0gmli5GFeMSQn0P0aHFhnB5W5s7Rapqq5B6Y7HismutvCNv2dZBcLhHTALFlo7MnjMbp6m6b5cNS0ng126cEx/7/nf/z4b1QoKU8k0pZVexuBYImfN4hL4hUuxEuGzxVJQ0eipK7iUQN1HV/Wt9LUoGGJBytMrh0MLqraPi9J4hKfTZW6puSwp4T+h2d3ZU1VY/oA3FwpYwT4C0k9tHI3V7OkVCCEfUVdV2rAWIDQ3/tqp12gWUeCpK7vNUlPQbg0ACBdibQohNQoieQpLvAP4d5j1FCDGRYifCZY+nomQtMAFYCLT0B1EyQGHhxrAHF1YxfhdChL7I08kK4eq2Vju5qn3GggD1KcKjC2yZWBJIJaH5sG2CYGfMjHGALeLxI627J3RorWZ0QK3AN4CxnoqS1XbsxWZmSCnHA9cTCPYs7fqCEOLbBMI//9RXm4sQGiLFToQrAk9FieapKPkpMHyda58tQYRWcLvb6mNimsOWg9XFSmaHfrrFqzUICNkxlp2p5wDxUiYgZZOdazYk2mMuCJB35G3bYjeEiEoUzhzb/v6vOf73aCkNRbO+AgzzVJT8j6eiJGQiditIKWs7/3sceA2YDCCEuA24Eficwe85wmVApNiJcEXhqSg5+uj3v/VloAybIyeMUFi0cZcQ2KbtCJadjEoL9T2UVn/IPHbAfoEyQFTgjc02tg8S7Xatld6w5SqktM0LyBU7NxebdE8nOo6OaPGfDiZGYgfwEU9Fyac9FSW2mCWGAiFEnBAioev3BAwBtwshrgMeBW6WUoa9Ixsh9ESKnQhXJOXl5e8SSCj+Cga9eayj+9PSDg8L7z2hnZjmNmJDfl/RrNraJenpFnYvmKjrtu55/VBhm2ZJkbozvqXGtpgExZFWgIizxWQQYFX9qwO7iXfP5zTwAIEjq7ftumcIyQRWCSGqgPXAP6WU/wGeBhKApZ0j6Yv6cpMR7CesFvYRIoST8vJyDXimvLz8r8DjwJeBkCaBA2Rn79kghJwW6vuczwam7EaISaG+Tyg9dsDe1PMuMjWt/YTTvpe77YPEYAl+YdNraO7Rd6J2Df+iHUsB4Iqdhdr6L1vWOqOezD/lPbYiNTq7tNvDfuBZ4LueipKTttwoDEgpDwBjenh8cB9sJ0IYiXR2IlhCCOEQQlQKIZac9/jXhBBSCBHyY5VLUV5efrK8vPw+AiLmoAwJrZA3aGufTIGtYlZY2u9Kqz/EbtDC9vXzVPuMBQF8LhHb4bLHXBAg8/jGMdgUwgmguIZOAMcBu9Zbffy1od2Od/4GjPRUlCy4nAqdCB9uIsVOBKt8lcCI6VmEELnA1VgM8LSb8vLyqvLy8uuBUmBlKO4RH39yr8vlDatjchd7GRLKCamziHZ/SIu5UHR2ClV7jQUBqjPtmcgCUKTmjm2r227XeoEx9LG2aWfatZbM6pbtfwWmeSpKPumpKLHNDNEKvbghf0oIsUMIoQshwj4kEKF/Eil2IphGCOEBbgCeP+9LP+P/t3fnwXmV1x3Hv0eSbeENs9rGC8IKNg5gHHZCKbbEUIZSN4TimGlSd6AJEwyFRIGa0Mm8DUPC0ISGPzJQCDBJExoBhlJEakK9YDZjbDDIIGOqxIAtGzAGr1h6JZ3+8dwXvyiSrOXed+P3mbkj6b7SvQ8gpKN7znMO3EACv7TikEqlnkmlUn9O2HoaW20DQPUXVsXS/r+/djL6wzaGTc3JzdKdsfat6SqJAuXqtnRsO54y1sTYXBBg0qblsf48rjjorJOBOGqV1gIXnvPzq66I2jwUmq7dkNcBXwVW5HFNUmAU7Mhg/IwQ1Hw65M/M5gCb3f3VHr+qQKRSqcXAacDfAG8M9nrl5W07R43altPp5hkv8GcbsPjTP91KtscOnkCBctyNBQFeOtZi7bI77r0XT8J9T1zXMxs6sqxi8tpBXGIDMA84ua6+oWia7Ll7k7u/me91SGFRsCMDYmYXAe+7+5qsc8OBm4Af5G1h/ZRKpTyVSi0iDBi9jLCFdkCOrnr1FTNGxra4fniOc2KZxH1AbR3bjaT/GePtswMwob1jbNzX3HKYTe60eOZkAZR3pg866JMPYm2XUDG8dgp8ZuJ4XzQBfwt8sa6+ob6uvqEgn9BGDtQNWQRQsCMDdzYwx8w2Ar8l9LX5D+AY4NXo/ETgZTPLSS3JYKRSqc5o19aJwKV0GT/RF+PHb5gU+8L6aCPH5GTgqe1p73X4ahySSGNVuh9k7rG3IPhwVHzNBQEmtKzob2DSq7LyQyZRNmp1Hz+9EfgacEJdfcMDdfUNsRZ1J6THbsgi2RTsyIC4+43uPtHdqwiPupe6+yXufqS7V0XnNwEnu/vWfK61P6InPQ8TevR8hT7W9Bx2+Nsvl5V1Tkl0cT34gCNaOmxIToKdsuR77CSSxgIY5h7bU5iM14+2WHfAHbXl+Rm474vzmkMOmnWg2qIXgDnASXX1DQ/W1TfEGnAlqaduyCJdqc+OSDdSqZQDjwGPRTu4rgdm9/T5U6asyU0aqRvPcu4fgaNycS/blW5N+h5xj4vIGNPZuWNrWbx/3704zcbMaoxvuRUdrSOHtW5f1Vp5WGy/tMuHHvul9J6Kt6C961Da3wM/rqtvWB7XvXIp6oBc5u67sroh/zDPy5ICpSc7MmjuvtzdL+rmfJW7b8vHmuKUSqX+J5VK1QAzgHuBz/zlPaxyV8uwYXvytsV1JV/O2b3K9vTUSDc+SaSxAMa1d8T6xASgscqmemiwF5sJLc/GHjiXV56cebq6j/A9fGJdfcNfFGugE+m2G7KZXWxmm4CzgCfM7Mm8rlIKgp7siPRRKpVqBP4hlUotJHRjvgqYUF29eoNZbp6sdKeFiTlLn9knHblomJhItDM5ne5cWzks1mu2DbHhrUNYX5kmtjEdE1qeOeEPx8xJYxbb1vaKyjMmdOx76Sbwe+rqG2JP5+VDL92QHyWktEQ+pSc7Iv2USqW2pVKpHwFVwLwxY7bEtl24v95l8h87rXx8zm7YlmyPHUimqSBAdTqdyGDWt4+Mr7kgwJD2Tw4e2rYjrtYNzwLzzIYcV1f/+I9KJdAR6S892REZoFQq1Q7UQ6p+ydLq44ErgW8AY3K1hhXMepewAy43Oj32LdxdJZXGqm5LJ7JlfvWxZeXTNsdb03vUluc/2Vh14UC/fBdhh+TPF9xVU7D9rqJO678CxhG2x9/t7ndkvf494F+BI0ohHS75pSc7IjGorWl+vbam+R+BCcDlhBqCxK3mjKG5uA8AbZ07DEYnfRtPYDYWQFW6PbZJ5dlWH2uxtxyYuHn58fQ8abwnzxG+98YvuKvmW4Uc6ETagTp3nw6cSdg6/kUo3JEzUrz0ZEckRrU1zXuB+4H7lyytnglcAcwFjoz7Xp1Y5/uMnRb3dXtie9JbgYNzcKtE0ljj29vH4u5xd5refLhN7oRtZRDb0Nuh6T2HDknvfjk9dNSBOnJvBn4N3L/grpqi6hrs7luALdH7u8ysifDHwhvsHznzWP5WKKVET3ZEElJb07y2tqb5GsIP8AsIj+x3xXX9t5i2AbPEa2gyyna3f5yL+yTVZ2coDC0jvo7H2baPJrYJ4xnjt67c3cNLewkBzvnA5AV31SwstkCnKzOrIvS2erGYRs5I8dCTHZGE1dY0twNPAk8uWVp9JfBXhNEUFwID3h70DLPeg/h2AR1ILnrsRHdKbDxBpfu2vWaxP2V7fbLtPXddvMuetGnZce9MOq8TszKglfA99CDw3wvuqoktaM43MxsJLAKuI6S2biIEciKxUbAjkkO1Nc37gIeAh5YsrR4NXEQYRHoB0K9t3a9wSuyTvHtje3LTN7EzoQJlgEM6OnfujbmxIMCqaTYm7mBnWNuO0ZX7Prx330GHryAEODtjvUEBsLC9fhHwG3d/xMxOZP/IGdg/cub0YurELoVHwY5IntTWNO8EHgAeWLK0egRhvs8lwF8Co3r72nbK0x9zyPTkV7lf2d6OyhzdKrFoZ3x7e+vmIfH/2Hutyo516DAoH+SldgBPEPrELL7il3N7SmUVPQvRzL1Ak7vfDuDujWTVt0Uz9k7VbiwZLAU7UrTMrBxYTcjvX2RmKeCb7K/L+L67/y5f6+uP2prmPcDDwMNLllYPIzzGvzB6+ydNA9cxowmzGTldZLozF8XJiY2LADg63c7qBNoitg61Ea1DeLMyzUAKxt8CFhOCnGXT1ze1xbu6gnU2oVVDo5mtjc4Vzf+zUlwU7EgxuxZo4rPbof/N3X+Sp/XEoramuRV4PDpYsrS6mhD0nE+Yz3XwCmZ/lPOFdXhOptcn1WcHkmssCPDOEbw/taVPwc4uYDkhwFk8fX1T7MXNxcDdn+UAT/GigcIig6ZgR4qSmU0kpHtuAb6b5+UkqramuRm4E7hzydLqcuCMLUw4k9CI7Swg+fRSunOH5WbbOSSYxpqSTveaHhyMNV8os6kt3TYXbANWAkuA/wVWTV/flPyQsYRFKaZdQAfQ7u6nmtmhQD2hu/hGYK675z4wF+lCwY4Uq58R+nB0/eV1tZn9HSG9VVdqP2hra5o7gOdXwfPA7eOWrR0GnA7Mio6z6Gehc1/Ynvb3yFGwk2QaqyqdPiypa7801SZetgKAnYTg5rnoWDl9fVPeRookbHaXepqFwBJ3v9XMFkYf/1N+liayn4IdKTpmdhHwvruvMbNZWS/dCdxMaEp3M/BTQkfZkrV19sxW4JnouHncsrVDgZOBU7OO4xhk4WzZ7nROeuwAdCYW6sC49o6xuHcQ6r3i0ElIpa7adIStJAQ566avb4p3fkTx+GtC0A3wS0K6TsGO5J2CHSlGZwNzzOxCQgpntJn92t2/nvkEM7sHaMjXAvNl6+yZmZTJysy5ccvWDic0bDuVEAjNAKbTjx4/tiu9L96V9nq3xNJY5VBeBls6YSDDU9uA9UAj8BrwErC6cX7j/p4382NZZrFw4Pdm5sC/u/vdwNioMzLuvsUS6GkkMhAKdqTouPuNwI0A0ZOd77n7181sfOYHLXAxsC5PSywoW2fP3Mv+lAoA45atrQCmEQKfzHE8MIluOqvb7vYEn7d8VlJTzzOGd/q23eXWW7DTBvwfIbBpInwfNQIbGuc35qbZUHE4291booDmKTNbn+8FiYspazoAAAatSURBVPREwY6UktvMbCbhl+VGwhRy6cbW2TPbgdej4z8z58ctWzuEUFxaTdjyXg1MsbaOdmA7kMgwzWxJ7sYCOKyzY/fu8rKPgLcJ3ydvR0czIcD5Q+P8xqIvIE6au7dEb983s0cJtWPvZf7oMLPxwPt5XaRIxNxz9gebiBS5qoVPjCB0tZ2UdYwnBEFdjwFNSL+14p6n51UsO3cAX7oL+Cg6tkdHS3RszrxdPGL4uxdcv6VUC4ZzwsxGAGXRAM8RwFPAD4Fa4MOsAuVD3f2GfK5VBBTsiEhCqhY+UUEIeEZlHSOz3h9CSJllH/adiof2XFvx6HBC8W9H1tEO7AF2EwKb3Vnvf0xqh57G5IiZTSF0eYaQIXjA3W8xs8MI87smA+8Al7r79jwtU+RTCnZERESkpMU/EU9ERAqSmZWb2Stm1hB9fJKZvWBmjWb2uJkNKPUoUugU7IiIfH5kRqxk/AJY6O4nEtJS1+dlVSIJU7AjIvI5kDVi5RdZp6cBK6L3nwIuyfW6RHJBwY7IAHRNB0TnrjGzN83sdTO7LZ/rE+lGZsRKdnfndcCc6P1LCbvrREqOgh2RgflMOsDMZhNa5c9w9+OBop68LqUle8RKl5cuBxaY2RrCDrm2nC9OJAcU7Ij0Uw/pgG8Dt7p7K4RGa/lYm0gPMiNWNgK/BWqiESvr3f18dz+F0FyyOZ+LFEmKgh2R/usuHTAVOMfMXjSzp83stPwsTeRPufuN7j7R3auAecDSaMTKkQBmVgb8M3BXHpcpkhgFOyL90Es6oAI4BDiTsKPlQbPkBlpK6TKzSWa2zMyaovqva6PzKTPbbGZro+PCGG53mZltIIzJaAHuj+GaIgVHTQVF+sHMfgx8g9DNt5LQIfgR4HBCGmt59HnNwJnu/kGelipFKpopNd7dXzazUcAa4CvAXGC3u6seTKSf9GRHpB96SgcA/wXUAJjZVGAosC1vC5Wi5e5b3P3l6P1dhEL4CfldlUhxU7AjEo/7gClmto5QADrf9dhUBsnMqoAvAS9Gp642s9fM7D4zOyRvCxMpMkpjiRQRM5sE/AoYRyiQvtvd7zCzekKDOIAxwMfuPjNPy5QYmNlI4GngFnd/xMzGEp4WOnAzIdV1eT7XKFIsFOyIFJGe6jnc/Y2sz/kpsMPdf5ivdX4emFk5sBrY7O4XmdlMwm6mSkJN11XuvmqA1x4CNABPuvvt3bxeBTS4+wkDXL7I54rSWCJF5ED1HNEOsLmEnimSrK5zpm4D/iV6ovaD6ON+i/4b3gs0ZQc6UaCbcTGh+7GI9EFFvhcgIgPTTT0HwDnAe+7+Vj7W9HmR1VjyFuC70Wkn7M4DOJiwlXsgzibs+Gs0s7XRue8TtonPjO6zEbhygNcX+dxRsCNShKJ6jkXAde6+M+uly0joqU5P9ULRa9cAVxPSN0+4+w1JrKGP6+yaXkqininTWHJU1rnrgCfN7CeEp+ZfHsiF3f1ZoLseTb8byPVERMGOSNGJ6jkWAb9x90eyzlcAXwVOSejW7UBddr2QmT0FjGX/XLDWTFfePMqkl0YDuPvXMi9k6pkGc/HsxpJmNivrpW8D33H3RWY2l5CKOm8w9xKReKhmR6SI9FTPETkPWO/um5K4dy/1QgUzF6yHuWWZ1+KqZ+p2zhQwn9BgEuAh4PRB3kdEYqJgR6S4ZOo5aroZGzCPHBUmd6kXKqS5YN3NLcuIpZ6pl8aSLcC50afVAKqbEikQSmOJFJFe6jlw97/PxRq61gtF6bPMXLDTCHPBpuS6qWIv6aWMxOqZIt8E7oj+fewDvpXgvUSkH9RnR0T6rLv+L2a2mAKYC9bT3LJouncFsBk4Jak0n4gULqWxRKRPeqkXKoi5YL2klyDheiYRKWxKY4lIX/XU/+U+4L5oLlgbhTkXLGf1TCJSeJTGEhERkZKmNJaIiIiUNAU7IiIiUtIU7IiIiEhJU7AjIiIiJU3BjoiIiJQ0BTsiIiJS0hTsiIiISElTsCMiIiIlTcGOiIiIlDQFOyIiIlLSFOyIiIhISVOwIyIiIiVNwY6IiIiUNAU7IiIiUtIU7IiIiEhJU7AjIiIiJU3BjoiIiJQ0BTsiIiJS0hTsiIiISElTsCMiIiIlTcGOiIiIlDQFOyIiIlLSFOyIiIhISVOwIyIiIiVNwY6IiIiUNAU7IiIiUtIU7IiIiEhJU7AjIiIiJU3BjoiIiJQ0BTsiIiJS0hTsiIiISElTsCMiIiIlTcGOiIiIlDQFOyIiIlLSFOyIiIhISVOwIyIiIiXt/wHR9zwmnWk+YwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "1    0.5084\n",
      "2    0.4590\n",
      "3    0.0266\n",
      "4    0.0060\n",
      "Name: NumOfProducts, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "1    0.7055\n",
      "0    0.2945\n",
      "Name: HasCrCard, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "1    0.5151\n",
      "0    0.4849\n",
      "Name: IsActiveMember, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n"
     ]
    }
   ],
   "source": [
    "# Plot Pie and Bar charts for independent variables\n",
    "for i in data_og[['Exited','Geography','Age','Tenure','NumOfProducts','HasCrCard','IsActiveMember']].columns:\n",
    "    if (data_og[i].unique().shape[0] <= 10):\n",
    "        print(data_og[i].value_counts(ascending=False, normalize=True))\n",
    "        data_og[i].value_counts(ascending=False, normalize=True).plot(kind='bar')\n",
    "        plt.ylabel('% Frequency', fontsize=14)\n",
    "        plt.xlabel(data_og[i].name, fontsize=14)\n",
    "    else:\n",
    "        data_og[i].value_counts(ascending=False, normalize=True).plot(kind='pie',autopct='%1.0f%%',figsize=(10, 10))\n",
    "    plt.show()\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of univariate\n",
    "- 79.6% of customers existed the bank, while 20.4% stayed after 6 months\n",
    "- Most customers are between ages 30-40 years old\n",
    "- Tenure for customer is 10% each of 1-9 years, with 4% for 0 years and 5% for 10 years\n",
    "- Majority of customers have 1 product (50.8%) and 2 products (15.9%)\n",
    "- 70% of customers have 1 credit card, while the rest have none\n",
    "- 51.5% are active members, while 48.5 are not active\n",
    "- Half of customers are from France, while a quarter are from each of Germany and Spain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new DataFrame \"data\" with Geography converted to digits Geo_Tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_og.copy()\n",
    "data['Geo_Tmp'] = data['Geography'].replace(['France','Germany','Spain'], [1, 2, 3])\n",
    "data['Gender_Tmp'] = data['Gender'].replace(['Male','Female'], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting pair plots of independent variables with a hue of the \"Exited\" dependent variable\n",
    "#sns.pairplot(data, hue='Exited');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HasCrCard     0     1\n",
      "Exited               \n",
      "0          2332  5631\n",
      "1           613  1424\n",
      "---------\n",
      "Gender  Female  Male\n",
      "Exited              \n",
      "0         3404  4559\n",
      "1         1139   898\n",
      "---------\n",
      "Geography  France  Germany  Spain\n",
      "Exited                           \n",
      "0            4204     1695   2064\n",
      "1             810      814    413\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# CrossTab of categorical variables\n",
    "for i in data[['Exited']].columns:\n",
    "    for j in data[['HasCrCard','Gender','Geography']].columns:\n",
    "        if (i != j):\n",
    "            print(pd.crosstab(data[i], data[j]))\n",
    "            print('---------')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Box Plots to show distribution of Continuous dependant variables with respect to Exited\n",
    "plt.figure(figsize=(20, 20))\n",
    "p = 1\n",
    "for i in data[['CreditScore', 'Balance', 'EstimatedSalary']].columns:\n",
    "    plt.subplot(3, 3, p)\n",
    "    sns.boxplot(x='Exited', y=data[i], data=data)\n",
    "    p += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights from Pairplot & CrossTab\n",
    "- Age - average age for those who exited is higher than those who stayed\n",
    "- Balance - the balance distribution shows two gaussians for those who stayed and those who exited. Those who stayed have more clients with a lower balance, than those with a higher balance. Those who exited have more clients with a higher balance than those with a lower balance\n",
    "- NumOfProducts - clients who stayed mostly have 1 or 2 products, while those who left mostly have 1 product as well a few who had 2/3/4 products\n",
    "- HasCrCard - double the customers have 1 credit card compared to 0 credit cards, whether they exited (1424:613) or not (5631:2332)\n",
    "- Geography - 19.3% of France customers existed (810/4204), 48% of German customers existed (814/1695) and 20% of France customers existed (413/2064)\n",
    "- Gender - 33.5% of Female customers exited(1139/3404), while 19.7% of Male customers exited (898/4559)\n",
    "- IsActiveMember - Group of clients that exited have double the inactive members (1302) compared to active members (735). Clients that stayed have slightly more active members (4416) than inactive members (3547)\n",
    "- EstimatedSalary, Tenure, CreditScore - these independent variables do not distinguish between clients who exited and those who stayed\n",
    "\n",
    "#### Insights from BoxPlot\n",
    "- CreditScore - customers with credit score below 400 exited the bank\n",
    "- EstimatedSalary - does not distinguish between clients who exited and those who stayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Gender_Male  Geography_France  \\\n",
       "0               1        101348.88       1            0                 1   \n",
       "1               1        112542.58       0            0                 0   \n",
       "2               0        113931.57       1            0                 1   \n",
       "3               0         93826.63       0            0                 1   \n",
       "4               1         79084.10       0            0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                  0                0  \n",
       "1                  0                1  \n",
       "2                  0                0  \n",
       "3                  0                0  \n",
       "4                  0                1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Geo_Tmp & Gender_Tmp\n",
    "data.drop(columns=['Geo_Tmp'], inplace=True, axis=1)\n",
    "data.drop(columns=['Gender_Tmp'], inplace=True, axis=1)\n",
    "\n",
    "# One-Hot Encoding of Geography & Gender\n",
    "data = pd.get_dummies(data, columns=['Gender'], drop_first=True)\n",
    "data = pd.get_dummies(data, columns=['Geography'], drop_first=False)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = abs(data.corr()) # correlation matrix\n",
    "lower_triangle = np.tril(corr, k = -1)  # select only the lower triangle of the correlation matrix\n",
    "mask = lower_triangle == 0  # to mask the upper triangle in the following heatmap\n",
    "\n",
    "plt.figure(figsize = (18,12))  # setting the figure size\n",
    "sns.set_style(style = 'white')  # Setting it to white so that we do not see the grid lines\n",
    "sns.heatmap(lower_triangle, center=0.5, cmap= 'Blues', annot= True, xticklabels = corr.index, yticklabels = corr.columns,\n",
    "            cbar= False, linewidths= 1, mask = mask)   # Da Heatmap\n",
    "plt.xticks(rotation = 50)   # Aesthetic purposes\n",
    "plt.yticks(rotation = 20)   # Aesthetic purposes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights from Correlation HeatMap\n",
    "- The remaining independent variables have no correlation between them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d64e485640>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASsAAAEsCAYAAACboZUMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8de9d2aSyUIgCSAg+74jghZZVKzgQoCqLdpKcanYylel8rNftWptpXX/VoutW5Wl1AoVEBfcgCqrskNE1rAGQiAbWSaZmTv3/v4IUEQIk/Uu83k+Hj4kIZl5DzDvnHvvuecopmmaCCGEzalWBxBCiGhIWQkhHEHKSgjhCFJWQghHkLISQjiClJUQwhGkrFyga9euZGRkMGbMGMaOHcvIkSO58cYbyczMrPPneuihhxg6dChjxoz5zn+zZs2q8vvuuusudu/eDcAdd9xBQUFBtZ43MzOT4cOHn/X3srKymDhxIhkZGWRkZHDrrbeybt268z7mtGnT+MMf/lAn+UT981gdQNSNmTNnkpqaeurjN998k6lTpzJnzpw6f67bbruNO++8s1rf88Ybb5z69cqVK+s0z3333cfkyZO5+uqrAVi7di133303S5YsoXHjxpbnE3VDRlYupOs6OTk5pKSkAJCXl8c999zDuHHjGD58OOPHjyc/P58ZM2bw4IMPAhAOh+nfvz/z5s0DYN26dfz4xz+u1vPm5eUxZMgQvvzySwBefPFFbr/9dgzDYPjw4WRmZvLwww8DMGHCBHJycsjNzWXSpEnccMMNZGRk8Oqrr556vLfffvvUKPHtt98+5/MeO3aMQCBw6uOBAwfy4osvomka2dnZXHnllTz++OOMGTOG0aNHn3XUda58wj6krFxiwoQJZGRkMGTIEEaOHAnAU089BcBHH31Ev379mDNnDkuWLCE+Pp6FCxcyYsQIVqxYgWEYrF+/noSEBFatWgXA0qVLGTFixFmfa8aMGd87DNyxYwfp6ek8/fTTPPbYY3z++ee89957vPDCC6jqf/+Zncw0c+ZMWrRowYMPPsiNN97I/Pnzeffdd1m1ahWLFi1i27ZtvPzyy8yePZt58+bh9XrP+doff/xxpk6dypAhQ7j//vuZPXs2vXv3Jjk5GYDDhw8zcOBAFi5cyJQpU5g8eTLhcPisj3VmPmEfchjoEicPA7du3crEiRO59NJLSUtLAyqLbN26dUyfPp19+/axa9cu+vbtS8uWLWnRogXffPMNy5cvZ+LEibz++uuYpsnSpUt5/fXXz/pcVR0GDhkyhOuuu457772X2bNnf+fQ9EyBQIC1a9dy/PhxXnrppVOf2759O0eOHGHw4ME0bdoUgHHjxrFixYqzPs6oUaO4+uqrWb9+PWvXrmXevHm88sorpw6BU1JSyMjIAODyyy9H0zR27NgRxZ+qsBMZWblMz549efjhh3nooYfIzs4G4LnnnuOll16iSZMmjBs3jsGDB3PyltAf/vCHLFu2jJUrVzJy5EhatmzJokWLiI+Pp02bNtV+ftM0ycrKIj09nU2bNlX5tYZhYJom77zzDgsXLmThwoXMmTOHu++++9RjnaRp2lkfIysri+eff564uDguu+wy7r//fhYsWEDnzp359NNPz/q9hmGc8/GEfUlZudCoUaPo06fPqUOaFStWMGHCBMaOHUtaWhqrVq0iEokAMGLECD744AMMw6B58+YMHjyY55577pyHgOczY8YMAoEA8+bNY8aMGWzZsuV7X6NpGrquk5SURL9+/Zg+fToAxcXF3HLLLSxZsoTBgwezcuVKjhw5AsCCBQvO+nzp6enMnTuXTz755NTnioqKyM3NpUePHgAUFBSwbNkyoPLw1uv10qVLl3O+hpP5hL3IYaBLPfbYY4wePZrly5czadIknn32WV566SW8Xi/9+/fnwIEDAHTq1AlFURg0aBBQeRj3t7/97dR5r7OZMWMG77///nc+17dvX26++WZeffVV3n33XZo3b84jjzzClClTvlc011xzDePHj2fatGk8//zzPPnkk2RkZBAKhRg1ahSjR48G4MEHH2TChAkkJibSp0+fs2ZJSUlh5syZvPDCCzz77LP4/X58Ph933303gwYNIjs7m7i4OBYuXMjzzz9PfHw8f/3rX6scWZ2er6pSEw1LkSVihJtlZ2eTkZHBxo0brY4iakkOA4UQjiAjKyGEI8jISgjhCFJWQghHkLISQjiClJUQwhGkrIQQjiBlJYRwBCkrIYQjSFkJIRxBykoI4QhSVkIIR5CyEkI4gpSVEMIRpKyEEI4gZSWEcAQpKyGEI0hZCSEcQcpKCOEIUlZCCEeQshJCOIKUlRDCEaSshBCOIGUlhHAEKSshhCNIWQkhHEHKSgjhCFJWQghHkLISQjiClJUQwhGkrIQQjiBlJYRwBI/VAYRzlYd0whETAFVV8KoKXk0lqEcoDUYoqQhzvDyMHjExTBPDBBMTTVHwaCperfLrE3waKX4vSfEeDANCEQPDqHxcj6YQ79FQVcXKlypsQMpKVCkcMSgPRVAVhXivSlF5mP35ZXx7uIQduSVkFwYoCoQpCoQoKg9TXB7mRM/USHKch7QkH2lJcaQn+UhN9NG8UTy9WqbQ5YJkWqTEE9INIoaJ36fh1eTgIFYopmnW4p+WcBPDMCkL6Xg1lUAowrr9BWzYX8jevDKyjpVxID9AKGJYmlFVoHVqAl2aJ9OlWRJ9Wjem2wXJtEjxUxGOkODT8EiBuZKUVQw7OWqK92ocLipnZVYeq3bns25/AbnFQavjVYvfq9G/bWMu65jOld2a0alpEkG98rXJ6MsdpKxiTCCkoyoKOccr+GhLDquy8th0sIhAKGJ1tDoV51Hp36YJgzqmMbxbMzo3TyKkGyTHe62OJmpIyioGlAbDeDWVLdnHWbDhEEu25zpu5FRbiT6NK7o240f9WzG4Yzq6YZAU50FR5MS9U0hZuVQgpKOpChv2F/Lv9dks/jaX4grd6li24NNUhnRO5+aBrRnWpSl6xCBJRly2J2XlIoZhUh6OcLw8zN+X7+HdDdkUl0tBVSXeq3JVt+ZMuKwtfS5sjKoo+DxyjsuOpKxcoHJqAXyx8xhvrtjLmr0FVkdypLZpCdwxuD03XXwhAIlxMrPHTqSsHKw0qFMW1HlrxV7mrjtIYSBsdSRXiPeqjOnXinuu6Eh6Uhx+r0xKtQMpKwcqC+ocLAzw9KLtfLnrGPI3WH8ubtuEX17ekSGd0/GqiszhspCUlYOUBXUOFAT406JtLN+VZ3WcmNIuLYGHru3G5V2a4fMoaKqUVkOTsnKAsqDO/vwy/rhoGyt351sdJ6Z1bpbEb6/vzqXt04jzqHJ42ICkrGzsZElN/Wgbq7KkpOykV6tGPHp9D/pcmILfq8l8rQYgZWVD5SGdQDjCI/O/4dOtR6yOI6rQv00Tfj+mJx3SE+XqYT2TsrKRiGEQipjMWrWPFxfvojzsrltg3OzG/q14YnRPfJpKnFezOo4rSVnZRFlQZ+vhYv533hb25pVZHUfUQIrfy+8yenBtrxb4fVJYdU3KymLlIZ1AKMIjCzL5dGuu1XFEHbi4bRP+PK4f6Uk+EnxyaFhXpKwsVB6KMHfdQZ76eBsVYWvXiRJ1y6MqTBzWgXuHd8KrqTI/qw5IWVmgIhyhLKgz6e0NfLVHbo1xswub+Hl9/MW0S0+UUVYtSVk1sEBIZ+n2ozw8L5OSoNxkHAs0VeH+qzpz19AOci6rFqSsGkjEMAiGDR5ekMnCTYetjiMs0L9NY14fP4Bkv4c4j5RWdUlZNYBASOdQYTl3zlzHgYKA1XGEhRr5Pbx8S38GtG1CgszLqhYpq3oWCOks2pLDwwsyT21bJcTdwzow+Ydd5LCwGqSs6lF5KMJzn27nrZX7rI4ibGhA2yZMv30gCT5NboyOgpRVPTi5YuevZq9nmayOIKrQNi2BORMHkZroxSfnsaokZVXHQrpBYSDET9/4mqxjpVbHEQ7QOMHLP+64lE7NkuSwsApSVnUoENLZlVvKhOlrKJJVO0U1+DSVv9zSj2Fdmsp8rHOQsqojgZDO4m25TJm7WU6kixr7zciu3Da4nRTWWUhZ1YFASOeDzYd5aH6mLDEsau2mi1vx5Jjeckh4BimrWgqEdOZvOMSj731jdRThIqP6tOC5m/pKYZ1Gxpq1EAjpvLPmIH/48FurowiX+XBLDoAU1mmkrGooENL5x+r9PPXxdqujCJf6cEsOqqrwzA19pLBweVkZhsETTzzBjh078Pl8TJ06lbZt29b6cQMhnTdX7OWFz3bWQUohzu39TYdRgaeksHD1tNnFixcTCoWYM2cOU6ZM4emnn671Y0pRiYb23qbDPLIgk/JQbC9z7eqyWr9+PUOHDgWgX79+fPNN7U6CB0I6izJzpKhEg1uw8RCPvhfbheXqsiotLSUpKenUx5qmoes1W0OqIhxh88Hj/O+8zLqKJ0S1zNtwiFe/3E0gFJvroLm6rJKSkigr++/mC4Zh4PFU/zRdOGKcWOJlLRFDZnoI67y0ZDdLth2NyRGWq8uqf//+LFu2DIBNmzbRpUuXaj+GYZgcLw9z8xtfEYjBfyDCfqbM3czuo6WE9Nhat9/Vk0JPXg3cuXMnpmnypz/9iY4dO1brMcqCOmP/upJdR+WmZGEfTRK8fDJ5GE2T4mJmC3tXl1VtlYci3DFjLav3yNbtwn46pCfy/r1DSIqRFUddfRhYG4GQzjOfbJeiEra1J6+Mu2ati5nzV1JWZ1ERjrBiVx4zVu2zOooQVVqdlc/zn20nEAM7JUlZncEwTPLLQvx6ziarowgRlTdX7GPt/kKCurtHWFJWZwjqEW6fvoayGBlaC3e4918bKKlw9+hKyuo0gaDOHxdtZ2euXPkTzlJcrnPXTHefv5KyOiGoR1i7v5DZX+23OooQNbLxYBF/X7HHtTPcpaxOCIQi3P/ORqtjCFErLy7exYGCABHDfRNGpayonKbwm3e3yCYPwvEihsnd/1hP0IWz22O+rMIRg7V7C/j821yrowhRJ/bnB3jhs52um84gZaUb/GbeFqtjCFGnZqzax9GSoNUx6lRMl1VZUOe5T3eQW+yuv1QhIobJA3M3uerqYMyWlWGYZBcGmLl6n9VRhKgXGw4U8cnWHIJhdxRWzJZVUDe4/51NyPJUws1+/8G3hCPuONkek2VVHorwrzUH2H6kxOooQtSrokCYqR9to8wFJ9tjsqwihsH/fS7rqIvYMGfdQQ4UBDAcfhgRc2UVCOn8ZcluSl3wk0aIaJgm/ObdLY6fexVzZRXUDTmpLmJO5qHjrN9f4OiZ7TFVVmVBnWc/2e74nzBC1MSfFm0npDv3UDCmyqo0qPPvddlWxxDCEt/mFPP13nzHjq5ipqzKgjpTP/wW3eEnGYWojaccPLqKmbI6VhLkw8wcq2MIYakduSWsyspz5OgqJsqqNKjz1MfbkH18hICnP95OOOK8N0NMlFVFOCKrKghxwq6jpSzfdcxxoyvXl1UgpPPGsj1yW40Qp3l56W6CYSkrW1EVhX+tPWB1DCFsZXP2cY4UV1gdo1pcvZWrHjH4YPNhisttOFvdiOBZ/zZKoBAUBf2in2AqKt7174ACZqMW6H1vAEXFs3EuyvHDRDoMxmgzEMLleDbPQx9wq9WvQjjYq1/u4XcZPUh0yI7Orh5ZhQ2T15btsTrGWalHtoFpEL78PvRuI9C+XYQn8330HtcSHnYvmCZqzjcQLINgKeHL70PbvwYAbccSIl2usvgVCKd7f/MhFMXqFNFzdVltzylm91F7bqtlJjUFwwDTQAlXgKKhFh3ETO8IgNG8O+rRXaB5wIhARAfVA2X5KJEQZqMWFr8C4XQVYYN5Gw45ZgkZ15ZVaYXOy//ZbXWMczI9PpRAAd7Pn8GzcS6RjkMrf+PEjzrTGwd6OXjiMFr0xLP2H+jdRuLZ/jl6x6Fom+ejbXkPdFnlVNTc9BV70R0yjcEZB6s1EDEM/rP9qNUxzknbvQyjeVciPUdBoBDvilcqR1AnKOEgeP0AGO0vw2h/GUr+XsykNNRju06NwNSDGzDaD7LkNQjn25NXxs7cEvq2bmx1lPNy5chKjxgs2HjI3tMVfH7w+E/8OgHFjGCmtEI5VjkaVHO3YaR1+M63aLu/JNLxcpRI+NQITImEGjS2cJ/XlmVR6oCt5105sgrqBv9eb+8bliOdLsez4R28y6aBEUHvcR1m49Z4Ns6FrRHM5OYYrfqe+no1eyPGBT3B4yPSqi/eNbNAUQgPHG/hqxBusGTbUTya/c+0K6bpvptQcorKGfT0UqtjCOEYr4+/mKt7NEex8eVB1x0GhvSI7UdVQtjN3HUHbb96ruvKSjdMPtxy2OoYQjjK8l15eFR714G909VAcbnOzlx7zq0Swq6CusGqrDyrY1TJVWUVjhgs3HTI6hhCONLCTYcprQhbHeOcXFVWFeEIn26VpWCEqIkvdhzF57FvJdg3WQ34NJUt2UVWxxDCkYordLbl2HfjX1eVVeah47LGuhC1sHhbLiGb7v7kmrIKhiMs3iaHgELUxtd7C6jQI+f/Qgu4pqzCEYNVWflWxxDC0TYfLCLeo1kd46xcU1YeTWXr4WKrYwjhaEHdIOuYPaf+uKasNh0sIiLnq4SotS93HrPle8kVZVUh56uEqDNfZeUTCNnv1htXlFU4YrB2b4HVMYRwhfX7C4n32u+8lSvKyu/V2JFr3/khQjhJSVDncFG51TG+xxVlVRAIUeGwPdCEsLPM7ONWR/geV5TVLrlxWYg6lXnoOGGbTQ51fFlFDJNNBwutjiGEq+w+Vkp52F6TQx1fVoGQve9nEsKJso6Woqn2WjXU8WWloLDjiJSVEHXpYGE5cTZbgcFeaWogzquyN6/M6hhCuErEMDlaYq89KR1fVkdLgrLSghD1wG67mTu+rI4ct998ECHc4JtDxzFsNBBwQVlVWB1BCFfam19mqyuCVW5yevjwuXeJadmyZZ2HqYnsQhlZCVEfCspCtrqhucqy+vWvfw1AUVERZWVldO7cmd27d5Oens6CBQsaJGBVguEIR4plZCVEfSgsC1kd4TuqLKs5c+YAMGnSJJ555hmSkpIIBAI88MADDRLufEIRg2M2u2IhhFsUlIVQbTTXKqpzVkeOHCEpKQmAhIQEjh49Wq+homWYSFkJUU8KAiG8mn3KqsqR1UlDhgzh1ltvpVevXmzZsoUxY8bUd66oaIpCXqmUlRD1obhct9UuzYppmlGdQdu1axe7du2iQ4cOdOvWrb5zRSWkGwyY+jnFFfZbKEwIN8h8YgTJ8V6rYwBRjqxyc3N57bXXKCwsZOTIkQSDQfr27Vvf2c7LqylSVELUo+IK3TZlFdUY77HHHuPGG28kFAoxYMAA/vjHP9Z3rqjY6bKqEG50PGCf7eSjKqtgMMigQYNQFIUOHToQFxdX37miIrfZCFG/QhH7TAqNqqx8Ph/Lly/HMAw2bdqEz+er71xRkbISon5FbLT+XlRl9eSTTzJ//nwKCwt56623+P3vf1/fuaISsdOfpBAuFDHs8x6L6gT78uXL+fOf/3zq41mzZvHzn/+83kJFS8ZVztKhaSLTf9YL+8zcEefTrJE9TvnAecrqww8/ZOnSpXz99dd89dVXABiGwc6dO21RVsJZhnZOp01jL8rnj1sdRURr0L2Q0MnqFMB5ymro0KE0bdqUoqIixo0bB4CqqrRu3bpBwgl3+deagzxxbSfY+SmU5FgdR0Sjz82Q7oCyKi8v59JLL6VZs2bf+XwgEKjXUNFSFDmgcJKQbnDseBnNulwD66dbHUdEQ7XPZqdVltX06dN5+OGHefzx7w7bFUVh1qxZ9RosGvE2WyNanN+inSVM6P1jFCkrZ1CjOq3dIKK63SY3N5fmzZuf+njr1q307NmzXoNFwzBNOv/2Y5kc6iCtmsSzYsoQlGfaQljWIrO9X62C5ta/1yHKqQt33nknK1asAOCtt97it7/9bb2GilY4YpAcb5/mF+d3qLCCivIAtL/c6igiGv5UqxOcElVZzZgxg7feeouxY8dy+PBh5s6dW9+5oqJHTBrZ5L4lEb2VByswe4y1OoaIRnwjqxOcElVZ7dixg2PHjtG3b1+2bdvGkSNH6jtXVCKGSSO/jKycZubqA9D1GqtjiPNRVPD6rU5xSlTv9GnTpvHaa6/RsmVLNm3axC9+8Qs+++yz+s4WlRS/jKycZvmuPAylB1qLfpCzyeo44lwSUkEPgTfe6iTAeUZWkydPBmD27Nl88sknAPTr14/ExMT6TxYFRUEOAx1qR14Qs9t1VscQVUlIg4h91mGvsqzy8/MB8Hg8fPHFF6c+n5ycXK+hoqWpCo1kZOVI727MhZ43Wh1DVCUhHTvd1Bb1RKUoFxRtUHEejRYp9hiiiup5++sDkHIhJF9gdRRxLonpYKM7Oassq9NniNtxtrimKnS7wD5XK0T0KnSDvOIAdB5pdRRxLglptpoUWmWS3bt3M2XKFEzT/M6vs7KyGirfeXVqlmR1BFFDi3YU8/PeN6FsmGl1FHE2qR3BY58jlypnsK9Zs+ac33jJJZfUS6DqKgvq9Pzdp1bHEDXQuomfZVMuQ3m6LeiyWa3t3LYI2g22OsUpVY6s7FJIVfFqKo38HorLZeMIpzlYWE5FeTn+9sNglz2mwojT2GS1hZMcfydwhR6hXZo9plKI6luVHcTs+SOrY4gzeeIrz1nZiOPLSgEpKwf7x1cHoMu1VscQZ0rrBCF7LAV1kuPLKsHnoX1TKSun+mLHMQzVAxf0sTqKOF3TrpWzrm3E8WWlqQp9WqVYHUPUws68IGa3662OIU7XrDt4E6xO8R2OLyuAfq0bWx1B1MK8zUeh5w1WxxCna3mRrVYJBZeUVVK8h6ZJ9tmFQ1TP7NX7oUkbSGp+/i8WDaNZD6sTfI8ryiqkG/RvK6Mrp6rQDfKLA9BFZrPbQmK67a4EgkvKKsGncUk7+6xoKKrv4x0lmL1usjqGAGhzGehBq1N8jyvKSlNVBndKtzqGqIW/r9gDbS4FjxzOW67jcPDZ7zY2V5QVQIemSXg1e11qFdHbnx8gWFEO7YdZHUV0HA6q/arBfolqKKhH6NFCVmBwsq+yg5jdx1gdI7b5m9h22R7XlJVXUxkg560cbebqgyCrh1qrzQ9seb4KXFRW8V6N63rb8yeCiM5/dhzFVOPggt5WR4ldHa4Enz3vCHFNWQH0apVCgs9eE9lE9ezKD2J2ldGVZTpdZbvJoCe5qqxCuiFXBR3u3U250EvWZrdEcovKpaZtylVllejzcG0vORR0sn9+vR+atIOkZlZHiT09xoBhWJ3inFxVVqqqcHWP5qgyg8GxAiGD/OIy6DzC6iix56Lx4LPXzcunc1VZQeX6Vhe3bWJ1DFELn+6U2ewNLvkC260MeibXlVW8V2N035ZWxxC18Pfle6DNIJnN3pC62/sQEFxYVh5N5fo+Le22bpiohr35AYLBcmg3xNIcYQMeXJ3CTxenctOnqSzJjmN/icYtn6fy08Wp/G5tI4wT2608vqYRP/kslff2Vu4GUxJS+H+rHLTOWn97HwKCC8sKwOdRGdTBfneNi+h9dSiE2WOspRne3+ensc/g7R8W8MYVhTy5vhFPbUxmcp9S3v5hASawJDuOwqBCXoXKO1cXMG9P5Rv+tW8TmdijzNL8UUtqDumdrU5xXq4sqwSvxh2D21sdQ9TC7K8OQFdrVw+9pnUF9/cpPfWxpphsLfBySbMQAMNaBFmV6yNOA92EYAR8qsnBUo1yXaFLY4fsuGTzq4AnubKsVFVhaOd0miR4rY4iamjxtqOYnjho3tOyDIlekySvSWlY4b4VjZncpxST/y5NnugxKQmpJHhMhrcK8sCqxvxP71L+9k0iP+8aYOr6ZP60IZmAbvNzEpfcZftDQHBpWQEYJtx0cWurY4ha2J0XxLR4dJVTpvLzpamMaVdBRruK77xhynSFRr7KEcnNncp5ZVgRpgltkiOszvUxoGmI/ukhPtxnn12Nv6fVxdColdUpouLasvL7NO4Y3M7qGKIW5m85Cr2sW5s9r1zlji9SebBvCTd1LAegR5MwX+f6AFiWE8eApuHvfM+MHYnc1rWMCl1BUypHYbYeWQ2ebKst4qvi2rICaOT3MkDmXDnWrNX7ILVD5TK7Fnj120SKQwp/25rE+CWpjF+SyuQ+pUzLTGLcZ6mEIzCy9X+3vf9ofzxXtqzA74Fr2lTw5vZEZu5I5No2FVU8i4USm1ZOvrXpvYBnUkzTNK0OUV8Mw+Tjb44w6e0NVkcRNbThN4NIXfYobPqn1VHc5/KHYMhk8PqtThIVV4+sVFXhqu7NSPHLiXan+nRXCabc2Fz3VA9c+kvHFBW4vKwATBMmDpNpDE71xoq90HYwaD6ro7hLt+srC8tBXF9Wfp/G7YPbkxznrL8YUWnPsTJCwQpoN9TqKO4y5AGIT7Y6RbW4vqwAFBTuGCqjK6dacziI2WO01THco/UljpixfqaYKCu/T+OuoR1IlFVEHekfXx2AbqOsjuEe1zwDXvtPAj1TTJQVgKrAhMvaWR1D1MBn3x7F9MRDs+5WR3G+DldA06448U7/mCmrBJ+HX13RkXhvzLxkV8nKr7B8NrsrXPO0bTeEOJ+YeudqisKtl7a1Ooaogflb8mRt9trqei2kOPcWtJgqq4Q4D/dd1VmuDDrQrFX7Ia0jJMjSPzWiKDDyKYiz37bw0YqpsgLwelT+38iuVscQ1VQW0ikskbXZa6znDZW31zhYzJWV36vxk4Gt6djUuT9hYtVnu0plbfaa0LwwYqqjR1UQg2UF4NMUnr2pj9UxRDX9ffkeaDe48s0nojfkAYh30BLL5xCTZaWpKt0vSGZkz+ZWRxHVsPtYGaFgENpauza7o6R2qLxZ2aFXAE8Xk2UFlSfb//ij3sR5YvaPwJHWHg5i9hhjdQznGPsKqO64rzKm36kJPo3/GW7vvdLEd/1zTXblTbji/Hr/BC7oDZo7rn7HeFl5+MWQDrRJdd6tB7Hq42+OYHoToWk3q6PYm78JXP+8Kw7/TorpsgLwagp/+1l/2XLeQfYVVGB2vc7qGHqhPA0AAAmfSURBVPZ2zTOu2yQ25svKo6m0T09k4tAOVkcRUaqczS5TGM6pzSDonuGYtdWjFfNlBZAY5+H+H3ahUzNnz0OJFTNX74P0TpCQanUU+/ElwY9nOGJrreqSsjohzqPy+viL8WnyR2J3JRU6RSVl0Olqq6PYz5i/Qnxjq1PUC3lnnqCqChekxPPb62UZEif4PKtMZrOfqc846Hw1eN11+HeSlNVpEnwefjKgNcM6W7P1k4je35fvgfZDZTb7SakdYNSfXXX170xSVmfw+zSm/bQ/zRu560qK2+zMLSUcCkKby6yOYj1PPPzsXdedUD+TlNVZJPg0Zt95qcxut7l1sjZ7pdHToFFLx2xWWlPybjwLr6ZyYWoCf7nlIqujiCrMXpMN3WO8rPr9rHJGfzX3/9u8eTPjx4+vp1D1Q8rqHPxejaGd0uV2HBtblHliNnt6F6ujWKPND+C66s9Sf+ONN3j00UcJBoP1FKx+SFlVISHOw6QrOnFV92ZWRxHnELOz2dM6wU//XaP5VG3atGHatGn1EKp+SVmdh9+n8ZebL6JLc5kwakcLMvOg94+tjtGwEpvC7YsqJ4DWwMiRI/F4nHdzs5RVFPxejdm/uJQmCXKZ3G5mrNpXuWGnv4nVURqGNwEmfAj+VFBj6+0bW6+2hlRVobHfx5y7B8lmEzZTUqFzvLSscjKk26ka3PIONGkbk/PLpKyi5POotE1N4J27f0CC7OxsK4t3B2JjNvuol+DCgdW+8ucWimmaptUhnKQiHGFbTjE3v/4VQd2wOo4AurVI5uN7BqA81RoM3eo49eOKh+Gye109Q/18ZGRVTfFeje4tGjHrjkvkpmeb2J5TQjgUgrYunc0+/NGYLyqQsqqReK9Gnwsb8/cJA/DIqn22sCEnhNk9w+oYde/qqfCDe2K+qEDKqsb8Po2B7VJ55daLZZVRG/jnWhfOZr/ueRh4hxTVCVJWteD3aQzulMb02wbKfYQW+2BzDmZccuU0BqdTFBj9MvT7qRTVaeQdVksJPg+XdEhj/j2X0VjmYVnqQEEFZpdrrY5RO4oKP3oNet0gRXUGKas64PdqdG6WxKL7hnJhk9i8rGwHCzLznT2bXfNVLkncbZQU1VlIWdURn0ejeaM4Prx3CD1bNrI6TkyavnIvNO3qzNnsiU3hF0sql2qWojorKas6pKkqKX4v//7lIFlt1ALFFTrFpWXQ6Sqro1RP815wz2po1s2VGz3UFSmrOqYoCgk+D6+NH8C4ARdaHSfmLM5y2Gz2bqPgzs8gIb3yMFCck5RVPfH7NH43uifP3dRHJo82oDdX7IH2l4PqgHs4r3gEbnyj8rBPkfkv5yPvonqU4PMwqk9LPrxvCC1T3L0+tl18m1NCOByuXJjOrrx+uPlfcNn/VK6iIKIiZVXP/D6NDumJfPrrYVzZVRbxawgbjwQx7TpBtHkvuOcr6HilnEivJimrBuDRVJLjvfztZxfx+9E98Woy5K9P/7Tj2uyKCkN+Db/4HFLaxOzKCbUhZdWA/D4PPxlwIYvuG0q7NBn+15f3N+dgxqdAWkero1RKubByWsKwBysP+2Js0by6In9qDczv89ChaSIf3z+MSVd2khuh68nBgnJ7rM3e+ydwz9dwQR857KslKSsLaKqK36cx6cqOfP7AMHq1kkmkde29b/LByikM8Y0rT6JnvAhxSaA54OqkzcniexYzTZOKsMGctQd45pMdlIcjVkdyhcYJHjY+cgXK812goqjhnlhRoO/P4Jo/gSfO9bskNyQZWVlMURT8Po1xA9uw7DdXMqSTzHyvC0UBC2azt+oPv1oN1z0D8SlSVHVMysom/D6NpslxvP7zi3lt/MVyQ3QdWLo3gNnzhvp/osSmcOObcNtH0LRbjbfIElWTw0AbCkcMIobJ/A3ZvPDZTvLLQlZHcqReLRvxwS/7ozzdGox6OLxWPXDpr+DKhyt/7Ymr++cQp0hZ2VgwHMEw4a2Ve3jliz2UBl26GUI92vXYELxzb4H9K+vuQRW1ch7XiKmQkCpX+RqIlJUDlIci6IbBi4t38Y/V+wlFZFedaP174kAGHJ2H8slDtX8wVau8wnjV45VX++LkcK8hSVk5SFlQpyIc4eX/7Gbu2oOUheTK4fn86KJW/N+1zVD+r3vNH0TzQd9bYPhvwZsoJWURKSsHCoQqDwf/vS6bN5bvIbuw3OJE9qWqsPuJK1FfHQwFe6r3zZ54uPg2uPx/KwtLSspSUlYOFtINDNPk6735vLx0N2v3FVodyZaW/foHtN70Asrqv0b3DWmdYMCdcNGtlYd+ck7KFqSsXMAwTMrDEXKLK3j5P7v5OPOITC49zZQRXZjUtRT1jSvO/UXeBOg5tnKPvrSOoHjAI4vh2YmUlcuUBnU8qsLS7Ud5++sDrMrKw4jxv+H/zmbvDBXHv/ubLfvDJXdBj7FgGnKoZ2NSVi5lGCaBkE7EhA+3HOa9jYdYt7+QWP3b3vLwIBp9NgW2zodm3aH7mMp9+RLTQIuXe/ccQMoqBkQMg/KQQcQ0+Tgzh8Xbcvl6TwElMTJvy6MqTL99IEPSSlG8CZWjJ5nE6ThSVjHGMEzKQjpxHo0DBWV8/m0uy3bmseFAIUHdPfO32qcnckn7VK7v3YKB7VLRDYMEr4Ym6+E7lpRVjNMjBuXhCHEelW9zSvhs6xE2ZxexPafEMbf5pPi9XNS6Mf3bNmFwpzS6t2gEJphAYpwc3rmFlJX4jpAeoSJsEOdVCekGWUdL2XiwiMxDx9meU8Luo6WWzaD3ezVap/ppm5ZIm9QEBrZL5aI2jWmS4KNCj5Dg1fDIyMm1pKzEeZmmSVkwgomJ36tRGAiTXxokp7iCgwUBDhWWk1scJLekgqPFQY6VVlAeihCOnP+flqYqJMV5SI4/+Z+XpDgPjRO8tElNoOsFyXRIT6RFYz8JXo2KsIGBSZxHJc6jNcCrF3YhZSVqLRwxCIYrT+BrioLPo6KpCooCesSsXEXCNDFNME7836MqxHs1PKpC2DDQIyaGaWKYoFBZYvFeDU2WfRYnSFkJIRxBDvCFEI4gZSWEcAQpKyGEI0hZCSEcQcpKCOEIUlZCCEeQshJCOIKUlRDCEaSshBCOIGUlhHAEKSshhCNIWQkhHEHKSgjhCFJWQghHkLISQjiClJUQwhGkrIQQjiBlJYRwBCkrIYQjSFkJIRxBykoI4QhSVkIIR5CyEkI4gpSVEMIRpKyEEI4gZSWEcAQpKyGEI0hZCSEcQcpKCOEIUlZCCEeQshJCOIKUlRDCEaSshBCO8P8BS+tUHPe6ic4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Exited'].value_counts(ascending=False).plot(kind='pie',autopct='%1.0f%%',figsize=(5, 5), title='Raw Exited Split')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, Test & Validation matrices (raw data):\n",
    "- Training Raw data: X0_train, y0_train\n",
    "- Validation Raw data: X0_valid, y0_valid\n",
    "- Cross Validation Raw data: X1_train, y_train\n",
    "- Test Raw Data: X1_test, y_test\n",
    "\n",
    "#### Train, Test & Validation matrices (scaled data):\n",
    "\n",
    "- Training Scaled data: X0_train1\n",
    "- Validation Scaled data: X0_valid1\n",
    "- Training Scaled data for Final Model: X1_train1\n",
    "- Test Scaled Data: X1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Gender_Male  Geography_France  \\\n",
       "0               1        101348.88            0                 1   \n",
       "1               1        112542.58            0                 0   \n",
       "2               0        113931.57            0                 1   \n",
       "3               0         93826.63            0                 1   \n",
       "4               1         79084.10            0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  \n",
       "0                  0                0  \n",
       "1                  0                1  \n",
       "2                  0                0  \n",
       "3                  0                0  \n",
       "4                  0                1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create matrix X1 and y\n",
    "y = data['Exited']\n",
    "X1 = data.drop(['Exited'], axis=1, inplace=False)\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and store Train & Testing data: X1_train, X1_test\n",
    "X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and store Train & Validation data: X0_train, X0_valid\n",
    "X0_train, X0_valid, y0_train, y0_valid = train_test_split(X1_train, y_train, test_size=0.3, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 12), (3000, 12), (7000,), (3000,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train.shape, X1_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review balance state of dependant variable in train and test data\n",
    "- Equal split ratio of 0 & 1 classes, in train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d64e6e1700>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 3, 1, title='Train Exited Split')\n",
    "y_train.value_counts(ascending=False).plot(kind='pie',autopct='%1.0f%%',figsize=(10, 10))\n",
    "plt.subplot(1, 3, 2, title='Validation Exited Split')\n",
    "y0_train.value_counts(ascending=False).plot(kind='pie',autopct='%1.0f%%',figsize=(10, 10))\n",
    "plt.subplot(1, 3, 3, title='Test Exited Split')\n",
    "y_test.value_counts(ascending=False).plot(kind='pie',autopct='%1.0f%%',figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>709</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56214.09</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>797</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117916.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3807</th>\n",
       "      <td>470</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>101140.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50906.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>835</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>130420.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106276.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>626</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>132287.92</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51467.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>676</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>179066.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9160</th>\n",
       "      <td>778</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162809.20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>678</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>129646.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184125.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>601</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160607.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>580</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>136281.41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24799.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "5795          709   39       8       0.00              2          1   \n",
       "1490          797   31       8       0.00              2          1   \n",
       "3807          470   30       3  101140.76              1          1   \n",
       "3042          835   29      10  130420.20              2          0   \n",
       "4064          626   39      10  132287.92              3          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "6400          676   30       5       0.00              2          0   \n",
       "9160          778   24       4       0.00              2          1   \n",
       "9859          678   55       4  129646.91              1          1   \n",
       "1688          601   41       1       0.00              2          0   \n",
       "5994          580   35      10  136281.41              2          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Gender_Male  Geography_France  \\\n",
       "5795               0         56214.09            1                 1   \n",
       "1490               0        117916.63            0                 0   \n",
       "3807               1         50906.65            1                 1   \n",
       "3042               0        106276.55            0                 0   \n",
       "4064               1         51467.92            1                 0   \n",
       "...              ...              ...          ...               ...   \n",
       "6400               0        179066.58            0                 0   \n",
       "9160               1        162809.20            1                 1   \n",
       "9859               1        184125.10            1                 0   \n",
       "1688               1        160607.06            0                 1   \n",
       "5994               1         24799.47            1                 0   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "5795                  0                0  \n",
       "1490                  0                1  \n",
       "3807                  0                0  \n",
       "3042                  1                0  \n",
       "4064                  1                0  \n",
       "...                 ...              ...  \n",
       "6400                  0                1  \n",
       "9160                  0                0  \n",
       "9859                  1                0  \n",
       "1688                  0                0  \n",
       "5994                  1                0  \n",
       "\n",
       "[7000 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.764286</td>\n",
       "      <td>38.854571</td>\n",
       "      <td>5.007571</td>\n",
       "      <td>76307.841974</td>\n",
       "      <td>1.531286</td>\n",
       "      <td>0.703286</td>\n",
       "      <td>0.513286</td>\n",
       "      <td>99459.704037</td>\n",
       "      <td>0.544714</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.254714</td>\n",
       "      <td>0.243286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.306040</td>\n",
       "      <td>10.464699</td>\n",
       "      <td>2.887929</td>\n",
       "      <td>62379.324360</td>\n",
       "      <td>0.581069</td>\n",
       "      <td>0.456842</td>\n",
       "      <td>0.499859</td>\n",
       "      <td>57532.855761</td>\n",
       "      <td>0.498032</td>\n",
       "      <td>0.500032</td>\n",
       "      <td>0.435732</td>\n",
       "      <td>0.429097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50128.262500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>96772.765000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98772.465000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>717.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127486.577500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>148590.555000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>238387.560000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CreditScore          Age       Tenure        Balance  NumOfProducts  \\\n",
       "count  7000.000000  7000.000000  7000.000000    7000.000000    7000.000000   \n",
       "mean    650.764286    38.854571     5.007571   76307.841974       1.531286   \n",
       "std      96.306040    10.464699     2.887929   62379.324360       0.581069   \n",
       "min     350.000000    18.000000     0.000000       0.000000       1.000000   \n",
       "25%     584.000000    32.000000     3.000000       0.000000       1.000000   \n",
       "50%     652.000000    37.000000     5.000000   96772.765000       1.000000   \n",
       "75%     717.000000    44.000000     7.000000  127486.577500       2.000000   \n",
       "max     850.000000    92.000000    10.000000  238387.560000       4.000000   \n",
       "\n",
       "         HasCrCard  IsActiveMember  EstimatedSalary  Gender_Male  \\\n",
       "count  7000.000000     7000.000000      7000.000000  7000.000000   \n",
       "mean      0.703286        0.513286     99459.704037     0.544714   \n",
       "std       0.456842        0.499859     57532.855761     0.498032   \n",
       "min       0.000000        0.000000        11.580000     0.000000   \n",
       "25%       0.000000        0.000000     50128.262500     0.000000   \n",
       "50%       1.000000        1.000000     98772.465000     1.000000   \n",
       "75%       1.000000        1.000000    148590.555000     1.000000   \n",
       "max       1.000000        1.000000    199992.480000     1.000000   \n",
       "\n",
       "       Geography_France  Geography_Germany  Geography_Spain  \n",
       "count       7000.000000        7000.000000      7000.000000  \n",
       "mean           0.502000           0.254714         0.243286  \n",
       "std            0.500032           0.435732         0.429097  \n",
       "min            0.000000           0.000000         0.000000  \n",
       "25%            0.000000           0.000000         0.000000  \n",
       "50%            1.000000           0.000000         0.000000  \n",
       "75%            1.000000           1.000000         0.000000  \n",
       "max            1.000000           1.000000         1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review of dataframe before scaling data using zscore\n",
    "X1_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale original data using zscore to remove weighting bias of larger non-binary variables\n",
    "X0_train1 = X0_train.apply(zscore)\n",
    "X0_valid1 = X0_valid.apply(zscore)\n",
    "X1_test = X1_test.apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "      <td>4.900000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.139558e-16</td>\n",
       "      <td>1.534770e-17</td>\n",
       "      <td>1.500161e-16</td>\n",
       "      <td>3.869920e-16</td>\n",
       "      <td>9.178599e-17</td>\n",
       "      <td>-6.004721e-16</td>\n",
       "      <td>-9.516197e-19</td>\n",
       "      <td>1.953200e-16</td>\n",
       "      <td>-1.385740e-16</td>\n",
       "      <td>-7.617489e-17</td>\n",
       "      <td>5.487221e-16</td>\n",
       "      <td>-3.312090e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000102e+00</td>\n",
       "      <td>1.000102e+00</td>\n",
       "      <td>1.000102e+00</td>\n",
       "      <td>1.000102e+00</td>\n",
       "      <td>1.000102e+00</td>\n",
       "      <td>1.000102e+00</td>\n",
       "      <td>1.000102e+00</td>\n",
       "      <td>1.000102e+00</td>\n",
       "      <td>1.000102e+00</td>\n",
       "      <td>1.000102e+00</td>\n",
       "      <td>1.000102e+00</td>\n",
       "      <td>1.000102e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.161306e+00</td>\n",
       "      <td>-1.992404e+00</td>\n",
       "      <td>-1.726700e+00</td>\n",
       "      <td>-1.220811e+00</td>\n",
       "      <td>-9.080418e-01</td>\n",
       "      <td>-1.537981e+00</td>\n",
       "      <td>-1.028151e+00</td>\n",
       "      <td>-1.715157e+00</td>\n",
       "      <td>-1.077262e+00</td>\n",
       "      <td>-1.003680e+00</td>\n",
       "      <td>-5.845772e-01</td>\n",
       "      <td>-5.672950e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.009919e-01</td>\n",
       "      <td>-6.565924e-01</td>\n",
       "      <td>-1.036583e+00</td>\n",
       "      <td>-1.220811e+00</td>\n",
       "      <td>-9.080418e-01</td>\n",
       "      <td>-1.537981e+00</td>\n",
       "      <td>-1.028151e+00</td>\n",
       "      <td>-8.554009e-01</td>\n",
       "      <td>-1.077262e+00</td>\n",
       "      <td>-1.003680e+00</td>\n",
       "      <td>-5.845772e-01</td>\n",
       "      <td>-5.672950e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.139822e-02</td>\n",
       "      <td>-1.795168e-01</td>\n",
       "      <td>-1.408401e-03</td>\n",
       "      <td>3.287319e-01</td>\n",
       "      <td>-9.080418e-01</td>\n",
       "      <td>6.502032e-01</td>\n",
       "      <td>9.726196e-01</td>\n",
       "      <td>-1.515086e-02</td>\n",
       "      <td>9.282791e-01</td>\n",
       "      <td>9.963333e-01</td>\n",
       "      <td>-5.845772e-01</td>\n",
       "      <td>-5.672950e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.809718e-01</td>\n",
       "      <td>4.883892e-01</td>\n",
       "      <td>6.887081e-01</td>\n",
       "      <td>8.210186e-01</td>\n",
       "      <td>8.085496e-01</td>\n",
       "      <td>6.502032e-01</td>\n",
       "      <td>9.726196e-01</td>\n",
       "      <td>8.595105e-01</td>\n",
       "      <td>9.282791e-01</td>\n",
       "      <td>9.963333e-01</td>\n",
       "      <td>1.710638e+00</td>\n",
       "      <td>-5.672950e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.073405e+00</td>\n",
       "      <td>5.068316e+00</td>\n",
       "      <td>1.723883e+00</td>\n",
       "      <td>2.588283e+00</td>\n",
       "      <td>4.241733e+00</td>\n",
       "      <td>6.502032e-01</td>\n",
       "      <td>9.726196e-01</td>\n",
       "      <td>1.746346e+00</td>\n",
       "      <td>9.282791e-01</td>\n",
       "      <td>9.963333e-01</td>\n",
       "      <td>1.710638e+00</td>\n",
       "      <td>1.762751e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore           Age        Tenure       Balance  NumOfProducts  \\\n",
       "count  4.900000e+03  4.900000e+03  4.900000e+03  4.900000e+03   4.900000e+03   \n",
       "mean  -2.139558e-16  1.534770e-17  1.500161e-16  3.869920e-16   9.178599e-17   \n",
       "std    1.000102e+00  1.000102e+00  1.000102e+00  1.000102e+00   1.000102e+00   \n",
       "min   -3.161306e+00 -1.992404e+00 -1.726700e+00 -1.220811e+00  -9.080418e-01   \n",
       "25%   -7.009919e-01 -6.565924e-01 -1.036583e+00 -1.220811e+00  -9.080418e-01   \n",
       "50%    2.139822e-02 -1.795168e-01 -1.408401e-03  3.287319e-01  -9.080418e-01   \n",
       "75%    6.809718e-01  4.883892e-01  6.887081e-01  8.210186e-01   8.085496e-01   \n",
       "max    2.073405e+00  5.068316e+00  1.723883e+00  2.588283e+00   4.241733e+00   \n",
       "\n",
       "          HasCrCard  IsActiveMember  EstimatedSalary   Gender_Male  \\\n",
       "count  4.900000e+03    4.900000e+03     4.900000e+03  4.900000e+03   \n",
       "mean  -6.004721e-16   -9.516197e-19     1.953200e-16 -1.385740e-16   \n",
       "std    1.000102e+00    1.000102e+00     1.000102e+00  1.000102e+00   \n",
       "min   -1.537981e+00   -1.028151e+00    -1.715157e+00 -1.077262e+00   \n",
       "25%   -1.537981e+00   -1.028151e+00    -8.554009e-01 -1.077262e+00   \n",
       "50%    6.502032e-01    9.726196e-01    -1.515086e-02  9.282791e-01   \n",
       "75%    6.502032e-01    9.726196e-01     8.595105e-01  9.282791e-01   \n",
       "max    6.502032e-01    9.726196e-01     1.746346e+00  9.282791e-01   \n",
       "\n",
       "       Geography_France  Geography_Germany  Geography_Spain  \n",
       "count      4.900000e+03       4.900000e+03     4.900000e+03  \n",
       "mean      -7.617489e-17       5.487221e-16    -3.312090e-16  \n",
       "std        1.000102e+00       1.000102e+00     1.000102e+00  \n",
       "min       -1.003680e+00      -5.845772e-01    -5.672950e-01  \n",
       "25%       -1.003680e+00      -5.845772e-01    -5.672950e-01  \n",
       "50%        9.963333e-01      -5.845772e-01    -5.672950e-01  \n",
       "75%        9.963333e-01       1.710638e+00    -5.672950e-01  \n",
       "max        9.963333e-01       1.710638e+00     1.762751e+00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review of dataframe after scaling data using zscore\n",
    "X0_train1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize & build initial Deep Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model, its Input Layer, Hidden Layers and Output Layers\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(X0_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(int(X0_train.shape[1]*1.5), activation='tanh'))\n",
    "#model.add(tf.keras.layers.Dense(int(X0_train.shape[1]*1.5*(np.power(0.5, 1))), activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(int(X0_train.shape[1]*1.5*(np.power(0.5, 2))), activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, name='SGD') \n",
    "#optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01, name='RMSprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow.keras.metrics import Recall, Accuracy\n",
    "\n",
    "tf.keras.metrics.Recall(thresholds=None, top_k=None, class_id=None, name='recall', dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', \n",
    "              metrics=['accuracy', tf.keras.metrics.BinaryCrossentropy(),\n",
    "                       tf.keras.metrics.Recall(thresholds=0.5), \n",
    "                       tf.keras.metrics.Precision(thresholds=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 18)                234       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 76        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 315\n",
      "Trainable params: 315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Deep Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "154/154 [==============================] - 3s 12ms/step - loss: 0.6387 - accuracy: 0.6453 - binary_crossentropy: 0.6387 - recall: 0.4782 - precision: 0.2937 - val_loss: 0.5401 - val_accuracy: 0.7695 - val_binary_crossentropy: 0.5401 - val_recall: 0.1820 - val_precision: 0.3798\n",
      "Epoch 2/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7814 - binary_crossentropy: 0.5178 - recall: 0.1217 - precision: 0.3428 - val_loss: 0.4886 - val_accuracy: 0.8000 - val_binary_crossentropy: 0.4886 - val_recall: 0.0691 - val_precision: 0.6522\n",
      "Epoch 3/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.8028 - binary_crossentropy: 0.4804 - recall: 0.0378 - precision: 0.6319 - val_loss: 0.4660 - val_accuracy: 0.8024 - val_binary_crossentropy: 0.4660 - val_recall: 0.0622 - val_precision: 0.7714\n",
      "Epoch 4/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8045 - binary_crossentropy: 0.4556 - recall: 0.0467 - precision: 0.7168 - val_loss: 0.4534 - val_accuracy: 0.8048 - val_binary_crossentropy: 0.4534 - val_recall: 0.0806 - val_precision: 0.7609\n",
      "Epoch 5/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8082 - binary_crossentropy: 0.4419 - recall: 0.0717 - precision: 0.6338 - val_loss: 0.4452 - val_accuracy: 0.8081 - val_binary_crossentropy: 0.4452 - val_recall: 0.1244 - val_precision: 0.7013\n",
      "Epoch 6/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.8121 - binary_crossentropy: 0.4345 - recall: 0.1164 - precision: 0.6560 - val_loss: 0.4397 - val_accuracy: 0.8129 - val_binary_crossentropy: 0.4397 - val_recall: 0.1659 - val_precision: 0.6990\n",
      "Epoch 7/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8164 - binary_crossentropy: 0.4200 - recall: 0.1428 - precision: 0.6557 - val_loss: 0.4358 - val_accuracy: 0.8138 - val_binary_crossentropy: 0.4358 - val_recall: 0.1935 - val_precision: 0.6720\n",
      "Epoch 8/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8062 - binary_crossentropy: 0.4303 - recall: 0.1693 - precision: 0.6341 - val_loss: 0.4332 - val_accuracy: 0.8152 - val_binary_crossentropy: 0.4332 - val_recall: 0.2189 - val_precision: 0.6597\n",
      "Epoch 9/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8193 - binary_crossentropy: 0.4103 - recall: 0.1871 - precision: 0.6243 - val_loss: 0.4317 - val_accuracy: 0.8138 - val_binary_crossentropy: 0.4317 - val_recall: 0.2396 - val_precision: 0.6303\n",
      "Epoch 10/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8151 - binary_crossentropy: 0.4074 - recall: 0.2109 - precision: 0.5727 - val_loss: 0.4307 - val_accuracy: 0.8157 - val_binary_crossentropy: 0.4307 - val_recall: 0.2535 - val_precision: 0.6358\n",
      "Epoch 11/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8237 - binary_crossentropy: 0.4027 - recall: 0.2346 - precision: 0.6157 - val_loss: 0.4301 - val_accuracy: 0.8176 - val_binary_crossentropy: 0.4301 - val_recall: 0.2719 - val_precision: 0.6378\n",
      "Epoch 12/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8080 - binary_crossentropy: 0.4184 - recall: 0.2424 - precision: 0.5860 - val_loss: 0.4294 - val_accuracy: 0.8171 - val_binary_crossentropy: 0.4294 - val_recall: 0.2765 - val_precision: 0.6316\n",
      "Epoch 13/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8269 - binary_crossentropy: 0.4006 - recall: 0.2393 - precision: 0.6230 - val_loss: 0.4289 - val_accuracy: 0.8186 - val_binary_crossentropy: 0.4289 - val_recall: 0.2926 - val_precision: 0.6318\n",
      "Epoch 14/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8219 - binary_crossentropy: 0.4048 - recall: 0.2634 - precision: 0.6121 - val_loss: 0.4284 - val_accuracy: 0.8186 - val_binary_crossentropy: 0.4284 - val_recall: 0.2857 - val_precision: 0.6359\n",
      "Epoch 15/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8188 - binary_crossentropy: 0.4149 - recall: 0.2829 - precision: 0.6654 - val_loss: 0.4279 - val_accuracy: 0.8181 - val_binary_crossentropy: 0.4279 - val_recall: 0.2926 - val_precision: 0.6287\n",
      "Epoch 16/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8321 - binary_crossentropy: 0.3915 - recall: 0.2804 - precision: 0.6527 - val_loss: 0.4273 - val_accuracy: 0.8181 - val_binary_crossentropy: 0.4273 - val_recall: 0.3018 - val_precision: 0.6238\n",
      "Epoch 17/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8272 - binary_crossentropy: 0.3967 - recall: 0.2961 - precision: 0.6438 - val_loss: 0.4267 - val_accuracy: 0.8190 - val_binary_crossentropy: 0.4267 - val_recall: 0.2995 - val_precision: 0.6311\n",
      "Epoch 18/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8300 - binary_crossentropy: 0.4027 - recall: 0.3168 - precision: 0.6839 - val_loss: 0.4261 - val_accuracy: 0.8190 - val_binary_crossentropy: 0.4261 - val_recall: 0.3088 - val_precision: 0.6262\n",
      "Epoch 19/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8231 - binary_crossentropy: 0.4041 - recall: 0.3036 - precision: 0.6576 - val_loss: 0.4253 - val_accuracy: 0.8200 - val_binary_crossentropy: 0.4253 - val_recall: 0.3065 - val_precision: 0.6333\n",
      "Epoch 20/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8269 - binary_crossentropy: 0.3971 - recall: 0.3023 - precision: 0.6529 - val_loss: 0.4243 - val_accuracy: 0.8205 - val_binary_crossentropy: 0.4243 - val_recall: 0.2995 - val_precision: 0.6404\n",
      "Epoch 21/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8315 - binary_crossentropy: 0.3922 - recall: 0.2896 - precision: 0.6886 - val_loss: 0.4237 - val_accuracy: 0.8200 - val_binary_crossentropy: 0.4237 - val_recall: 0.3041 - val_precision: 0.6346\n",
      "Epoch 22/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8288 - binary_crossentropy: 0.3994 - recall: 0.3074 - precision: 0.6814 - val_loss: 0.4229 - val_accuracy: 0.8224 - val_binary_crossentropy: 0.4229 - val_recall: 0.3065 - val_precision: 0.6488\n",
      "Epoch 23/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8333 - binary_crossentropy: 0.3933 - recall: 0.3117 - precision: 0.6816 - val_loss: 0.4220 - val_accuracy: 0.8248 - val_binary_crossentropy: 0.4220 - val_recall: 0.3041 - val_precision: 0.6667\n",
      "Epoch 24/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8289 - binary_crossentropy: 0.3933 - recall: 0.3078 - precision: 0.6574 - val_loss: 0.4213 - val_accuracy: 0.8252 - val_binary_crossentropy: 0.4213 - val_recall: 0.3065 - val_precision: 0.6683\n",
      "Epoch 25/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8374 - binary_crossentropy: 0.3868 - recall: 0.2948 - precision: 0.6720 - val_loss: 0.4198 - val_accuracy: 0.8248 - val_binary_crossentropy: 0.4198 - val_recall: 0.3065 - val_precision: 0.6650\n",
      "Epoch 26/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8387 - binary_crossentropy: 0.3831 - recall: 0.3259 - precision: 0.6860 - val_loss: 0.4190 - val_accuracy: 0.8224 - val_binary_crossentropy: 0.4190 - val_recall: 0.3088 - val_precision: 0.6473\n",
      "Epoch 27/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8383 - binary_crossentropy: 0.3877 - recall: 0.3339 - precision: 0.6913 - val_loss: 0.4179 - val_accuracy: 0.8257 - val_binary_crossentropy: 0.4179 - val_recall: 0.3134 - val_precision: 0.6667\n",
      "Epoch 28/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8373 - binary_crossentropy: 0.3887 - recall: 0.3374 - precision: 0.7242 - val_loss: 0.4167 - val_accuracy: 0.8267 - val_binary_crossentropy: 0.4167 - val_recall: 0.3088 - val_precision: 0.6768\n",
      "Epoch 29/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8322 - binary_crossentropy: 0.3991 - recall: 0.3074 - precision: 0.6921 - val_loss: 0.4158 - val_accuracy: 0.8248 - val_binary_crossentropy: 0.4158 - val_recall: 0.3134 - val_precision: 0.6602\n",
      "Epoch 30/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8560 - binary_crossentropy: 0.3644 - recall: 0.3861 - precision: 0.7192 - val_loss: 0.4146 - val_accuracy: 0.8271 - val_binary_crossentropy: 0.4146 - val_recall: 0.3272 - val_precision: 0.6667\n",
      "Epoch 31/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8449 - binary_crossentropy: 0.3843 - recall: 0.3616 - precision: 0.7197 - val_loss: 0.4133 - val_accuracy: 0.8262 - val_binary_crossentropy: 0.4133 - val_recall: 0.3249 - val_precision: 0.6620\n",
      "Epoch 32/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8409 - binary_crossentropy: 0.3766 - recall: 0.3460 - precision: 0.6973 - val_loss: 0.4118 - val_accuracy: 0.8281 - val_binary_crossentropy: 0.4118 - val_recall: 0.3180 - val_precision: 0.6798\n",
      "Epoch 33/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8419 - binary_crossentropy: 0.3767 - recall: 0.3462 - precision: 0.7232 - val_loss: 0.4103 - val_accuracy: 0.8271 - val_binary_crossentropy: 0.4103 - val_recall: 0.3226 - val_precision: 0.6699\n",
      "Epoch 34/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8558 - binary_crossentropy: 0.3586 - recall: 0.3691 - precision: 0.7236 - val_loss: 0.4088 - val_accuracy: 0.8276 - val_binary_crossentropy: 0.4088 - val_recall: 0.3226 - val_precision: 0.6731\n",
      "Epoch 35/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8483 - binary_crossentropy: 0.3677 - recall: 0.3739 - precision: 0.7094 - val_loss: 0.4073 - val_accuracy: 0.8267 - val_binary_crossentropy: 0.4073 - val_recall: 0.3318 - val_precision: 0.6606\n",
      "Epoch 36/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8365 - binary_crossentropy: 0.3863 - recall: 0.3593 - precision: 0.7354 - val_loss: 0.4055 - val_accuracy: 0.8295 - val_binary_crossentropy: 0.4055 - val_recall: 0.3272 - val_precision: 0.6827\n",
      "Epoch 37/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8539 - binary_crossentropy: 0.3684 - recall: 0.3953 - precision: 0.7505 - val_loss: 0.4043 - val_accuracy: 0.8286 - val_binary_crossentropy: 0.4043 - val_recall: 0.3318 - val_precision: 0.6729\n",
      "Epoch 38/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8531 - binary_crossentropy: 0.3659 - recall: 0.3910 - precision: 0.7392 - val_loss: 0.4024 - val_accuracy: 0.8271 - val_binary_crossentropy: 0.4024 - val_recall: 0.3410 - val_precision: 0.6578\n",
      "Epoch 39/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8510 - binary_crossentropy: 0.3658 - recall: 0.3466 - precision: 0.7356 - val_loss: 0.4011 - val_accuracy: 0.8276 - val_binary_crossentropy: 0.4011 - val_recall: 0.3410 - val_precision: 0.6607\n",
      "Epoch 40/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8576 - binary_crossentropy: 0.3531 - recall: 0.3897 - precision: 0.7386 - val_loss: 0.3996 - val_accuracy: 0.8262 - val_binary_crossentropy: 0.3996 - val_recall: 0.3387 - val_precision: 0.6533\n",
      "Epoch 41/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8604 - binary_crossentropy: 0.3486 - recall: 0.3961 - precision: 0.7209 - val_loss: 0.3980 - val_accuracy: 0.8271 - val_binary_crossentropy: 0.3980 - val_recall: 0.3525 - val_precision: 0.6511\n",
      "Epoch 42/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8536 - binary_crossentropy: 0.3507 - recall: 0.3813 - precision: 0.7187 - val_loss: 0.3961 - val_accuracy: 0.8300 - val_binary_crossentropy: 0.3961 - val_recall: 0.3410 - val_precision: 0.6758\n",
      "Epoch 43/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8500 - binary_crossentropy: 0.3665 - recall: 0.4071 - precision: 0.7459 - val_loss: 0.3943 - val_accuracy: 0.8286 - val_binary_crossentropy: 0.3943 - val_recall: 0.3525 - val_precision: 0.6595\n",
      "Epoch 44/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8562 - binary_crossentropy: 0.3596 - recall: 0.3980 - precision: 0.7555 - val_loss: 0.3932 - val_accuracy: 0.8267 - val_binary_crossentropy: 0.3932 - val_recall: 0.3548 - val_precision: 0.6471\n",
      "Epoch 45/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8562 - binary_crossentropy: 0.3532 - recall: 0.4170 - precision: 0.7435 - val_loss: 0.3916 - val_accuracy: 0.8319 - val_binary_crossentropy: 0.3916 - val_recall: 0.3456 - val_precision: 0.6849\n",
      "Epoch 46/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8562 - binary_crossentropy: 0.3567 - recall: 0.4153 - precision: 0.7558 - val_loss: 0.3911 - val_accuracy: 0.8271 - val_binary_crossentropy: 0.3911 - val_recall: 0.3525 - val_precision: 0.6511\n",
      "Epoch 47/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8452 - binary_crossentropy: 0.3651 - recall: 0.4320 - precision: 0.7279 - val_loss: 0.3894 - val_accuracy: 0.8305 - val_binary_crossentropy: 0.3894 - val_recall: 0.3410 - val_precision: 0.6789\n",
      "Epoch 48/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8569 - binary_crossentropy: 0.3470 - recall: 0.4141 - precision: 0.7685 - val_loss: 0.3883 - val_accuracy: 0.8310 - val_binary_crossentropy: 0.3883 - val_recall: 0.3733 - val_precision: 0.6612\n",
      "Epoch 49/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8605 - binary_crossentropy: 0.3537 - recall: 0.4679 - precision: 0.7673 - val_loss: 0.3871 - val_accuracy: 0.8333 - val_binary_crossentropy: 0.3871 - val_recall: 0.3664 - val_precision: 0.6795\n",
      "Epoch 50/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8575 - binary_crossentropy: 0.3561 - recall: 0.4169 - precision: 0.7647 - val_loss: 0.3863 - val_accuracy: 0.8333 - val_binary_crossentropy: 0.3863 - val_recall: 0.3710 - val_precision: 0.6765\n",
      "Epoch 51/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8656 - binary_crossentropy: 0.3427 - recall: 0.5034 - precision: 0.7850 - val_loss: 0.3843 - val_accuracy: 0.8348 - val_binary_crossentropy: 0.3843 - val_recall: 0.3710 - val_precision: 0.6851\n",
      "Epoch 52/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8532 - binary_crossentropy: 0.3500 - recall: 0.4319 - precision: 0.7538 - val_loss: 0.3841 - val_accuracy: 0.8352 - val_binary_crossentropy: 0.3841 - val_recall: 0.3779 - val_precision: 0.6833\n",
      "Epoch 53/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8585 - binary_crossentropy: 0.3500 - recall: 0.4541 - precision: 0.7719 - val_loss: 0.3832 - val_accuracy: 0.8357 - val_binary_crossentropy: 0.3832 - val_recall: 0.3618 - val_precision: 0.6978\n",
      "Epoch 54/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8630 - binary_crossentropy: 0.3396 - recall: 0.4279 - precision: 0.7757 - val_loss: 0.3827 - val_accuracy: 0.8338 - val_binary_crossentropy: 0.3827 - val_recall: 0.3779 - val_precision: 0.6749\n",
      "Epoch 55/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8567 - binary_crossentropy: 0.3558 - recall: 0.4245 - precision: 0.7809 - val_loss: 0.3821 - val_accuracy: 0.8348 - val_binary_crossentropy: 0.3821 - val_recall: 0.3756 - val_precision: 0.6820\n",
      "Epoch 56/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8620 - binary_crossentropy: 0.3405 - recall: 0.4396 - precision: 0.7606 - val_loss: 0.3818 - val_accuracy: 0.8348 - val_binary_crossentropy: 0.3818 - val_recall: 0.4078 - val_precision: 0.6629\n",
      "Epoch 57/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8607 - binary_crossentropy: 0.3537 - recall: 0.4362 - precision: 0.7411 - val_loss: 0.3819 - val_accuracy: 0.8348 - val_binary_crossentropy: 0.3819 - val_recall: 0.4147 - val_precision: 0.6593\n",
      "Epoch 58/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8640 - binary_crossentropy: 0.3429 - recall: 0.4905 - precision: 0.7558 - val_loss: 0.3823 - val_accuracy: 0.8348 - val_binary_crossentropy: 0.3823 - val_recall: 0.4124 - val_precision: 0.6605\n",
      "Epoch 59/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8665 - binary_crossentropy: 0.3395 - recall: 0.4554 - precision: 0.7653 - val_loss: 0.3786 - val_accuracy: 0.8367 - val_binary_crossentropy: 0.3786 - val_recall: 0.3940 - val_precision: 0.6813\n",
      "Epoch 60/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8529 - binary_crossentropy: 0.3514 - recall: 0.4494 - precision: 0.7431 - val_loss: 0.3791 - val_accuracy: 0.8338 - val_binary_crossentropy: 0.3791 - val_recall: 0.3894 - val_precision: 0.6680\n",
      "Epoch 61/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8671 - binary_crossentropy: 0.3357 - recall: 0.4660 - precision: 0.7776 - val_loss: 0.3770 - val_accuracy: 0.8367 - val_binary_crossentropy: 0.3770 - val_recall: 0.3871 - val_precision: 0.6857\n",
      "Epoch 62/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8613 - binary_crossentropy: 0.3479 - recall: 0.4844 - precision: 0.7738 - val_loss: 0.3778 - val_accuracy: 0.8343 - val_binary_crossentropy: 0.3778 - val_recall: 0.4009 - val_precision: 0.6641\n",
      "Epoch 63/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8669 - binary_crossentropy: 0.3290 - recall: 0.4876 - precision: 0.7536 - val_loss: 0.3779 - val_accuracy: 0.8333 - val_binary_crossentropy: 0.3779 - val_recall: 0.4124 - val_precision: 0.6533\n",
      "Epoch 64/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8691 - binary_crossentropy: 0.3326 - recall: 0.4982 - precision: 0.7757 - val_loss: 0.3776 - val_accuracy: 0.8329 - val_binary_crossentropy: 0.3776 - val_recall: 0.4032 - val_precision: 0.6554\n",
      "Epoch 65/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8636 - binary_crossentropy: 0.3363 - recall: 0.4807 - precision: 0.7729 - val_loss: 0.3782 - val_accuracy: 0.8348 - val_binary_crossentropy: 0.3782 - val_recall: 0.4147 - val_precision: 0.6593\n",
      "Epoch 66/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8653 - binary_crossentropy: 0.3341 - recall: 0.4867 - precision: 0.7579 - val_loss: 0.3760 - val_accuracy: 0.8371 - val_binary_crossentropy: 0.3760 - val_recall: 0.4055 - val_precision: 0.6769\n",
      "Epoch 67/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8652 - binary_crossentropy: 0.3335 - recall: 0.4811 - precision: 0.7415 - val_loss: 0.3770 - val_accuracy: 0.8352 - val_binary_crossentropy: 0.3770 - val_recall: 0.4171 - val_precision: 0.6606\n",
      "Epoch 68/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8698 - binary_crossentropy: 0.3348 - recall: 0.4845 - precision: 0.7759 - val_loss: 0.3766 - val_accuracy: 0.8362 - val_binary_crossentropy: 0.3766 - val_recall: 0.3986 - val_precision: 0.6758\n",
      "Epoch 69/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8726 - binary_crossentropy: 0.3273 - recall: 0.4940 - precision: 0.7927 - val_loss: 0.3759 - val_accuracy: 0.8371 - val_binary_crossentropy: 0.3759 - val_recall: 0.4171 - val_precision: 0.6704\n",
      "Epoch 70/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8717 - binary_crossentropy: 0.3267 - recall: 0.4912 - precision: 0.7635 - val_loss: 0.3754 - val_accuracy: 0.8352 - val_binary_crossentropy: 0.3754 - val_recall: 0.4171 - val_precision: 0.6606\n",
      "Epoch 71/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8567 - binary_crossentropy: 0.3475 - recall: 0.4694 - precision: 0.7605 - val_loss: 0.3748 - val_accuracy: 0.8367 - val_binary_crossentropy: 0.3748 - val_recall: 0.4055 - val_precision: 0.6743\n",
      "Epoch 72/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8651 - binary_crossentropy: 0.3338 - recall: 0.4668 - precision: 0.7633 - val_loss: 0.3749 - val_accuracy: 0.8376 - val_binary_crossentropy: 0.3749 - val_recall: 0.4009 - val_precision: 0.6824\n",
      "Epoch 73/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8721 - binary_crossentropy: 0.3241 - recall: 0.4902 - precision: 0.7680 - val_loss: 0.3754 - val_accuracy: 0.8376 - val_binary_crossentropy: 0.3754 - val_recall: 0.4147 - val_precision: 0.6742\n",
      "Epoch 74/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8798 - binary_crossentropy: 0.3154 - recall: 0.5337 - precision: 0.7843 - val_loss: 0.3749 - val_accuracy: 0.8357 - val_binary_crossentropy: 0.3749 - val_recall: 0.4171 - val_precision: 0.6630\n",
      "Epoch 75/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8623 - binary_crossentropy: 0.3399 - recall: 0.5047 - precision: 0.7527 - val_loss: 0.3759 - val_accuracy: 0.8362 - val_binary_crossentropy: 0.3759 - val_recall: 0.4286 - val_precision: 0.6596\n",
      "Epoch 76/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8700 - binary_crossentropy: 0.3319 - recall: 0.4886 - precision: 0.7585 - val_loss: 0.3754 - val_accuracy: 0.8348 - val_binary_crossentropy: 0.3754 - val_recall: 0.4124 - val_precision: 0.6605\n",
      "Epoch 77/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8678 - binary_crossentropy: 0.3319 - recall: 0.4924 - precision: 0.7700 - val_loss: 0.3748 - val_accuracy: 0.8367 - val_binary_crossentropy: 0.3748 - val_recall: 0.4194 - val_precision: 0.6667\n",
      "Epoch 78/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8694 - binary_crossentropy: 0.3286 - recall: 0.5025 - precision: 0.7667 - val_loss: 0.3762 - val_accuracy: 0.8367 - val_binary_crossentropy: 0.3762 - val_recall: 0.4355 - val_precision: 0.6585\n",
      "Epoch 79/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8707 - binary_crossentropy: 0.3231 - recall: 0.5164 - precision: 0.7573 - val_loss: 0.3747 - val_accuracy: 0.8367 - val_binary_crossentropy: 0.3747 - val_recall: 0.4240 - val_precision: 0.6643\n",
      "Epoch 80/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8679 - binary_crossentropy: 0.3251 - recall: 0.4994 - precision: 0.7658 - val_loss: 0.3742 - val_accuracy: 0.8371 - val_binary_crossentropy: 0.3742 - val_recall: 0.4147 - val_precision: 0.6716\n",
      "Epoch 81/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8726 - binary_crossentropy: 0.3202 - recall: 0.4906 - precision: 0.7867 - val_loss: 0.3734 - val_accuracy: 0.8390 - val_binary_crossentropy: 0.3734 - val_recall: 0.4032 - val_precision: 0.6890\n",
      "Epoch 82/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8631 - binary_crossentropy: 0.3362 - recall: 0.4873 - precision: 0.7581 - val_loss: 0.3740 - val_accuracy: 0.8381 - val_binary_crossentropy: 0.3740 - val_recall: 0.4240 - val_precision: 0.6715\n",
      "Epoch 83/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8731 - binary_crossentropy: 0.3207 - recall: 0.5148 - precision: 0.7621 - val_loss: 0.3762 - val_accuracy: 0.8352 - val_binary_crossentropy: 0.3762 - val_recall: 0.4378 - val_precision: 0.6507\n",
      "Epoch 84/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8700 - binary_crossentropy: 0.3308 - recall: 0.5322 - precision: 0.7470 - val_loss: 0.3733 - val_accuracy: 0.8390 - val_binary_crossentropy: 0.3733 - val_recall: 0.4263 - val_precision: 0.6752\n",
      "Epoch 85/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8754 - binary_crossentropy: 0.3155 - recall: 0.5288 - precision: 0.7748 - val_loss: 0.3736 - val_accuracy: 0.8381 - val_binary_crossentropy: 0.3736 - val_recall: 0.4240 - val_precision: 0.6715\n",
      "Epoch 86/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8695 - binary_crossentropy: 0.3187 - recall: 0.5029 - precision: 0.7538 - val_loss: 0.3737 - val_accuracy: 0.8376 - val_binary_crossentropy: 0.3737 - val_recall: 0.4332 - val_precision: 0.6643\n",
      "Epoch 87/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8695 - binary_crossentropy: 0.3283 - recall: 0.5299 - precision: 0.7666 - val_loss: 0.3734 - val_accuracy: 0.8386 - val_binary_crossentropy: 0.3734 - val_recall: 0.4171 - val_precision: 0.6779\n",
      "Epoch 88/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8630 - binary_crossentropy: 0.3358 - recall: 0.4691 - precision: 0.7344 - val_loss: 0.3758 - val_accuracy: 0.8371 - val_binary_crossentropy: 0.3758 - val_recall: 0.4355 - val_precision: 0.6608\n",
      "Epoch 89/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8668 - binary_crossentropy: 0.3250 - recall: 0.5094 - precision: 0.7406 - val_loss: 0.3769 - val_accuracy: 0.8367 - val_binary_crossentropy: 0.3769 - val_recall: 0.4309 - val_precision: 0.6608\n",
      "Epoch 90/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8719 - binary_crossentropy: 0.3293 - recall: 0.5128 - precision: 0.7730 - val_loss: 0.3759 - val_accuracy: 0.8367 - val_binary_crossentropy: 0.3759 - val_recall: 0.4401 - val_precision: 0.6564\n",
      "Epoch 91/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8745 - binary_crossentropy: 0.3106 - recall: 0.5386 - precision: 0.7685 - val_loss: 0.3747 - val_accuracy: 0.8352 - val_binary_crossentropy: 0.3747 - val_recall: 0.4240 - val_precision: 0.6571\n",
      "Epoch 92/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8746 - binary_crossentropy: 0.3187 - recall: 0.5318 - precision: 0.7730 - val_loss: 0.3733 - val_accuracy: 0.8381 - val_binary_crossentropy: 0.3733 - val_recall: 0.4332 - val_precision: 0.6667\n",
      "Epoch 93/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8751 - binary_crossentropy: 0.3099 - recall: 0.5175 - precision: 0.7698 - val_loss: 0.3739 - val_accuracy: 0.8381 - val_binary_crossentropy: 0.3739 - val_recall: 0.4124 - val_precision: 0.6780\n",
      "Epoch 94/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8688 - binary_crossentropy: 0.3284 - recall: 0.4986 - precision: 0.7693 - val_loss: 0.3745 - val_accuracy: 0.8376 - val_binary_crossentropy: 0.3745 - val_recall: 0.4147 - val_precision: 0.6742\n",
      "Epoch 95/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8726 - binary_crossentropy: 0.3198 - recall: 0.5353 - precision: 0.7700 - val_loss: 0.3757 - val_accuracy: 0.8357 - val_binary_crossentropy: 0.3757 - val_recall: 0.4378 - val_precision: 0.6529\n",
      "Epoch 96/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8715 - binary_crossentropy: 0.3224 - recall: 0.5019 - precision: 0.7620 - val_loss: 0.3750 - val_accuracy: 0.8376 - val_binary_crossentropy: 0.3750 - val_recall: 0.4309 - val_precision: 0.6655\n",
      "Epoch 97/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8673 - binary_crossentropy: 0.3200 - recall: 0.5022 - precision: 0.7680 - val_loss: 0.3768 - val_accuracy: 0.8386 - val_binary_crossentropy: 0.3768 - val_recall: 0.4539 - val_precision: 0.6589\n",
      "Epoch 98/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8715 - binary_crossentropy: 0.3244 - recall: 0.5232 - precision: 0.7731 - val_loss: 0.3746 - val_accuracy: 0.8376 - val_binary_crossentropy: 0.3746 - val_recall: 0.4240 - val_precision: 0.6691\n",
      "Epoch 99/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8721 - binary_crossentropy: 0.3169 - recall: 0.4972 - precision: 0.7721 - val_loss: 0.3742 - val_accuracy: 0.8400 - val_binary_crossentropy: 0.3742 - val_recall: 0.4493 - val_precision: 0.6678\n",
      "Epoch 100/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8757 - binary_crossentropy: 0.3167 - recall: 0.4983 - precision: 0.7621 - val_loss: 0.3739 - val_accuracy: 0.8371 - val_binary_crossentropy: 0.3739 - val_recall: 0.4355 - val_precision: 0.6608\n"
     ]
    }
   ],
   "source": [
    "modHistory = model.fit(X0_train1, y0_train.values, epochs=100, verbose=1, validation_data=(X0_valid1, y0_valid.values)) #, batch_size = 1000, callbacks=[tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8557 - binary_crossentropy: 0.3621 - recall: 0.4669 - precision: 0.7372\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X1_test, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy', 'binary_crossentropy', 'recall', 'precision']\n",
      "[0.362070769071579, 0.8556666374206543, 0.362070769071579, 0.4668820798397064, 0.7372449040412903]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>binary_crossentropy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.362071</td>\n",
       "      <td>0.855667</td>\n",
       "      <td>0.362071</td>\n",
       "      <td>0.466882</td>\n",
       "      <td>0.737245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  binary_crossentropy    recall  precision\n",
       "0  0.362071  0.855667             0.362071  0.466882   0.737245"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_DF0 = pd.DataFrame(columns=model.metrics_names)\n",
    "res_DF0.loc[0] = np.array(results)\n",
    "res_DF0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modHistory.history['accuracy'])\n",
    "plt.plot(modHistory.history['val_accuracy'])\n",
    "plt.title('Base Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modHistory.history['recall'])\n",
    "plt.plot(modHistory.history['val_recall'])\n",
    "plt.title('Base Model Recall')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modHistory.history['binary_crossentropy'])\n",
    "plt.plot(modHistory.history['val_binary_crossentropy'])\n",
    "plt.title('Base Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized Search Cross Validation\n",
    "1. Attempt to improve convergence of model in terms of:\n",
    "    - Epoc count\n",
    "    - Accuracy\n",
    "    - Recall\n",
    "    - Loss (binary_crossentropy)\n",
    "2. Tune hyperparameters:\n",
    "    - Hidden Layers (n_hidden_layer)\n",
    "    - 1st hidden layer neuron count as a multiple of input layer (neuronMult)\n",
    "    - Activation Function (activ1)\n",
    "    - Learning Rate (l_rate)\n",
    "    - How many neurons in subsequent hidden layers as a fraction of previous layer (neuFrac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 12), (7000,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trape = X1_train.shape[1]\n",
    "X1_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden_layer=2, neuronMult=1, optim='SGD', activ1='tanh', #activ2on='sigmoid',\n",
    "                l_rate=0.01, rand1=0.5, rand2=0.0, neuFrac=0.5):\n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(trape,)))\n",
    "    \n",
    "    init0 = False\n",
    "    for layer in range(1, n_hidden_layer+1):\n",
    "        if init0 == False:\n",
    "            model.add(tf.keras.layers.Dense(int(neuronMult*trape), activation=activ1))\n",
    "            init0 = True\n",
    "        else:\n",
    "            model.add(tf.keras.layers.Dense(int(neuronMult*trape*(np.power(neuFrac, layer-1))), activation=activ1))#activ2on))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer for model\n",
    "    optimiz = tf.keras.optimizers.Optimizer\n",
    "    if optim == 'SGD':\n",
    "        optimiz = tf.keras.optimizers.SGD(learning_rate=l_rate, momentum=rand2, nesterov=False, name='SGD') \n",
    "    if optim == 'RMSprop':\n",
    "        optimiz = tf.keras.optimizers.RMSprop(learning_rate=l_rate, rho=0.9, momentum=rand2, centered=False, name='RMSprop')#, epsilon=1e-07\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimiz, loss='binary_crossentropy', \n",
    "                  metrics=['accuracy', tf.keras.metrics.Recall(thresholds=0.5), \n",
    "                           tf.keras.metrics.Precision(thresholds=0.5)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier at 0x1d6580b5160>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "keras_class = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model, epochs=100, batch_size=2000)\n",
    "clone(keras_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epochs', 'batch_size', 'build_fn'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_class.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with PowerTransformer and keras classifier\n",
    "# ensuring specific scaling for each cross validation iteration\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "annPipeL = Pipeline([('powTransY', PowerTransformer(method='yeo-johnson', standardize=True)), (\"kerClass\", keras_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preserving the percentage of samples for each class\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf3 = StratifiedKFold(n_splits=3, shuffle=True, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6881 - accuracy: 0.6991 - recall_1: 0.0622 - precision_1: 0.1009\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6841 - accuracy: 0.7787 - recall_1: 0.0014 - precision_1: 0.0169\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6798 - accuracy: 0.7978 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6760 - accuracy: 0.7955 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.8005 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.8015 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.7952 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6611 - accuracy: 0.7961 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6572 - accuracy: 0.7986 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.7977 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.7954 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.7985 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.7974 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.7984 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.7972 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.8039 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.7960 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.7956 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6273 - accuracy: 0.7952 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.7995 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.7999 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6185 - accuracy: 0.7989 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6155 - accuracy: 0.8005 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.7977 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6107 - accuracy: 0.7997 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.8005 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6069 - accuracy: 0.7977 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.7985 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6033 - accuracy: 0.7957 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.8000 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5989 - accuracy: 0.7965 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.7962 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7944 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5932 - accuracy: 0.7958 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.8006 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.8000 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5873 - accuracy: 0.7969 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.7945 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.7962 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5846 - accuracy: 0.7919 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7977 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.7954 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.8003 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.7971 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7982 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5740 - accuracy: 0.7947 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7975 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.7959 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7998 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7965 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.7979 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5653 - accuracy: 0.7963 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7983 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.8015 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7987 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7978 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.7985 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.7989 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7965 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5534 - accuracy: 0.8008 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7975 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7960 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7990 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7970 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7965 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7969 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7975 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7981 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7977 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7970 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7995 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7969 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7956 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7994 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7986 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7975 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7969 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7956 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7943 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7983 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7984 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7996 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7980 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7983 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7974 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7955 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7980 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7979 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7957 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7973 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7980 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7989 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7947 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7976 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7974 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7977 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7980 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7944 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7983 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7980 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7973 - recall_1: 0.0000e+00 - precision_1: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5568 - accuracy: 0.8005 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.7963 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.8003 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.8002 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7983 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7978 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7963 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7955 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7990 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7989 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7954 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7951 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7980 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7960 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7952 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7964 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.8022 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7975 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7970 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7988 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7956 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7973 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.8003 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7964 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7972 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7991 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7985 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7932 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7968 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7952 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7962 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7987 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7967 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7997 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7977 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7924 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7944 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7998 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7974 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7975 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7966 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.8000 - recall_2: 0.0000e+00 - precision_2: 0.0000e+0 - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7987 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7962 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7980 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7935 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7962 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7982 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7959 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5202 - accuracy: 0.7982 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7992 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7955 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7968 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7977 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.7985 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.8003 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7976 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7962 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7980 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7984 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.8005 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7951 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7932 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7961 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7975 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7957 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7977 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7952 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7959 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7980 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7957 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7957 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7962 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.8005 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7985 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7987 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7961 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7973 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7969 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8003 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7965 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7950 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7981 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7971 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7958 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7972 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7956 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7981 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7970 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7987 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7961 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7935 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8004 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7933 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7993 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7970 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7960 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7965 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7962 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.8000 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7963 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5097 - accuracy: 0.7977 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6028 - accuracy: 0.7957 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.7949 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7963 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.7992 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.7973 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.7961 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.8010 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7953 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.7978 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7951 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.7960 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7948 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7977 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7986 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7966 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7976 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7973 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.8010 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.7975 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7961 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7973 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.7968 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7973 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7977 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7984 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7902 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7979 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7954 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7985 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.7960 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.8017 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7954 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7987 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7985 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.8006 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7979 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7976 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7968 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7962 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7979 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7984 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7975 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7989 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7972 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7994 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7993 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7989 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7967 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7978 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7929 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7971 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7957 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7939 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7974 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7963 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.8008 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7975 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.8006 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7967 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7953 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7973 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7981 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7983 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7970 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7982 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7987 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.8008 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7976 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7996 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7987 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7969 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7951 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7963 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7991 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7959 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7966 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7987 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7943 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7989 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7994 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.8005 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.8023 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7969 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7957 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7969 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7983 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7953 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7997 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7980 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7993 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7964 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7982 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7967 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7988 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.8008 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.7995 - recall_3: 0.0000e+00 - precision_3: 0.0000e+0 - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7979 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.8008 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7958 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7964 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7974 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5100 - accuracy: 0.7973 - recall_3: 0.0000e+00 - precision_3: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.0136 - accuracy: 0.2063 - recall_4: 1.0000 - precision_4: 0.2063\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0082 - accuracy: 0.2034 - recall_4: 1.0000 - precision_4: 0.2034\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0014 - accuracy: 0.2023 - recall_4: 1.0000 - precision_4: 0.2023\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9901 - accuracy: 0.2071 - recall_4: 1.0000 - precision_4: 0.2071\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9864 - accuracy: 0.2021 - recall_4: 1.0000 - precision_4: 0.2021\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9809 - accuracy: 0.1996 - recall_4: 1.0000 - precision_4: 0.1996\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9728 - accuracy: 0.2006 - recall_4: 1.0000 - precision_4: 0.2006\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9658 - accuracy: 0.2004 - recall_4: 1.0000 - precision_4: 0.2004\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9595 - accuracy: 0.1995 - recall_4: 1.0000 - precision_4: 0.1995\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9519 - accuracy: 0.2003 - recall_4: 1.0000 - precision_4: 0.2003\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9458 - accuracy: 0.1995 - recall_4: 1.0000 - precision_4: 0.1995\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9381 - accuracy: 0.2011 - recall_4: 1.0000 - precision_4: 0.2011\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9291 - accuracy: 0.2049 - recall_4: 1.0000 - precision_4: 0.2049\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9255 - accuracy: 0.2002 - recall_4: 1.0000 - precision_4: 0.2002\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9188 - accuracy: 0.2006 - recall_4: 1.0000 - precision_4: 0.2006\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9103 - accuracy: 0.2047 - recall_4: 1.0000 - precision_4: 0.2047\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9070 - accuracy: 0.1995 - recall_4: 1.0000 - precision_4: 0.1995\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8979 - accuracy: 0.2048 - recall_4: 1.0000 - precision_4: 0.2048\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8921 - accuracy: 0.2043 - recall_4: 1.0000 - precision_4: 0.2043\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8868 - accuracy: 0.2031 - recall_4: 1.0000 - precision_4: 0.2031\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8837 - accuracy: 0.1981 - recall_4: 1.0000 - precision_4: 0.1981\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8771 - accuracy: 0.1996 - recall_4: 1.0000 - precision_4: 0.1996\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8691 - accuracy: 0.2045 - recall_4: 1.0000 - precision_4: 0.2045\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8658 - accuracy: 0.2003 - recall_4: 1.0000 - precision_4: 0.2003\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8596 - accuracy: 0.2020 - recall_4: 1.0000 - precision_4: 0.2020\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8548 - accuracy: 0.2005 - recall_4: 1.0000 - precision_4: 0.2005\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8482 - accuracy: 0.2036 - recall_4: 1.0000 - precision_4: 0.2036\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8436 - accuracy: 0.2025 - recall_4: 1.0000 - precision_4: 0.2025\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8384 - accuracy: 0.2023 - recall_4: 1.0000 - precision_4: 0.2023\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8325 - accuracy: 0.2048 - recall_4: 1.0000 - precision_4: 0.2048\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8275 - accuracy: 0.2049 - recall_4: 1.0000 - precision_4: 0.2049\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8233 - accuracy: 0.2031 - recall_4: 1.0000 - precision_4: 0.2031\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8186 - accuracy: 0.2025 - recall_4: 1.0000 - precision_4: 0.2025\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8137 - accuracy: 0.2038 - recall_4: 1.0000 - precision_4: 0.2038\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8087 - accuracy: 0.2041 - recall_4: 1.0000 - precision_4: 0.2041\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8043 - accuracy: 0.2040 - recall_4: 1.0000 - precision_4: 0.2040\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7998 - accuracy: 0.2034 - recall_4: 1.0000 - precision_4: 0.2034\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7958 - accuracy: 0.2028 - recall_4: 1.0000 - precision_4: 0.2028\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7914 - accuracy: 0.2029 - recall_4: 1.0000 - precision_4: 0.2029\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7878 - accuracy: 0.2004 - recall_4: 1.0000 - precision_4: 0.2004\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7826 - accuracy: 0.2036 - recall_4: 1.0000 - precision_4: 0.2036\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7794 - accuracy: 0.2004 - recall_4: 1.0000 - precision_4: 0.2004\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7753 - accuracy: 0.2002 - recall_4: 1.0000 - precision_4: 0.2002\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7713 - accuracy: 0.2001 - recall_4: 1.0000 - precision_4: 0.2001\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7667 - accuracy: 0.2030 - recall_4: 1.0000 - precision_4: 0.2030\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7636 - accuracy: 0.1994 - recall_4: 1.0000 - precision_4: 0.1994\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7594 - accuracy: 0.2010 - recall_4: 1.0000 - precision_4: 0.2010\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7548 - accuracy: 0.2056 - recall_4: 1.0000 - precision_4: 0.2056\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7514 - accuracy: 0.2040 - recall_4: 1.0000 - precision_4: 0.2040\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7482 - accuracy: 0.2015 - recall_4: 1.0000 - precision_4: 0.2015\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7451 - accuracy: 0.1984 - recall_4: 1.0000 - precision_4: 0.1984\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7412 - accuracy: 0.2008 - recall_4: 1.0000 - precision_4: 0.2008\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7375 - accuracy: 0.2035 - recall_4: 1.0000 - precision_4: 0.2035\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7342 - accuracy: 0.2025 - recall_4: 1.0000 - precision_4: 0.2025\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7305 - accuracy: 0.2058 - recall_4: 1.0000 - precision_4: 0.2058\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7279 - accuracy: 0.1998 - recall_4: 1.0000 - precision_4: 0.1998\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7246 - accuracy: 0.2006 - recall_4: 1.0000 - precision_4: 0.2006\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7214 - accuracy: 0.1998 - recall_4: 1.0000 - precision_4: 0.1998\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7179 - accuracy: 0.2041 - recall_4: 1.0000 - precision_4: 0.2041\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7148 - accuracy: 0.2041 - recall_4: 1.0000 - precision_4: 0.2041\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7118 - accuracy: 0.2031 - recall_4: 1.0000 - precision_4: 0.2031\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7088 - accuracy: 0.2038 - recall_4: 0.9992 - precision_4: 0.2030\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7057 - accuracy: 0.2148 - recall_4: 0.9914 - precision_4: 0.2063\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7028 - accuracy: 0.2352 - recall_4: 0.9667 - precision_4: 0.2064\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7000 - accuracy: 0.2794 - recall_4: 0.8956 - precision_4: 0.2050\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6971 - accuracy: 0.3608 - recall_4: 0.7851 - precision_4: 0.2134\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.4616 - recall_4: 0.6516 - precision_4: 0.2192\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5560 - recall_4: 0.4722 - precision_4: 0.2257\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.6572 - recall_4: 0.3139 - precision_4: 0.2377\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.7239 - recall_4: 0.1748 - precision_4: 0.2482\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.7662 - recall_4: 0.0846 - precision_4: 0.2629\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.7918 - recall_4: 0.0419 - precision_4: 0.3570\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.7969 - recall_4: 0.0075 - precision_4: 0.3438\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6760 - accuracy: 0.7990 - recall_4: 0.0015 - precision_4: 0.6250\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.7982 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.8012 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.8012 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.7972 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.7987 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.7968 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6591 - accuracy: 0.8070 - recall_4: 0.0000e+00 - precision_4: 0.0000e+0 - 0s 4ms/step - loss: 0.6596 - accuracy: 0.7997 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.8013 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.7972 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.7942 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.7959 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.7977 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.7977 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.7977 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.7990 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.7985 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.7978 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7982 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7988 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7977 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.7965 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.8002 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.7974 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.7944 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.7975 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.8019 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "WARNING:tensorflow:5 out of the last 6701 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C51C4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 0.6222 - accuracy: 0.7973 - recall_4: 0.0000e+00 - precision_4: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8315 - accuracy: 0.1995 - recall_5: 1.0000 - precision_5: 0.1995\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8274 - accuracy: 0.1997 - recall_5: 1.0000 - precision_5: 0.1997\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8238 - accuracy: 0.1986 - recall_5: 1.0000 - precision_5: 0.1986\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8185 - accuracy: 0.2021 - recall_5: 1.0000 - precision_5: 0.2021\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8139 - accuracy: 0.2040 - recall_5: 1.0000 - precision_5: 0.2040\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8109 - accuracy: 0.2015 - recall_5: 1.0000 - precision_5: 0.2015\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8070 - accuracy: 0.2020 - recall_5: 1.0000 - precision_5: 0.2020\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8041 - accuracy: 0.1995 - recall_5: 1.0000 - precision_5: 0.1995\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7987 - accuracy: 0.2051 - recall_5: 1.0000 - precision_5: 0.2051\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7956 - accuracy: 0.2035 - recall_5: 1.0000 - precision_5: 0.2035\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7916 - accuracy: 0.2045 - recall_5: 1.0000 - precision_5: 0.2045\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7882 - accuracy: 0.2040 - recall_5: 1.0000 - precision_5: 0.2040\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7854 - accuracy: 0.2014 - recall_5: 1.0000 - precision_5: 0.2014\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7818 - accuracy: 0.2022 - recall_5: 1.0000 - precision_5: 0.2022\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7783 - accuracy: 0.2025 - recall_5: 1.0000 - precision_5: 0.2025\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7756 - accuracy: 0.1995 - recall_5: 1.0000 - precision_5: 0.1995\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7711 - accuracy: 0.2046 - recall_5: 1.0000 - precision_5: 0.2046\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7689 - accuracy: 0.2004 - recall_5: 1.0000 - precision_5: 0.2004\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7650 - accuracy: 0.2031 - recall_5: 1.0000 - precision_5: 0.2031\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7627 - accuracy: 0.1994 - recall_5: 1.0000 - precision_5: 0.1994\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7583 - accuracy: 0.2055 - recall_5: 1.0000 - precision_5: 0.2055\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7565 - accuracy: 0.1992 - recall_5: 1.0000 - precision_5: 0.1992\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7527 - accuracy: 0.2028 - recall_5: 1.0000 - precision_5: 0.2028\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7498 - accuracy: 0.2017 - recall_5: 1.0000 - precision_5: 0.2017\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7470 - accuracy: 0.2008 - recall_5: 1.0000 - precision_5: 0.2008\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.2008 - recall_5: 1.0000 - precision_5: 0.2008\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.2040 - recall_5: 1.0000 - precision_5: 0.2040\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7380 - accuracy: 0.2034 - recall_5: 1.0000 - precision_5: 0.2034\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.2008 - recall_5: 1.0000 - precision_5: 0.2008\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7323 - accuracy: 0.2041 - recall_5: 1.0000 - precision_5: 0.2041\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7295 - accuracy: 0.2043 - recall_5: 1.0000 - precision_5: 0.2043\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7273 - accuracy: 0.2003 - recall_5: 1.0000 - precision_5: 0.2003\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7242 - accuracy: 0.2037 - recall_5: 1.0000 - precision_5: 0.2037\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7221 - accuracy: 0.1987 - recall_5: 1.0000 - precision_5: 0.1987\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7191 - accuracy: 0.2031 - recall_5: 1.0000 - precision_5: 0.2031\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7164 - accuracy: 0.2043 - recall_5: 1.0000 - precision_5: 0.2043\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7139 - accuracy: 0.2034 - recall_5: 1.0000 - precision_5: 0.2034\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7120 - accuracy: 0.2010 - recall_5: 1.0000 - precision_5: 0.201 - 0s 4ms/step - loss: 0.7115 - accuracy: 0.2024 - recall_5: 1.0000 - precision_5: 0.2024\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7088 - accuracy: 0.2051 - recall_5: 1.0000 - precision_5: 0.2051\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.2003 - recall_5: 1.0000 - precision_5: 0.2003\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7042 - accuracy: 0.2032 - recall_5: 1.0000 - precision_5: 0.2032\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7018 - accuracy: 0.2045 - recall_5: 1.0000 - precision_5: 0.2045\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.2133 - recall_5: 0.9961 - precision_5: 0.2025\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6972 - accuracy: 0.2728 - recall_5: 0.9577 - precision_5: 0.2114\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.3906 - recall_5: 0.8156 - precision_5: 0.2234\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5394 - recall_5: 0.5676 - precision_5: 0.2322\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.6643 - recall_5: 0.3154 - precision_5: 0.2458\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.7485 - recall_5: 0.1651 - precision_5: 0.2913\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.7858 - recall_5: 0.0714 - precision_5: 0.3779\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.7940 - recall_5: 0.0263 - precision_5: 0.5414\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.7973 - recall_5: 0.0071 - precision_5: 0.6563\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6797 - accuracy: 0.7991 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.7958 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.7988 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.7947 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.7979 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.8004 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.7967 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.7958 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.7985 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.7957 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.7980 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.7960 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6570 - accuracy: 0.7960 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.7957 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.7991 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.7952 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.7955 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.7989 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.7996 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6461 - accuracy: 0.7925 - recall_5: 0.0000e+00 - precision_5: 0.0000e+0 - 0s 4ms/step - loss: 0.6451 - accuracy: 0.7967 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.7960 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.7978 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7984 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.7964 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7931 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7977 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.7977 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.7938 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.7945 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.7993 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6279 - accuracy: 0.7997 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.7958 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.7993 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.7971 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.7973 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.7985 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.7948 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.8040 - recall_5: 0.0000e+00 - precision_5: 0.0000e+0 - 0s 3ms/step - loss: 0.6186 - accuracy: 0.7989 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.7994 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.7976 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.7963 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.7982 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.7960 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.7929 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7942 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.7947 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.7996 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7953 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.8019 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 6703 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65815CC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.7977 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5774 - accuracy: 0.7952 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5734 - accuracy: 0.8018 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.7974 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.7981 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7974 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.7970 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.7991 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7980 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7976 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.7989 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7969 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7968 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7984 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.8012 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7979 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7972 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.7959 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7989 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7952 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7975 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.7987 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7989 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7959 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7951 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7958 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7995 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7966 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5583 - accuracy: 0.7989 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7984 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7945 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7956 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7993 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7975 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7956 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7979 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7962 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.8015 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.7978 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7942 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.7996 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7996 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7971 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7988 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7984 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7974 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7974 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.7995 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7986 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7978 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.8010 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.7968 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7984 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7983 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7998 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.7983 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.8014 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7971 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7990 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7995 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7984 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7963 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7968 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7984 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7958 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7988 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7981 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7987 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7939 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7989 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7995 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7993 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7981 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.8006 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7973 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7968 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.8003 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7966 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7991 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7921 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7990 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7976 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7986 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.8015 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.7990 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7932 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7969 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7941 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7982 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7973 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7974 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7978 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7974 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7958 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7972 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7976 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7977 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7974 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7976 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7970 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.8003 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657C9E5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7973 - recall_6: 0.0000e+00 - precision_6: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6955 - accuracy: 0.5317 - recall_7: 0.5852 - precision_7: 0.2340\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6958 - accuracy: 0.5303 - recall_7: 0.5721 - precision_7: 0.2316\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5424 - recall_7: 0.5794 - precision_7: 0.2395\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5430 - recall_7: 0.5797 - precision_7: 0.2408\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.5457 - recall_7: 0.5711 - precision_7: 0.2428\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.5494 - recall_7: 0.5779 - precision_7: 0.2402\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5486 - recall_7: 0.5606 - precision_7: 0.2390\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5546 - recall_7: 0.5641 - precision_7: 0.2400\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5508 - recall_7: 0.5602 - precision_7: 0.2382\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.5584 - recall_7: 0.5515 - precision_7: 0.2408\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.5623 - recall_7: 0.5472 - precision_7: 0.2405\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.5709 - recall_7: 0.5421 - precision_7: 0.2441\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.5719 - recall_7: 0.5405 - precision_7: 0.2463\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.5758 - recall_7: 0.5378 - precision_7: 0.2456\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.5746 - recall_7: 0.5270 - precision_7: 0.2467\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.5826 - recall_7: 0.5280 - precision_7: 0.2484\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.5817 - recall_7: 0.5248 - precision_7: 0.2488\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.5842 - recall_7: 0.5219 - precision_7: 0.2543\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.5931 - recall_7: 0.5351 - precision_7: 0.2567\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.5942 - recall_7: 0.5159 - precision_7: 0.2576\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.5907 - recall_7: 0.5077 - precision_7: 0.2469\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.5997 - recall_7: 0.5164 - precision_7: 0.2565\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.6018 - recall_7: 0.5070 - precision_7: 0.2541\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6040 - recall_7: 0.5082 - precision_7: 0.2523\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.6014 - recall_7: 0.5008 - precision_7: 0.2556\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.6097 - recall_7: 0.4870 - precision_7: 0.2559\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.6106 - recall_7: 0.4915 - precision_7: 0.2588\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.6140 - recall_7: 0.4758 - precision_7: 0.2540\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.6106 - recall_7: 0.4725 - precision_7: 0.2499\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6552 - accuracy: 0.6185 - recall_7: 0.4836 - precision_7: 0.2588\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.6187 - recall_7: 0.4701 - precision_7: 0.2627\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.6184 - recall_7: 0.4702 - precision_7: 0.2584\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.6216 - recall_7: 0.4645 - precision_7: 0.2603\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.6265 - recall_7: 0.4582 - precision_7: 0.2629\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.6233 - recall_7: 0.4573 - precision_7: 0.2612\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.6317 - recall_7: 0.4603 - precision_7: 0.2628\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.6363 - recall_7: 0.4702 - precision_7: 0.2752\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6355 - recall_7: 0.4440 - precision_7: 0.2623\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.6429 - recall_7: 0.4404 - precision_7: 0.2657\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6407 - recall_7: 0.4561 - precision_7: 0.2677\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6418 - accuracy: 0.6439 - recall_7: 0.4490 - precision_7: 0.2682\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.6442 - recall_7: 0.4380 - precision_7: 0.2703\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6479 - recall_7: 0.4414 - precision_7: 0.2741\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6516 - recall_7: 0.4448 - precision_7: 0.2745\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6571 - recall_7: 0.4409 - precision_7: 0.2755\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6548 - recall_7: 0.4478 - precision_7: 0.2803\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6579 - recall_7: 0.4229 - precision_7: 0.2752\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.6623 - recall_7: 0.4328 - precision_7: 0.2810\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6574 - recall_7: 0.4152 - precision_7: 0.2677\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.6630 - recall_7: 0.4193 - precision_7: 0.2857\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.6678 - recall_7: 0.4274 - precision_7: 0.2810\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6623 - recall_7: 0.4034 - precision_7: 0.2744\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6719 - recall_7: 0.4234 - precision_7: 0.2871\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.6737 - recall_7: 0.4178 - precision_7: 0.2865\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.6742 - recall_7: 0.4143 - precision_7: 0.2917\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6796 - recall_7: 0.4108 - precision_7: 0.2887\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6813 - recall_7: 0.4033 - precision_7: 0.2923\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6812 - recall_7: 0.3985 - precision_7: 0.2911\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6226 - accuracy: 0.6835 - recall_7: 0.3963 - precision_7: 0.2898\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6864 - recall_7: 0.3961 - precision_7: 0.2990\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.6887 - recall_7: 0.4025 - precision_7: 0.2979\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.6884 - recall_7: 0.3874 - precision_7: 0.2861\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6871 - recall_7: 0.3819 - precision_7: 0.2954\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.6964 - recall_7: 0.3848 - precision_7: 0.3056\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6978 - recall_7: 0.3937 - precision_7: 0.3063\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.6951 - recall_7: 0.3732 - precision_7: 0.2966\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.6957 - recall_7: 0.3705 - precision_7: 0.2997\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.7002 - recall_7: 0.3800 - precision_7: 0.3054\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.7037 - recall_7: 0.3680 - precision_7: 0.3055\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.7043 - recall_7: 0.3674 - precision_7: 0.3041\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6124 - accuracy: 0.7024 - recall_7: 0.3589 - precision_7: 0.3037\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.7087 - recall_7: 0.3607 - precision_7: 0.3096\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.7092 - recall_7: 0.3598 - precision_7: 0.3045\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.7072 - recall_7: 0.3458 - precision_7: 0.3052\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7101 - recall_7: 0.3467 - precision_7: 0.3034\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.7136 - recall_7: 0.3523 - precision_7: 0.3163\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.7122 - recall_7: 0.3313 - precision_7: 0.2985\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.7158 - recall_7: 0.3436 - precision_7: 0.3195\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.7206 - recall_7: 0.3434 - precision_7: 0.3185\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.7201 - recall_7: 0.3318 - precision_7: 0.3157\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7218 - recall_7: 0.3365 - precision_7: 0.3242\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7233 - recall_7: 0.3370 - precision_7: 0.3245\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.7253 - recall_7: 0.3300 - precision_7: 0.3179\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7241 - recall_7: 0.3284 - precision_7: 0.3250\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.7236 - recall_7: 0.3230 - precision_7: 0.3120\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.7232 - recall_7: 0.3140 - precision_7: 0.3181\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.7262 - recall_7: 0.3113 - precision_7: 0.3208\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7298 - recall_7: 0.3150 - precision_7: 0.3337\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.7259 - recall_7: 0.2985 - precision_7: 0.3189\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7311 - recall_7: 0.3115 - precision_7: 0.3252\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.7362 - recall_7: 0.2988 - precision_7: 0.3283\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.7339 - recall_7: 0.3047 - precision_7: 0.3369\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.7338 - recall_7: 0.2940 - precision_7: 0.3249\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.7338 - recall_7: 0.2870 - precision_7: 0.3280\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.7417 - recall_7: 0.2758 - precision_7: 0.3213\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.7424 - recall_7: 0.2901 - precision_7: 0.3394\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7418 - recall_7: 0.2785 - precision_7: 0.3304\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7422 - recall_7: 0.2749 - precision_7: 0.3437\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.7452 - recall_7: 0.2755 - precision_7: 0.3420\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7485 - recall_7: 0.2715 - precision_7: 0.3419\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE74C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5889 - accuracy: 0.7536 - recall_7: 0.3214 - precision_7: 0.3744\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7374 - accuracy: 0.4504 - recall_8: 0.3777 - precision_8: 0.1491\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.4611 - recall_8: 0.3771 - precision_8: 0.1568\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7325 - accuracy: 0.4609 - recall_8: 0.3679 - precision_8: 0.1529\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7284 - accuracy: 0.4656 - recall_8: 0.3626 - precision_8: 0.1569\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7249 - accuracy: 0.4697 - recall_8: 0.3626 - precision_8: 0.1546\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.4741 - recall_8: 0.3412 - precision_8: 0.1481\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7183 - accuracy: 0.4779 - recall_8: 0.3366 - precision_8: 0.1505\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7146 - accuracy: 0.4873 - recall_8: 0.3467 - precision_8: 0.1555\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7127 - accuracy: 0.4882 - recall_8: 0.3308 - precision_8: 0.1529\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.4940 - recall_8: 0.3271 - precision_8: 0.1507\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.4990 - recall_8: 0.3194 - precision_8: 0.1507\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7042 - accuracy: 0.5045 - recall_8: 0.3101 - precision_8: 0.1506\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7022 - accuracy: 0.5044 - recall_8: 0.2999 - precision_8: 0.1497\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.5118 - recall_8: 0.2964 - precision_8: 0.1463\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.5225 - recall_8: 0.2927 - precision_8: 0.1463\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6937 - accuracy: 0.5226 - recall_8: 0.2769 - precision_8: 0.1459\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5302 - recall_8: 0.2816 - precision_8: 0.1487\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5400 - recall_8: 0.2785 - precision_8: 0.1542\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.5385 - recall_8: 0.2604 - precision_8: 0.1453\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.5459 - recall_8: 0.2544 - precision_8: 0.1462\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.5492 - recall_8: 0.2476 - precision_8: 0.1412\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.5546 - recall_8: 0.2427 - precision_8: 0.1430\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5661 - recall_8: 0.2465 - precision_8: 0.1500\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.5709 - recall_8: 0.2375 - precision_8: 0.1540\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.5810 - recall_8: 0.2329 - precision_8: 0.1518\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.5857 - recall_8: 0.2293 - precision_8: 0.1506\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.5890 - recall_8: 0.2158 - precision_8: 0.1494\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.5986 - recall_8: 0.2220 - precision_8: 0.1572\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6013 - recall_8: 0.2154 - precision_8: 0.1518\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.6072 - recall_8: 0.2082 - precision_8: 0.1540\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.6187 - recall_8: 0.2034 - precision_8: 0.1544\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.6238 - recall_8: 0.2049 - precision_8: 0.1592\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.6232 - recall_8: 0.1984 - precision_8: 0.1591\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6321 - recall_8: 0.1998 - precision_8: 0.1642\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.6369 - recall_8: 0.1910 - precision_8: 0.1609\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.6474 - recall_8: 0.1835 - precision_8: 0.1668\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6528 - recall_8: 0.1931 - precision_8: 0.1697\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.6563 - recall_8: 0.1800 - precision_8: 0.1633\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.6562 - recall_8: 0.1755 - precision_8: 0.1693\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6652 - recall_8: 0.1740 - precision_8: 0.1715\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6703 - recall_8: 0.1620 - precision_8: 0.1690\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6734 - recall_8: 0.1621 - precision_8: 0.1793\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.6794 - recall_8: 0.1630 - precision_8: 0.1778\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.6834 - recall_8: 0.1511 - precision_8: 0.1730\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6900 - recall_8: 0.1514 - precision_8: 0.1841\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.6938 - recall_8: 0.1469 - precision_8: 0.1824\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.6956 - recall_8: 0.1304 - precision_8: 0.1699\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.7008 - recall_8: 0.1369 - precision_8: 0.1822\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.7062 - recall_8: 0.1311 - precision_8: 0.1885\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.7100 - recall_8: 0.1301 - precision_8: 0.1892\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.7172 - recall_8: 0.1157 - precision_8: 0.1808\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.7158 - recall_8: 0.1148 - precision_8: 0.1846\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.7234 - recall_8: 0.1085 - precision_8: 0.1865\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.7293 - recall_8: 0.0999 - precision_8: 0.1849\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.7299 - recall_8: 0.1005 - precision_8: 0.1879\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.7330 - recall_8: 0.0946 - precision_8: 0.1877\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.7344 - recall_8: 0.0862 - precision_8: 0.1766\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.7378 - recall_8: 0.0852 - precision_8: 0.1824\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.7441 - recall_8: 0.0840 - precision_8: 0.1915\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.7423 - recall_8: 0.0797 - precision_8: 0.1922\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7471 - recall_8: 0.0730 - precision_8: 0.1859\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.7520 - recall_8: 0.0744 - precision_8: 0.2025\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.7561 - recall_8: 0.0698 - precision_8: 0.1965\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.7535 - recall_8: 0.0642 - precision_8: 0.1945\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.7575 - recall_8: 0.0568 - precision_8: 0.1788\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7594 - recall_8: 0.0628 - precision_8: 0.1986\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7603 - recall_8: 0.0607 - precision_8: 0.2049\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5913 - accuracy: 0.7565 - recall_8: 0.0510 - precision_8: 0.179 - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7611 - recall_8: 0.0539 - precision_8: 0.1930\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7669 - recall_8: 0.0506 - precision_8: 0.1943\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7683 - recall_8: 0.0502 - precision_8: 0.1911\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7678 - recall_8: 0.0463 - precision_8: 0.1969\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7670 - recall_8: 0.0423 - precision_8: 0.1868\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.7697 - recall_8: 0.0430 - precision_8: 0.1934\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.7730 - recall_8: 0.0399 - precision_8: 0.1982\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7746 - recall_8: 0.0417 - precision_8: 0.2044\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7712 - recall_8: 0.0401 - precision_8: 0.2025\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7774 - recall_8: 0.0374 - precision_8: 0.2034\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7801 - recall_8: 0.0386 - precision_8: 0.2049\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7799 - recall_8: 0.0354 - precision_8: 0.2082\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.7760 - recall_8: 0.0322 - precision_8: 0.1880\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5697 - accuracy: 0.7818 - recall_8: 0.0330 - precision_8: 0.2083\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7817 - recall_8: 0.0361 - precision_8: 0.2246\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.7852 - recall_8: 0.0341 - precision_8: 0.2162\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7827 - recall_8: 0.0335 - precision_8: 0.2352\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7817 - recall_8: 0.0279 - precision_8: 0.2155\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7822 - recall_8: 0.0309 - precision_8: 0.2336\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7822 - recall_8: 0.0288 - precision_8: 0.2298\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7876 - recall_8: 0.0334 - precision_8: 0.2682\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7847 - recall_8: 0.0283 - precision_8: 0.2487\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7860 - recall_8: 0.0286 - precision_8: 0.2476\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7860 - recall_8: 0.0241 - precision_8: 0.2322\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7807 - recall_8: 0.0223 - precision_8: 0.2182\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7885 - recall_8: 0.0209 - precision_8: 0.2135\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7842 - recall_8: 0.0204 - precision_8: 0.2243\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5540 - accuracy: 0.7891 - recall_8: 0.0218 - precision_8: 0.2320\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.7896 - recall_8: 0.0234 - precision_8: 0.2481\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7880 - recall_8: 0.0183 - precision_8: 0.2333\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7888 - recall_8: 0.0204 - precision_8: 0.2383\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7884 - recall_8: 0.0181 - precision_8: 0.2294\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7867 - recall_8: 0.0203 - precision_8: 0.2635\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FBDDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5528 - accuracy: 0.7904 - recall_8: 0.0254 - precision_8: 0.2927\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7862 - accuracy: 0.4149 - recall_9: 0.3352 - precision_9: 0.1328\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7845 - accuracy: 0.4170 - recall_9: 0.3368 - precision_9: 0.1361\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7821 - accuracy: 0.4199 - recall_9: 0.3356 - precision_9: 0.1294\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7806 - accuracy: 0.4206 - recall_9: 0.3345 - precision_9: 0.1316\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7784 - accuracy: 0.4254 - recall_9: 0.3326 - precision_9: 0.1328\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7759 - accuracy: 0.4264 - recall_9: 0.3289 - precision_9: 0.1331\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7760 - accuracy: 0.4231 - recall_9: 0.3200 - precision_9: 0.1281\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7745 - accuracy: 0.4257 - recall_9: 0.3223 - precision_9: 0.1320\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7750 - accuracy: 0.4226 - recall_9: 0.3209 - precision_9: 0.1307\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7714 - accuracy: 0.4292 - recall_9: 0.3225 - precision_9: 0.1326\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7718 - accuracy: 0.4250 - recall_9: 0.3099 - precision_9: 0.1266\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7673 - accuracy: 0.4351 - recall_9: 0.3226 - precision_9: 0.1335\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7686 - accuracy: 0.4292 - recall_9: 0.3103 - precision_9: 0.1254\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7663 - accuracy: 0.4357 - recall_9: 0.3103 - precision_9: 0.1297\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7636 - accuracy: 0.4359 - recall_9: 0.3094 - precision_9: 0.1316\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7627 - accuracy: 0.4412 - recall_9: 0.3088 - precision_9: 0.1289\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7633 - accuracy: 0.4372 - recall_9: 0.3009 - precision_9: 0.1251\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7614 - accuracy: 0.4401 - recall_9: 0.3116 - precision_9: 0.1343\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7588 - accuracy: 0.4410 - recall_9: 0.3100 - precision_9: 0.1279\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7587 - accuracy: 0.4402 - recall_9: 0.2947 - precision_9: 0.1250\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7585 - accuracy: 0.4418 - recall_9: 0.3013 - precision_9: 0.1266\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7580 - accuracy: 0.4420 - recall_9: 0.2938 - precision_9: 0.1256\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7548 - accuracy: 0.4460 - recall_9: 0.3034 - precision_9: 0.1301\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7527 - accuracy: 0.4496 - recall_9: 0.2977 - precision_9: 0.1278\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7533 - accuracy: 0.4461 - recall_9: 0.2907 - precision_9: 0.1237\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7521 - accuracy: 0.4447 - recall_9: 0.2942 - precision_9: 0.1240\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7522 - accuracy: 0.4433 - recall_9: 0.2890 - precision_9: 0.1250\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.4527 - recall_9: 0.3004 - precision_9: 0.1291\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7469 - accuracy: 0.4519 - recall_9: 0.3010 - precision_9: 0.1280\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7487 - accuracy: 0.4513 - recall_9: 0.2963 - precision_9: 0.1280\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7470 - accuracy: 0.4522 - recall_9: 0.2954 - precision_9: 0.1299\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7454 - accuracy: 0.4558 - recall_9: 0.2927 - precision_9: 0.1277\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.4589 - recall_9: 0.2939 - precision_9: 0.1308\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.4626 - recall_9: 0.2868 - precision_9: 0.1259\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.4571 - recall_9: 0.2847 - precision_9: 0.1267\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.4585 - recall_9: 0.2801 - precision_9: 0.1259\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7408 - accuracy: 0.4600 - recall_9: 0.2765 - precision_9: 0.1208\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.4607 - recall_9: 0.2814 - precision_9: 0.1291\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.4667 - recall_9: 0.2782 - precision_9: 0.1251\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7366 - accuracy: 0.4673 - recall_9: 0.2765 - precision_9: 0.1256\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.4685 - recall_9: 0.2750 - precision_9: 0.1267\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7349 - accuracy: 0.4659 - recall_9: 0.2665 - precision_9: 0.1273\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7349 - accuracy: 0.4666 - recall_9: 0.2636 - precision_9: 0.1212\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7325 - accuracy: 0.4707 - recall_9: 0.2691 - precision_9: 0.1270\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.4693 - recall_9: 0.2610 - precision_9: 0.1190\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7310 - accuracy: 0.4706 - recall_9: 0.2584 - precision_9: 0.1209\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7299 - accuracy: 0.4708 - recall_9: 0.2568 - precision_9: 0.1219\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7291 - accuracy: 0.4698 - recall_9: 0.2553 - precision_9: 0.1195\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7297 - accuracy: 0.4697 - recall_9: 0.2484 - precision_9: 0.1174\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7241 - accuracy: 0.4814 - recall_9: 0.2558 - precision_9: 0.1246\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7269 - accuracy: 0.4741 - recall_9: 0.2600 - precision_9: 0.1231\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7238 - accuracy: 0.4793 - recall_9: 0.2539 - precision_9: 0.1231\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7236 - accuracy: 0.4810 - recall_9: 0.2566 - precision_9: 0.1240\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7220 - accuracy: 0.4807 - recall_9: 0.2494 - precision_9: 0.1189\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7212 - accuracy: 0.4802 - recall_9: 0.2527 - precision_9: 0.1233\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7196 - accuracy: 0.4839 - recall_9: 0.2541 - precision_9: 0.1247\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7190 - accuracy: 0.4853 - recall_9: 0.2485 - precision_9: 0.1195\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7165 - accuracy: 0.4890 - recall_9: 0.2547 - precision_9: 0.1266\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7179 - accuracy: 0.4880 - recall_9: 0.2462 - precision_9: 0.1233\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7158 - accuracy: 0.4861 - recall_9: 0.2499 - precision_9: 0.1224\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7159 - accuracy: 0.4895 - recall_9: 0.2404 - precision_9: 0.1185\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7157 - accuracy: 0.4904 - recall_9: 0.2495 - precision_9: 0.1244\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7144 - accuracy: 0.4941 - recall_9: 0.2388 - precision_9: 0.1221\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.4943 - recall_9: 0.2411 - precision_9: 0.1204\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7118 - accuracy: 0.4953 - recall_9: 0.2420 - precision_9: 0.1242\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7115 - accuracy: 0.4968 - recall_9: 0.2466 - precision_9: 0.1272\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7095 - accuracy: 0.5006 - recall_9: 0.2436 - precision_9: 0.1265\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7087 - accuracy: 0.5024 - recall_9: 0.2457 - precision_9: 0.1255\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7070 - accuracy: 0.5017 - recall_9: 0.2350 - precision_9: 0.1213\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7062 - accuracy: 0.5028 - recall_9: 0.2441 - precision_9: 0.1249\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7059 - accuracy: 0.5055 - recall_9: 0.2352 - precision_9: 0.1223\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.5007 - recall_9: 0.2202 - precision_9: 0.1149\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.5033 - recall_9: 0.2210 - precision_9: 0.1147\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.5062 - recall_9: 0.2329 - precision_9: 0.1228\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7018 - accuracy: 0.5089 - recall_9: 0.2296 - precision_9: 0.1222\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7030 - accuracy: 0.5064 - recall_9: 0.2181 - precision_9: 0.1197\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7015 - accuracy: 0.5110 - recall_9: 0.2205 - precision_9: 0.1189\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7012 - accuracy: 0.5074 - recall_9: 0.2207 - precision_9: 0.1179\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6985 - accuracy: 0.5144 - recall_9: 0.2239 - precision_9: 0.1218\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6993 - accuracy: 0.5122 - recall_9: 0.2142 - precision_9: 0.1166\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.5199 - recall_9: 0.2247 - precision_9: 0.1240\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.5192 - recall_9: 0.2141 - precision_9: 0.1183\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.5143 - recall_9: 0.2088 - precision_9: 0.1155\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6967 - accuracy: 0.5150 - recall_9: 0.2158 - precision_9: 0.1211\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5226 - recall_9: 0.2098 - precision_9: 0.1172\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.5207 - recall_9: 0.2139 - precision_9: 0.1214\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.5226 - recall_9: 0.2087 - precision_9: 0.1162\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.5278 - recall_9: 0.2066 - precision_9: 0.1184\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6891 - accuracy: 0.5324 - recall_9: 0.2025 - precision_9: 0.1167\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5273 - recall_9: 0.2058 - precision_9: 0.1184\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5330 - recall_9: 0.2068 - precision_9: 0.1191\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.5319 - recall_9: 0.2019 - precision_9: 0.1182\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5347 - recall_9: 0.1982 - precision_9: 0.1159\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.5358 - recall_9: 0.1969 - precision_9: 0.1168\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5369 - recall_9: 0.1911 - precision_9: 0.1144\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.5381 - recall_9: 0.1947 - precision_9: 0.1181\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.5393 - recall_9: 0.1905 - precision_9: 0.1171\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.5374 - recall_9: 0.1873 - precision_9: 0.1149\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.5374 - recall_9: 0.1904 - precision_9: 0.1138\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.5383 - recall_9: 0.1836 - precision_9: 0.1126\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE75E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6760 - accuracy: 0.5559 - recall_9: 0.1882 - precision_9: 0.1201\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5802 - accuracy: 0.7971 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.7965 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.7967 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.7945 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7991 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7987 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7987 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7950 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7950 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7982 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7992 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7966 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7979 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.8014 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7967 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7989 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7955 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7986 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7974 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7985 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7990 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.8027 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7972 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7951 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7949 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7997 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.7944 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7971 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7954 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7989 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7979 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7955 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.8002 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7968 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7977 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7957 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7981 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.7954 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7999 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7954 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7989 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7990 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7952 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7948 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7980 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.8027 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.7972 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7981 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.8019 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7999 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7979 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7991 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7997 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7984 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7977 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.8005 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7984 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7982 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7953 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7980 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7996 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7968 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.8032 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7992 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7983 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7977 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7972 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7980 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7953 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7982 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7969 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7950 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.8003 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7994 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7980 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7975 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7977 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7995 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7994 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7937 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7999 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7969 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7975 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7949 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7992 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7995 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7931 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7967 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7990 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7966 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7987 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7975 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7942 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7935 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7949 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7945 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.8002 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7968 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7959 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.8005 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C2501F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.7973 - recall_10: 0.0000e+00 - precision_10: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6733 - accuracy: 0.6881 - recall_11: 0.3883 - precision_11: 0.2930\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.6986 - recall_11: 0.3227 - precision_11: 0.2791\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.7143 - recall_11: 0.2897 - precision_11: 0.2890\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.7310 - recall_11: 0.2685 - precision_11: 0.3038\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.7430 - recall_11: 0.2315 - precision_11: 0.3070\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.7490 - recall_11: 0.1853 - precision_11: 0.3087\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6608 - accuracy: 0.7534 - recall_11: 0.1554 - precision_11: 0.2882\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.7655 - recall_11: 0.1374 - precision_11: 0.3182\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.7706 - recall_11: 0.1120 - precision_11: 0.3035\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.7710 - recall_11: 0.0921 - precision_11: 0.3196\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.7847 - recall_11: 0.0799 - precision_11: 0.3308\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.7864 - recall_11: 0.0718 - precision_11: 0.3831\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.7895 - recall_11: 0.0573 - precision_11: 0.3576\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.7913 - recall_11: 0.0430 - precision_11: 0.3548\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.7910 - recall_11: 0.0368 - precision_11: 0.3475\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.7907 - recall_11: 0.0292 - precision_11: 0.3627\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.7897 - recall_11: 0.0248 - precision_11: 0.3632\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7944 - recall_11: 0.0192 - precision_11: 0.4063\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.8012 - recall_11: 0.0200 - precision_11: 0.4645\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.7964 - recall_11: 0.0142 - precision_11: 0.4593\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.7951 - recall_11: 0.0079 - precision_11: 0.4866\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7942 - recall_11: 0.0059 - precision_11: 0.4375\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.7976 - recall_11: 0.0022 - precision_11: 0.2708    \n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.7991 - recall_11: 0.0038 - precision_11: 0.6042\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7985 - recall_11: 0.0028 - precision_11: 0.4750\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.7969 - recall_11: 0.0037 - precision_11: 0.6167\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.7987 - recall_11: 0.0019 - precision_11: 0.4250    \n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.7945 - recall_11: 8.3416e-04 - precision_11: 0.2917\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.7983 - recall_11: 8.3604e-04 - precision_11: 0.3750\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.7980 - recall_11: 0.0015 - precision_11: 0.6250\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6178 - accuracy: 0.7998 - recall_11: 8.4026e-04 - precision_11: 0.7500\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.7972 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.7955 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.7955 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.7942 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.7966 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.7968 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.7947 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7952 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6069 - accuracy: 0.7937 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.7962 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.7955 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.7987 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.7971 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.7982 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7950 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7999 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7975 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.7985 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7962 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.7953 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.8019 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.7979 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.7967 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7958 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.7971 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.7978 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.7937 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.7957 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7959 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7947 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7974 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.8003 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7975 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7975 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.7985 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7939 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7984 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7987 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7965 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.7972 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.8015 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7954 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.7967 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7967 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7967 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7955 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7980 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7984 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7969 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7960 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7964 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7954 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7987 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7950 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7950 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7989 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7955 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.7984 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.7963 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7958 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.7982 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7955 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7993 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7971 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7964 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7985 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.8015 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7912 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7976 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657F8D1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7977 - recall_11: 0.0000e+00 - precision_11: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5313 - accuracy: 0.7953 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7993 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7959 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7935 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7979 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7963 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7965 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7993 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7984 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7946 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8000 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7966 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.8008 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7981 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7999 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7971 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7953 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7981 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7995 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7971 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7971 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7970 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.8001 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7973 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7934 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.8024 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7934 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7961 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7961 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7984 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7973 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7941 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7948 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7965 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7997 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7982 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7930 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7961 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7978 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7963 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7960 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7979 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7959 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.8001 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7998 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7993 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7983 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7964 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7979 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7969 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7997 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7974 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.8005 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7972 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7974 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7948 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7966 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7956 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7981 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7972 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7969 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7969 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7970 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7995 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7966 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7959 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7959 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7962 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7983 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7961 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7975 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7984 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7965 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7976 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7994 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.8004 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7951 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7932 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7999 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7965 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7993 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7948 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7958 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7958 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7989 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7937 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.8002 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7971 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.8003 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.8013 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7997 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7992 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.8011 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7973 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7999 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7980 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7959 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7977 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7994 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7988 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FBD700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7973 - recall_12: 0.0000e+00 - precision_12: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7116 - accuracy: 0.4510 - recall_13: 0.3487 - precision_13: 0.1432\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7069 - accuracy: 0.4627 - recall_13: 0.3272 - precision_13: 0.1421\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.4903 - recall_13: 0.2986 - precision_13: 0.1417\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5099 - recall_13: 0.2612 - precision_13: 0.1373\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.5375 - recall_13: 0.2279 - precision_13: 0.1319\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.5600 - recall_13: 0.1978 - precision_13: 0.1303\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.5796 - recall_13: 0.1699 - precision_13: 0.1201\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.6054 - recall_13: 0.1459 - precision_13: 0.1161\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.6276 - recall_13: 0.1313 - precision_13: 0.1223\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.6502 - recall_13: 0.1148 - precision_13: 0.1176\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6543 - accuracy: 0.6618 - recall_13: 0.0897 - precision_13: 0.1035\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.6805 - recall_13: 0.0789 - precision_13: 0.1080\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.6988 - recall_13: 0.0615 - precision_13: 0.1036\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.7126 - recall_13: 0.0443 - precision_13: 0.0869\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7237 - recall_13: 0.0356 - precision_13: 0.0814\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6299 - accuracy: 0.7435 - recall_13: 0.0344 - precision_13: 0.104 - 0s 3ms/step - loss: 0.6309 - accuracy: 0.7409 - recall_13: 0.0325 - precision_13: 0.0952\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7525 - recall_13: 0.0235 - precision_13: 0.0883\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.7595 - recall_13: 0.0169 - precision_13: 0.0769\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.7679 - recall_13: 0.0086 - precision_13: 0.0501\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.7766 - recall_13: 0.0069 - precision_13: 0.0533\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.7814 - recall_13: 0.0078 - precision_13: 0.0744\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.7841 - recall_13: 0.0048 - precision_13: 0.0651\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.7875 - recall_13: 0.0060 - precision_13: 0.1004\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7912 - recall_13: 0.0059 - precision_13: 0.1187\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.7910 - recall_13: 0.0022 - precision_13: 0.0685    \n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5938 - accuracy: 0.7940 - recall_13: 0.0031 - precision_13: 0.1297\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7944 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5877 - accuracy: 0.7960 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7972 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7941 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7976 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.7987 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.8000 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5698 - accuracy: 0.7991 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.8014 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.7903 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.7993 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7959 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7962 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7980 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7932 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.7979 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7987 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5466 - accuracy: 0.7988 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7984 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7995 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7984 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.8001 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7952 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7958 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7985 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.8002 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7959 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7986 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7964 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7984 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7978 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7964 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7998 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7981 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.8022 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7977 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7990 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7991 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7989 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7996 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7984 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7962 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7947 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7975 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7969 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.8007 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7957 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.8005 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.8007 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7975 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7945 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7968 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.8007 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7975 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7950 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7974 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7948 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7934 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7970 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7960 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7962 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7988 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7973 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7929 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7975 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7992 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7987 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7979 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7947 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7940 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7958 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7973 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7963 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7982 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE70D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7973 - recall_13: 0.0000e+00 - precision_13: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7540 - accuracy: 0.4651 - recall_14: 0.4138 - precision_14: 0.1689\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7380 - accuracy: 0.4803 - recall_14: 0.4042 - precision_14: 0.1735\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7254 - accuracy: 0.4925 - recall_14: 0.3884 - precision_14: 0.1712\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7100 - accuracy: 0.5117 - recall_14: 0.3789 - precision_14: 0.1724\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6980 - accuracy: 0.5353 - recall_14: 0.3725 - precision_14: 0.1806\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5582 - recall_14: 0.3708 - precision_14: 0.1916\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.5733 - recall_14: 0.3501 - precision_14: 0.1957\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.5861 - recall_14: 0.3220 - precision_14: 0.1940\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.6028 - recall_14: 0.3136 - precision_14: 0.2000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.6229 - recall_14: 0.2946 - precision_14: 0.2034\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6430 - recall_14: 0.2867 - precision_14: 0.2151\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6503 - recall_14: 0.2482 - precision_14: 0.2015\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.6650 - recall_14: 0.2361 - precision_14: 0.2123\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.6868 - recall_14: 0.2302 - precision_14: 0.2228\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.6948 - recall_14: 0.2089 - precision_14: 0.2272\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7124 - recall_14: 0.2009 - precision_14: 0.2451\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.7216 - recall_14: 0.1838 - precision_14: 0.2444\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7296 - recall_14: 0.1613 - precision_14: 0.2377\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7346 - recall_14: 0.1497 - precision_14: 0.2482\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.7440 - recall_14: 0.1408 - precision_14: 0.2625\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7536 - recall_14: 0.1328 - precision_14: 0.2753\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7596 - recall_14: 0.1217 - precision_14: 0.2852\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7624 - recall_14: 0.1185 - precision_14: 0.2954\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.7683 - recall_14: 0.1124 - precision_14: 0.3197\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7735 - recall_14: 0.1002 - precision_14: 0.3177\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7787 - recall_14: 0.0937 - precision_14: 0.3258\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7783 - recall_14: 0.0878 - precision_14: 0.3334\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7821 - recall_14: 0.0764 - precision_14: 0.3302\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7844 - recall_14: 0.0803 - precision_14: 0.3776\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7890 - recall_14: 0.0768 - precision_14: 0.4080\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7947 - recall_14: 0.0742 - precision_14: 0.4173\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7906 - recall_14: 0.0645 - precision_14: 0.3951\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7955 - recall_14: 0.0692 - precision_14: 0.4447\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7970 - recall_14: 0.0637 - precision_14: 0.5177\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7983 - recall_14: 0.0579 - precision_14: 0.4590\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7973 - recall_14: 0.0600 - precision_14: 0.5094\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.8012 - recall_14: 0.0565 - precision_14: 0.5302\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7998 - recall_14: 0.0559 - precision_14: 0.5093\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7992 - recall_14: 0.0564 - precision_14: 0.5283\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.8042 - recall_14: 0.0570 - precision_14: 0.5760\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.8006 - recall_14: 0.0513 - precision_14: 0.5524\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7972 - recall_14: 0.0520 - precision_14: 0.5687\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.8036 - recall_14: 0.0543 - precision_14: 0.6607\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.8010 - recall_14: 0.0508 - precision_14: 0.6166\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.8024 - recall_14: 0.0575 - precision_14: 0.6805\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.8029 - recall_14: 0.0589 - precision_14: 0.6958\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.8037 - recall_14: 0.0528 - precision_14: 0.6583\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.8015 - recall_14: 0.0558 - precision_14: 0.6929\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7990 - recall_14: 0.0518 - precision_14: 0.6577\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.8053 - recall_14: 0.0635 - precision_14: 0.6990\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.8014 - recall_14: 0.0559 - precision_14: 0.6589\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.8054 - recall_14: 0.0592 - precision_14: 0.6679\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.8044 - recall_14: 0.0625 - precision_14: 0.7036\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.8070 - recall_14: 0.0599 - precision_14: 0.6716\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8037 - recall_14: 0.0620 - precision_14: 0.6722\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.8030 - recall_14: 0.0605 - precision_14: 0.6853\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.8055 - recall_14: 0.0614 - precision_14: 0.6739\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.8065 - recall_14: 0.0656 - precision_14: 0.7029\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.8007 - recall_14: 0.0736 - precision_14: 0.7341\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.8047 - recall_14: 0.0694 - precision_14: 0.6937\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.8044 - recall_14: 0.0735 - precision_14: 0.6966\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.8063 - recall_14: 0.0701 - precision_14: 0.6874\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.8061 - recall_14: 0.0708 - precision_14: 0.6944\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.8056 - recall_14: 0.0720 - precision_14: 0.7053\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.8058 - recall_14: 0.0712 - precision_14: 0.6919\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.8061 - recall_14: 0.0752 - precision_14: 0.7022\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.8045 - recall_14: 0.0761 - precision_14: 0.7099\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.8085 - recall_14: 0.0780 - precision_14: 0.7221\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.8089 - recall_14: 0.0794 - precision_14: 0.7377\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.8060 - recall_14: 0.0828 - precision_14: 0.7102\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.8074 - recall_14: 0.0777 - precision_14: 0.7021\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.8052 - recall_14: 0.0774 - precision_14: 0.7290\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.8100 - recall_14: 0.0839 - precision_14: 0.7287\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.8087 - recall_14: 0.0850 - precision_14: 0.7304\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.8086 - recall_14: 0.0833 - precision_14: 0.7194\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.8076 - recall_14: 0.0875 - precision_14: 0.7057\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.8093 - recall_14: 0.0865 - precision_14: 0.6953\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.8041 - recall_14: 0.0855 - precision_14: 0.6755\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.8094 - recall_14: 0.0879 - precision_14: 0.6861\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.8073 - recall_14: 0.0872 - precision_14: 0.7116\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.8081 - recall_14: 0.0912 - precision_14: 0.6937\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8104 - recall_14: 0.0936 - precision_14: 0.7131\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8100 - recall_14: 0.0980 - precision_14: 0.7089\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8076 - recall_14: 0.0940 - precision_14: 0.6927\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.8035 - recall_14: 0.0954 - precision_14: 0.6715\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8044 - recall_14: 0.0905 - precision_14: 0.6224\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.8068 - recall_14: 0.0930 - precision_14: 0.6661\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8051 - recall_14: 0.0948 - precision_14: 0.6713\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.8031 - recall_14: 0.0968 - precision_14: 0.6473\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8065 - recall_14: 0.0969 - precision_14: 0.6760\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.8037 - recall_14: 0.0929 - precision_14: 0.6464\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8037 - recall_14: 0.0956 - precision_14: 0.6507\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8083 - recall_14: 0.0981 - precision_14: 0.6637\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8051 - recall_14: 0.1045 - precision_14: 0.6535\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.8043 - recall_14: 0.0982 - precision_14: 0.6317\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8051 - recall_14: 0.1073 - precision_14: 0.6436\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.8099 - recall_14: 0.1085 - precision_14: 0.6625\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.8067 - recall_14: 0.1115 - precision_14: 0.6729\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8100 - recall_14: 0.1103 - precision_14: 0.6625\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8062 - recall_14: 0.1092 - precision_14: 0.6488\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65536F940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8127 - recall_14: 0.1123 - precision_14: 0.7465\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.0020 - accuracy: 0.4080 - recall_15: 0.2668 - precision_15: 0.1080\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9816 - accuracy: 0.4158 - recall_15: 0.2635 - precision_15: 0.1104\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9580 - accuracy: 0.4223 - recall_15: 0.2486 - precision_15: 0.1077\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9265 - accuracy: 0.4387 - recall_15: 0.2244 - precision_15: 0.0994\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9051 - accuracy: 0.4446 - recall_15: 0.2133 - precision_15: 0.0967\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8920 - accuracy: 0.4458 - recall_15: 0.2041 - precision_15: 0.0955\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8708 - accuracy: 0.4609 - recall_15: 0.1992 - precision_15: 0.0964\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8451 - accuracy: 0.4811 - recall_15: 0.2034 - precision_15: 0.1019\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8320 - accuracy: 0.4849 - recall_15: 0.1865 - precision_15: 0.0961\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8186 - accuracy: 0.4949 - recall_15: 0.1826 - precision_15: 0.1017\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7976 - accuracy: 0.5116 - recall_15: 0.1740 - precision_15: 0.0978\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7876 - accuracy: 0.5188 - recall_15: 0.1589 - precision_15: 0.0946\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7733 - accuracy: 0.5292 - recall_15: 0.1611 - precision_15: 0.0980\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7582 - accuracy: 0.5392 - recall_15: 0.1481 - precision_15: 0.0935\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7499 - accuracy: 0.5495 - recall_15: 0.1356 - precision_15: 0.0917\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.5574 - recall_15: 0.1276 - precision_15: 0.0898\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7247 - accuracy: 0.5722 - recall_15: 0.1174 - precision_15: 0.0859\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7070 - accuracy: 0.5922 - recall_15: 0.1233 - precision_15: 0.0950\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7077 - accuracy: 0.5937 - recall_15: 0.1060 - precision_15: 0.0892\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6956 - accuracy: 0.6108 - recall_15: 0.1090 - precision_15: 0.0953\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.6156 - recall_15: 0.0986 - precision_15: 0.0896\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.6216 - recall_15: 0.0854 - precision_15: 0.0826\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.6311 - recall_15: 0.0837 - precision_15: 0.0838\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.6409 - recall_15: 0.0753 - precision_15: 0.0820\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.6473 - recall_15: 0.0741 - precision_15: 0.0857\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6528 - accuracy: 0.6615 - recall_15: 0.0656 - precision_15: 0.0812\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6702 - recall_15: 0.0607 - precision_15: 0.0822\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.6828 - recall_15: 0.0586 - precision_15: 0.0880\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.6933 - recall_15: 0.0573 - precision_15: 0.0912\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.6977 - recall_15: 0.0526 - precision_15: 0.0884\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.7072 - recall_15: 0.0471 - precision_15: 0.0844\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.7113 - recall_15: 0.0453 - precision_15: 0.0876\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.7180 - recall_15: 0.0444 - precision_15: 0.0911\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.7217 - recall_15: 0.0415 - precision_15: 0.0899\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.7275 - recall_15: 0.0373 - precision_15: 0.0890\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.7326 - recall_15: 0.0377 - precision_15: 0.0924\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7384 - recall_15: 0.0392 - precision_15: 0.1095\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.7442 - recall_15: 0.0334 - precision_15: 0.0988\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7478 - recall_15: 0.0374 - precision_15: 0.1179\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.7481 - recall_15: 0.0308 - precision_15: 0.1032\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7543 - recall_15: 0.0292 - precision_15: 0.1054\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.7611 - recall_15: 0.0274 - precision_15: 0.1126\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.7635 - recall_15: 0.0259 - precision_15: 0.1202\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.7632 - recall_15: 0.0245 - precision_15: 0.1145\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7702 - recall_15: 0.0224 - precision_15: 0.1120\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7706 - recall_15: 0.0144 - precision_15: 0.0852\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7728 - recall_15: 0.0186 - precision_15: 0.1187\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7728 - recall_15: 0.0193 - precision_15: 0.1206\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7773 - recall_15: 0.0144 - precision_15: 0.1039\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7757 - recall_15: 0.0104 - precision_15: 0.0822\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.7762 - recall_15: 0.0084 - precision_15: 0.0722\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7801 - recall_15: 0.0086 - precision_15: 0.0801\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7791 - recall_15: 0.0056 - precision_15: 0.0550\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7819 - recall_15: 0.0055 - precision_15: 0.0559\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7839 - recall_15: 0.0049 - precision_15: 0.0563\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7882 - recall_15: 0.0061 - precision_15: 0.0886\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7869 - recall_15: 0.0048 - precision_15: 0.0688\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7838 - recall_15: 0.0045 - precision_15: 0.0699\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7902 - recall_15: 0.0053 - precision_15: 0.0902\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7876 - recall_15: 0.0014 - precision_15: 0.0326    \n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7902 - recall_15: 0.0023 - precision_15: 0.0579\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7944 - recall_15: 0.0014 - precision_15: 0.0375    \n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7934 - recall_15: 0.0023 - precision_15: 0.0690\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7917 - recall_15: 0.0014 - precision_15: 0.0525    \n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7964 - recall_15: 0.0023 - precision_15: 0.1050\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7944 - recall_15: 0.0020 - precision_15: 0.1197\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7956 - recall_15: 0.0023 - precision_15: 0.1524\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5256 - accuracy: 0.7947 - recall_15: 0.0029 - precision_15: 0.1500\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7945 - recall_15: 0.0023 - precision_15: 0.1528\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7957 - recall_15: 0.0020 - precision_15: 0.2020\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7971 - recall_15: 0.0023 - precision_15: 0.3159\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7961 - recall_15: 0.0023 - precision_15: 0.2248\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7951 - recall_15: 0.0020 - precision_15: 0.1516\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7953 - recall_15: 0.0029 - precision_15: 0.2659\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7948 - recall_15: 0.0023 - precision_15: 0.2181\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7987 - recall_15: 0.0023 - precision_15: 0.1917\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7969 - recall_15: 0.0023 - precision_15: 0.1917\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7917 - recall_15: 0.0022 - precision_15: 0.2125\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7967 - recall_15: 0.0023 - precision_15: 0.2361\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7924 - recall_15: 0.0019 - precision_15: 0.2345\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7962 - recall_15: 0.0017 - precision_15: 0.2262    \n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7941 - recall_15: 0.0020 - precision_15: 0.3179\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7994 - recall_15: 0.0017 - precision_15: 0.2429    \n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7977 - recall_15: 0.0020 - precision_15: 0.2470\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5044 - accuracy: 0.7987 - recall_15: 0.0023 - precision_15: 0.2643\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7948 - recall_15: 0.0020 - precision_15: 0.2167\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7950 - recall_15: 0.0020 - precision_15: 0.4250\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7966 - recall_15: 0.0014 - precision_15: 0.1845    \n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.8012 - recall_15: 8.4476e-04 - precision_15: 0.1500\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7964 - recall_15: 0.0029 - precision_15: 0.4167\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7962 - recall_15: 0.0023 - precision_15: 0.3917\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7998 - recall_15: 0.0025 - precision_15: 0.3214    \n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7942 - recall_15: 0.0037 - precision_15: 0.4214\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7980 - recall_15: 0.0031 - precision_15: 0.3646\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7972 - recall_15: 0.0022 - precision_15: 0.2589    \n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7973 - recall_15: 0.0031 - precision_15: 0.3780\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7988 - recall_15: 0.0038 - precision_15: 0.4271\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7999 - recall_15: 0.0022 - precision_15: 0.2292    \n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7983 - recall_15: 0.0028 - precision_15: 0.2958\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7971 - recall_15: 0.0022 - precision_15: 0.2125    \n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FBDF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7964 - recall_15: 0.0085 - precision_15: 0.4000\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6195 - accuracy: 0.8000 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.7970 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.7930 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6140 - accuracy: 0.7965 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.7967 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6101 - accuracy: 0.7961 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.7964 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.7977 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.7974 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.7983 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7983 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7994 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.7987 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.7972 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.7989 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.8021 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.7959 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.7955 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.7979 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7969 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.7997 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.8009 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.7980 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.7993 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.8002 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.7958 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.7987 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5740 - accuracy: 0.7989 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.7960 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.7956 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7999 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5698 - accuracy: 0.7975 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7977 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7953 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5659 - accuracy: 0.7983 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.7977 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7982 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.7944 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7972 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7977 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.7997 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7982 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7974 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.8007 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7991 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7934 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7984 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.7969 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7963 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.8012 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7976 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7959 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7977 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7962 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5471 - accuracy: 0.7981 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7965 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.8015 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7994 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7964 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.8014 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7980 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7964 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7972 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7957 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7957 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7984 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7960 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7980 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7944 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7978 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.8024 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7957 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7995 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7964 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7970 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7980 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7969 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7940 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7986 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7981 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7975 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.8010 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7939 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7975 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7981 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7988 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7957 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5286 - accuracy: 0.7975 - recall_16: 0.0000e+00 - precision_16: 0.0000e+0 - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7969 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.8000 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7988 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7991 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7984 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.8015 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7945 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7953 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.8000 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.8000 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.8005 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7939 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7954 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657C9E430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7973 - recall_16: 0.0000e+00 - precision_16: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6169 - accuracy: 0.7970 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6134 - accuracy: 0.8002 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.7957 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.8010 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.7994 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7980 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6027 - accuracy: 0.7972 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.8012 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7968 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7969 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.7971 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.7949 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.7918 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.7953 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.8008 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7968 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.7953 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7941 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7957 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7990 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7993 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7980 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7967 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7970 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7944 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7959 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7962 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.7970 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7962 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7959 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.8010 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7972 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5609 - accuracy: 0.7952 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.7992 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7982 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.8000 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.7983 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7962 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.7962 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5526 - accuracy: 0.7963 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7965 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7988 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.7992 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7962 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7975 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7992 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7980 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7974 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7980 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7947 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7975 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7994 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.7967 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7990 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7978 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7965 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7932 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7947 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7970 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.8000 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7971 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7975 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7941 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7965 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7962 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7992 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7980 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7984 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7980 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7978 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7963 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7961 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7971 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7962 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7942 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7955 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7968 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7979 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7967 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7950 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7960 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7973 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7991 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7969 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7947 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7995 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7983 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.8006 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.8003 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7999 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7992 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7980 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7998 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7972 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7968 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7951 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7985 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7992 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.8005 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7938 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE7310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7977 - recall_17: 0.0000e+00 - precision_17: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5642 - accuracy: 0.7995 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7974 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7940 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7920 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.7973 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7959 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7989 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.7955 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7932 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7945 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7948 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7956 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7958 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7974 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7954 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7978 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7960 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7998 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7978 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7986 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.8004 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7998 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7955 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7986 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7984 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7954 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7972 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7966 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7943 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7973 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7967 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7988 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7962 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5419 - accuracy: 0.7920 - recall_18: 0.0000e+00 - precision_18: 0.0000e+0 - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7964 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7981 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7978 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.8003 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7982 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7990 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7979 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7987 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7978 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7954 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7959 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7968 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7986 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7939 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.8009 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7968 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7974 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.8001 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7940 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7958 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7991 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7994 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7961 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.8014 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7951 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7938 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.8004 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7990 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7949 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7976 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7966 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7969 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7958 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7939 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7968 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5225 - accuracy: 0.7970 - recall_18: 0.0000e+00 - precision_18: 0.0000e+0 - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7981 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7949 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7989 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7984 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.8009 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7977 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7960 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7956 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7957 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7984 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7971 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7989 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.8011 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7940 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.8001 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7974 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7968 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7991 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7993 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7972 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7958 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7966 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7977 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7959 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7969 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7969 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7961 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7990 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7957 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7940 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7953 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7994 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657C9E5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7973 - recall_18: 0.0000e+00 - precision_18: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.1120 - accuracy: 0.2009 - recall_19: 1.0000 - precision_19: 0.2009\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0858 - accuracy: 0.2015 - recall_19: 1.0000 - precision_19: 0.2015\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0609 - accuracy: 0.2018 - recall_19: 1.0000 - precision_19: 0.2018\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0368 - accuracy: 0.2021 - recall_19: 1.0000 - precision_19: 0.2021\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0135 - accuracy: 0.2028 - recall_19: 1.0000 - precision_19: 0.2028\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9912 - accuracy: 0.2043 - recall_19: 1.0000 - precision_19: 0.2043\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9694 - accuracy: 0.2058 - recall_19: 1.0000 - precision_19: 0.2058\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9512 - accuracy: 0.2036 - recall_19: 1.0000 - precision_19: 0.2036\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9321 - accuracy: 0.2043 - recall_19: 1.0000 - precision_19: 0.2043\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9154 - accuracy: 0.2021 - recall_19: 1.0000 - precision_19: 0.2021\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8976 - accuracy: 0.2033 - recall_19: 1.0000 - precision_19: 0.2033\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8801 - accuracy: 0.2051 - recall_19: 1.0000 - precision_19: 0.2051\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8675 - accuracy: 0.1988 - recall_19: 1.0000 - precision_19: 0.1988\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8489 - accuracy: 0.2070 - recall_19: 1.0000 - precision_19: 0.2070\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8375 - accuracy: 0.1998 - recall_19: 1.0000 - precision_19: 0.1998\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8223 - accuracy: 0.2034 - recall_19: 1.0000 - precision_19: 0.2034\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8095 - accuracy: 0.2026 - recall_19: 1.0000 - precision_19: 0.2026\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7970 - accuracy: 0.2035 - recall_19: 1.0000 - precision_19: 0.2035\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7849 - accuracy: 0.2036 - recall_19: 1.0000 - precision_19: 0.2036\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7736 - accuracy: 0.2037 - recall_19: 1.0000 - precision_19: 0.2037\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7632 - accuracy: 0.2006 - recall_19: 1.0000 - precision_19: 0.2006\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7523 - accuracy: 0.2030 - recall_19: 1.0000 - precision_19: 0.2030\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.2033 - recall_19: 1.0000 - precision_19: 0.2033\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7324 - accuracy: 0.2068 - recall_19: 1.0000 - precision_19: 0.2068\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7233 - accuracy: 0.2068 - recall_19: 0.9868 - precision_19: 0.2032\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7148 - accuracy: 0.2314 - recall_19: 0.8948 - precision_19: 0.1922\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7067 - accuracy: 0.3544 - recall_19: 0.6709 - precision_19: 0.1893\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6988 - accuracy: 0.4832 - recall_19: 0.4026 - precision_19: 0.1720\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.5404 - recall_19: 0.2925 - precision_19: 0.1603\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.6013 - recall_19: 0.1776 - precision_19: 0.1355\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.6886 - recall_19: 0.0622 - precision_19: 0.0974\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.7686 - recall_19: 0.0211 - precision_19: 0.1300\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.7987 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.7956 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.7921 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.8012 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.7990 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7978 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.7976 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.7982 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6239 - accuracy: 0.7915 - recall_19: 0.0000e+00 - precision_19: 0.0000e+0 - 0s 3ms/step - loss: 0.6216 - accuracy: 0.7959 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.7955 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.7972 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.7963 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.7990 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7985 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.7974 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7969 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7965 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.7972 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7965 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7951 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.7972 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7974 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.7967 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7997 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7980 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7954 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7979 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7995 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7974 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7991 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7955 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7988 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7983 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7952 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7972 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7973 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7991 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7976 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7980 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.7980 - recall_19: 0.0000e+00 - precision_19: 0.0000e+0 - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7982 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7960 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7974 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7985 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7987 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7994 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7956 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7961 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7991 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7977 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7972 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7994 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.8010 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7951 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7969 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7984 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7960 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7985 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7976 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7937 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7972 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7983 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7974 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7947 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7979 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7983 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7972 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7994 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7984 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7973 - recall_19: 0.0000e+00 - precision_19: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5732 - accuracy: 0.8027 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5740 - accuracy: 0.7950 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7975 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7982 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7993 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7978 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7992 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.7934 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7962 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7991 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7970 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7945 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7938 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.8010 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7960 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7950 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7958 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.8000 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7950 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7967 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7971 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7972 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7986 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7967 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7979 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7982 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7947 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7962 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7995 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7988 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7940 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7989 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7996 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7958 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7983 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7998 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7952 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7985 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7978 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7982 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.8005 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7973 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7943 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7933 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7931 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7972 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7971 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7948 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7947 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7978 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.7924 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7982 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7980 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7993 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7999 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7970 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7965 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7942 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7953 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7981 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.8007 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7970 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7994 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7971 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.8007 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7958 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7977 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7955 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7985 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7996 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7980 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7985 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7975 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7952 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7957 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7989 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7940 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7940 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7980 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.8015 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7950 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.8007 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.8003 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7967 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7981 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7981 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7950 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7983 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7940 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.8001 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7984 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7967 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.8008 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7955 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7983 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7984 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7925 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7940 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7980 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7968 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65536F3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7977 - recall_20: 0.0000e+00 - precision_20: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5189 - accuracy: 0.7981 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7990 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.8001 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7971 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7981 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.8004 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7963 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7989 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7969 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7985 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.8006 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7973 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7918 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7951 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7951 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7968 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7961 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7992 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7971 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7992 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7954 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7964 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7984 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7973 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.8018 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7964 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7959 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7993 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7986 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8007 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.8020 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7959 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7986 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7964 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7986 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7988 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7959 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7966 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7975 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7974 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7949 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7973 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.8004 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7973 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7944 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7958 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7963 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7946 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7994 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7994 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7953 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7949 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7984 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7974 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7960 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7993 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7973 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7974 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7971 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7998 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7954 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7979 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7955 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8000 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7991 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7994 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7946 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7929 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7954 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7991 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7979 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7994 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7969 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7981 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.8001 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7963 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7964 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7961 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7966 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7962 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7971 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7981 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7966 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7965 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7983 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7974 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7963 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7983 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7961 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7948 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4995 - accuracy: 0.7987 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7951 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.8013 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7964 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7994 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7996 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.8004 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7981 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7978 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7961 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE74C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7973 - recall_21: 0.0000e+00 - precision_21: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6191 - accuracy: 0.7937 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6165 - accuracy: 0.7959 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.7980 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.7965 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.7972 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.7985 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.7992 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.7954 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.7941 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.7970 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.7980 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7984 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.7960 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7948 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7988 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.7968 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7972 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7966 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.7954 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.7975 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.8014 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.7949 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.7982 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7961 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.8004 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7969 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7959 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.8020 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7970 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7979 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7984 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7955 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7945 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7959 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.8025 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.8003 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.8022 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7999 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.8004 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7979 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7978 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7971 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7994 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.8009 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7949 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7937 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7949 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.8012 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7966 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.7971 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.8013 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7954 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7964 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7952 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7969 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7969 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7978 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7927 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7981 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7967 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7980 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7962 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7936 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7988 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7978 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7947 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7982 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7980 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7956 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.7963 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7992 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7983 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7955 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.8035 - recall_22: 0.0000e+00 - precision_22: 0.0000e+0 - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7995 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7967 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7959 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7957 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7962 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7976 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.8009 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.8011 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7958 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7996 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7970 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7954 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.8004 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7980 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7962 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7969 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7995 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7952 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7972 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7957 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7984 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7986 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7993 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7993 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7932 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7957 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7981 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE7940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7973 - recall_22: 0.0000e+00 - precision_22: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 2ms/step - loss: 0.5537 - accuracy: 0.7957 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7964 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7968 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7937 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7997 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7969 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7963 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7952 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7997 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7978 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.8011 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7930 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.8002 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.8001 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7913 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7967 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7955 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7988 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7985 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7937 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7985 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7985 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7981 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7962 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7973 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7963 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7948 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7943 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7958 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7965 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7968 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7980 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7962 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7988 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7965 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7982 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7970 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7985 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7998 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7992 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7951 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7988 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7998 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7953 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7991 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7942 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7983 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7978 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7975 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7983 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7997 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7960 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7978 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7945 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7972 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7992 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7975 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7974 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7983 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7993 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7970 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7965 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7974 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7972 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7995 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7977 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7983 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7955 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7955 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7950 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7995 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7977 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.8003 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7949 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7988 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7973 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7967 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7988 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7984 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7937 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7987 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7942 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7939 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7981 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7987 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7977 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7930 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7945 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.8000 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7986 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7910 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7988 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5198 - accuracy: 0.7968 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.8010 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7988 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7978 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7998 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7970 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7970 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7954 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D658032E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7977 - recall_23: 0.0000e+00 - precision_23: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6654 - accuracy: 0.7689 - recall_24: 0.0118 - precision_24: 0.0734\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.7795 - recall_24: 0.0074 - precision_24: 0.0832\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.7905 - recall_24: 0.0038 - precision_24: 0.0816\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.7908 - recall_24: 0.0023 - precision_24: 0.0893\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.8001 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.7978 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.7969 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.7973 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.7963 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.8014 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.7983 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.7976 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7969 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.7976 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.7984 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.7984 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.7974 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.7982 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.7959 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.7949 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.7939 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.7973 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.7957 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.7971 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.7957 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7989 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.7973 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.7996 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.7953 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.7978 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7966 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.7963 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.7950 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.8015 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7966 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.7989 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7983 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5867 - accuracy: 0.7967 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7961 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7964 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7965 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7980 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7957 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7946 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7961 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.7985 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7964 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7973 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7976 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7966 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7992 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7974 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.8003 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7995 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.8008 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7958 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7974 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7983 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7921 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.7957 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7966 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7967 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7979 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7969 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7974 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7968 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.8026 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.7962 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7989 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7979 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7969 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7966 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7971 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7946 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7961 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7996 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7999 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7984 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.8006 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7986 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7959 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7979 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.8001 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7968 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7968 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7961 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.8004 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7991 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7951 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7984 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7969 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7969 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7969 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7985 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7951 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7959 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.8016 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.8005 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7983 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7959 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE7E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7973 - recall_24: 0.0000e+00 - precision_24: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.5228 - recall_25: 0.5625 - precision_25: 0.2247\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5369 - recall_25: 0.5496 - precision_25: 0.2305\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.5411 - recall_25: 0.5282 - precision_25: 0.2262\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.5614 - recall_25: 0.5131 - precision_25: 0.2344\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.5753 - recall_25: 0.4858 - precision_25: 0.2350\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.5850 - recall_25: 0.4854 - precision_25: 0.2416\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.5951 - recall_25: 0.4530 - precision_25: 0.2360\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.6051 - recall_25: 0.4367 - precision_25: 0.2411\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.6177 - recall_25: 0.4269 - precision_25: 0.2487\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6256 - recall_25: 0.4146 - precision_25: 0.2498\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.6394 - recall_25: 0.4063 - precision_25: 0.2558\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.6417 - recall_25: 0.3765 - precision_25: 0.2469\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.6582 - recall_25: 0.3766 - precision_25: 0.2571\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.6614 - recall_25: 0.3490 - precision_25: 0.2586\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6757 - recall_25: 0.3384 - precision_25: 0.2621\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6828 - recall_25: 0.3356 - precision_25: 0.2716\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.6926 - recall_25: 0.3104 - precision_25: 0.2704\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6972 - recall_25: 0.3002 - precision_25: 0.2786\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.7046 - recall_25: 0.2890 - precision_25: 0.2861\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.7150 - recall_25: 0.2829 - precision_25: 0.2981\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7243 - recall_25: 0.2758 - precision_25: 0.3054\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7289 - recall_25: 0.2617 - precision_25: 0.3040\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.7346 - recall_25: 0.2539 - precision_25: 0.3136\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.7392 - recall_25: 0.2359 - precision_25: 0.3118\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.7428 - recall_25: 0.2095 - precision_25: 0.3090\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.7483 - recall_25: 0.2022 - precision_25: 0.3190\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.7552 - recall_25: 0.1920 - precision_25: 0.3113\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6175 - accuracy: 0.7603 - recall_25: 0.1812 - precision_25: 0.3114\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7598 - recall_25: 0.1851 - precision_25: 0.3363\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.7611 - recall_25: 0.1699 - precision_25: 0.3353\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.7667 - recall_25: 0.1451 - precision_25: 0.3172\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.7678 - recall_25: 0.1350 - precision_25: 0.3181\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.7735 - recall_25: 0.1281 - precision_25: 0.3340\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.7725 - recall_25: 0.1185 - precision_25: 0.3391\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.7795 - recall_25: 0.1187 - precision_25: 0.3621\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.7783 - recall_25: 0.1115 - precision_25: 0.3612\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7814 - recall_25: 0.0956 - precision_25: 0.3623\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5991 - accuracy: 0.7814 - recall_25: 0.0876 - precision_25: 0.3438\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.7855 - recall_25: 0.0869 - precision_25: 0.3670\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.7886 - recall_25: 0.0756 - precision_25: 0.3292\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7828 - recall_25: 0.0687 - precision_25: 0.3528\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.7852 - recall_25: 0.0614 - precision_25: 0.3421\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.7852 - recall_25: 0.0513 - precision_25: 0.3238\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.7897 - recall_25: 0.0505 - precision_25: 0.3469\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.7862 - recall_25: 0.0481 - precision_25: 0.3702\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7881 - recall_25: 0.0413 - precision_25: 0.3503\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.7908 - recall_25: 0.0362 - precision_25: 0.3398\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7926 - recall_25: 0.0358 - precision_25: 0.3701\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.7921 - recall_25: 0.0334 - precision_25: 0.3329\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7942 - recall_25: 0.0313 - precision_25: 0.3563\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7938 - recall_25: 0.0282 - precision_25: 0.3853\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.7905 - recall_25: 0.0205 - precision_25: 0.3302\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.7937 - recall_25: 0.0198 - precision_25: 0.3195\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7906 - recall_25: 0.0135 - precision_25: 0.2959\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7948 - recall_25: 0.0132 - precision_25: 0.3152\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5748 - accuracy: 0.7870 - recall_25: 0.0118 - precision_25: 0.454 - 0s 4ms/step - loss: 0.5715 - accuracy: 0.7930 - recall_25: 0.0127 - precision_25: 0.3575\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7912 - recall_25: 0.0111 - precision_25: 0.2801\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7958 - recall_25: 0.0089 - precision_25: 0.2705\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7964 - recall_25: 0.0086 - precision_25: 0.2768\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.7942 - recall_25: 0.0064 - precision_25: 0.2809\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.7977 - recall_25: 0.0078 - precision_25: 0.2936\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7951 - recall_25: 0.0065 - precision_25: 0.2955\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7961 - recall_25: 0.0078 - precision_25: 0.3734\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5587 - accuracy: 0.7992 - recall_25: 0.0059 - precision_25: 0.3214\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7940 - recall_25: 0.0054 - precision_25: 0.3542\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7933 - recall_25: 0.0036 - precision_25: 0.2997\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7968 - recall_25: 0.0046 - precision_25: 0.4583\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7975 - recall_25: 0.0011 - precision_25: 0.1111    \n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.7995 - recall_25: 0.0011 - precision_25: 0.1429    \n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7953 - recall_25: 0.0023 - precision_25: 0.3333\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.8035 - recall_25: 0.0000e+00 - precision_25: 0.0000e+0 - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7989 - recall_25: 5.2910e-04 - precision_25: 0.1000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7988 - recall_25: 0.0015 - precision_25: 0.3125\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7995 - recall_25: 8.3851e-04 - precision_25: 0.2083\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7960 - recall_25: 5.2910e-04 - precision_25: 0.1250\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7967 - recall_25: 0.0015 - precision_25: 0.2500\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.8004 - recall_25: 0.0015 - precision_25: 0.3125\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7986 - recall_25: 0.0015 - precision_25: 0.3125\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.8008 - recall_25: 0.0015 - precision_25: 0.5000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7932 - recall_25: 0.0014 - precision_25: 0.5000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.7935 - recall_25: 0.0014 - precision_25: 0.5000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7989 - recall_25: 8.3736e-04 - precision_25: 0.3750\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7954 - recall_25: 0.0014 - precision_25: 0.6250\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7994 - recall_25: 0.0015 - precision_25: 0.6250\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7959 - recall_25: 5.2910e-04 - precision_25: 0.2500\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.8006 - recall_25: 8.3774e-04 - precision_25: 0.3750\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7944 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7971 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7995 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7945 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7951 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7967 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7967 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7971 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7966 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7965 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7967 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7972 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7989 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7970 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7986 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657F8D9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7973 - recall_25: 0.0000e+00 - precision_25: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8293 - accuracy: 0.4387 - recall_26: 0.4259 - precision_26: 0.1639\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8308 - accuracy: 0.4349 - recall_26: 0.4098 - precision_26: 0.1555\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8214 - accuracy: 0.4439 - recall_26: 0.4049 - precision_26: 0.1600\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8162 - accuracy: 0.4458 - recall_26: 0.3949 - precision_26: 0.1540\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8123 - accuracy: 0.4494 - recall_26: 0.4018 - precision_26: 0.1596\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8056 - accuracy: 0.4546 - recall_26: 0.3960 - precision_26: 0.1577\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8002 - accuracy: 0.4565 - recall_26: 0.3813 - precision_26: 0.1555\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7980 - accuracy: 0.4586 - recall_26: 0.3877 - precision_26: 0.1599\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7897 - accuracy: 0.4643 - recall_26: 0.3907 - precision_26: 0.1588\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7841 - accuracy: 0.4690 - recall_26: 0.3770 - precision_26: 0.1586\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7817 - accuracy: 0.4714 - recall_26: 0.3746 - precision_26: 0.1610\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7752 - accuracy: 0.4770 - recall_26: 0.3669 - precision_26: 0.1579\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7736 - accuracy: 0.4744 - recall_26: 0.3598 - precision_26: 0.1577\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7697 - accuracy: 0.4752 - recall_26: 0.3474 - precision_26: 0.1537\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7625 - accuracy: 0.4847 - recall_26: 0.3511 - precision_26: 0.1598\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7604 - accuracy: 0.4853 - recall_26: 0.3465 - precision_26: 0.1582\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7553 - accuracy: 0.4929 - recall_26: 0.3324 - precision_26: 0.1527\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7478 - accuracy: 0.4990 - recall_26: 0.3416 - precision_26: 0.1563\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7463 - accuracy: 0.4995 - recall_26: 0.3233 - precision_26: 0.1550\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7445 - accuracy: 0.5012 - recall_26: 0.3307 - precision_26: 0.1565\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7415 - accuracy: 0.5017 - recall_26: 0.3225 - precision_26: 0.1542\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7343 - accuracy: 0.5120 - recall_26: 0.3193 - precision_26: 0.1560\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7327 - accuracy: 0.5119 - recall_26: 0.3145 - precision_26: 0.1547\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7262 - accuracy: 0.5193 - recall_26: 0.3115 - precision_26: 0.1549\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7254 - accuracy: 0.5223 - recall_26: 0.3086 - precision_26: 0.1572\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7222 - accuracy: 0.5264 - recall_26: 0.3111 - precision_26: 0.1589\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7170 - accuracy: 0.5297 - recall_26: 0.3014 - precision_26: 0.1577\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7159 - accuracy: 0.5328 - recall_26: 0.2955 - precision_26: 0.1555\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7093 - accuracy: 0.5409 - recall_26: 0.3045 - precision_26: 0.1652\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7058 - accuracy: 0.5433 - recall_26: 0.2987 - precision_26: 0.1623\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.5489 - recall_26: 0.2892 - precision_26: 0.1582\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7002 - accuracy: 0.5500 - recall_26: 0.2890 - precision_26: 0.1594\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7006 - accuracy: 0.5528 - recall_26: 0.2754 - precision_26: 0.1592\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5637 - recall_26: 0.2798 - precision_26: 0.1656\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5659 - recall_26: 0.2703 - precision_26: 0.1596\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5705 - recall_26: 0.2727 - precision_26: 0.1619\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6819 - accuracy: 0.5738 - recall_26: 0.2659 - precision_26: 0.1582\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.5730 - recall_26: 0.2553 - precision_26: 0.1584\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.5752 - recall_26: 0.2527 - precision_26: 0.1595\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.5801 - recall_26: 0.2508 - precision_26: 0.1579\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.5840 - recall_26: 0.2484 - precision_26: 0.1633\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6711 - accuracy: 0.5885 - recall_26: 0.2439 - precision_26: 0.1627\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.5922 - recall_26: 0.2412 - precision_26: 0.1602\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.6012 - recall_26: 0.2414 - precision_26: 0.1655\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.5994 - recall_26: 0.2447 - precision_26: 0.1706\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.5989 - recall_26: 0.2198 - precision_26: 0.1542\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.6023 - recall_26: 0.2202 - precision_26: 0.1597\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.6063 - recall_26: 0.2179 - precision_26: 0.1574\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.6182 - recall_26: 0.2171 - precision_26: 0.1644\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.6179 - recall_26: 0.2140 - precision_26: 0.1613\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.6117 - recall_26: 0.2076 - precision_26: 0.1593\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6227 - recall_26: 0.2096 - precision_26: 0.1598\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.6231 - recall_26: 0.2016 - precision_26: 0.1586\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.6296 - recall_26: 0.2023 - precision_26: 0.1622\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6247 - recall_26: 0.1862 - precision_26: 0.1540\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.6348 - recall_26: 0.1868 - precision_26: 0.1571\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.6323 - recall_26: 0.1854 - precision_26: 0.1597\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6340 - recall_26: 0.1807 - precision_26: 0.1562\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.6386 - recall_26: 0.1702 - precision_26: 0.1507\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.6325 - recall_26: 0.1158 - precision_26: 0.111 - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6388 - recall_26: 0.1556 - precision_26: 0.1416\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6446 - recall_26: 0.1703 - precision_26: 0.1553\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6499 - recall_26: 0.1717 - precision_26: 0.1566\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6499 - recall_26: 0.1649 - precision_26: 0.1565\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.6545 - recall_26: 0.1578 - precision_26: 0.1557\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.6595 - recall_26: 0.1544 - precision_26: 0.1529\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.6584 - recall_26: 0.1498 - precision_26: 0.1517\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6643 - recall_26: 0.1473 - precision_26: 0.1556\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.6659 - recall_26: 0.1404 - precision_26: 0.1577\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6734 - recall_26: 0.1439 - precision_26: 0.1595\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6779 - recall_26: 0.1481 - precision_26: 0.1653\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.6841 - recall_26: 0.1441 - precision_26: 0.1704\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.6935 - recall_26: 0.1496 - precision_26: 0.1757\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.6978 - recall_26: 0.1443 - precision_26: 0.1817\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7019 - recall_26: 0.1380 - precision_26: 0.1842\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7087 - recall_26: 0.1388 - precision_26: 0.1871\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7039 - recall_26: 0.1314 - precision_26: 0.1856\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.7116 - recall_26: 0.1232 - precision_26: 0.1823\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.7179 - recall_26: 0.1192 - precision_26: 0.1862\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.7214 - recall_26: 0.1124 - precision_26: 0.1829\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7241 - recall_26: 0.1099 - precision_26: 0.1852\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7228 - recall_26: 0.0988 - precision_26: 0.1774\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7249 - recall_26: 0.1007 - precision_26: 0.1813\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7346 - recall_26: 0.0911 - precision_26: 0.1789\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.7387 - recall_26: 0.0893 - precision_26: 0.1864\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7445 - recall_26: 0.0848 - precision_26: 0.1834\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.7468 - recall_26: 0.0877 - precision_26: 0.2086\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7459 - recall_26: 0.0830 - precision_26: 0.2028\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7500 - recall_26: 0.0764 - precision_26: 0.1968\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.7535 - recall_26: 0.0729 - precision_26: 0.2012\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.7583 - recall_26: 0.0750 - precision_26: 0.2133\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7606 - recall_26: 0.0727 - precision_26: 0.2301\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.7620 - recall_26: 0.0710 - precision_26: 0.2438\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.7675 - recall_26: 0.0727 - precision_26: 0.2600\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7732 - recall_26: 0.0739 - precision_26: 0.2643\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.7753 - recall_26: 0.0710 - precision_26: 0.2793\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7736 - recall_26: 0.0628 - precision_26: 0.2616\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7827 - recall_26: 0.0651 - precision_26: 0.2990\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7834 - recall_26: 0.0644 - precision_26: 0.3270\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7830 - recall_26: 0.0597 - precision_26: 0.3103\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.7854 - recall_26: 0.0529 - precision_26: 0.2917\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580C9E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.7805 - recall_26: 0.0551 - precision_26: 0.2826\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6991 - accuracy: 0.4953 - recall_27: 0.5014 - precision_27: 0.2008\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6955 - accuracy: 0.5083 - recall_27: 0.4766 - precision_27: 0.1974\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.5209 - recall_27: 0.4678 - precision_27: 0.2032\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.5361 - recall_27: 0.4349 - precision_27: 0.2019\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5445 - recall_27: 0.4140 - precision_27: 0.1989\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6822 - accuracy: 0.5707 - recall_27: 0.4042 - precision_27: 0.2119\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.5758 - recall_27: 0.3857 - precision_27: 0.2053\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.5852 - recall_27: 0.3722 - precision_27: 0.2077\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5968 - recall_27: 0.3503 - precision_27: 0.2076\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.6059 - recall_27: 0.3267 - precision_27: 0.2055\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.6135 - recall_27: 0.3156 - precision_27: 0.2057\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.6291 - recall_27: 0.3067 - precision_27: 0.2093\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.6388 - recall_27: 0.2878 - precision_27: 0.2112\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6611 - accuracy: 0.6471 - recall_27: 0.2747 - precision_27: 0.2181\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.6573 - recall_27: 0.2443 - precision_27: 0.2049\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.6707 - recall_27: 0.2481 - precision_27: 0.2219\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.6762 - recall_27: 0.2288 - precision_27: 0.2178\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.6891 - recall_27: 0.2082 - precision_27: 0.2153\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.6938 - recall_27: 0.1991 - precision_27: 0.2226\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.7005 - recall_27: 0.1953 - precision_27: 0.2223\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.7077 - recall_27: 0.1918 - precision_27: 0.2311\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.7182 - recall_27: 0.1903 - precision_27: 0.2453\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.7187 - recall_27: 0.1717 - precision_27: 0.2349\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.7212 - recall_27: 0.1649 - precision_27: 0.2339\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.7292 - recall_27: 0.1589 - precision_27: 0.2345\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.7350 - recall_27: 0.1505 - precision_27: 0.2378\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.7337 - recall_27: 0.1438 - precision_27: 0.2455\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6273 - accuracy: 0.7429 - recall_27: 0.1463 - precision_27: 0.2545\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.7367 - recall_27: 0.1336 - precision_27: 0.2403\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.7397 - recall_27: 0.1216 - precision_27: 0.2404\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.7465 - recall_27: 0.1079 - precision_27: 0.2235\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7431 - recall_27: 0.1091 - precision_27: 0.2407\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7521 - recall_27: 0.1030 - precision_27: 0.2340\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6161 - accuracy: 0.7553 - recall_27: 0.0925 - precision_27: 0.2297\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.7522 - recall_27: 0.0898 - precision_27: 0.2240\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.7571 - recall_27: 0.0870 - precision_27: 0.2348\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7586 - recall_27: 0.0802 - precision_27: 0.2263\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.7617 - recall_27: 0.0794 - precision_27: 0.2420\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.7610 - recall_27: 0.0748 - precision_27: 0.2363\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7629 - recall_27: 0.0634 - precision_27: 0.2264\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.7657 - recall_27: 0.0563 - precision_27: 0.2137\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.7693 - recall_27: 0.0571 - precision_27: 0.2312\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.7704 - recall_27: 0.0508 - precision_27: 0.2162\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.7684 - recall_27: 0.0422 - precision_27: 0.1939\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.7775 - recall_27: 0.0456 - precision_27: 0.2146\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5955 - accuracy: 0.7812 - recall_27: 0.0466 - precision_27: 0.2417\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.7817 - recall_27: 0.0413 - precision_27: 0.2393\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.7805 - recall_27: 0.0380 - precision_27: 0.2324\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7826 - recall_27: 0.0368 - precision_27: 0.2374\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7819 - recall_27: 0.0347 - precision_27: 0.2427\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.7874 - recall_27: 0.0337 - precision_27: 0.2668\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5864 - accuracy: 0.7882 - recall_27: 0.0320 - precision_27: 0.2542\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7872 - recall_27: 0.0357 - precision_27: 0.2851\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.7866 - recall_27: 0.0290 - precision_27: 0.2628\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7885 - recall_27: 0.0315 - precision_27: 0.2962\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5819 - accuracy: 0.7896 - recall_27: 0.0310 - precision_27: 0.3061\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.7946 - recall_27: 0.0305 - precision_27: 0.3311\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.7904 - recall_27: 0.0207 - precision_27: 0.2472\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5768 - accuracy: 0.7925 - recall_27: 0.0151 - precision_27: 0.2175\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.7880 - recall_27: 0.0163 - precision_27: 0.2432\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5716 - accuracy: 0.7995 - recall_27: 0.0103 - precision_27: 0.181 - 0s 4ms/step - loss: 0.5743 - accuracy: 0.7937 - recall_27: 0.0140 - precision_27: 0.2308\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7871 - recall_27: 0.0150 - precision_27: 0.2818\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7920 - recall_27: 0.0126 - precision_27: 0.2346\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7902 - recall_27: 0.0112 - precision_27: 0.2660\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7925 - recall_27: 0.0112 - precision_27: 0.2592\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.7925 - recall_27: 0.0102 - precision_27: 0.2835\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.7954 - recall_27: 0.0087 - precision_27: 0.2441\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7939 - recall_27: 0.0071 - precision_27: 0.2149\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7980 - recall_27: 0.0070 - precision_27: 0.2432\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5661 - accuracy: 0.7940 - recall_27: 0.0069 - precision_27: 0.2545\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.7982 - recall_27: 0.0049 - precision_27: 0.2210\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.7981 - recall_27: 0.0067 - precision_27: 0.3399\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7932 - recall_27: 0.0053 - precision_27: 0.3003\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7957 - recall_27: 0.0066 - precision_27: 0.3646\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.8009 - recall_27: 0.0052 - precision_27: 0.3388\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7939 - recall_27: 0.0028 - precision_27: 0.3328\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7967 - recall_27: 0.0038 - precision_27: 0.3083\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7956 - recall_27: 0.0028 - precision_27: 0.3125\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.7960 - recall_27: 0.0037 - precision_27: 0.4125\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.7953 - recall_27: 0.0037 - precision_27: 0.5446\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7968 - recall_27: 0.0031 - precision_27: 0.5000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7980 - recall_27: 0.0044 - precision_27: 0.7000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7978 - recall_27: 0.0037 - precision_27: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7977 - recall_27: 0.0020 - precision_27: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7978 - recall_27: 0.0023 - precision_27: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7978 - recall_27: 8.4005e-04 - precision_27: 0.7500\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7974 - recall_27: 0.0015 - precision_27: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7959 - recall_27: 8.3660e-04 - precision_27: 0.7500\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7977 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7966 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7981 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7933 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7979 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7976 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7980 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7986 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7984 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7989 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.8016 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7959 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA19D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7973 - recall_27: 0.0000e+00 - precision_27: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8328 - accuracy: 0.4390 - recall_28: 0.4011 - precision_28: 0.1545\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8231 - accuracy: 0.4493 - recall_28: 0.3948 - precision_28: 0.1564\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8101 - accuracy: 0.4622 - recall_28: 0.3848 - precision_28: 0.1564\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8073 - accuracy: 0.4625 - recall_28: 0.3741 - precision_28: 0.1562\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7992 - accuracy: 0.4707 - recall_28: 0.3787 - precision_28: 0.1609\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7845 - accuracy: 0.4812 - recall_28: 0.3703 - precision_28: 0.1608\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7827 - accuracy: 0.4815 - recall_28: 0.3635 - precision_28: 0.1565\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7733 - accuracy: 0.4897 - recall_28: 0.3514 - precision_28: 0.1550\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7642 - accuracy: 0.5018 - recall_28: 0.3630 - precision_28: 0.1659\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7582 - accuracy: 0.5044 - recall_28: 0.3551 - precision_28: 0.1641\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7526 - accuracy: 0.5086 - recall_28: 0.3343 - precision_28: 0.1611\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.5179 - recall_28: 0.3365 - precision_28: 0.1618\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7402 - accuracy: 0.5202 - recall_28: 0.3227 - precision_28: 0.1592\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.5256 - recall_28: 0.3183 - precision_28: 0.1608\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7248 - accuracy: 0.5360 - recall_28: 0.3204 - precision_28: 0.1668\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7193 - accuracy: 0.5465 - recall_28: 0.3148 - precision_28: 0.1647\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7127 - accuracy: 0.5498 - recall_28: 0.3090 - precision_28: 0.1662\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7101 - accuracy: 0.5583 - recall_28: 0.3041 - precision_28: 0.1711\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.5587 - recall_28: 0.2915 - precision_28: 0.1682\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6959 - accuracy: 0.5774 - recall_28: 0.3024 - precision_28: 0.1819\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.5862 - recall_28: 0.2990 - precision_28: 0.1804\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.5878 - recall_28: 0.2991 - precision_28: 0.1843\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5922 - recall_28: 0.2839 - precision_28: 0.1808\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.6013 - recall_28: 0.2724 - precision_28: 0.1795\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.6086 - recall_28: 0.2691 - precision_28: 0.1827\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.6193 - recall_28: 0.2746 - precision_28: 0.1915\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.6250 - recall_28: 0.2653 - precision_28: 0.1843\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6261 - recall_28: 0.2561 - precision_28: 0.1880\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.6303 - recall_28: 0.2494 - precision_28: 0.1855\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.6380 - recall_28: 0.2511 - precision_28: 0.1962\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.6462 - recall_28: 0.2399 - precision_28: 0.1957\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.6475 - recall_28: 0.2367 - precision_28: 0.1981\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.6562 - recall_28: 0.2373 - precision_28: 0.2057\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6604 - recall_28: 0.2305 - precision_28: 0.2046\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6624 - recall_28: 0.2226 - precision_28: 0.2028\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.6676 - recall_28: 0.2255 - precision_28: 0.2095\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6688 - recall_28: 0.2029 - precision_28: 0.1966\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.6780 - recall_28: 0.2137 - precision_28: 0.2103\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.6863 - recall_28: 0.2089 - precision_28: 0.2133\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6080 - accuracy: 0.6894 - recall_28: 0.2038 - precision_28: 0.2131\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6102 - accuracy: 0.6838 - recall_28: 0.1967 - precision_28: 0.2047\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.6907 - recall_28: 0.1957 - precision_28: 0.2122\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.6959 - recall_28: 0.1918 - precision_28: 0.2161\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.6969 - recall_28: 0.1963 - precision_28: 0.2204\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7026 - recall_28: 0.1958 - precision_28: 0.2320\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.7077 - recall_28: 0.2024 - precision_28: 0.2381\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.7078 - recall_28: 0.1913 - precision_28: 0.2336\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.7113 - recall_28: 0.1770 - precision_28: 0.2264\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7122 - recall_28: 0.1734 - precision_28: 0.2279\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7156 - recall_28: 0.1696 - precision_28: 0.2259\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.7215 - recall_28: 0.1725 - precision_28: 0.2409\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.7188 - recall_28: 0.1663 - precision_28: 0.2314\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5704 - accuracy: 0.7289 - recall_28: 0.1685 - precision_28: 0.2408\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7268 - recall_28: 0.1657 - precision_28: 0.2404\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7288 - recall_28: 0.1567 - precision_28: 0.2420\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.7315 - recall_28: 0.1489 - precision_28: 0.2320\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7310 - recall_28: 0.1577 - precision_28: 0.2471\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7338 - recall_28: 0.1418 - precision_28: 0.2278\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7359 - recall_28: 0.1418 - precision_28: 0.2398\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.7415 - recall_28: 0.1429 - precision_28: 0.2459\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5539 - accuracy: 0.7418 - recall_28: 0.1469 - precision_28: 0.2534\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7422 - recall_28: 0.1395 - precision_28: 0.2472\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7466 - recall_28: 0.1350 - precision_28: 0.2532\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7493 - recall_28: 0.1367 - precision_28: 0.2618\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7501 - recall_28: 0.1325 - precision_28: 0.2671\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.7520 - recall_28: 0.1321 - precision_28: 0.2640\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7525 - recall_28: 0.1287 - precision_28: 0.2681\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7509 - recall_28: 0.1289 - precision_28: 0.2732\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7557 - recall_28: 0.1328 - precision_28: 0.2794\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7586 - recall_28: 0.1266 - precision_28: 0.2694\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7575 - recall_28: 0.1249 - precision_28: 0.2889\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7591 - recall_28: 0.1184 - precision_28: 0.2768\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7626 - recall_28: 0.1194 - precision_28: 0.2896\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7611 - recall_28: 0.1213 - precision_28: 0.2985\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7654 - recall_28: 0.1233 - precision_28: 0.3094\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7644 - recall_28: 0.1163 - precision_28: 0.2976\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7655 - recall_28: 0.1139 - precision_28: 0.2916\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7680 - recall_28: 0.1147 - precision_28: 0.3017\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7630 - recall_28: 0.1110 - precision_28: 0.3013\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7683 - recall_28: 0.1134 - precision_28: 0.3026\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7664 - recall_28: 0.1104 - precision_28: 0.3038\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7690 - recall_28: 0.1145 - precision_28: 0.3205\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7714 - recall_28: 0.1104 - precision_28: 0.3406\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7774 - recall_28: 0.1137 - precision_28: 0.3223\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7680 - recall_28: 0.1052 - precision_28: 0.3217\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7720 - recall_28: 0.1000 - precision_28: 0.3163\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7736 - recall_28: 0.1014 - precision_28: 0.3157\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7784 - recall_28: 0.1076 - precision_28: 0.3467\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7760 - recall_28: 0.1042 - precision_28: 0.3358\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7770 - recall_28: 0.0985 - precision_28: 0.3205\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7763 - recall_28: 0.0983 - precision_28: 0.3337\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7782 - recall_28: 0.0949 - precision_28: 0.3317\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7791 - recall_28: 0.0949 - precision_28: 0.3341\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7755 - recall_28: 0.0946 - precision_28: 0.3288\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7804 - recall_28: 0.0930 - precision_28: 0.3299\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7770 - recall_28: 0.0881 - precision_28: 0.3341\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7772 - recall_28: 0.0900 - precision_28: 0.3480\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7787 - recall_28: 0.0874 - precision_28: 0.3346\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7813 - recall_28: 0.0918 - precision_28: 0.3447\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7811 - recall_28: 0.0870 - precision_28: 0.3392\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580A55E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7849 - recall_28: 0.0846 - precision_28: 0.3670\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7257 - accuracy: 0.5215 - recall_29: 0.5320 - precision_29: 0.2172\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.5214 - recall_29: 0.5126 - precision_29: 0.2097\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7216 - accuracy: 0.5270 - recall_29: 0.5034 - precision_29: 0.2173\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7186 - accuracy: 0.5321 - recall_29: 0.5118 - precision_29: 0.2229\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7142 - accuracy: 0.5354 - recall_29: 0.5070 - precision_29: 0.2192\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7125 - accuracy: 0.5371 - recall_29: 0.4997 - precision_29: 0.2167\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7079 - accuracy: 0.5434 - recall_29: 0.4932 - precision_29: 0.2216\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7067 - accuracy: 0.5454 - recall_29: 0.4897 - precision_29: 0.2211\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6981 - accuracy: 0.5544 - recall_29: 0.4870 - precision_29: 0.2247\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6980 - accuracy: 0.5506 - recall_29: 0.4727 - precision_29: 0.2211\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.5535 - recall_29: 0.4616 - precision_29: 0.2205\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.5573 - recall_29: 0.4447 - precision_29: 0.2151\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5618 - recall_29: 0.4510 - precision_29: 0.2164\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5641 - recall_29: 0.4351 - precision_29: 0.2169\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.5717 - recall_29: 0.4392 - precision_29: 0.2203\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.5720 - recall_29: 0.4310 - precision_29: 0.2179\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.5782 - recall_29: 0.4250 - precision_29: 0.2179\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.5837 - recall_29: 0.4292 - precision_29: 0.2204\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.5861 - recall_29: 0.4324 - precision_29: 0.2282\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.5889 - recall_29: 0.4144 - precision_29: 0.2244\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.5933 - recall_29: 0.4155 - precision_29: 0.2297\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.5932 - recall_29: 0.4089 - precision_29: 0.2274\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.5970 - recall_29: 0.4085 - precision_29: 0.2277\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.6001 - recall_29: 0.3968 - precision_29: 0.2233\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.6047 - recall_29: 0.4125 - precision_29: 0.2327\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6064 - recall_29: 0.3924 - precision_29: 0.2260\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6100 - recall_29: 0.3921 - precision_29: 0.2286\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.6101 - recall_29: 0.3852 - precision_29: 0.2260\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.6117 - recall_29: 0.3657 - precision_29: 0.2214\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6153 - recall_29: 0.3577 - precision_29: 0.2222\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6239 - recall_29: 0.3534 - precision_29: 0.2207\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.6290 - recall_29: 0.3739 - precision_29: 0.2353\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6306 - recall_29: 0.3592 - precision_29: 0.2310\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.6283 - recall_29: 0.3499 - precision_29: 0.2291\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6304 - recall_29: 0.3394 - precision_29: 0.2296\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6345 - recall_29: 0.3492 - precision_29: 0.2376\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.6351 - recall_29: 0.3353 - precision_29: 0.2310\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.6440 - recall_29: 0.3374 - precision_29: 0.2330\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.6480 - recall_29: 0.3209 - precision_29: 0.250 - 0s 4ms/step - loss: 0.6251 - accuracy: 0.6461 - recall_29: 0.3252 - precision_29: 0.2379\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.6475 - recall_29: 0.3246 - precision_29: 0.2329\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6500 - recall_29: 0.3231 - precision_29: 0.2362\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6531 - recall_29: 0.3077 - precision_29: 0.2317\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.6619 - recall_29: 0.3249 - precision_29: 0.2433\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.6571 - recall_29: 0.3130 - precision_29: 0.2445\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.6674 - recall_29: 0.3070 - precision_29: 0.2415\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.6687 - recall_29: 0.3007 - precision_29: 0.2382\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6702 - recall_29: 0.2985 - precision_29: 0.2428\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6713 - recall_29: 0.2885 - precision_29: 0.2476\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.6739 - recall_29: 0.2927 - precision_29: 0.2449\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6723 - recall_29: 0.2890 - precision_29: 0.2475\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.6825 - recall_29: 0.2883 - precision_29: 0.2539\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.6861 - recall_29: 0.2840 - precision_29: 0.2549\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.6817 - recall_29: 0.2776 - precision_29: 0.2536\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.6890 - recall_29: 0.2719 - precision_29: 0.2461\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6858 - recall_29: 0.2767 - precision_29: 0.2530\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5934 - accuracy: 0.6937 - recall_29: 0.2754 - precision_29: 0.2541\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.6988 - recall_29: 0.2661 - precision_29: 0.2620\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.6972 - recall_29: 0.2668 - precision_29: 0.2565\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.6982 - recall_29: 0.2605 - precision_29: 0.2575\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.7000 - recall_29: 0.2617 - precision_29: 0.2595\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.7010 - recall_29: 0.2556 - precision_29: 0.2585\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7018 - recall_29: 0.2531 - precision_29: 0.2562\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7094 - recall_29: 0.2583 - precision_29: 0.2729\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7071 - recall_29: 0.2430 - precision_29: 0.2610\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.7067 - recall_29: 0.2378 - precision_29: 0.2591\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7122 - recall_29: 0.2342 - precision_29: 0.2553\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.7108 - recall_29: 0.2373 - precision_29: 0.2670\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7146 - recall_29: 0.2366 - precision_29: 0.2658\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.7136 - recall_29: 0.2294 - precision_29: 0.2747\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7165 - recall_29: 0.2300 - precision_29: 0.2699\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.7175 - recall_29: 0.2302 - precision_29: 0.2730\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5723 - accuracy: 0.7201 - recall_29: 0.2266 - precision_29: 0.2693\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7204 - recall_29: 0.2212 - precision_29: 0.2698\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.7244 - recall_29: 0.2266 - precision_29: 0.2800\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7271 - recall_29: 0.2216 - precision_29: 0.2788\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7268 - recall_29: 0.2269 - precision_29: 0.2861\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.7250 - recall_29: 0.2151 - precision_29: 0.2689\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7273 - recall_29: 0.2118 - precision_29: 0.2808\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7321 - recall_29: 0.2045 - precision_29: 0.2768\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7319 - recall_29: 0.2073 - precision_29: 0.2805\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7306 - recall_29: 0.2064 - precision_29: 0.2840\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7313 - recall_29: 0.1945 - precision_29: 0.2755\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7360 - recall_29: 0.1944 - precision_29: 0.2769\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.7326 - recall_29: 0.1933 - precision_29: 0.2824\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.7384 - recall_29: 0.1943 - precision_29: 0.2830\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.7359 - recall_29: 0.1846 - precision_29: 0.2724\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7404 - recall_29: 0.1861 - precision_29: 0.2842\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.7384 - recall_29: 0.1723 - precision_29: 0.2675\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7404 - recall_29: 0.1801 - precision_29: 0.2801\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7396 - recall_29: 0.1737 - precision_29: 0.2817\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7458 - recall_29: 0.1809 - precision_29: 0.2920\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7436 - recall_29: 0.1729 - precision_29: 0.2844\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7445 - recall_29: 0.1712 - precision_29: 0.2806\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7482 - recall_29: 0.1720 - precision_29: 0.2912\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7446 - recall_29: 0.1650 - precision_29: 0.2888\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7461 - recall_29: 0.1612 - precision_29: 0.2767\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7520 - recall_29: 0.1629 - precision_29: 0.2999\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7491 - recall_29: 0.1619 - precision_29: 0.2936\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7563 - recall_29: 0.1645 - precision_29: 0.3127\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7531 - recall_29: 0.1564 - precision_29: 0.2961\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657F8D1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5464 - accuracy: 0.7523 - recall_29: 0.1356 - precision_29: 0.2735\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7035 - accuracy: 0.5345 - recall_30: 0.5952 - precision_30: 0.2385\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7007 - accuracy: 0.5357 - recall_30: 0.5854 - precision_30: 0.2378\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6987 - accuracy: 0.5398 - recall_30: 0.5892 - precision_30: 0.2380\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6956 - accuracy: 0.5465 - recall_30: 0.5823 - precision_30: 0.2436\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5438 - recall_30: 0.5651 - precision_30: 0.2350\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5562 - recall_30: 0.5660 - precision_30: 0.2442\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.5632 - recall_30: 0.5604 - precision_30: 0.2463\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.5649 - recall_30: 0.5600 - precision_30: 0.2439\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5723 - recall_30: 0.5564 - precision_30: 0.2534\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.5693 - recall_30: 0.5465 - precision_30: 0.2461\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.5814 - recall_30: 0.5577 - precision_30: 0.2504\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6771 - accuracy: 0.5725 - recall_30: 0.5051 - precision_30: 0.232 - 0s 4ms/step - loss: 0.6732 - accuracy: 0.5805 - recall_30: 0.5333 - precision_30: 0.2471\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.5898 - recall_30: 0.5476 - precision_30: 0.2613\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.5949 - recall_30: 0.5435 - precision_30: 0.2601\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.5956 - recall_30: 0.5424 - precision_30: 0.2617\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.6006 - recall_30: 0.5309 - precision_30: 0.2617\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.5996 - recall_30: 0.5154 - precision_30: 0.2540\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6046 - recall_30: 0.5133 - precision_30: 0.2604\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.6120 - recall_30: 0.5156 - precision_30: 0.2668\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6122 - recall_30: 0.4985 - precision_30: 0.2596\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6210 - recall_30: 0.5050 - precision_30: 0.2662\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6239 - recall_30: 0.5001 - precision_30: 0.2696\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6268 - recall_30: 0.4950 - precision_30: 0.2702\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6296 - recall_30: 0.4853 - precision_30: 0.2647\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.6343 - recall_30: 0.4930 - precision_30: 0.2753\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6368 - accuracy: 0.6372 - recall_30: 0.4867 - precision_30: 0.2787\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.6471 - recall_30: 0.4826 - precision_30: 0.2819\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6509 - recall_30: 0.4871 - precision_30: 0.2851\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6439 - recall_30: 0.4632 - precision_30: 0.2768\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6505 - recall_30: 0.4626 - precision_30: 0.2788\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.6572 - recall_30: 0.4614 - precision_30: 0.2839\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.6664 - recall_30: 0.4692 - precision_30: 0.2923\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6689 - recall_30: 0.4520 - precision_30: 0.2912\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.6722 - recall_30: 0.4504 - precision_30: 0.2981\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.6767 - recall_30: 0.4429 - precision_30: 0.2985\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.6811 - recall_30: 0.4418 - precision_30: 0.3050\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.6805 - recall_30: 0.4374 - precision_30: 0.3071\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.6852 - recall_30: 0.4352 - precision_30: 0.3089\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.6920 - recall_30: 0.4320 - precision_30: 0.3077\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.7030 - recall_30: 0.4367 - precision_30: 0.3194\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.7012 - recall_30: 0.4302 - precision_30: 0.3226\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.7067 - recall_30: 0.4349 - precision_30: 0.3284\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7120 - recall_30: 0.4288 - precision_30: 0.3341\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.7144 - recall_30: 0.4160 - precision_30: 0.3302\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.7133 - recall_30: 0.4061 - precision_30: 0.3324\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.7167 - recall_30: 0.4073 - precision_30: 0.3414\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.7215 - recall_30: 0.4002 - precision_30: 0.3362\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.7191 - recall_30: 0.3955 - precision_30: 0.3340\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5881 - accuracy: 0.7262 - recall_30: 0.3986 - precision_30: 0.3430\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.7225 - recall_30: 0.3821 - precision_30: 0.3385\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.7296 - recall_30: 0.3822 - precision_30: 0.3484\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.7260 - recall_30: 0.3743 - precision_30: 0.3379\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.7360 - recall_30: 0.3744 - precision_30: 0.3571\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.7355 - recall_30: 0.3717 - precision_30: 0.3535\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.7391 - recall_30: 0.3698 - precision_30: 0.3533\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7441 - recall_30: 0.3698 - precision_30: 0.3602\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5806 - accuracy: 0.7380 - recall_30: 0.3511 - precision_30: 0.339 - 0s 3ms/step - loss: 0.5777 - accuracy: 0.7410 - recall_30: 0.3563 - precision_30: 0.3551\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7425 - recall_30: 0.3593 - precision_30: 0.3686\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7474 - recall_30: 0.3543 - precision_30: 0.3772\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.7438 - recall_30: 0.3516 - precision_30: 0.3666\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7476 - recall_30: 0.3402 - precision_30: 0.3620\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.7522 - recall_30: 0.3395 - precision_30: 0.3741\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5651 - accuracy: 0.7553 - recall_30: 0.3451 - precision_30: 0.3799\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.7529 - recall_30: 0.3258 - precision_30: 0.3753\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.7567 - recall_30: 0.3309 - precision_30: 0.3878\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7603 - recall_30: 0.3286 - precision_30: 0.3899\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.7585 - recall_30: 0.3174 - precision_30: 0.3843\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7588 - recall_30: 0.3142 - precision_30: 0.3856\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.7684 - recall_30: 0.3101 - precision_30: 0.3947\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7699 - recall_30: 0.3208 - precision_30: 0.4025\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7636 - recall_30: 0.3024 - precision_30: 0.3911\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7663 - recall_30: 0.3086 - precision_30: 0.4044\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.7679 - recall_30: 0.3068 - precision_30: 0.4006\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7713 - recall_30: 0.3034 - precision_30: 0.4086\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.7716 - recall_30: 0.3072 - precision_30: 0.4232\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7756 - recall_30: 0.2973 - precision_30: 0.4276\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7745 - recall_30: 0.2973 - precision_30: 0.4271\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7781 - recall_30: 0.2904 - precision_30: 0.4387\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7758 - recall_30: 0.2834 - precision_30: 0.4116\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7823 - recall_30: 0.2926 - precision_30: 0.4397\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7850 - recall_30: 0.2897 - precision_30: 0.4363\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7828 - recall_30: 0.2817 - precision_30: 0.4397\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7871 - recall_30: 0.2898 - precision_30: 0.4431\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7820 - recall_30: 0.2813 - precision_30: 0.4437\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7867 - recall_30: 0.2678 - precision_30: 0.4461\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7878 - recall_30: 0.2823 - precision_30: 0.4578\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7861 - recall_30: 0.2750 - precision_30: 0.4615\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7872 - recall_30: 0.2753 - precision_30: 0.4665\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7894 - recall_30: 0.2784 - precision_30: 0.4697\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7898 - recall_30: 0.2786 - precision_30: 0.4736\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7917 - recall_30: 0.2691 - precision_30: 0.4809\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7969 - recall_30: 0.2784 - precision_30: 0.4946\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7978 - recall_30: 0.2755 - precision_30: 0.4881\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7945 - recall_30: 0.2653 - precision_30: 0.4960\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7957 - recall_30: 0.2663 - precision_30: 0.4878\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7983 - recall_30: 0.2637 - precision_30: 0.5017\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7961 - recall_30: 0.2531 - precision_30: 0.4886\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7975 - recall_30: 0.2549 - precision_30: 0.4976\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7974 - recall_30: 0.2507 - precision_30: 0.4996\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.8007 - recall_30: 0.2595 - precision_30: 0.5094\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580A58B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7947 - recall_30: 0.2474 - precision_30: 0.4875\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7291 - accuracy: 0.4597 - recall_31: 0.4227 - precision_31: 0.1657\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7267 - accuracy: 0.4604 - recall_31: 0.4248 - precision_31: 0.1664\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7275 - accuracy: 0.4586 - recall_31: 0.4060 - precision_31: 0.1643\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.4609 - recall_31: 0.4045 - precision_31: 0.1641\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7218 - accuracy: 0.4658 - recall_31: 0.3996 - precision_31: 0.1667\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7211 - accuracy: 0.4685 - recall_31: 0.3937 - precision_31: 0.1646\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7179 - accuracy: 0.4750 - recall_31: 0.4073 - precision_31: 0.1688\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7148 - accuracy: 0.4809 - recall_31: 0.3939 - precision_31: 0.1695\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7127 - accuracy: 0.4825 - recall_31: 0.3957 - precision_31: 0.1675\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7116 - accuracy: 0.4807 - recall_31: 0.3798 - precision_31: 0.1603\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7088 - accuracy: 0.4883 - recall_31: 0.3831 - precision_31: 0.1635\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.4867 - recall_31: 0.3808 - precision_31: 0.1651\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7051 - accuracy: 0.4889 - recall_31: 0.3746 - precision_31: 0.1642\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7033 - accuracy: 0.4975 - recall_31: 0.3691 - precision_31: 0.1642\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7000 - accuracy: 0.5016 - recall_31: 0.3672 - precision_31: 0.1657\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6975 - accuracy: 0.5076 - recall_31: 0.3748 - precision_31: 0.1683\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6981 - accuracy: 0.5087 - recall_31: 0.3710 - precision_31: 0.1739\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.5109 - recall_31: 0.3568 - precision_31: 0.1685\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.5120 - recall_31: 0.3527 - precision_31: 0.1669\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.5194 - recall_31: 0.3526 - precision_31: 0.1683\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.5230 - recall_31: 0.3488 - precision_31: 0.1667\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5297 - recall_31: 0.3479 - precision_31: 0.1732\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5357 - recall_31: 0.3433 - precision_31: 0.1772\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5360 - recall_31: 0.3333 - precision_31: 0.1711\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6798 - accuracy: 0.5410 - recall_31: 0.3336 - precision_31: 0.1733\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6799 - accuracy: 0.5426 - recall_31: 0.3211 - precision_31: 0.1657\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.5491 - recall_31: 0.3286 - precision_31: 0.1742\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6774 - accuracy: 0.5436 - recall_31: 0.3079 - precision_31: 0.1620\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.5540 - recall_31: 0.3198 - precision_31: 0.1751\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.5522 - recall_31: 0.3098 - precision_31: 0.1714\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6707 - accuracy: 0.5585 - recall_31: 0.3137 - precision_31: 0.1708\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.5631 - recall_31: 0.3088 - precision_31: 0.1746\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.5645 - recall_31: 0.3039 - precision_31: 0.1732\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.5630 - recall_31: 0.2944 - precision_31: 0.1724\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.5702 - recall_31: 0.2996 - precision_31: 0.1706\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.5771 - recall_31: 0.2941 - precision_31: 0.1737\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.5789 - recall_31: 0.2879 - precision_31: 0.1721\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.5794 - recall_31: 0.2696 - precision_31: 0.1648\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.5860 - recall_31: 0.2778 - precision_31: 0.1714\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.5935 - recall_31: 0.2780 - precision_31: 0.1739\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.5948 - recall_31: 0.2788 - precision_31: 0.1778\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.5909 - recall_31: 0.2747 - precision_31: 0.1782\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6505 - accuracy: 0.6008 - recall_31: 0.2687 - precision_31: 0.1779\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6037 - recall_31: 0.2655 - precision_31: 0.1799\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6059 - recall_31: 0.2622 - precision_31: 0.1800\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.6117 - recall_31: 0.2683 - precision_31: 0.1858\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6182 - recall_31: 0.2530 - precision_31: 0.1823\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.6167 - recall_31: 0.2504 - precision_31: 0.1773\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6160 - recall_31: 0.2441 - precision_31: 0.1804\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.6259 - recall_31: 0.2387 - precision_31: 0.1804\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.6289 - recall_31: 0.2437 - precision_31: 0.1866\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.6302 - recall_31: 0.2309 - precision_31: 0.1786\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6367 - recall_31: 0.2274 - precision_31: 0.1799\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.6438 - recall_31: 0.2316 - precision_31: 0.1899\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6446 - recall_31: 0.2253 - precision_31: 0.1863\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6430 - recall_31: 0.2141 - precision_31: 0.1800\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.6498 - recall_31: 0.2168 - precision_31: 0.1895\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6538 - recall_31: 0.2137 - precision_31: 0.1876\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.6563 - recall_31: 0.2078 - precision_31: 0.1895\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6583 - recall_31: 0.2048 - precision_31: 0.1904\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.6643 - recall_31: 0.2045 - precision_31: 0.1950\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.6710 - recall_31: 0.2143 - precision_31: 0.2041\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6684 - recall_31: 0.2061 - precision_31: 0.1991\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.6706 - recall_31: 0.2048 - precision_31: 0.2003\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.6710 - recall_31: 0.1891 - precision_31: 0.1890\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.6730 - recall_31: 0.1858 - precision_31: 0.1854\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.6785 - recall_31: 0.1838 - precision_31: 0.1947\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6821 - recall_31: 0.1834 - precision_31: 0.1922\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6142 - accuracy: 0.6859 - recall_31: 0.1822 - precision_31: 0.1995\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.6934 - recall_31: 0.1853 - precision_31: 0.2084\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.6937 - recall_31: 0.1748 - precision_31: 0.2062\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.6918 - recall_31: 0.1730 - precision_31: 0.1972\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6073 - accuracy: 0.6961 - recall_31: 0.1679 - precision_31: 0.1970\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.6941 - recall_31: 0.1600 - precision_31: 0.1947\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.7036 - recall_31: 0.1604 - precision_31: 0.2000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.7025 - recall_31: 0.1654 - precision_31: 0.2076\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.7045 - recall_31: 0.1610 - precision_31: 0.2096\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.7080 - recall_31: 0.1571 - precision_31: 0.2089\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.7110 - recall_31: 0.1509 - precision_31: 0.2115\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.7135 - recall_31: 0.1449 - precision_31: 0.2071\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.7161 - recall_31: 0.1555 - precision_31: 0.2208\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.7145 - recall_31: 0.1414 - precision_31: 0.2111\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7173 - recall_31: 0.1459 - precision_31: 0.2151\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.7211 - recall_31: 0.1380 - precision_31: 0.2083\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.7246 - recall_31: 0.1325 - precision_31: 0.2069\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.7265 - recall_31: 0.1390 - precision_31: 0.2207\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.7272 - recall_31: 0.1351 - precision_31: 0.2061\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.7303 - recall_31: 0.1315 - precision_31: 0.2219\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7320 - recall_31: 0.1240 - precision_31: 0.2105\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7320 - recall_31: 0.1207 - precision_31: 0.2189\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.7352 - recall_31: 0.1161 - precision_31: 0.2203\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5891 - accuracy: 0.7386 - recall_31: 0.1122 - precision_31: 0.2204\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.7422 - recall_31: 0.1129 - precision_31: 0.2273\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7435 - recall_31: 0.1104 - precision_31: 0.2244\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7436 - recall_31: 0.1041 - precision_31: 0.2213\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7471 - recall_31: 0.1083 - precision_31: 0.2320\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7500 - recall_31: 0.1079 - precision_31: 0.2402\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.7549 - recall_31: 0.1080 - precision_31: 0.2450\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7535 - recall_31: 0.0974 - precision_31: 0.2214\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7567 - recall_31: 0.1042 - precision_31: 0.2481\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5783 - accuracy: 0.7472 - recall_31: 0.0825 - precision_31: 0.2000\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7078 - accuracy: 0.4646 - recall_32: 0.4276 - precision_32: 0.1733\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.4704 - recall_32: 0.4151 - precision_32: 0.1686\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7051 - accuracy: 0.4731 - recall_32: 0.4217 - precision_32: 0.1768\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7035 - accuracy: 0.4769 - recall_32: 0.4108 - precision_32: 0.1677\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7025 - accuracy: 0.4812 - recall_32: 0.4084 - precision_32: 0.1686\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7012 - accuracy: 0.4826 - recall_32: 0.3903 - precision_32: 0.1669\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7006 - accuracy: 0.4870 - recall_32: 0.3912 - precision_32: 0.1685\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.4949 - recall_32: 0.3914 - precision_32: 0.1744\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6975 - accuracy: 0.4940 - recall_32: 0.3824 - precision_32: 0.1699\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.4996 - recall_32: 0.3691 - precision_32: 0.1664\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6961 - accuracy: 0.5033 - recall_32: 0.3734 - precision_32: 0.1703\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5141 - recall_32: 0.3653 - precision_32: 0.1682\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5194 - recall_32: 0.3635 - precision_32: 0.1746\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.5212 - recall_32: 0.3611 - precision_32: 0.1772\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.5274 - recall_32: 0.3501 - precision_32: 0.1718\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5275 - recall_32: 0.3438 - precision_32: 0.1727\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.5323 - recall_32: 0.3519 - precision_32: 0.1765\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5298 - recall_32: 0.3256 - precision_32: 0.1644\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.5426 - recall_32: 0.3367 - precision_32: 0.1731\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.5444 - recall_32: 0.3321 - precision_32: 0.1745\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5476 - recall_32: 0.3120 - precision_32: 0.1667\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.5497 - recall_32: 0.3108 - precision_32: 0.1653\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.5628 - recall_32: 0.3028 - precision_32: 0.1718\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.5591 - recall_32: 0.3000 - precision_32: 0.1667\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.5633 - recall_32: 0.2866 - precision_32: 0.1663\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.5742 - recall_32: 0.2888 - precision_32: 0.1741\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.5770 - recall_32: 0.2908 - precision_32: 0.1777\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.5777 - recall_32: 0.2797 - precision_32: 0.1719\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5897 - recall_32: 0.2840 - precision_32: 0.1824\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.5938 - recall_32: 0.2751 - precision_32: 0.1766\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.5985 - recall_32: 0.2794 - precision_32: 0.1785\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.6026 - recall_32: 0.2733 - precision_32: 0.1827\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.6089 - recall_32: 0.2624 - precision_32: 0.1818\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.6128 - recall_32: 0.2582 - precision_32: 0.1805\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.6120 - recall_32: 0.2551 - precision_32: 0.1832\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6218 - recall_32: 0.2417 - precision_32: 0.1802\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.6238 - recall_32: 0.2386 - precision_32: 0.1773\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.6272 - recall_32: 0.2279 - precision_32: 0.1752\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6657 - accuracy: 0.6306 - recall_32: 0.2273 - precision_32: 0.1757\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6363 - recall_32: 0.2190 - precision_32: 0.1724\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.6393 - recall_32: 0.2180 - precision_32: 0.1802\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.6385 - recall_32: 0.2063 - precision_32: 0.1732\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.6572 - recall_32: 0.2036 - precision_32: 0.1830\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.6536 - recall_32: 0.1907 - precision_32: 0.1716\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.6577 - recall_32: 0.1914 - precision_32: 0.1834\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6665 - recall_32: 0.1896 - precision_32: 0.1793\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.6632 - recall_32: 0.1773 - precision_32: 0.1738\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.6662 - recall_32: 0.1753 - precision_32: 0.1760\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.6719 - recall_32: 0.1808 - precision_32: 0.1855\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.6744 - recall_32: 0.1779 - precision_32: 0.1836\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.6789 - recall_32: 0.1698 - precision_32: 0.1814\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6841 - recall_32: 0.1637 - precision_32: 0.1784\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.6842 - recall_32: 0.1630 - precision_32: 0.1861\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6505 - accuracy: 0.6896 - recall_32: 0.1550 - precision_32: 0.1777\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6953 - recall_32: 0.1678 - precision_32: 0.2006\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.6916 - recall_32: 0.1488 - precision_32: 0.1779\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.6953 - recall_32: 0.1456 - precision_32: 0.1836\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.7004 - recall_32: 0.1475 - precision_32: 0.1945\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.7033 - recall_32: 0.1402 - precision_32: 0.1898\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.7078 - recall_32: 0.1280 - precision_32: 0.1762\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.7085 - recall_32: 0.1313 - precision_32: 0.1868\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.7099 - recall_32: 0.1247 - precision_32: 0.1865\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.7161 - recall_32: 0.1275 - precision_32: 0.1970\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.7144 - recall_32: 0.1212 - precision_32: 0.1909\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.7198 - recall_32: 0.1276 - precision_32: 0.1967\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7202 - recall_32: 0.1167 - precision_32: 0.1903\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.7230 - recall_32: 0.1180 - precision_32: 0.1961\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.7256 - recall_32: 0.1204 - precision_32: 0.2017\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6373 - accuracy: 0.7330 - recall_32: 0.1153 - precision_32: 0.202 - 0s 4ms/step - loss: 0.6376 - accuracy: 0.7283 - recall_32: 0.1098 - precision_32: 0.1933\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.7276 - recall_32: 0.1121 - precision_32: 0.2021\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.7281 - recall_32: 0.1032 - precision_32: 0.1924\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.7351 - recall_32: 0.1058 - precision_32: 0.2005\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7367 - recall_32: 0.1051 - precision_32: 0.2033\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7349 - recall_32: 0.1095 - precision_32: 0.2142\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.7366 - recall_32: 0.1082 - precision_32: 0.2243\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.7467 - recall_32: 0.1055 - precision_32: 0.2242\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.7445 - recall_32: 0.1014 - precision_32: 0.2190\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7440 - recall_32: 0.1022 - precision_32: 0.2268\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6302 - accuracy: 0.7460 - recall_32: 0.0991 - precision_32: 0.2168\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.7530 - recall_32: 0.0946 - precision_32: 0.2117\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.7502 - recall_32: 0.0909 - precision_32: 0.2177\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.7531 - recall_32: 0.0848 - precision_32: 0.2107\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.7507 - recall_32: 0.0844 - precision_32: 0.2097\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.7562 - recall_32: 0.0790 - precision_32: 0.2141\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6256 - accuracy: 0.7549 - recall_32: 0.0801 - precision_32: 0.2140\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.7592 - recall_32: 0.0785 - precision_32: 0.2286\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.7600 - recall_32: 0.0747 - precision_32: 0.2280\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.7633 - recall_32: 0.0724 - precision_32: 0.2206\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.7646 - recall_32: 0.0733 - precision_32: 0.2199\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.7550 - recall_32: 0.0650 - precision_32: 0.2085\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.7668 - recall_32: 0.0624 - precision_32: 0.2156\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.7662 - recall_32: 0.0631 - precision_32: 0.2208\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6205 - accuracy: 0.7636 - recall_32: 0.0630 - precision_32: 0.2277\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.7652 - recall_32: 0.0623 - precision_32: 0.2309\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.7670 - recall_32: 0.0606 - precision_32: 0.2346\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6175 - accuracy: 0.7697 - recall_32: 0.0613 - precision_32: 0.2348\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6158 - accuracy: 0.7722 - recall_32: 0.0555 - precision_32: 0.2341\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.7698 - recall_32: 0.0551 - precision_32: 0.2323\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6155 - accuracy: 0.7697 - recall_32: 0.0502 - precision_32: 0.2174\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.7735 - recall_32: 0.0491 - precision_32: 0.2196\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA11F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.6140 - accuracy: 0.7711 - recall_32: 0.0508 - precision_32: 0.2182\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6886 - accuracy: 0.5663 - recall_33: 0.6193 - precision_33: 0.2630\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.5739 - recall_33: 0.6171 - precision_33: 0.2606\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.5747 - recall_33: 0.6130 - precision_33: 0.2608\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5785 - recall_33: 0.6119 - precision_33: 0.2648\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.5729 - recall_33: 0.6020 - precision_33: 0.2560\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.5782 - recall_33: 0.5970 - precision_33: 0.2654\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6806 - accuracy: 0.5787 - recall_33: 0.6057 - precision_33: 0.2648\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.5783 - recall_33: 0.5997 - precision_33: 0.2637\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.5837 - recall_33: 0.5907 - precision_33: 0.2634\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.5846 - recall_33: 0.5975 - precision_33: 0.2653\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.5801 - recall_33: 0.5719 - precision_33: 0.2578\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.5853 - recall_33: 0.5832 - precision_33: 0.2632\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.5875 - recall_33: 0.5682 - precision_33: 0.2610\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.5907 - recall_33: 0.5790 - precision_33: 0.2630\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.5922 - recall_33: 0.5753 - precision_33: 0.2630\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.5847 - recall_33: 0.5726 - precision_33: 0.2622\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.5956 - recall_33: 0.5631 - precision_33: 0.2634\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.5950 - recall_33: 0.5730 - precision_33: 0.2646\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.5944 - recall_33: 0.5619 - precision_33: 0.2652\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.5958 - recall_33: 0.5528 - precision_33: 0.2602\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.6025 - recall_33: 0.5640 - precision_33: 0.2693\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.5966 - recall_33: 0.5545 - precision_33: 0.2681\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.6038 - recall_33: 0.5543 - precision_33: 0.2650\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.6055 - recall_33: 0.5488 - precision_33: 0.2691\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6050 - recall_33: 0.5445 - precision_33: 0.2671\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 0.6039 - recall_33: 0.5426 - precision_33: 0.2684\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.6044 - recall_33: 0.5318 - precision_33: 0.2640\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.6069 - recall_33: 0.5288 - precision_33: 0.2639\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.6076 - recall_33: 0.5307 - precision_33: 0.2615\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.6135 - recall_33: 0.5258 - precision_33: 0.2692\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6120 - recall_33: 0.5232 - precision_33: 0.2680\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.6158 - recall_33: 0.5204 - precision_33: 0.2685\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.6202 - recall_33: 0.5298 - precision_33: 0.2725\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6174 - recall_33: 0.5218 - precision_33: 0.2694\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.6200 - recall_33: 0.5122 - precision_33: 0.2721\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6217 - recall_33: 0.5192 - precision_33: 0.2713\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.6200 - recall_33: 0.5157 - precision_33: 0.2710\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.6248 - recall_33: 0.5134 - precision_33: 0.2736\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6462 - accuracy: 0.6233 - recall_33: 0.4983 - precision_33: 0.2696\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6233 - recall_33: 0.5004 - precision_33: 0.2725\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6285 - recall_33: 0.5033 - precision_33: 0.2674\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.6249 - recall_33: 0.4954 - precision_33: 0.2660\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.6290 - recall_33: 0.4842 - precision_33: 0.2652\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6313 - recall_33: 0.4976 - precision_33: 0.2752\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6341 - recall_33: 0.5019 - precision_33: 0.2745\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.6406 - recall_33: 0.4925 - precision_33: 0.2754\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6436 - accuracy: 0.6260 - recall_33: 0.4916 - precision_33: 0.275 - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6332 - recall_33: 0.4894 - precision_33: 0.2752\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6368 - recall_33: 0.4883 - precision_33: 0.2773\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.6406 - recall_33: 0.4833 - precision_33: 0.2769\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6394 - recall_33: 0.4767 - precision_33: 0.2717\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.6436 - recall_33: 0.4833 - precision_33: 0.2780\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.6451 - recall_33: 0.4817 - precision_33: 0.2837\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6434 - recall_33: 0.4660 - precision_33: 0.2757\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6447 - recall_33: 0.4613 - precision_33: 0.2734\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.6416 - recall_33: 0.4561 - precision_33: 0.2708\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.6470 - recall_33: 0.4590 - precision_33: 0.2732\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6504 - recall_33: 0.4677 - precision_33: 0.2778\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6524 - recall_33: 0.4671 - precision_33: 0.2836\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.6509 - recall_33: 0.4605 - precision_33: 0.2801\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.6528 - recall_33: 0.4536 - precision_33: 0.2764\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6499 - recall_33: 0.4515 - precision_33: 0.2768\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6564 - recall_33: 0.4507 - precision_33: 0.2802\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.6523 - recall_33: 0.4500 - precision_33: 0.2836\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.6592 - recall_33: 0.4457 - precision_33: 0.2811\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.6566 - recall_33: 0.4497 - precision_33: 0.2821\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.6540 - recall_33: 0.4301 - precision_33: 0.2761\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6575 - recall_33: 0.4439 - precision_33: 0.2796\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6610 - recall_33: 0.4294 - precision_33: 0.2812\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6224 - accuracy: 0.6549 - recall_33: 0.4238 - precision_33: 0.2708\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6611 - recall_33: 0.4398 - precision_33: 0.2827\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.6622 - recall_33: 0.4340 - precision_33: 0.2846\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.6659 - recall_33: 0.4326 - precision_33: 0.2919\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.6638 - recall_33: 0.4136 - precision_33: 0.2736\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.6690 - recall_33: 0.4236 - precision_33: 0.2887\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6698 - recall_33: 0.4193 - precision_33: 0.2832\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.6721 - recall_33: 0.4150 - precision_33: 0.2844\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.6756 - recall_33: 0.4191 - precision_33: 0.2878\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.6699 - recall_33: 0.4142 - precision_33: 0.2851\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.6722 - recall_33: 0.4041 - precision_33: 0.2898\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.6739 - recall_33: 0.4057 - precision_33: 0.2894\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6764 - recall_33: 0.4061 - precision_33: 0.2852\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6771 - recall_33: 0.4013 - precision_33: 0.2866\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.6791 - recall_33: 0.3935 - precision_33: 0.2897\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.6781 - recall_33: 0.3906 - precision_33: 0.2845\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6804 - recall_33: 0.3931 - precision_33: 0.2888\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6814 - recall_33: 0.3888 - precision_33: 0.2805\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.6859 - recall_33: 0.3836 - precision_33: 0.2856\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6058 - accuracy: 0.6863 - recall_33: 0.3898 - precision_33: 0.2906\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.6850 - recall_33: 0.3970 - precision_33: 0.2982\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6826 - recall_33: 0.3796 - precision_33: 0.2840\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6852 - recall_33: 0.3764 - precision_33: 0.2900\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.6879 - recall_33: 0.3866 - precision_33: 0.2918\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.6885 - recall_33: 0.3828 - precision_33: 0.2958\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.6941 - recall_33: 0.3746 - precision_33: 0.3004\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.6951 - recall_33: 0.3741 - precision_33: 0.2981\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.6966 - recall_33: 0.3765 - precision_33: 0.2997\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.6945 - recall_33: 0.3654 - precision_33: 0.2945\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.6939 - recall_33: 0.3710 - precision_33: 0.2900\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.6965 - recall_33: 0.3625 - precision_33: 0.2991\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.6980 - recall_33: 0.3614 - precision_33: 0.2991\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C585550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.6032 - accuracy: 0.6850 - recall_33: 0.3805 - precision_33: 0.2894\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.5818 - accuracy: 0.7997 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7970 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7960 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7984 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7929 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7995 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.7969 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7981 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7990 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7958 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7965 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.7948 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7984 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7970 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7963 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7977 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7972 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7991 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.7977 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.8004 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7980 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7980 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7955 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.7936 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7995 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7930 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7969 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7974 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.8015 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7982 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7992 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7990 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7993 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7972 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7997 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7962 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7987 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7960 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.8004 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7966 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7994 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7938 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.8007 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7992 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7945 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7972 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7974 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7970 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7959 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7952 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7974 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7971 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7976 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7952 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.8007 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7993 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7994 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.8020 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7977 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7950 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7982 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7967 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7977 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7975 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7946 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7955 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7914 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7959 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7987 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7979 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7999 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7995 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.8007 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7965 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.8013 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8020 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7977 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7957 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.8007 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7944 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7972 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7988 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7995 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7995 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7932 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.8004 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7988 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7986 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7975 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.8003 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7969 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.8005 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5026 - accuracy: 0.7980 - recall_34: 0.0000e+00 - precision_34: 0.0000e+0 - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7976 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7984 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7962 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7943 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7977 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7962 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7967 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7964 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA18B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.7973 - recall_34: 0.0000e+00 - precision_34: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8216 - accuracy: 0.2025 - recall_35: 1.0000 - precision_35: 0.2025\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8107 - accuracy: 0.2028 - recall_35: 1.0000 - precision_35: 0.2028\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7997 - accuracy: 0.2035 - recall_35: 1.0000 - precision_35: 0.2035\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7899 - accuracy: 0.2017 - recall_35: 1.0000 - precision_35: 0.2017\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7804 - accuracy: 0.1995 - recall_35: 1.0000 - precision_35: 0.1995\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7702 - accuracy: 0.2024 - recall_35: 1.0000 - precision_35: 0.2024\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7607 - accuracy: 0.2026 - recall_35: 1.0000 - precision_35: 0.2026\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7509 - accuracy: 0.2052 - recall_35: 1.0000 - precision_35: 0.2052\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7427 - accuracy: 0.2036 - recall_35: 1.0000 - precision_35: 0.2034\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7349 - accuracy: 0.2046 - recall_35: 1.0000 - precision_35: 0.2018\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.2193 - recall_35: 0.9964 - precision_35: 0.2068\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7188 - accuracy: 0.2439 - recall_35: 0.9812 - precision_35: 0.2089\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7116 - accuracy: 0.2916 - recall_35: 0.9552 - precision_35: 0.2139\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7042 - accuracy: 0.3704 - recall_35: 0.9110 - precision_35: 0.2325\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.4669 - recall_35: 0.8357 - precision_35: 0.2522\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.5491 - recall_35: 0.7261 - precision_35: 0.2710\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.6289 - recall_35: 0.5917 - precision_35: 0.2966\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.6855 - recall_35: 0.4597 - precision_35: 0.3176\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.7403 - recall_35: 0.3270 - precision_35: 0.3450\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.7718 - recall_35: 0.2075 - precision_35: 0.3737\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.7864 - recall_35: 0.1177 - precision_35: 0.3940\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.7916 - recall_35: 0.0599 - precision_35: 0.4186\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.7986 - recall_35: 0.0257 - precision_35: 0.4731\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7974 - recall_35: 0.0065 - precision_35: 0.3139\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.7960 - recall_35: 0.0051 - precision_35: 0.6220\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7944 - recall_35: 0.0023 - precision_35: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.7968 - recall_35: 0.0014 - precision_35: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.7980 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7985 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.7975 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.7961 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.7970 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.7948 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.8022 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.7973 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.7921 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7954 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.8000 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7998 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7988 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7976 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.7981 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7996 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.7965 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7969 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7973 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7980 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7968 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7966 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7986 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7978 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7988 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7951 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7997 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7957 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7971 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7962 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7958 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7941 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7990 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7942 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7963 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7956 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7960 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7987 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7965 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7955 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7963 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7955 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7957 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7951 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.8010 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7953 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7956 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7942 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7982 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7970 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7983 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7985 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7999 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7963 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7968 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7941 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7983 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7957 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7947 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7970 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7933 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7958 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7982 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7974 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7977 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7963 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7965 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7981 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.8008 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7952 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7955 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7954 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7975 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AD0BAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5119 - accuracy: 0.7977 - recall_35: 0.0000e+00 - precision_35: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7427 - accuracy: 0.2008 - recall_36: 1.0000 - precision_36: 0.2007\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7322 - accuracy: 0.2079 - recall_36: 1.0000 - precision_36: 0.2055\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7239 - accuracy: 0.2206 - recall_36: 0.9912 - precision_36: 0.2036\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7148 - accuracy: 0.2780 - recall_36: 0.9646 - precision_36: 0.2164\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.3608 - recall_36: 0.9161 - precision_36: 0.2289\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.4463 - recall_36: 0.8447 - precision_36: 0.2463\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5279 - recall_36: 0.7412 - precision_36: 0.2648\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.6125 - recall_36: 0.5894 - precision_36: 0.2826\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.7051 - recall_36: 0.4175 - precision_36: 0.3230\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.7575 - recall_36: 0.2146 - precision_36: 0.3584\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.7917 - recall_36: 0.0767 - precision_36: 0.3974\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.7967 - recall_36: 0.0291 - precision_36: 0.6422\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.8003 - recall_36: 0.0030 - precision_36: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.7999 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.7989 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.7977 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.7968 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6239 - accuracy: 0.7976 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.7994 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.7986 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.7976 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.7952 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.7983 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7997 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.8000 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5909 - accuracy: 0.8009 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.8010 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7931 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.7945 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.7986 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7994 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.7956 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7991 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7978 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.8006 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7971 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7956 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7963 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7943 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7970 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7986 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7957 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7968 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.7967 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7987 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7953 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7968 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7976 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7994 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7990 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7984 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7949 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7966 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7966 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7978 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7983 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7986 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7994 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.8007 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.8005 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7914 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.8020 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7979 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7955 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7983 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7964 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7957 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7994 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7954 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7983 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7969 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7971 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7978 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7994 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7946 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7981 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7972 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7948 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7988 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7999 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7961 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7956 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7934 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7975 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7989 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7966 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7965 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7964 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8009 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.8003 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7971 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7961 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7976 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.8001 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7966 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.8000 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.8006 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7924 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7975 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7996 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AD25700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7973 - recall_36: 0.0000e+00 - precision_36: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.5353 - accuracy: 0.7949 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7964 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7987 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7948 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7999 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7973 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7995 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7985 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.8002 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7967 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7938 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7968 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7969 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7994 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7950 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.8024 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7955 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7984 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7979 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7951 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.8012 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7945 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7988 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7957 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7912 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7923 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.7930 - recall_37: 0.0000e+00 - precision_37: 0.0000e+0 - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7948 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7984 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.8015 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7940 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7975 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.8004 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7992 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7978 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7981 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7949 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7998 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.8009 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.8021 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7952 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7988 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7947 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7949 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.7930 - recall_37: 0.0000e+00 - precision_37: 0.0000e+0 - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7964 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7995 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7948 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7947 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7986 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7966 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7959 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7978 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7981 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.8012 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7944 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7975 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.8009 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7970 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7988 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7996 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7939 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7955 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7991 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.8012 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7941 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7957 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7959 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7989 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7974 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7967 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.8010 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7985 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7937 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.8005 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7965 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7986 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7939 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.8003 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7991 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7976 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7968 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7986 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7960 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7953 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7979 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7942 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7979 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7947 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7969 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7969 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7982 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7947 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7952 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7971 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.8010 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7974 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7976 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7987 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7946 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7988 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7946 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A969D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7973 - recall_37: 0.0000e+00 - precision_37: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.5561 - accuracy: 0.7920 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7976 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.8012 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5542 - accuracy: 0.7935 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7994 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7949 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7987 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7992 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7960 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7963 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7984 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7990 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7976 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7962 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5499 - accuracy: 0.7951 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7960 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7966 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7956 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7979 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7977 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7952 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7960 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5505 - accuracy: 0.7910 - recall_38: 0.0000e+00 - precision_38: 0.0000e+0 - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7962 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7965 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7978 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7978 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7973 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7983 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7980 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7992 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7971 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7935 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7982 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7950 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7975 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7960 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7951 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7978 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7962 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7965 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7948 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7970 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7997 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7952 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7982 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7967 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7998 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7962 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.8022 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7980 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7992 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7955 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7977 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7968 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.8005 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.8024 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7982 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7990 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7971 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7968 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7973 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.8007 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7983 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7975 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7955 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7991 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7975 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7963 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7982 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7953 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7967 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7953 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7985 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7956 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7962 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7964 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7985 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7980 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7961 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7988 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7980 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7979 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7991 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7947 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7968 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7976 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7975 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7962 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7983 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7997 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7992 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7960 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7980 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7962 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7957 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7968 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.8007 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7983 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7990 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7949 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C1D25E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7977 - recall_38: 0.0000e+00 - precision_38: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.7978 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7997 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7963 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7941 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7969 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7959 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7993 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7984 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7996 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7982 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7976 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7987 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7949 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.8025 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.8021 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7941 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7943 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7963 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.7989 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7963 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7951 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7987 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.8000 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7995 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7969 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7964 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7960 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7993 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7975 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7973 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7973 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.8001 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7987 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7974 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7981 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7976 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7966 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7953 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.8011 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.7975 - recall_39: 0.0000e+00 - precision_39: 0.0000e+0 - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7978 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7993 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7986 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7973 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7984 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7985 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7971 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7948 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7961 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.7996 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7988 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7973 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7977 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7969 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7988 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7988 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7961 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.8010 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7948 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7987 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7954 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.8002 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7962 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.8023 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7959 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7967 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7963 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.8013 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7947 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7977 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7989 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7979 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7929 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.7989 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7977 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7955 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7972 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7943 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.8006 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7961 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7975 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7978 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7969 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7958 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7974 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5132 - accuracy: 0.7963 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7987 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7968 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7963 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.8007 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7978 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7957 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7983 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7958 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.8006 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7938 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7972 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7981 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7971 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7975 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7996 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5115 - accuracy: 0.7973 - recall_39: 0.0000e+00 - precision_39: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7028 - accuracy: 0.5225 - recall_40: 0.5817 - precision_40: 0.2305\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.5306 - recall_40: 0.5752 - precision_40: 0.2294\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6992 - accuracy: 0.5326 - recall_40: 0.5761 - precision_40: 0.2325\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6983 - accuracy: 0.5314 - recall_40: 0.5686 - precision_40: 0.2306\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6966 - accuracy: 0.5362 - recall_40: 0.5776 - precision_40: 0.2326\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5420 - recall_40: 0.5732 - precision_40: 0.2384\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5385 - recall_40: 0.5521 - precision_40: 0.2320\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5418 - recall_40: 0.5535 - precision_40: 0.2328\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.5455 - recall_40: 0.5548 - precision_40: 0.2358\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.5547 - recall_40: 0.5527 - precision_40: 0.2414\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5556 - recall_40: 0.5614 - precision_40: 0.2403\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5538 - recall_40: 0.5398 - precision_40: 0.2320\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.5635 - recall_40: 0.5466 - precision_40: 0.2466\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.5560 - recall_40: 0.5290 - precision_40: 0.230 - 0s 3ms/step - loss: 0.6821 - accuracy: 0.5603 - recall_40: 0.5371 - precision_40: 0.2390\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.5632 - recall_40: 0.5424 - precision_40: 0.2433\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.5690 - recall_40: 0.5364 - precision_40: 0.2406\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5730 - recall_40: 0.5331 - precision_40: 0.2420\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.5732 - recall_40: 0.5324 - precision_40: 0.2425\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.5790 - recall_40: 0.5386 - precision_40: 0.2536\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.5824 - recall_40: 0.5234 - precision_40: 0.2455\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5825 - recall_40: 0.5186 - precision_40: 0.2486\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.5875 - recall_40: 0.5271 - precision_40: 0.2477\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.5920 - recall_40: 0.5143 - precision_40: 0.2517\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.5932 - recall_40: 0.5089 - precision_40: 0.2468\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.5959 - recall_40: 0.5160 - precision_40: 0.2551\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.5951 - recall_40: 0.5026 - precision_40: 0.2496\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.6006 - recall_40: 0.5040 - precision_40: 0.2527\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6020 - recall_40: 0.5131 - precision_40: 0.2554\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.6089 - recall_40: 0.5015 - precision_40: 0.2588\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.6059 - recall_40: 0.4950 - precision_40: 0.2551\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6575 - accuracy: 0.6066 - recall_40: 0.4869 - precision_40: 0.2503\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.6095 - recall_40: 0.4932 - precision_40: 0.2575\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.6180 - recall_40: 0.4894 - precision_40: 0.2647\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.6159 - recall_40: 0.4735 - precision_40: 0.2566\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.6245 - recall_40: 0.4939 - precision_40: 0.2687\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.6263 - recall_40: 0.4868 - precision_40: 0.2653\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.6277 - recall_40: 0.4896 - precision_40: 0.2690\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.6221 - recall_40: 0.4739 - precision_40: 0.2632\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.6317 - recall_40: 0.4803 - precision_40: 0.2673\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6297 - recall_40: 0.4700 - precision_40: 0.2667\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6322 - recall_40: 0.4703 - precision_40: 0.2688\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.6384 - recall_40: 0.4819 - precision_40: 0.2747\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.6365 - recall_40: 0.4678 - precision_40: 0.2715\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.6415 - recall_40: 0.4625 - precision_40: 0.2702\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.6472 - recall_40: 0.4659 - precision_40: 0.2789\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6543 - recall_40: 0.4763 - precision_40: 0.2809\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6322 - accuracy: 0.6545 - recall_40: 0.4684 - precision_40: 0.2861\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.6553 - recall_40: 0.4562 - precision_40: 0.2828\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6315 - accuracy: 0.6567 - recall_40: 0.4643 - precision_40: 0.2909\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.6591 - recall_40: 0.4597 - precision_40: 0.2836\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6603 - recall_40: 0.4598 - precision_40: 0.2868\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6593 - recall_40: 0.4359 - precision_40: 0.2808\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.6659 - recall_40: 0.4457 - precision_40: 0.2876\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.6683 - recall_40: 0.4417 - precision_40: 0.2933\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.6707 - recall_40: 0.4440 - precision_40: 0.2878\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.6710 - recall_40: 0.4355 - precision_40: 0.2884\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.6765 - recall_40: 0.4404 - precision_40: 0.2912\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.6699 - recall_40: 0.4288 - precision_40: 0.2874\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.6735 - recall_40: 0.4295 - precision_40: 0.2926\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.6786 - recall_40: 0.4307 - precision_40: 0.2947\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.6779 - recall_40: 0.4265 - precision_40: 0.2949\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6814 - recall_40: 0.4325 - precision_40: 0.2962\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6791 - recall_40: 0.4154 - precision_40: 0.2999\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.6824 - recall_40: 0.4166 - precision_40: 0.2960\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6124 - accuracy: 0.6822 - recall_40: 0.4185 - precision_40: 0.2959\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.6862 - recall_40: 0.4157 - precision_40: 0.3015\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6843 - recall_40: 0.4087 - precision_40: 0.3025\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.6875 - recall_40: 0.4130 - precision_40: 0.3036\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6887 - recall_40: 0.4134 - precision_40: 0.3039\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.6958 - recall_40: 0.4078 - precision_40: 0.3092\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.6905 - recall_40: 0.4082 - precision_40: 0.3042\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.6900 - recall_40: 0.3899 - precision_40: 0.2987\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.6975 - recall_40: 0.3985 - precision_40: 0.3120\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.7037 - recall_40: 0.3981 - precision_40: 0.3156\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.7014 - recall_40: 0.3989 - precision_40: 0.3164\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.7037 - recall_40: 0.3854 - precision_40: 0.3091\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7074 - recall_40: 0.4040 - precision_40: 0.3244\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7100 - recall_40: 0.3900 - precision_40: 0.3132\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5980 - accuracy: 0.7071 - recall_40: 0.3834 - precision_40: 0.3155\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7059 - recall_40: 0.3794 - precision_40: 0.3121\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7079 - recall_40: 0.3751 - precision_40: 0.3096\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7128 - recall_40: 0.3823 - precision_40: 0.3216\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7111 - recall_40: 0.3774 - precision_40: 0.3214\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.7126 - recall_40: 0.3671 - precision_40: 0.3171\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.7149 - recall_40: 0.3690 - precision_40: 0.3199\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7144 - recall_40: 0.3632 - precision_40: 0.3182\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7158 - recall_40: 0.3657 - precision_40: 0.3197\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7217 - recall_40: 0.3753 - precision_40: 0.3354\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.7210 - recall_40: 0.3633 - precision_40: 0.3278\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.7240 - recall_40: 0.3596 - precision_40: 0.3352\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.7211 - recall_40: 0.3509 - precision_40: 0.3266\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7229 - recall_40: 0.3559 - precision_40: 0.3317\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7216 - recall_40: 0.3474 - precision_40: 0.3278\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7227 - recall_40: 0.3378 - precision_40: 0.3249\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.7216 - recall_40: 0.3345 - precision_40: 0.3222\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.7274 - recall_40: 0.3455 - precision_40: 0.3297\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7231 - recall_40: 0.3316 - precision_40: 0.3278\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7260 - recall_40: 0.3358 - precision_40: 0.3292\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7316 - recall_40: 0.3284 - precision_40: 0.3294\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7323 - recall_40: 0.3330 - precision_40: 0.3367\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FBD310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7391 - recall_40: 0.3488 - precision_40: 0.3541\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8021 - accuracy: 0.4727 - recall_41: 0.3756 - precision_41: 0.1622\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8031 - accuracy: 0.4714 - recall_41: 0.3829 - precision_41: 0.1621\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7998 - accuracy: 0.4760 - recall_41: 0.3743 - precision_41: 0.1628\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7965 - accuracy: 0.4756 - recall_41: 0.3651 - precision_41: 0.1582\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7967 - accuracy: 0.4747 - recall_41: 0.3735 - precision_41: 0.1586\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7879 - accuracy: 0.4859 - recall_41: 0.3834 - precision_41: 0.1649\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7901 - accuracy: 0.4823 - recall_41: 0.3791 - precision_41: 0.1676\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7915 - accuracy: 0.4767 - recall_41: 0.3650 - precision_41: 0.1602\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7864 - accuracy: 0.4845 - recall_41: 0.3688 - precision_41: 0.1608\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7840 - accuracy: 0.4876 - recall_41: 0.3648 - precision_41: 0.1635\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7849 - accuracy: 0.4866 - recall_41: 0.3605 - precision_41: 0.1586\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7810 - accuracy: 0.4893 - recall_41: 0.3651 - precision_41: 0.1602\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7826 - accuracy: 0.4878 - recall_41: 0.3577 - precision_41: 0.1583\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7796 - accuracy: 0.4876 - recall_41: 0.3543 - precision_41: 0.1595\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7736 - accuracy: 0.4963 - recall_41: 0.3653 - precision_41: 0.1657\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7699 - accuracy: 0.4989 - recall_41: 0.3632 - precision_41: 0.1595\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7686 - accuracy: 0.4978 - recall_41: 0.3634 - precision_41: 0.1651\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7692 - accuracy: 0.4977 - recall_41: 0.3581 - precision_41: 0.1636\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7675 - accuracy: 0.4981 - recall_41: 0.3528 - precision_41: 0.1620\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7656 - accuracy: 0.5015 - recall_41: 0.3534 - precision_41: 0.1663\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7636 - accuracy: 0.5036 - recall_41: 0.3604 - precision_41: 0.1676\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7643 - accuracy: 0.5045 - recall_41: 0.3504 - precision_41: 0.1641\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7591 - accuracy: 0.5064 - recall_41: 0.3444 - precision_41: 0.1597\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7575 - accuracy: 0.5120 - recall_41: 0.3511 - precision_41: 0.1653\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7559 - accuracy: 0.5110 - recall_41: 0.3557 - precision_41: 0.1676\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.5123 - recall_41: 0.3510 - precision_41: 0.1671\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7505 - accuracy: 0.5105 - recall_41: 0.3429 - precision_41: 0.1636\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7539 - accuracy: 0.5101 - recall_41: 0.3386 - precision_41: 0.1638\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7491 - accuracy: 0.5130 - recall_41: 0.3434 - precision_41: 0.1667\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7429 - accuracy: 0.5208 - recall_41: 0.3502 - precision_41: 0.1676\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7506 - accuracy: 0.5092 - recall_41: 0.3354 - precision_41: 0.1613\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7427 - accuracy: 0.5206 - recall_41: 0.3531 - precision_41: 0.1683\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7423 - accuracy: 0.5183 - recall_41: 0.3446 - precision_41: 0.1686\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.5211 - recall_41: 0.3480 - precision_41: 0.1679\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7354 - accuracy: 0.5220 - recall_41: 0.3400 - precision_41: 0.1641\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.5217 - recall_41: 0.3443 - precision_41: 0.1698\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7355 - accuracy: 0.5226 - recall_41: 0.3280 - precision_41: 0.1606\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7342 - accuracy: 0.5207 - recall_41: 0.3232 - precision_41: 0.1593\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7303 - accuracy: 0.5242 - recall_41: 0.3241 - precision_41: 0.1627\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7305 - accuracy: 0.5216 - recall_41: 0.3277 - precision_41: 0.1614\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.5267 - recall_41: 0.3319 - precision_41: 0.1632\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7260 - accuracy: 0.5247 - recall_41: 0.3213 - precision_41: 0.1593\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7269 - accuracy: 0.5245 - recall_41: 0.3181 - precision_41: 0.1594\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7252 - accuracy: 0.5247 - recall_41: 0.3209 - precision_41: 0.1630\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7212 - accuracy: 0.5318 - recall_41: 0.3195 - precision_41: 0.1647\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7199 - accuracy: 0.5321 - recall_41: 0.3170 - precision_41: 0.1647\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7204 - accuracy: 0.5350 - recall_41: 0.3215 - precision_41: 0.1669\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7182 - accuracy: 0.5366 - recall_41: 0.3121 - precision_41: 0.1651\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7184 - accuracy: 0.5340 - recall_41: 0.3029 - precision_41: 0.1577\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7137 - accuracy: 0.5412 - recall_41: 0.3158 - precision_41: 0.1653\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7120 - accuracy: 0.5437 - recall_41: 0.3083 - precision_41: 0.1643\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7140 - accuracy: 0.5396 - recall_41: 0.3077 - precision_41: 0.1636\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7105 - accuracy: 0.5435 - recall_41: 0.2973 - precision_41: 0.1606\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7083 - accuracy: 0.5485 - recall_41: 0.3107 - precision_41: 0.1709\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7096 - accuracy: 0.5459 - recall_41: 0.3003 - precision_41: 0.1640\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7064 - accuracy: 0.5515 - recall_41: 0.3036 - precision_41: 0.1678\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7045 - accuracy: 0.5486 - recall_41: 0.2996 - precision_41: 0.1642\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7013 - accuracy: 0.5562 - recall_41: 0.3077 - precision_41: 0.1703\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7005 - accuracy: 0.5565 - recall_41: 0.3119 - precision_41: 0.1706\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.5616 - recall_41: 0.3070 - precision_41: 0.1700\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6987 - accuracy: 0.5561 - recall_41: 0.3051 - precision_41: 0.1694\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.5589 - recall_41: 0.3073 - precision_41: 0.1720\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5660 - recall_41: 0.3121 - precision_41: 0.1740\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.5605 - recall_41: 0.3120 - precision_41: 0.1748\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.5630 - recall_41: 0.2941 - precision_41: 0.1713\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5656 - recall_41: 0.3006 - precision_41: 0.1712\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5689 - recall_41: 0.3123 - precision_41: 0.1802\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.5712 - recall_41: 0.3001 - precision_41: 0.1804\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6869 - accuracy: 0.5707 - recall_41: 0.3052 - precision_41: 0.1770\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5713 - recall_41: 0.2903 - precision_41: 0.1717\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.5756 - recall_41: 0.3008 - precision_41: 0.1757\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.5775 - recall_41: 0.2964 - precision_41: 0.1767\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.5730 - recall_41: 0.2997 - precision_41: 0.1744\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.5737 - recall_41: 0.2903 - precision_41: 0.1749\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.5807 - recall_41: 0.2949 - precision_41: 0.1735\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.5804 - recall_41: 0.2795 - precision_41: 0.1685\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.5858 - recall_41: 0.2964 - precision_41: 0.1846\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.5802 - recall_41: 0.2874 - precision_41: 0.1728\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.5796 - recall_41: 0.2887 - precision_41: 0.1781\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.5860 - recall_41: 0.2839 - precision_41: 0.1730\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.5908 - recall_41: 0.2904 - precision_41: 0.1807\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.5906 - recall_41: 0.2815 - precision_41: 0.1792\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6673 - accuracy: 0.5940 - recall_41: 0.2748 - precision_41: 0.1736\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.5911 - recall_41: 0.2818 - precision_41: 0.1783\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.5906 - recall_41: 0.2800 - precision_41: 0.1737\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.5944 - recall_41: 0.2798 - precision_41: 0.1777\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.5942 - recall_41: 0.2815 - precision_41: 0.1819\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.5956 - recall_41: 0.2693 - precision_41: 0.1777\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.5962 - recall_41: 0.2683 - precision_41: 0.1730\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.6002 - recall_41: 0.2642 - precision_41: 0.1751\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.5980 - recall_41: 0.2552 - precision_41: 0.1692\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.5995 - recall_41: 0.2598 - precision_41: 0.1720\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.6037 - recall_41: 0.2598 - precision_41: 0.1743\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.6069 - recall_41: 0.2571 - precision_41: 0.1760\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6045 - recall_41: 0.2566 - precision_41: 0.1759\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6068 - recall_41: 0.2494 - precision_41: 0.1679\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6074 - recall_41: 0.2561 - precision_41: 0.1770\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6075 - recall_41: 0.2583 - precision_41: 0.1764\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6070 - recall_41: 0.2574 - precision_41: 0.1807\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6106 - recall_41: 0.2618 - precision_41: 0.1832\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6583F2B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 0.6392 - accuracy: 0.6112 - recall_41: 0.2331 - precision_41: 0.1679\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7788 - accuracy: 0.4667 - recall_42: 0.4446 - precision_42: 0.1738\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7787 - accuracy: 0.4672 - recall_42: 0.4400 - precision_42: 0.1732\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7750 - accuracy: 0.4711 - recall_42: 0.4484 - precision_42: 0.1770\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7722 - accuracy: 0.4711 - recall_42: 0.4328 - precision_42: 0.1712\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7731 - accuracy: 0.4714 - recall_42: 0.4249 - precision_42: 0.1764\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7696 - accuracy: 0.4736 - recall_42: 0.4369 - precision_42: 0.1717\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7671 - accuracy: 0.4760 - recall_42: 0.4352 - precision_42: 0.1753\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7685 - accuracy: 0.4741 - recall_42: 0.4271 - precision_42: 0.1747\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7593 - accuracy: 0.4833 - recall_42: 0.4369 - precision_42: 0.1806\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7638 - accuracy: 0.4833 - recall_42: 0.4341 - precision_42: 0.1802\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7594 - accuracy: 0.4878 - recall_42: 0.4249 - precision_42: 0.1791\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7574 - accuracy: 0.4918 - recall_42: 0.4310 - precision_42: 0.1853\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7540 - accuracy: 0.4923 - recall_42: 0.4270 - precision_42: 0.1777\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7551 - accuracy: 0.4918 - recall_42: 0.4157 - precision_42: 0.1798\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.4973 - recall_42: 0.4088 - precision_42: 0.1794\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.4975 - recall_42: 0.4177 - precision_42: 0.1793\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.5001 - recall_42: 0.4163 - precision_42: 0.1822\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7446 - accuracy: 0.5011 - recall_42: 0.4185 - precision_42: 0.1794\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7460 - accuracy: 0.5008 - recall_42: 0.4074 - precision_42: 0.1759\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7430 - accuracy: 0.5056 - recall_42: 0.4242 - precision_42: 0.1851\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7389 - accuracy: 0.5107 - recall_42: 0.4098 - precision_42: 0.1848\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.5087 - recall_42: 0.3967 - precision_42: 0.1784\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.5188 - recall_42: 0.4086 - precision_42: 0.1867\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7339 - accuracy: 0.5185 - recall_42: 0.4038 - precision_42: 0.1872\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.5164 - recall_42: 0.3875 - precision_42: 0.1757\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.5171 - recall_42: 0.3931 - precision_42: 0.1825\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7314 - accuracy: 0.5224 - recall_42: 0.3897 - precision_42: 0.1868\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7261 - accuracy: 0.5262 - recall_42: 0.3801 - precision_42: 0.1783\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7284 - accuracy: 0.5252 - recall_42: 0.3805 - precision_42: 0.1819\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7231 - accuracy: 0.5315 - recall_42: 0.3782 - precision_42: 0.1834\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7260 - accuracy: 0.5268 - recall_42: 0.3704 - precision_42: 0.1789\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.5339 - recall_42: 0.3764 - precision_42: 0.1842\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7197 - accuracy: 0.5355 - recall_42: 0.3768 - precision_42: 0.1849\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7174 - accuracy: 0.5370 - recall_42: 0.3805 - precision_42: 0.1850\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.5422 - recall_42: 0.3711 - precision_42: 0.1827\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7138 - accuracy: 0.5410 - recall_42: 0.3798 - precision_42: 0.1888\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7104 - accuracy: 0.5406 - recall_42: 0.3687 - precision_42: 0.1815\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7081 - accuracy: 0.5465 - recall_42: 0.3715 - precision_42: 0.1887\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7059 - accuracy: 0.5500 - recall_42: 0.3727 - precision_42: 0.1869\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.5515 - recall_42: 0.3757 - precision_42: 0.1930\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7090 - accuracy: 0.5438 - recall_42: 0.3503 - precision_42: 0.1814\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6997 - accuracy: 0.5574 - recall_42: 0.3700 - precision_42: 0.1934\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7027 - accuracy: 0.5527 - recall_42: 0.3585 - precision_42: 0.1859\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7033 - accuracy: 0.5539 - recall_42: 0.3557 - precision_42: 0.1851\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7026 - accuracy: 0.5535 - recall_42: 0.3567 - precision_42: 0.1873\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6977 - accuracy: 0.5611 - recall_42: 0.3601 - precision_42: 0.1908\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.5592 - recall_42: 0.3468 - precision_42: 0.1861\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6944 - accuracy: 0.5630 - recall_42: 0.3532 - precision_42: 0.1904\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.5617 - recall_42: 0.3454 - precision_42: 0.1872\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5651 - recall_42: 0.3541 - precision_42: 0.1936\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5676 - recall_42: 0.3409 - precision_42: 0.1915\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5701 - recall_42: 0.3417 - precision_42: 0.1862\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5722 - recall_42: 0.3477 - precision_42: 0.1939\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5720 - recall_42: 0.3438 - precision_42: 0.1919\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5741 - recall_42: 0.3355 - precision_42: 0.1894\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.5774 - recall_42: 0.3376 - precision_42: 0.1912\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5802 - recall_42: 0.3421 - precision_42: 0.1979\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6829 - accuracy: 0.5759 - recall_42: 0.3266 - precision_42: 0.1868\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.5857 - recall_42: 0.3247 - precision_42: 0.1939\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.5865 - recall_42: 0.3228 - precision_42: 0.1906\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.5831 - recall_42: 0.3149 - precision_42: 0.1892\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.5884 - recall_42: 0.3181 - precision_42: 0.1903\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.5907 - recall_42: 0.3234 - precision_42: 0.1979\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.5914 - recall_42: 0.3163 - precision_42: 0.1922\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.5925 - recall_42: 0.3032 - precision_42: 0.1848\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.5885 - recall_42: 0.3044 - precision_42: 0.1906\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.5940 - recall_42: 0.3021 - precision_42: 0.1894\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.5937 - recall_42: 0.3124 - precision_42: 0.1955\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.5943 - recall_42: 0.2974 - precision_42: 0.1856\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.5990 - recall_42: 0.2997 - precision_42: 0.1919\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.5990 - recall_42: 0.2994 - precision_42: 0.1893\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.5998 - recall_42: 0.2970 - precision_42: 0.1888\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.6051 - recall_42: 0.3029 - precision_42: 0.1962\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.6027 - recall_42: 0.2949 - precision_42: 0.1895\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.6091 - recall_42: 0.3022 - precision_42: 0.2020\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.6100 - recall_42: 0.2949 - precision_42: 0.1938\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6161 - recall_42: 0.2984 - precision_42: 0.2013\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6147 - recall_42: 0.2912 - precision_42: 0.1896\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6149 - recall_42: 0.2902 - precision_42: 0.1955\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6194 - recall_42: 0.2794 - precision_42: 0.1906\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6174 - recall_42: 0.2881 - precision_42: 0.1951\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.6172 - recall_42: 0.2864 - precision_42: 0.1963\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.6203 - recall_42: 0.2835 - precision_42: 0.1953\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6208 - recall_42: 0.2798 - precision_42: 0.1969\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.6202 - recall_42: 0.2727 - precision_42: 0.1951\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6305 - recall_42: 0.2884 - precision_42: 0.2098\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.6329 - recall_42: 0.2798 - precision_42: 0.2030\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6343 - recall_42: 0.2762 - precision_42: 0.2011\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.6367 - recall_42: 0.2865 - precision_42: 0.2063\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6377 - recall_42: 0.2819 - precision_42: 0.2080\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6379 - accuracy: 0.6416 - recall_42: 0.2740 - precision_42: 0.2054\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.6384 - recall_42: 0.2654 - precision_42: 0.1987\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6407 - recall_42: 0.2674 - precision_42: 0.1970\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.6406 - recall_42: 0.2640 - precision_42: 0.2026\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.6444 - recall_42: 0.2659 - precision_42: 0.2099\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6335 - accuracy: 0.6461 - recall_42: 0.2744 - precision_42: 0.2112\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.6449 - recall_42: 0.2691 - precision_42: 0.2053\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6436 - recall_42: 0.2641 - precision_42: 0.2120\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6514 - recall_42: 0.2641 - precision_42: 0.2063\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6497 - recall_42: 0.2622 - precision_42: 0.2076\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.6451 - recall_42: 0.2389 - precision_42: 0.1945\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.6859 - accuracy: 0.5542 - recall_43: 0.6065 - precision_43: 0.2526\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6830 - accuracy: 0.5574 - recall_43: 0.5954 - precision_43: 0.2490\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.5681 - recall_43: 0.5914 - precision_43: 0.2607\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.5761 - recall_43: 0.5803 - precision_43: 0.2577\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.5825 - recall_43: 0.5682 - precision_43: 0.2584\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.5884 - recall_43: 0.5599 - precision_43: 0.2641\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.5953 - recall_43: 0.5456 - precision_43: 0.2603\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.5984 - recall_43: 0.5282 - precision_43: 0.2558\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6074 - recall_43: 0.5146 - precision_43: 0.2634\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6565 - accuracy: 0.6163 - recall_43: 0.5170 - precision_43: 0.2681\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.6191 - recall_43: 0.4949 - precision_43: 0.2685\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.6312 - recall_43: 0.4859 - precision_43: 0.2735\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.6395 - recall_43: 0.4640 - precision_43: 0.2665\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.6443 - recall_43: 0.4667 - precision_43: 0.2771\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.6530 - recall_43: 0.4552 - precision_43: 0.2808\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.6574 - recall_43: 0.4394 - precision_43: 0.2784\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.6647 - recall_43: 0.4240 - precision_43: 0.2763\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6682 - recall_43: 0.4101 - precision_43: 0.2792\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6336 - accuracy: 0.6724 - recall_43: 0.4069 - precision_43: 0.2851\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6872 - recall_43: 0.3900 - precision_43: 0.2929\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.6876 - recall_43: 0.3823 - precision_43: 0.2919\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.6948 - recall_43: 0.3733 - precision_43: 0.2944\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.7032 - recall_43: 0.3705 - precision_43: 0.3081\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.7058 - recall_43: 0.3526 - precision_43: 0.3006\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.7125 - recall_43: 0.3508 - precision_43: 0.3148\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.7187 - recall_43: 0.3398 - precision_43: 0.3161\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.7237 - recall_43: 0.3293 - precision_43: 0.3260\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.7291 - recall_43: 0.3222 - precision_43: 0.3263\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.7357 - recall_43: 0.3115 - precision_43: 0.3380\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7380 - recall_43: 0.3029 - precision_43: 0.3362\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.7362 - recall_43: 0.2822 - precision_43: 0.3266\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.7441 - recall_43: 0.2652 - precision_43: 0.3337\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.7444 - recall_43: 0.2583 - precision_43: 0.3357\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.7505 - recall_43: 0.2552 - precision_43: 0.3451\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5965 - accuracy: 0.7578 - recall_43: 0.2494 - precision_43: 0.3525\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5947 - accuracy: 0.7586 - recall_43: 0.2442 - precision_43: 0.3603\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.7633 - recall_43: 0.2427 - precision_43: 0.3735\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.7653 - recall_43: 0.2344 - precision_43: 0.3713\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.7682 - recall_43: 0.2260 - precision_43: 0.3796\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.7709 - recall_43: 0.2198 - precision_43: 0.3825\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.7728 - recall_43: 0.2018 - precision_43: 0.3769\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7761 - recall_43: 0.2039 - precision_43: 0.3873\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7758 - recall_43: 0.1919 - precision_43: 0.3860\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.7750 - recall_43: 0.1859 - precision_43: 0.3902\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7770 - recall_43: 0.1787 - precision_43: 0.3949\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7800 - recall_43: 0.1662 - precision_43: 0.3755\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5749 - accuracy: 0.7838 - recall_43: 0.1650 - precision_43: 0.3928\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.7808 - recall_43: 0.1569 - precision_43: 0.4008\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7813 - recall_43: 0.1525 - precision_43: 0.4020\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5713 - accuracy: 0.7867 - recall_43: 0.1551 - precision_43: 0.4252\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.7885 - recall_43: 0.1465 - precision_43: 0.4417\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7890 - recall_43: 0.1439 - precision_43: 0.4293\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.7902 - recall_43: 0.1369 - precision_43: 0.4375\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7909 - recall_43: 0.1243 - precision_43: 0.4131\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7922 - recall_43: 0.1316 - precision_43: 0.4447\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.7906 - recall_43: 0.1172 - precision_43: 0.4238\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7941 - recall_43: 0.1159 - precision_43: 0.4548\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7897 - recall_43: 0.1011 - precision_43: 0.4325\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7951 - recall_43: 0.0982 - precision_43: 0.4347\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.7873 - recall_43: 0.0952 - precision_43: 0.4456\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7918 - recall_43: 0.0849 - precision_43: 0.4495\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7882 - recall_43: 0.0831 - precision_43: 0.4413\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7953 - recall_43: 0.0818 - precision_43: 0.4542\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7986 - recall_43: 0.0792 - precision_43: 0.4736\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7956 - recall_43: 0.0765 - precision_43: 0.4900\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.7964 - recall_43: 0.0742 - precision_43: 0.4925\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7978 - recall_43: 0.0742 - precision_43: 0.5022\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7964 - recall_43: 0.0625 - precision_43: 0.4889\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7965 - recall_43: 0.0629 - precision_43: 0.5285\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7992 - recall_43: 0.0629 - precision_43: 0.5238\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.8009 - recall_43: 0.0557 - precision_43: 0.5046\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7985 - recall_43: 0.0598 - precision_43: 0.5574\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5446 - accuracy: 0.7885 - recall_43: 0.0443 - precision_43: 0.593 - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7964 - recall_43: 0.0524 - precision_43: 0.5593\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.8012 - recall_43: 0.0560 - precision_43: 0.5776\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7922 - recall_43: 0.0437 - precision_43: 0.5369\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.8006 - recall_43: 0.0403 - precision_43: 0.5347\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.8016 - recall_43: 0.0407 - precision_43: 0.5993\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.8001 - recall_43: 0.0420 - precision_43: 0.6142\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7974 - recall_43: 0.0358 - precision_43: 0.5660\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.8004 - recall_43: 0.0355 - precision_43: 0.5878\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7979 - recall_43: 0.0317 - precision_43: 0.5663\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7967 - recall_43: 0.0313 - precision_43: 0.5818\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7970 - recall_43: 0.0321 - precision_43: 0.6260\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7976 - recall_43: 0.0257 - precision_43: 0.5034\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7979 - recall_43: 0.0274 - precision_43: 0.5839\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7979 - recall_43: 0.0263 - precision_43: 0.5758\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7970 - recall_43: 0.0222 - precision_43: 0.5268\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7950 - recall_43: 0.0212 - precision_43: 0.5180\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.7885 - recall_43: 0.0072 - precision_43: 0.250 - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7947 - recall_43: 0.0142 - precision_43: 0.4329\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.8000 - recall_43: 0.0187 - precision_43: 0.5463\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.8022 - recall_43: 0.0132 - precision_43: 0.4460\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7949 - recall_43: 0.0127 - precision_43: 0.4779\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7985 - recall_43: 0.0123 - precision_43: 0.5043\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7960 - recall_43: 0.0139 - precision_43: 0.5377\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7942 - recall_43: 0.0103 - precision_43: 0.5053\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7963 - recall_43: 0.0134 - precision_43: 0.5947\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7996 - recall_43: 0.0097 - precision_43: 0.5504\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7969 - recall_43: 0.0105 - precision_43: 0.5459\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7987 - recall_43: 0.0124 - precision_43: 0.6375\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.8020 - recall_43: 0.0110 - precision_43: 0.7450\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657F8D0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7973 - recall_43: 0.0063 - precision_43: 0.5000\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.7185 - accuracy: 0.4745 - recall_44: 0.3879 - precision_44: 0.1645\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7143 - accuracy: 0.4852 - recall_44: 0.3721 - precision_44: 0.1643\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7087 - accuracy: 0.4941 - recall_44: 0.3635 - precision_44: 0.1629\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7050 - accuracy: 0.4988 - recall_44: 0.3545 - precision_44: 0.1635\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7018 - accuracy: 0.5074 - recall_44: 0.3333 - precision_44: 0.1607\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5263 - recall_44: 0.3271 - precision_44: 0.1659\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5300 - recall_44: 0.3037 - precision_44: 0.1564\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.5403 - recall_44: 0.3005 - precision_44: 0.1604\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.5472 - recall_44: 0.2867 - precision_44: 0.1590\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.5602 - recall_44: 0.2851 - precision_44: 0.1633\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.5684 - recall_44: 0.2754 - precision_44: 0.1612\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.5770 - recall_44: 0.2607 - precision_44: 0.1604\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6677 - accuracy: 0.5837 - recall_44: 0.2487 - precision_44: 0.1658\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.5923 - recall_44: 0.2395 - precision_44: 0.1612\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6585 - accuracy: 0.6065 - recall_44: 0.2348 - precision_44: 0.1666\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.6156 - recall_44: 0.2167 - precision_44: 0.1605\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6606 - accuracy: 0.6050 - recall_44: 0.1906 - precision_44: 0.153 - 0s 5ms/step - loss: 0.6539 - accuracy: 0.6212 - recall_44: 0.1982 - precision_44: 0.1599\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6475 - accuracy: 0.6337 - recall_44: 0.1807 - precision_44: 0.1520\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6448 - accuracy: 0.6434 - recall_44: 0.1771 - precision_44: 0.1615\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6477 - recall_44: 0.1627 - precision_44: 0.1540\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6624 - recall_44: 0.1643 - precision_44: 0.1622\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.6691 - recall_44: 0.1543 - precision_44: 0.1638\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6764 - recall_44: 0.1374 - precision_44: 0.1547\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6808 - recall_44: 0.1387 - precision_44: 0.1618\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6806 - recall_44: 0.1195 - precision_44: 0.1506\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6957 - recall_44: 0.1179 - precision_44: 0.1617\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.7009 - recall_44: 0.1152 - precision_44: 0.1664\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.7050 - recall_44: 0.1083 - precision_44: 0.1652\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.7150 - recall_44: 0.1053 - precision_44: 0.1724\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.7208 - recall_44: 0.0914 - precision_44: 0.1619\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.7270 - recall_44: 0.0846 - precision_44: 0.1532\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.7289 - recall_44: 0.0706 - precision_44: 0.1466\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6061 - accuracy: 0.7306 - recall_44: 0.0637 - precision_44: 0.1436\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.7365 - recall_44: 0.0632 - precision_44: 0.1481\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.7407 - recall_44: 0.0558 - precision_44: 0.1488\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5986 - accuracy: 0.7456 - recall_44: 0.0507 - precision_44: 0.1462\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.7521 - recall_44: 0.0519 - precision_44: 0.1614\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7574 - recall_44: 0.0517 - precision_44: 0.1677\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.7607 - recall_44: 0.0477 - precision_44: 0.1684\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7664 - recall_44: 0.0394 - precision_44: 0.1599\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5881 - accuracy: 0.7697 - recall_44: 0.0373 - precision_44: 0.1804\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7760 - recall_44: 0.0378 - precision_44: 0.2026\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7785 - recall_44: 0.0368 - precision_44: 0.2173\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5816 - accuracy: 0.7796 - recall_44: 0.0331 - precision_44: 0.2308\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.7810 - recall_44: 0.0277 - precision_44: 0.2257\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.7852 - recall_44: 0.0243 - precision_44: 0.2299\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7858 - recall_44: 0.0244 - precision_44: 0.2439\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7907 - recall_44: 0.0262 - precision_44: 0.2953\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.7929 - recall_44: 0.0221 - precision_44: 0.2873\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5710 - accuracy: 0.7928 - recall_44: 0.0202 - precision_44: 0.3395\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7948 - recall_44: 0.0160 - precision_44: 0.3029\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7936 - recall_44: 0.0137 - precision_44: 0.2978\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7933 - recall_44: 0.0158 - precision_44: 0.3821\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5656 - accuracy: 0.7927 - recall_44: 0.0126 - precision_44: 0.3472\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7960 - recall_44: 0.0139 - precision_44: 0.4356\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7996 - recall_44: 0.0112 - precision_44: 0.4126\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.7967 - recall_44: 0.0106 - precision_44: 0.4132\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.7977 - recall_44: 0.0091 - precision_44: 0.4391\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7980 - recall_44: 0.0104 - precision_44: 0.4833\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7938 - recall_44: 0.0048 - precision_44: 0.3104\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7973 - recall_44: 0.0058 - precision_44: 0.3694\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5521 - accuracy: 0.7970 - recall_44: 0.0037 - precision_44: 0.3333\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5540 - accuracy: 0.7924 - recall_44: 0.0051 - precision_44: 0.4544\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7959 - recall_44: 0.0057 - precision_44: 0.5000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7992 - recall_44: 0.0031 - precision_44: 0.3472    \n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7989 - recall_44: 0.0052 - precision_44: 0.6399\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7955 - recall_44: 0.0043 - precision_44: 0.6500\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7968 - recall_44: 0.0037 - precision_44: 0.5667\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7991 - recall_44: 0.0028 - precision_44: 0.6000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7973 - recall_44: 0.0031 - precision_44: 0.4375\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7935 - recall_44: 0.0022 - precision_44: 0.6250\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7963 - recall_44: 0.0023 - precision_44: 0.6250\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7984 - recall_44: 0.0020 - precision_44: 0.7083\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7972 - recall_44: 0.0023 - precision_44: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7978 - recall_44: 5.2854e-04 - precision_44: 0.5000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7944 - recall_44: 0.0014 - precision_44: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7983 - recall_44: 8.4301e-04 - precision_44: 0.7500\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.8009 - recall_44: 0.0015 - precision_44: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7926 - recall_44: 5.2854e-04 - precision_44: 0.5000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7990 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7955 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7970 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7963 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7974 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7963 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7982 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7963 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.8013 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7995 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7955 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7948 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7993 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7937 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7974 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7973 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7942 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7988 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7976 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7974 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7980 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659B5A3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7977 - recall_44: 0.0000e+00 - precision_44: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.7365 - accuracy: 0.4729 - recall_45: 0.4758 - precision_45: 0.1900\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7298 - accuracy: 0.4863 - recall_45: 0.4564 - precision_45: 0.1818\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7233 - accuracy: 0.4937 - recall_45: 0.4448 - precision_45: 0.1872\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7183 - accuracy: 0.4963 - recall_45: 0.4268 - precision_45: 0.1844\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7107 - accuracy: 0.5085 - recall_45: 0.4225 - precision_45: 0.1879\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7049 - accuracy: 0.5188 - recall_45: 0.4032 - precision_45: 0.1879\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6985 - accuracy: 0.5263 - recall_45: 0.4000 - precision_45: 0.1883\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.5361 - recall_45: 0.3853 - precision_45: 0.1881\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5452 - recall_45: 0.3685 - precision_45: 0.1884\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6819 - accuracy: 0.5593 - recall_45: 0.3673 - precision_45: 0.1921\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.5682 - recall_45: 0.3506 - precision_45: 0.1940\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.5711 - recall_45: 0.3318 - precision_45: 0.1872\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.6685 - accuracy: 0.5774 - recall_45: 0.3189 - precision_45: 0.1882\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.5900 - recall_45: 0.3060 - precision_45: 0.1899\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6008 - recall_45: 0.2875 - precision_45: 0.1836\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.6075 - recall_45: 0.2776 - precision_45: 0.1903\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6179 - recall_45: 0.2651 - precision_45: 0.1870\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.6253 - recall_45: 0.2499 - precision_45: 0.1862\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.6373 - recall_45: 0.2378 - precision_45: 0.1839\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6413 - recall_45: 0.2308 - precision_45: 0.1874\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6434 - recall_45: 0.2159 - precision_45: 0.1776\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.6564 - recall_45: 0.2095 - precision_45: 0.1877\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.6703 - recall_45: 0.2039 - precision_45: 0.1919\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.6713 - recall_45: 0.1961 - precision_45: 0.1892\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.6764 - recall_45: 0.1833 - precision_45: 0.1930\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.6801 - recall_45: 0.1788 - precision_45: 0.1963\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6877 - recall_45: 0.1707 - precision_45: 0.1922\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.6980 - recall_45: 0.1714 - precision_45: 0.2073\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6058 - accuracy: 0.6976 - recall_45: 0.1409 - precision_45: 0.1783\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.7019 - recall_45: 0.1419 - precision_45: 0.1924\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7090 - recall_45: 0.1358 - precision_45: 0.1902\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.7122 - recall_45: 0.1266 - precision_45: 0.1890\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.7163 - recall_45: 0.1206 - precision_45: 0.1840\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.7203 - recall_45: 0.1202 - precision_45: 0.1929\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.7243 - recall_45: 0.1078 - precision_45: 0.1846\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.7298 - recall_45: 0.1122 - precision_45: 0.1983\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7326 - recall_45: 0.1034 - precision_45: 0.1998\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5803 - accuracy: 0.7383 - recall_45: 0.0971 - precision_45: 0.1980\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5799 - accuracy: 0.7382 - recall_45: 0.0883 - precision_45: 0.1905\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7416 - recall_45: 0.0844 - precision_45: 0.1942\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7474 - recall_45: 0.0822 - precision_45: 0.2012\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.7463 - recall_45: 0.0714 - precision_45: 0.1846\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7513 - recall_45: 0.0681 - precision_45: 0.1833\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7540 - recall_45: 0.0644 - precision_45: 0.1848\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7541 - recall_45: 0.0660 - precision_45: 0.1987\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.7610 - recall_45: 0.0568 - precision_45: 0.1860\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7600 - recall_45: 0.0605 - precision_45: 0.2023\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7644 - recall_45: 0.0591 - precision_45: 0.2027\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7610 - recall_45: 0.0536 - precision_45: 0.2033\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7658 - recall_45: 0.0533 - precision_45: 0.1980\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5539 - accuracy: 0.7671 - recall_45: 0.0447 - precision_45: 0.1958\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7693 - recall_45: 0.0451 - precision_45: 0.2074\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7754 - recall_45: 0.0475 - precision_45: 0.2232\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7758 - recall_45: 0.0445 - precision_45: 0.2292\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7764 - recall_45: 0.0457 - precision_45: 0.2369\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7784 - recall_45: 0.0434 - precision_45: 0.2516\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7770 - recall_45: 0.0430 - precision_45: 0.2456\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7841 - recall_45: 0.0368 - precision_45: 0.2282\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7811 - recall_45: 0.0352 - precision_45: 0.2343\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7778 - recall_45: 0.0368 - precision_45: 0.2536\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7820 - recall_45: 0.0336 - precision_45: 0.2315\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7836 - recall_45: 0.0320 - precision_45: 0.2327\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7856 - recall_45: 0.0329 - precision_45: 0.2486\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7855 - recall_45: 0.0317 - precision_45: 0.2658\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7864 - recall_45: 0.0273 - precision_45: 0.2364\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7861 - recall_45: 0.0273 - precision_45: 0.2539\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7851 - recall_45: 0.0265 - precision_45: 0.2600\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7877 - recall_45: 0.0257 - precision_45: 0.2586\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7844 - recall_45: 0.0215 - precision_45: 0.2303\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7905 - recall_45: 0.0243 - precision_45: 0.2608\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7912 - recall_45: 0.0204 - precision_45: 0.2640\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7921 - recall_45: 0.0223 - precision_45: 0.2804\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7874 - recall_45: 0.0195 - precision_45: 0.2593\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7864 - recall_45: 0.0218 - precision_45: 0.2758\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7924 - recall_45: 0.0207 - precision_45: 0.2997\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7929 - recall_45: 0.0198 - precision_45: 0.2930\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7917 - recall_45: 0.0207 - precision_45: 0.3080\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7949 - recall_45: 0.0219 - precision_45: 0.3308\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7934 - recall_45: 0.0184 - precision_45: 0.3096\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7937 - recall_45: 0.0197 - precision_45: 0.3340\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7929 - recall_45: 0.0183 - precision_45: 0.3358\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7959 - recall_45: 0.0185 - precision_45: 0.3434\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7977 - recall_45: 0.0196 - precision_45: 0.3626\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7973 - recall_45: 0.0196 - precision_45: 0.3567\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7955 - recall_45: 0.0212 - precision_45: 0.3988\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7942 - recall_45: 0.0186 - precision_45: 0.3788\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7952 - recall_45: 0.0214 - precision_45: 0.4327\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7958 - recall_45: 0.0176 - precision_45: 0.4139\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7956 - recall_45: 0.0180 - precision_45: 0.3923\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7947 - recall_45: 0.0170 - precision_45: 0.3557\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7935 - recall_45: 0.0145 - precision_45: 0.3310\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7978 - recall_45: 0.0146 - precision_45: 0.3253\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7952 - recall_45: 0.0187 - precision_45: 0.4053\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7951 - recall_45: 0.0153 - precision_45: 0.3662\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7966 - recall_45: 0.0158 - precision_45: 0.4107\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7950 - recall_45: 0.0142 - precision_45: 0.3797\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7942 - recall_45: 0.0150 - precision_45: 0.3934\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7947 - recall_45: 0.0165 - precision_45: 0.4202\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7939 - recall_45: 0.0150 - precision_45: 0.3637\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7962 - recall_45: 0.0152 - precision_45: 0.3910\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657C9E820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7947 - recall_45: 0.0148 - precision_45: 0.3500\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5504 - accuracy: 0.7986 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7957 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7944 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7969 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5476 - accuracy: 0.7993 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7980 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5481 - accuracy: 0.7969 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7965 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7975 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.7989 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5439 - accuracy: 0.7996 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7970 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7963 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.8019 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7969 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7969 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7989 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7970 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7977 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7976 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7992 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7993 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7960 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.8003 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7956 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7945 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7966 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7976 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7963 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7992 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.7952 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7982 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5354 - accuracy: 0.7971 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7990 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7992 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7953 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.7967 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7983 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5330 - accuracy: 0.7972 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7987 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7979 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7998 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5286 - accuracy: 0.8010 - recall_46: 0.0000e+00 - precision_46: 0.0000e+0 - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7991 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.8004 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7969 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7990 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7957 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7964 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7977 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.7974 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7933 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7966 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7989 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7982 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7960 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7980 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.8027 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7957 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.8016 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7983 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.7996 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.8000 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7985 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.8008 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7972 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7957 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7954 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7977 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7975 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7984 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7973 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7945 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7950 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7979 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.8009 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7973 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7994 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7997 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.8009 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7958 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7977 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.8009 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7987 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7967 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7970 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7966 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7973 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7984 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7965 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7957 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7979 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5193 - accuracy: 0.7969 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7948 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7999 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7968 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7978 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7992 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7977 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7957 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7955 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.7973 - recall_46: 0.0000e+00 - precision_46: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5983 - accuracy: 0.7982 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.7931 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.8003 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5972 - accuracy: 0.7935 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7983 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7960 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.7948 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7957 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.7945 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7979 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5898 - accuracy: 0.7953 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.7963 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.7967 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.7965 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7969 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5860 - accuracy: 0.7940 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5824 - accuracy: 0.8000 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7976 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7967 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7950 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5795 - accuracy: 0.7991 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5797 - accuracy: 0.7969 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7990 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.7961 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.7976 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7942 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.7977 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5749 - accuracy: 0.7972 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.7948 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.7980 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.7948 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.7957 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7928 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.8010 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7935 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7996 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.8000 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.7956 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.7957 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7938 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.7953 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.8002 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7986 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.7980 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7977 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7956 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7942 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7975 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7973 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7985 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7986 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7953 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7979 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7955 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.7980 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7960 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.7980 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7930 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7987 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.7980 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7970 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7963 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7960 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.7974 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7983 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7998 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7967 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7981 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.7982 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7970 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7956 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7963 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.8008 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7966 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7974 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7974 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7993 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7982 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7993 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7916 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7973 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7963 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.8002 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7970 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7992 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7993 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7975 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7984 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7948 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5445 - accuracy: 0.7926 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7940 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7976 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5391 - accuracy: 0.7983 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7975 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7953 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7941 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7993 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7951 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5359 - accuracy: 0.7997 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7981 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657C9EDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5368 - accuracy: 0.7977 - recall_47: 0.0000e+00 - precision_47: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5356 - accuracy: 0.7961 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.8007 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7959 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7996 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7964 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7969 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7983 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7950 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7966 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7931 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7973 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7969 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7976 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7994 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7978 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7978 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7992 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7944 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7983 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7971 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7952 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7967 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7954 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7976 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.8080 - recall_48: 0.0000e+00 - precision_48: 0.0000e+0 - 0s 3ms/step - loss: 0.5233 - accuracy: 0.8010 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7946 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7974 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.8003 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7993 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7979 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7961 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.8002 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7968 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7935 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7958 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7982 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7964 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7990 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7978 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7952 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7944 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7979 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7962 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7983 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7977 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7981 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7964 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7948 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7989 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7976 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7988 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7983 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7973 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7938 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7987 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7962 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7989 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7971 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7994 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7958 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8007 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7938 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7981 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7976 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7963 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.8004 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7988 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7961 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7986 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7986 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7994 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7994 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7991 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.8001 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7988 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7981 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7979 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7979 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7974 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7944 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7979 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7943 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7995 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7961 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7952 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7970 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7969 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7994 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7967 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7951 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7944 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.8011 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7989 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7984 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.8005 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7956 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5137 - accuracy: 0.7971 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7994 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7981 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5111 - accuracy: 0.7992 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580C9CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 0.5130 - accuracy: 0.7973 - recall_48: 0.0000e+00 - precision_48: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.7218 - accuracy: 0.2012 - recall_49: 1.0000 - precision_49: 0.2012\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.2004 - recall_49: 1.0000 - precision_49: 0.2004\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7133 - accuracy: 0.2010 - recall_49: 1.0000 - precision_49: 0.2010\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7090 - accuracy: 0.2031 - recall_49: 1.0000 - precision_49: 0.2031\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7048 - accuracy: 0.2028 - recall_49: 1.0000 - precision_49: 0.2028\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7009 - accuracy: 0.2041 - recall_49: 0.9995 - precision_49: 0.2026\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.2985 - recall_49: 0.8724 - precision_49: 0.2077\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5404 - recall_49: 0.3867 - precision_49: 0.1876\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.6867 - recall_49: 0.1559 - precision_49: 0.1762\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.7779 - recall_49: 0.0190 - precision_49: 0.1454\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6822 - accuracy: 0.7969 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.7974 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.7999 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.7993 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.7984 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.7956 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.7965 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.8008 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.7965 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.7996 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.7959 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.7985 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.7970 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.7965 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.7927 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7989 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7982 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.7997 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.7946 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.7958 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.7954 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.7991 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.7959 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.7939 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7989 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.7965 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.7962 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.7956 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6069 - accuracy: 0.7979 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6052 - accuracy: 0.7970 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.7974 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.7935 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.7969 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.7949 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.7979 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5946 - accuracy: 0.7967 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.7981 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.8005 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.7974 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7992 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.8009 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7957 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.7968 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7969 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7994 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.7948 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7967 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7986 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5738 - accuracy: 0.7994 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7990 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7968 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7964 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7945 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7974 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7977 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7977 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.8027 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7969 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7955 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.7974 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7969 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7975 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7951 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7944 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7942 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7957 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5550 - accuracy: 0.7973 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.7949 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.7977 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7975 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7975 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7982 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7990 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7984 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7990 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.8007 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.8003 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7981 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7990 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7972 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7946 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7965 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7971 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7959 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7969 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7972 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7997 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7967 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7985 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7959 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D655258E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7973 - recall_49: 0.0000e+00 - precision_49: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 5ms/step - loss: 0.5552 - accuracy: 0.7968 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5532 - accuracy: 0.7981 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5524 - accuracy: 0.7977 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7957 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7985 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.8013 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7980 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.7997 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.8013 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.7978 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7980 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.7952 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7981 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7973 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7947 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7965 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7991 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7977 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7959 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7969 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7972 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.7987 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7997 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.8022 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7950 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7972 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7935 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7961 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7957 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7987 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7973 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7980 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7970 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7930 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7955 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7953 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7939 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7972 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7978 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5267 - accuracy: 0.7972 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7982 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5211 - accuracy: 0.8024 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5234 - accuracy: 0.7994 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7942 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.7951 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7972 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.8012 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7997 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5246 - accuracy: 0.7955 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7973 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.8002 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7942 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7973 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5207 - accuracy: 0.7980 - recall_50: 0.0000e+00 - precision_50: 0.0000e+0 - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7977 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7963 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7985 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7967 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7940 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7960 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5162 - accuracy: 0.8005 - recall_50: 0.0000e+00 - precision_50: 0.0000e+0 - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7992 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7965 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7973 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7984 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5213 - accuracy: 0.7942 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5192 - accuracy: 0.7961 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7948 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7957 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7963 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7990 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7964 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7971 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7981 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7999 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7977 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7947 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7978 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.8006 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.8023 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7977 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7986 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7948 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7970 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7975 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7977 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7947 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7946 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7982 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7937 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7987 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7979 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7965 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7924 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7987 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7967 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.8007 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7967 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7969 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7990 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7954 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7938 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5CA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5110 - accuracy: 0.7977 - recall_50: 0.0000e+00 - precision_50: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.2732 - accuracy: 0.2001 - recall_51: 1.0000 - precision_51: 0.2001\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2526 - accuracy: 0.1989 - recall_51: 1.0000 - precision_51: 0.1989\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2230 - accuracy: 0.2055 - recall_51: 1.0000 - precision_51: 0.2055\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2049 - accuracy: 0.2030 - recall_51: 1.0000 - precision_51: 0.2030\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1843 - accuracy: 0.2032 - recall_51: 1.0000 - precision_51: 0.2032\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1671 - accuracy: 0.2007 - recall_51: 1.0000 - precision_51: 0.2007\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1427 - accuracy: 0.2054 - recall_51: 1.0000 - precision_51: 0.2054\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1276 - accuracy: 0.2017 - recall_51: 1.0000 - precision_51: 0.2017\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1104 - accuracy: 0.2006 - recall_51: 1.0000 - precision_51: 0.2006\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0895 - accuracy: 0.2037 - recall_51: 1.0000 - precision_51: 0.2037\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0702 - accuracy: 0.2059 - recall_51: 1.0000 - precision_51: 0.2059\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0600 - accuracy: 0.1984 - recall_51: 1.0000 - precision_51: 0.1984\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0434 - accuracy: 0.1987 - recall_51: 1.0000 - precision_51: 0.1987\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0240 - accuracy: 0.2028 - recall_51: 1.0000 - precision_51: 0.2028\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0095 - accuracy: 0.2016 - recall_51: 1.0000 - precision_51: 0.2016\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9969 - accuracy: 0.1986 - recall_51: 1.0000 - precision_51: 0.1986\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9803 - accuracy: 0.2012 - recall_51: 1.0000 - precision_51: 0.2012\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9642 - accuracy: 0.2037 - recall_51: 1.0000 - precision_51: 0.2037\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9501 - accuracy: 0.2042 - recall_51: 1.0000 - precision_51: 0.2042\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9401 - accuracy: 0.1990 - recall_51: 1.0000 - precision_51: 0.1990\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9247 - accuracy: 0.2029 - recall_51: 1.0000 - precision_51: 0.2029\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9121 - accuracy: 0.2030 - recall_51: 1.0000 - precision_51: 0.2030\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9011 - accuracy: 0.2009 - recall_51: 1.0000 - precision_51: 0.2009\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8890 - accuracy: 0.2015 - recall_51: 1.0000 - precision_51: 0.2015\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8766 - accuracy: 0.2034 - recall_51: 1.0000 - precision_51: 0.2034\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8659 - accuracy: 0.2024 - recall_51: 1.0000 - precision_51: 0.2024\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8535 - accuracy: 0.2057 - recall_51: 1.0000 - precision_51: 0.2057\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8463 - accuracy: 0.1986 - recall_51: 1.0000 - precision_51: 0.1986\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8349 - accuracy: 0.2016 - recall_51: 1.0000 - precision_51: 0.2016\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8241 - accuracy: 0.2042 - recall_51: 1.0000 - precision_51: 0.2042\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8169 - accuracy: 0.1982 - recall_51: 1.0000 - precision_51: 0.1982\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8052 - accuracy: 0.2057 - recall_51: 1.0000 - precision_51: 0.2057\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7981 - accuracy: 0.2001 - recall_51: 1.0000 - precision_51: 0.2001\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7880 - accuracy: 0.2051 - recall_51: 1.0000 - precision_51: 0.2051\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7810 - accuracy: 0.2001 - recall_51: 1.0000 - precision_51: 0.2001\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7724 - accuracy: 0.2016 - recall_51: 1.0000 - precision_51: 0.2016\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7646 - accuracy: 0.2012 - recall_51: 1.0000 - precision_51: 0.2012\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7566 - accuracy: 0.2032 - recall_51: 1.0000 - precision_51: 0.2032\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7487 - accuracy: 0.2061 - recall_51: 1.0000 - precision_51: 0.2061\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7417 - accuracy: 0.2055 - recall_51: 1.0000 - precision_51: 0.2055\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7353 - accuracy: 0.2021 - recall_51: 1.0000 - precision_51: 0.2021\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7285 - accuracy: 0.2025 - recall_51: 1.0000 - precision_51: 0.2025\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7220 - accuracy: 0.2022 - recall_51: 1.0000 - precision_51: 0.2022\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7157 - accuracy: 0.2037 - recall_51: 1.0000 - precision_51: 0.2037\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7096 - accuracy: 0.2037 - recall_51: 1.0000 - precision_51: 0.2037\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.2038 - recall_51: 1.0000 - precision_51: 0.2038\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6979 - accuracy: 0.2141 - recall_51: 0.9824 - precision_51: 0.2024\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5895 - recall_51: 0.2923 - precision_51: 0.1819\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6869 - accuracy: 0.7955 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.8010 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.7984 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6715 - accuracy: 0.8023 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.8000 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.7979 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6585 - accuracy: 0.7951 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.7993 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.7994 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.7966 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.7961 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.8013 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.7971 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.7985 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6264 - accuracy: 0.8009 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.7958 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6200 - accuracy: 0.7998 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6175 - accuracy: 0.7974 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.8037 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.7993 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.7950 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.7976 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.7959 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.7989 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.7998 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7932 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.7999 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7997 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7949 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7962 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.7966 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5811 - accuracy: 0.7988 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.7977 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5777 - accuracy: 0.7976 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5771 - accuracy: 0.7948 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.7968 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7981 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.8006 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.7968 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.7945 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7946 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7954 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7988 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.7953 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7951 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7985 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7984 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7963 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7981 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7963 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7929 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.8016 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FBD820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7973 - recall_51: 0.0000e+00 - precision_51: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.9379 - accuracy: 0.2022 - recall_52: 1.0000 - precision_52: 0.2022\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9251 - accuracy: 0.2038 - recall_52: 1.0000 - precision_52: 0.2038\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9138 - accuracy: 0.2030 - recall_52: 1.0000 - precision_52: 0.2030\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9021 - accuracy: 0.2039 - recall_52: 1.0000 - precision_52: 0.2039\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8917 - accuracy: 0.2026 - recall_52: 1.0000 - precision_52: 0.2026\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8829 - accuracy: 0.1993 - recall_52: 1.0000 - precision_52: 0.1993\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8724 - accuracy: 0.1996 - recall_52: 1.0000 - precision_52: 0.1996\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8612 - accuracy: 0.2021 - recall_52: 1.0000 - precision_52: 0.2021\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8512 - accuracy: 0.2023 - recall_52: 1.0000 - precision_52: 0.2023\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8423 - accuracy: 0.2010 - recall_52: 1.0000 - precision_52: 0.2010\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8316 - accuracy: 0.2046 - recall_52: 1.0000 - precision_52: 0.2046\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8246 - accuracy: 0.1995 - recall_52: 1.0000 - precision_52: 0.1995\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8141 - accuracy: 0.2046 - recall_52: 1.0000 - precision_52: 0.2046\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8072 - accuracy: 0.1999 - recall_52: 1.0000 - precision_52: 0.1999\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7973 - accuracy: 0.2054 - recall_52: 1.0000 - precision_52: 0.2054\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7905 - accuracy: 0.2011 - recall_52: 1.0000 - precision_52: 0.2011\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7823 - accuracy: 0.2030 - recall_52: 1.0000 - precision_52: 0.2030\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7744 - accuracy: 0.2041 - recall_52: 1.0000 - precision_52: 0.2041\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7676 - accuracy: 0.2019 - recall_52: 1.0000 - precision_52: 0.2019\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7606 - accuracy: 0.2016 - recall_52: 1.0000 - precision_52: 0.2016\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7535 - accuracy: 0.2031 - recall_52: 1.0000 - precision_52: 0.2031\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7472 - accuracy: 0.2009 - recall_52: 1.0000 - precision_52: 0.2009\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7404 - accuracy: 0.2026 - recall_52: 1.0000 - precision_52: 0.2026\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7339 - accuracy: 0.2054 - recall_52: 1.0000 - precision_52: 0.2054\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7280 - accuracy: 0.2039 - recall_52: 1.0000 - precision_52: 0.2039\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7223 - accuracy: 0.2012 - recall_52: 1.0000 - precision_52: 0.2012\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.2016 - recall_52: 1.0000 - precision_52: 0.2016\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.2011 - recall_52: 1.0000 - precision_52: 0.2011\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7054 - accuracy: 0.2032 - recall_52: 1.0000 - precision_52: 0.2032\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7001 - accuracy: 0.2058 - recall_52: 1.0000 - precision_52: 0.2058\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.2504 - recall_52: 0.8778 - precision_52: 0.1996\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.8002 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.7995 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.7963 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.7993 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7987 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.7980 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.7975 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.7966 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.8005 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.7945 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.7966 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.7974 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.7984 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.7992 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6334 - accuracy: 0.7975 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6301 - accuracy: 0.7977 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.7992 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6234 - accuracy: 0.7997 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.8002 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.7964 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.7957 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.8005 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.7969 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6077 - accuracy: 0.7964 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.7985 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.7976 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.7987 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7968 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7977 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.8002 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.7955 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.7969 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.7975 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.8000 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.7991 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.8014 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.7975 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7960 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.8004 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7966 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7992 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.7970 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7979 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5670 - accuracy: 0.7987 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.7978 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.7984 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.8015 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5621 - accuracy: 0.7972 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7998 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7970 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7934 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7952 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7983 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7960 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.8005 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5528 - accuracy: 0.7962 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7983 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7956 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7973 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7977 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.7990 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7939 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5476 - accuracy: 0.7935 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7972 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7980 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7959 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7932 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7987 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7992 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7973 - recall_52: 0.0000e+00 - precision_52: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8636 - accuracy: 0.1998 - recall_53: 1.0000 - precision_53: 0.1998\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8523 - accuracy: 0.2026 - recall_53: 1.0000 - precision_53: 0.2026\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8429 - accuracy: 0.2017 - recall_53: 1.0000 - precision_53: 0.2017\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8325 - accuracy: 0.2042 - recall_53: 1.0000 - precision_53: 0.2042\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8247 - accuracy: 0.1999 - recall_53: 1.0000 - precision_53: 0.1999\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8147 - accuracy: 0.2028 - recall_53: 1.0000 - precision_53: 0.2028\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8059 - accuracy: 0.2034 - recall_53: 1.0000 - precision_53: 0.2034\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7978 - accuracy: 0.2023 - recall_53: 1.0000 - precision_53: 0.2023\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7888 - accuracy: 0.2053 - recall_53: 1.0000 - precision_53: 0.2053\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7818 - accuracy: 0.2019 - recall_53: 1.0000 - precision_53: 0.2019\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7731 - accuracy: 0.2056 - recall_53: 1.0000 - precision_53: 0.2056\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7665 - accuracy: 0.2018 - recall_53: 1.0000 - precision_53: 0.2018\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7590 - accuracy: 0.2025 - recall_53: 1.0000 - precision_53: 0.2025\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7520 - accuracy: 0.2029 - recall_53: 1.0000 - precision_53: 0.2029\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7454 - accuracy: 0.2012 - recall_53: 1.0000 - precision_53: 0.2012\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7388 - accuracy: 0.2011 - recall_53: 1.0000 - precision_53: 0.2011\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7326 - accuracy: 0.2000 - recall_53: 1.0000 - precision_53: 0.2000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7260 - accuracy: 0.2037 - recall_53: 1.0000 - precision_53: 0.2037\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.2031 - recall_53: 1.0000 - precision_53: 0.2031\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7144 - accuracy: 0.2008 - recall_53: 1.0000 - precision_53: 0.2008\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7087 - accuracy: 0.2010 - recall_53: 1.0000 - precision_53: 0.2010\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.2009 - recall_53: 1.0000 - precision_53: 0.2009\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.2126 - recall_53: 0.9709 - precision_53: 0.1991\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5586 - recall_53: 0.4432 - precision_53: 0.2121\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.7932 - recall_53: 0.0057 - precision_53: 0.3636\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.8003 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.7954 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.7959 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6685 - accuracy: 0.7991 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.7952 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6601 - accuracy: 0.7964 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.7994 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.7979 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.7963 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.7970 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.7973 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7957 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.7957 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.7970 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.7972 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.7958 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6204 - accuracy: 0.7982 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.7985 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.7952 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.7968 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.7945 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.7969 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.7952 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7963 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7997 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.7969 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7988 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.7972 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.7980 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7990 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.8000 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7963 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.7930 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7973 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7965 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.7965 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7976 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7975 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7972 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5704 - accuracy: 0.7949 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7980 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.7972 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7991 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7980 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7960 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7975 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.7933 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.7975 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.7985 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7994 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7949 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7942 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7944 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7994 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7993 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7988 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7971 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7957 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7979 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7930 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7977 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5419 - accuracy: 0.7982 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5410 - accuracy: 0.7982 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7927 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7964 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7965 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7977 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7962 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7992 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7981 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7945 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7980 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7988 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7980 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7927 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE78B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7977 - recall_53: 0.0000e+00 - precision_53: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6977 - accuracy: 0.2448 - recall_54: 0.9429 - precision_54: 0.2037\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5147 - recall_54: 0.4731 - precision_54: 0.2027\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.7800 - recall_54: 0.0499 - precision_54: 0.2345\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.7997 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.7945 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6745 - accuracy: 0.7994 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.8014 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.7960 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.7990 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6584 - accuracy: 0.7961 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.7976 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6506 - accuracy: 0.7975 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.8006 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.8011 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.7954 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.7959 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.7979 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.8034 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.8003 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6239 - accuracy: 0.7988 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.7989 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6178 - accuracy: 0.7993 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6163 - accuracy: 0.7952 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6129 - accuracy: 0.7971 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.7987 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6069 - accuracy: 0.7999 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7969 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.7969 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.7988 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.7944 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.7969 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.7989 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.7956 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7951 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.7957 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.7970 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5820 - accuracy: 0.8003 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7974 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7998 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7964 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7966 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.8008 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7954 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7994 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5682 - accuracy: 0.7999 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7988 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7973 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7975 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5637 - accuracy: 0.7973 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.7901 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7984 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.7993 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5589 - accuracy: 0.7963 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5562 - accuracy: 0.7986 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7975 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7970 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7984 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7955 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5487 - accuracy: 0.8015 - recall_54: 0.0000e+00 - precision_54: 0.0000e+0 - 0s 5ms/step - loss: 0.5507 - accuracy: 0.7981 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7989 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7958 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7959 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7918 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7996 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.8004 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7999 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7986 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7958 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7974 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7980 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.7957 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7986 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7983 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7978 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7965 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7974 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7969 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7970 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7981 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7996 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5338 - accuracy: 0.7955 - recall_54: 0.0000e+00 - precision_54: 0.0000e+0 - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7972 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.8006 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.8003 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.8028 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7961 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7964 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7981 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7969 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.7954 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7953 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7977 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7976 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.8018 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.8004 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7974 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7962 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7964 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7939 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.8024 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7932 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FBD1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7973 - recall_54: 0.0000e+00 - precision_54: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.7192 - accuracy: 0.4817 - recall_55: 0.4699 - precision_55: 0.1904\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7143 - accuracy: 0.4931 - recall_55: 0.4437 - precision_55: 0.1894\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7070 - accuracy: 0.5074 - recall_55: 0.4486 - precision_55: 0.1953\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.5125 - recall_55: 0.4164 - precision_55: 0.1851\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6973 - accuracy: 0.5238 - recall_55: 0.4106 - precision_55: 0.1889\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.5382 - recall_55: 0.4085 - precision_55: 0.1946\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5438 - recall_55: 0.3888 - precision_55: 0.1932\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5508 - recall_55: 0.3719 - precision_55: 0.1880\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5588 - recall_55: 0.3633 - precision_55: 0.1931\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.5641 - recall_55: 0.3439 - precision_55: 0.1895\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6704 - accuracy: 0.5724 - recall_55: 0.3264 - precision_55: 0.1839\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.5839 - recall_55: 0.3146 - precision_55: 0.1838\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.5918 - recall_55: 0.2935 - precision_55: 0.1817\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.6030 - recall_55: 0.2831 - precision_55: 0.1824\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.6149 - recall_55: 0.2794 - precision_55: 0.1944\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.6253 - recall_55: 0.2642 - precision_55: 0.1874\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6475 - accuracy: 0.6349 - recall_55: 0.2479 - precision_55: 0.1842\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.6397 - recall_55: 0.2347 - precision_55: 0.1868\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.6486 - recall_55: 0.2210 - precision_55: 0.1896\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6529 - recall_55: 0.2175 - precision_55: 0.1918\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.6750 - recall_55: 0.2245 - precision_55: 0.202 - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6682 - recall_55: 0.2104 - precision_55: 0.1957\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.6778 - recall_55: 0.2075 - precision_55: 0.2048\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6845 - recall_55: 0.1913 - precision_55: 0.2080\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.6979 - recall_55: 0.1931 - precision_55: 0.2111\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6981 - recall_55: 0.1807 - precision_55: 0.2142\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.7046 - recall_55: 0.1743 - precision_55: 0.2221\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6176 - accuracy: 0.7119 - recall_55: 0.1711 - precision_55: 0.2288\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.7212 - recall_55: 0.1656 - precision_55: 0.2407\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.7292 - recall_55: 0.1517 - precision_55: 0.2316\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6078 - accuracy: 0.7353 - recall_55: 0.1511 - precision_55: 0.2409\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.7404 - recall_55: 0.1516 - precision_55: 0.2545\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.7466 - recall_55: 0.1465 - precision_55: 0.2754\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.7479 - recall_55: 0.1441 - precision_55: 0.2641\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.7458 - recall_55: 0.1359 - precision_55: 0.2646\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5971 - accuracy: 0.7479 - recall_55: 0.1315 - precision_55: 0.2614\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7528 - recall_55: 0.1324 - precision_55: 0.2680\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.7538 - recall_55: 0.1229 - precision_55: 0.2704\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7597 - recall_55: 0.1243 - precision_55: 0.2852\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7576 - recall_55: 0.1094 - precision_55: 0.2551\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.7553 - recall_55: 0.1002 - precision_55: 0.2560\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.7597 - recall_55: 0.0925 - precision_55: 0.2529\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5836 - accuracy: 0.7575 - recall_55: 0.0861 - precision_55: 0.259 - 0s 4ms/step - loss: 0.5818 - accuracy: 0.7608 - recall_55: 0.0861 - precision_55: 0.2517\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.7625 - recall_55: 0.0797 - precision_55: 0.2440\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5761 - accuracy: 0.7700 - recall_55: 0.0740 - precision_55: 0.2537\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5761 - accuracy: 0.7682 - recall_55: 0.0783 - precision_55: 0.2769\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.7723 - recall_55: 0.0732 - precision_55: 0.2659\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.7754 - recall_55: 0.0592 - precision_55: 0.2451\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.7757 - recall_55: 0.0581 - precision_55: 0.2516\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.7759 - recall_55: 0.0507 - precision_55: 0.2419\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7766 - recall_55: 0.0509 - precision_55: 0.2526\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5650 - accuracy: 0.7784 - recall_55: 0.0464 - precision_55: 0.2607\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7829 - recall_55: 0.0469 - precision_55: 0.2723\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7824 - recall_55: 0.0364 - precision_55: 0.2315\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7836 - recall_55: 0.0293 - precision_55: 0.2211\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7808 - recall_55: 0.0342 - precision_55: 0.2546\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.7873 - recall_55: 0.0241 - precision_55: 0.2243\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7887 - recall_55: 0.0238 - precision_55: 0.2291\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.7875 - recall_55: 0.0207 - precision_55: 0.2321\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7859 - recall_55: 0.0229 - precision_55: 0.2563\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7873 - recall_55: 0.0227 - precision_55: 0.2688\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.7881 - recall_55: 0.0172 - precision_55: 0.2286\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7923 - recall_55: 0.0179 - precision_55: 0.2397\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7910 - recall_55: 0.0158 - precision_55: 0.2328\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5444 - accuracy: 0.7937 - recall_55: 0.0153 - precision_55: 0.2492\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7914 - recall_55: 0.0111 - precision_55: 0.1884\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.7930 - recall_55: 0.0111 - precision_55: 0.2200\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7919 - recall_55: 0.0113 - precision_55: 0.2434\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7914 - recall_55: 0.0108 - precision_55: 0.2312\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7945 - recall_55: 0.0078 - precision_55: 0.2017\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7905 - recall_55: 0.0079 - precision_55: 0.2291\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7944 - recall_55: 0.0057 - precision_55: 0.1904\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7949 - recall_55: 0.0051 - precision_55: 0.2553\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7928 - recall_55: 0.0034 - precision_55: 0.1552\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7949 - recall_55: 0.0017 - precision_55: 0.1024    \n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7949 - recall_55: 0.0023 - precision_55: 0.1686\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7972 - recall_55: 0.0014 - precision_55: 0.1187    \n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.8000 - recall_55: 0.0023 - precision_55: 0.2125\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7971 - recall_55: 0.0015 - precision_55: 0.2232\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.7994 - recall_55: 0.0015 - precision_55: 0.3714\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7958 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7975 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7942 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.8016 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7946 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7977 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7966 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7976 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7966 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7971 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7962 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7979 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7944 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7956 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7974 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7989 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5174 - accuracy: 0.7985 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.8001 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.8000 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7942 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7979 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FBDC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7973 - recall_55: 0.0000e+00 - precision_55: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6894 - accuracy: 0.5492 - recall_56: 0.6004 - precision_56: 0.2483\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.5681 - recall_56: 0.5816 - precision_56: 0.2533\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.5741 - recall_56: 0.5571 - precision_56: 0.2540\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6704 - accuracy: 0.5873 - recall_56: 0.5508 - precision_56: 0.2546\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6652 - accuracy: 0.5986 - recall_56: 0.5283 - precision_56: 0.2552\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.6084 - recall_56: 0.5044 - precision_56: 0.2588\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6196 - recall_56: 0.4875 - precision_56: 0.2595\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.6251 - recall_56: 0.4750 - precision_56: 0.2628\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6329 - recall_56: 0.4582 - precision_56: 0.2676\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6458 - recall_56: 0.4442 - precision_56: 0.2666\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6567 - recall_56: 0.4297 - precision_56: 0.2779\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6627 - recall_56: 0.4208 - precision_56: 0.2781\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6269 - accuracy: 0.6727 - recall_56: 0.3951 - precision_56: 0.2810\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6805 - recall_56: 0.3715 - precision_56: 0.2840\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.6898 - recall_56: 0.3705 - precision_56: 0.2933\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.6987 - recall_56: 0.3529 - precision_56: 0.2990\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.7027 - recall_56: 0.3413 - precision_56: 0.2980\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7086 - recall_56: 0.3138 - precision_56: 0.2960\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6051 - accuracy: 0.7139 - recall_56: 0.3091 - precision_56: 0.2992\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.7232 - recall_56: 0.2988 - precision_56: 0.3062\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.7251 - recall_56: 0.2756 - precision_56: 0.2963\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.7340 - recall_56: 0.2785 - precision_56: 0.3214\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5918 - accuracy: 0.7398 - recall_56: 0.2649 - precision_56: 0.3308\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.7398 - recall_56: 0.2448 - precision_56: 0.3268\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.7466 - recall_56: 0.2443 - precision_56: 0.3318\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5817 - accuracy: 0.7575 - recall_56: 0.2329 - precision_56: 0.3496\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.7589 - recall_56: 0.2220 - precision_56: 0.3506\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7628 - recall_56: 0.2068 - precision_56: 0.3550\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7717 - recall_56: 0.1927 - precision_56: 0.3672\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5741 - accuracy: 0.7628 - recall_56: 0.1851 - precision_56: 0.3618\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7684 - recall_56: 0.1760 - precision_56: 0.3674\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.7763 - recall_56: 0.1716 - precision_56: 0.3872\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.7801 - recall_56: 0.1626 - precision_56: 0.3923\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7847 - recall_56: 0.1514 - precision_56: 0.3959\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7864 - recall_56: 0.1556 - precision_56: 0.4326\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7821 - recall_56: 0.1322 - precision_56: 0.4069\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.7882 - recall_56: 0.1332 - precision_56: 0.4219\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5513 - accuracy: 0.7915 - recall_56: 0.1250 - precision_56: 0.4048\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7892 - recall_56: 0.1243 - precision_56: 0.4278\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5486 - accuracy: 0.7928 - recall_56: 0.1214 - precision_56: 0.4568\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7918 - recall_56: 0.1178 - precision_56: 0.4740\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7981 - recall_56: 0.1186 - precision_56: 0.4792\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7917 - recall_56: 0.0996 - precision_56: 0.4563\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7963 - recall_56: 0.1003 - precision_56: 0.4791\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7955 - recall_56: 0.0921 - precision_56: 0.4716\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7958 - recall_56: 0.0941 - precision_56: 0.4945\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7969 - recall_56: 0.0797 - precision_56: 0.4884\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7963 - recall_56: 0.0717 - precision_56: 0.4771\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7951 - recall_56: 0.0727 - precision_56: 0.4884\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7948 - recall_56: 0.0711 - precision_56: 0.5028\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7981 - recall_56: 0.0706 - precision_56: 0.4872\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.8014 - recall_56: 0.0633 - precision_56: 0.4861\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7977 - recall_56: 0.0664 - precision_56: 0.5370\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7985 - recall_56: 0.0591 - precision_56: 0.5374\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7975 - recall_56: 0.0578 - precision_56: 0.5387\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.8017 - recall_56: 0.0489 - precision_56: 0.5090\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.8021 - recall_56: 0.0521 - precision_56: 0.5468\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7981 - recall_56: 0.0501 - precision_56: 0.5462\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.8022 - recall_56: 0.0407 - precision_56: 0.5279\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.8018 - recall_56: 0.0531 - precision_56: 0.6190\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.8016 - recall_56: 0.0482 - precision_56: 0.5866\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.8014 - recall_56: 0.0419 - precision_56: 0.5537\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7968 - recall_56: 0.0408 - precision_56: 0.6334\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7994 - recall_56: 0.0344 - precision_56: 0.5738\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7993 - recall_56: 0.0331 - precision_56: 0.5862\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7958 - recall_56: 0.0355 - precision_56: 0.5728\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7987 - recall_56: 0.0312 - precision_56: 0.5384\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5113 - accuracy: 0.7978 - recall_56: 0.0258 - precision_56: 0.5280\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.7975 - recall_56: 0.0343 - precision_56: 0.560 - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7967 - recall_56: 0.0276 - precision_56: 0.5379\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7972 - recall_56: 0.0241 - precision_56: 0.5547\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7987 - recall_56: 0.0256 - precision_56: 0.5583\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.8003 - recall_56: 0.0176 - precision_56: 0.5180\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7968 - recall_56: 0.0210 - precision_56: 0.5562\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7983 - recall_56: 0.0192 - precision_56: 0.5649\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7929 - recall_56: 0.0138 - precision_56: 0.5345\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7951 - recall_56: 0.0134 - precision_56: 0.5119\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7963 - recall_56: 0.0124 - precision_56: 0.4899\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7976 - recall_56: 0.0155 - precision_56: 0.5644\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7958 - recall_56: 0.0121 - precision_56: 0.5109\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7979 - recall_56: 0.0119 - precision_56: 0.6498\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7971 - recall_56: 0.0135 - precision_56: 0.5519\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7979 - recall_56: 0.0105 - precision_56: 0.4963\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7979 - recall_56: 0.0114 - precision_56: 0.4837\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7948 - recall_56: 0.0130 - precision_56: 0.6115\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7953 - recall_56: 0.0070 - precision_56: 0.4500\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7979 - recall_56: 0.0068 - precision_56: 0.5056\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7952 - recall_56: 0.0070 - precision_56: 0.5038\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.7968 - recall_56: 0.0065 - precision_56: 0.5000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.8015 - recall_56: 0.0085 - precision_56: 0.6042\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.8001 - recall_56: 0.0084 - precision_56: 0.6333\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.7986 - recall_56: 0.0093 - precision_56: 0.6423\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.8003 - recall_56: 0.0065 - precision_56: 0.8083\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.8001 - recall_56: 0.0057 - precision_56: 0.6429\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7980 - recall_56: 0.0066 - precision_56: 0.6771\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7984 - recall_56: 0.0044 - precision_56: 0.4762    \n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.8007 - recall_56: 0.0060 - precision_56: 0.7396\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7965 - recall_56: 0.0065 - precision_56: 0.6771\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7992 - recall_56: 0.0048 - precision_56: 0.5312\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7985 - recall_56: 0.0058 - precision_56: 0.6429\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7987 - recall_56: 0.0055 - precision_56: 0.5688\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657C9E940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7968 - recall_56: 0.0064 - precision_56: 0.3750\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6941 - accuracy: 0.5673 - recall_57: 0.6199 - precision_57: 0.2609\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5787 - recall_57: 0.6132 - precision_57: 0.2621\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.5821 - recall_57: 0.6033 - precision_57: 0.2684\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5874 - recall_57: 0.5749 - precision_57: 0.2609\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.5989 - recall_57: 0.5787 - precision_57: 0.2662\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.6071 - recall_57: 0.5647 - precision_57: 0.2739\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.6082 - recall_57: 0.5484 - precision_57: 0.2706\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.6146 - recall_57: 0.5328 - precision_57: 0.2698\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.6247 - recall_57: 0.5228 - precision_57: 0.2709\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.6284 - recall_57: 0.5185 - precision_57: 0.2767\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.6346 - recall_57: 0.5131 - precision_57: 0.2763\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.6393 - recall_57: 0.4895 - precision_57: 0.2781\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.6489 - recall_57: 0.4879 - precision_57: 0.2861\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6241 - accuracy: 0.6554 - recall_57: 0.4841 - precision_57: 0.2850\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.6593 - recall_57: 0.4745 - precision_57: 0.2892\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.6611 - recall_57: 0.4440 - precision_57: 0.2818\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6131 - accuracy: 0.6700 - recall_57: 0.4456 - precision_57: 0.2957\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.6739 - recall_57: 0.4230 - precision_57: 0.2941\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.6774 - recall_57: 0.3973 - precision_57: 0.2882\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.6857 - recall_57: 0.3978 - precision_57: 0.2963\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.6879 - recall_57: 0.3822 - precision_57: 0.2894\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.6854 - recall_57: 0.3713 - precision_57: 0.2881\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.6922 - recall_57: 0.3570 - precision_57: 0.2890\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.6947 - recall_57: 0.3480 - precision_57: 0.2856\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7043 - recall_57: 0.3332 - precision_57: 0.2865\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7014 - recall_57: 0.3208 - precision_57: 0.2878\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.7066 - recall_57: 0.3104 - precision_57: 0.2896\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.7089 - recall_57: 0.2881 - precision_57: 0.2789\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5759 - accuracy: 0.7065 - recall_57: 0.2730 - precision_57: 0.2740\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7145 - recall_57: 0.2682 - precision_57: 0.2803\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7223 - recall_57: 0.2657 - precision_57: 0.2860\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.7195 - recall_57: 0.2450 - precision_57: 0.2831\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.7229 - recall_57: 0.2357 - precision_57: 0.2792\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7285 - recall_57: 0.2328 - precision_57: 0.2878\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7297 - recall_57: 0.2216 - precision_57: 0.2858\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7348 - recall_57: 0.2173 - precision_57: 0.2949\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.7419 - recall_57: 0.2198 - precision_57: 0.3056\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7434 - recall_57: 0.1991 - precision_57: 0.2933\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7446 - recall_57: 0.1943 - precision_57: 0.3000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7515 - recall_57: 0.1907 - precision_57: 0.3165\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7514 - recall_57: 0.1760 - precision_57: 0.3020\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7551 - recall_57: 0.1728 - precision_57: 0.3090\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7523 - recall_57: 0.1601 - precision_57: 0.3088\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.7475 - recall_57: 0.1422 - precision_57: 0.283 - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7550 - recall_57: 0.1497 - precision_57: 0.3006\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7602 - recall_57: 0.1433 - precision_57: 0.3100\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7607 - recall_57: 0.1366 - precision_57: 0.3154\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7649 - recall_57: 0.1301 - precision_57: 0.3170\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7679 - recall_57: 0.1203 - precision_57: 0.3077\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7740 - recall_57: 0.1171 - precision_57: 0.3220\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7713 - recall_57: 0.1075 - precision_57: 0.3090\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7743 - recall_57: 0.1050 - precision_57: 0.3240\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7753 - recall_57: 0.1026 - precision_57: 0.3271\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7767 - recall_57: 0.0971 - precision_57: 0.3313\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7847 - recall_57: 0.0989 - precision_57: 0.3722\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7802 - recall_57: 0.0872 - precision_57: 0.3327\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7865 - recall_57: 0.0836 - precision_57: 0.3548\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7849 - recall_57: 0.0766 - precision_57: 0.3417\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7857 - recall_57: 0.0748 - precision_57: 0.3443\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7910 - recall_57: 0.0733 - precision_57: 0.3427\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7869 - recall_57: 0.0681 - precision_57: 0.3557\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7878 - recall_57: 0.0670 - precision_57: 0.3663\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7881 - recall_57: 0.0673 - precision_57: 0.3819\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7903 - recall_57: 0.0563 - precision_57: 0.3718\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7893 - recall_57: 0.0537 - precision_57: 0.3692\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7875 - recall_57: 0.0508 - precision_57: 0.3805\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7901 - recall_57: 0.0446 - precision_57: 0.3514\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7937 - recall_57: 0.0479 - precision_57: 0.3864\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7922 - recall_57: 0.0429 - precision_57: 0.3540\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7914 - recall_57: 0.0385 - precision_57: 0.3502\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7950 - recall_57: 0.0374 - precision_57: 0.3734\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7922 - recall_57: 0.0341 - precision_57: 0.3911\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7883 - recall_57: 0.0341 - precision_57: 0.3850\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7937 - recall_57: 0.0320 - precision_57: 0.4038\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7972 - recall_57: 0.0282 - precision_57: 0.4022\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7949 - recall_57: 0.0300 - precision_57: 0.4276\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7946 - recall_57: 0.0243 - precision_57: 0.4053\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7972 - recall_57: 0.0196 - precision_57: 0.3681\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.7926 - recall_57: 0.0217 - precision_57: 0.4351\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7962 - recall_57: 0.0167 - precision_57: 0.4057\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7957 - recall_57: 0.0171 - precision_57: 0.4301\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7994 - recall_57: 0.0163 - precision_57: 0.4036\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7948 - recall_57: 0.0159 - precision_57: 0.4332\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.8023 - recall_57: 0.0140 - precision_57: 0.4044\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7983 - recall_57: 0.0157 - precision_57: 0.4142\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7968 - recall_57: 0.0134 - precision_57: 0.4227\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7984 - recall_57: 0.0126 - precision_57: 0.4470\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7975 - recall_57: 0.0110 - precision_57: 0.3791\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7997 - recall_57: 0.0106 - precision_57: 0.3928\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7965 - recall_57: 0.0126 - precision_57: 0.4408\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7989 - recall_57: 0.0127 - precision_57: 0.4678\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7947 - recall_57: 0.0100 - precision_57: 0.4802\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.8007 - recall_57: 0.0123 - precision_57: 0.5558\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7998 - recall_57: 0.0120 - precision_57: 0.5574\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7950 - recall_57: 0.0078 - precision_57: 0.4429\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.8011 - recall_57: 0.0099 - precision_57: 0.4788\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7969 - recall_57: 0.0095 - precision_57: 0.4408\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.7996 - recall_57: 0.0061 - precision_57: 0.4242\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7990 - recall_57: 0.0089 - precision_57: 0.5750\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7966 - recall_57: 0.0091 - precision_57: 0.5345\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7984 - recall_57: 0.0080 - precision_57: 0.5905\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7985 - recall_57: 0.0127 - precision_57: 0.6667\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.9105 - accuracy: 0.2030 - recall_58: 1.0000 - precision_58: 0.2030\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9070 - accuracy: 0.2037 - recall_58: 1.0000 - precision_58: 0.2037\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9051 - accuracy: 0.2019 - recall_58: 1.0000 - precision_58: 0.2019\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9017 - accuracy: 0.2026 - recall_58: 1.0000 - precision_58: 0.2026\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8966 - accuracy: 0.2064 - recall_58: 1.0000 - precision_58: 0.2064\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8964 - accuracy: 0.2014 - recall_58: 1.0000 - precision_58: 0.2014\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8927 - accuracy: 0.2027 - recall_58: 1.0000 - precision_58: 0.2027\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8901 - accuracy: 0.2021 - recall_58: 1.0000 - precision_58: 0.2021\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8874 - accuracy: 0.2018 - recall_58: 1.0000 - precision_58: 0.2018\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8836 - accuracy: 0.2036 - recall_58: 1.0000 - precision_58: 0.2036\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8809 - accuracy: 0.2033 - recall_58: 1.0000 - precision_58: 0.2033\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8800 - accuracy: 0.1995 - recall_58: 1.0000 - precision_58: 0.1995\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8740 - accuracy: 0.2058 - recall_58: 1.0000 - precision_58: 0.2058\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8727 - accuracy: 0.2029 - recall_58: 1.0000 - precision_58: 0.2029\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8700 - accuracy: 0.2026 - recall_58: 1.0000 - precision_58: 0.2026\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8670 - accuracy: 0.2031 - recall_58: 1.0000 - precision_58: 0.2031\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8633 - accuracy: 0.2053 - recall_58: 1.0000 - precision_58: 0.2053\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8627 - accuracy: 0.2009 - recall_58: 1.0000 - precision_58: 0.2009\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8589 - accuracy: 0.2032 - recall_58: 1.0000 - precision_58: 0.2032\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8591 - accuracy: 0.1971 - recall_58: 1.0000 - precision_58: 0.1971\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8545 - accuracy: 0.2015 - recall_58: 1.0000 - precision_58: 0.2015\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8513 - accuracy: 0.2026 - recall_58: 1.0000 - precision_58: 0.2026\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8481 - accuracy: 0.2040 - recall_58: 1.0000 - precision_58: 0.2040\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8467 - accuracy: 0.2014 - recall_58: 1.0000 - precision_58: 0.2014\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8456 - accuracy: 0.1980 - recall_58: 1.0000 - precision_58: 0.1980\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8417 - accuracy: 0.2012 - recall_58: 1.0000 - precision_58: 0.2012\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8393 - accuracy: 0.2011 - recall_58: 1.0000 - precision_58: 0.2011\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8358 - accuracy: 0.2037 - recall_58: 1.0000 - precision_58: 0.2037\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8334 - accuracy: 0.2033 - recall_58: 1.0000 - precision_58: 0.2033\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8306 - accuracy: 0.2041 - recall_58: 1.0000 - precision_58: 0.2041\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8277 - accuracy: 0.2053 - recall_58: 1.0000 - precision_58: 0.2053\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8260 - accuracy: 0.2034 - recall_58: 1.0000 - precision_58: 0.2034\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8241 - accuracy: 0.2021 - recall_58: 1.0000 - precision_58: 0.2021\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8229 - accuracy: 0.1990 - recall_58: 1.0000 - precision_58: 0.1990\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8191 - accuracy: 0.2028 - recall_58: 1.0000 - precision_58: 0.2028\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8167 - accuracy: 0.2030 - recall_58: 1.0000 - precision_58: 0.2030\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8146 - accuracy: 0.2024 - recall_58: 1.0000 - precision_58: 0.2024\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8111 - accuracy: 0.2057 - recall_58: 1.0000 - precision_58: 0.2057\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8095 - accuracy: 0.2037 - recall_58: 1.0000 - precision_58: 0.2037\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8085 - accuracy: 0.2002 - recall_58: 1.0000 - precision_58: 0.2002\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8055 - accuracy: 0.2024 - recall_58: 1.0000 - precision_58: 0.2024\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8025 - accuracy: 0.2048 - recall_58: 1.0000 - precision_58: 0.2048\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8005 - accuracy: 0.2040 - recall_58: 1.0000 - precision_58: 0.2040\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7995 - accuracy: 0.2003 - recall_58: 1.0000 - precision_58: 0.2003\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7953 - accuracy: 0.2068 - recall_58: 1.0000 - precision_58: 0.2068\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7945 - accuracy: 0.2022 - recall_58: 1.0000 - precision_58: 0.2022\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7920 - accuracy: 0.2033 - recall_58: 1.0000 - precision_58: 0.2033\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7903 - accuracy: 0.2020 - recall_58: 1.0000 - precision_58: 0.2020\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7884 - accuracy: 0.2012 - recall_58: 1.0000 - precision_58: 0.2012\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7868 - accuracy: 0.1996 - recall_58: 1.0000 - precision_58: 0.1996\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7839 - accuracy: 0.2027 - recall_58: 1.0000 - precision_58: 0.2027\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7816 - accuracy: 0.2036 - recall_58: 1.0000 - precision_58: 0.2036\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7798 - accuracy: 0.2026 - recall_58: 1.0000 - precision_58: 0.2026\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7773 - accuracy: 0.2043 - recall_58: 1.0000 - precision_58: 0.2043\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7758 - accuracy: 0.2022 - recall_58: 1.0000 - precision_58: 0.2022\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7728 - accuracy: 0.2063 - recall_58: 1.0000 - precision_58: 0.2063\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7724 - accuracy: 0.1998 - recall_58: 1.0000 - precision_58: 0.1998\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7697 - accuracy: 0.2028 - recall_58: 1.0000 - precision_58: 0.2028\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7680 - accuracy: 0.2019 - recall_58: 1.0000 - precision_58: 0.2019\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7659 - accuracy: 0.2023 - recall_58: 1.0000 - precision_58: 0.2023\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7646 - accuracy: 0.1995 - recall_58: 1.0000 - precision_58: 0.1995\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7623 - accuracy: 0.2017 - recall_58: 1.0000 - precision_58: 0.2017\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7606 - accuracy: 0.2006 - recall_58: 1.0000 - precision_58: 0.2006\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7594 - accuracy: 0.1972 - recall_58: 1.0000 - precision_58: 0.1972\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7562 - accuracy: 0.2037 - recall_58: 1.0000 - precision_58: 0.2037\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7546 - accuracy: 0.2026 - recall_58: 1.0000 - precision_58: 0.2026\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7530 - accuracy: 0.2014 - recall_58: 1.0000 - precision_58: 0.2014\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7512 - accuracy: 0.2011 - recall_58: 1.0000 - precision_58: 0.2011\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7488 - accuracy: 0.2047 - recall_58: 1.0000 - precision_58: 0.2047\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7474 - accuracy: 0.2025 - recall_58: 1.0000 - precision_58: 0.2025\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7454 - accuracy: 0.2038 - recall_58: 1.0000 - precision_58: 0.2038\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.1995 - recall_58: 1.0000 - precision_58: 0.1995\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7423 - accuracy: 0.2010 - recall_58: 1.0000 - precision_58: 0.2010\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7405 - accuracy: 0.2016 - recall_58: 1.0000 - precision_58: 0.2016\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7386 - accuracy: 0.2029 - recall_58: 1.0000 - precision_58: 0.2029\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7369 - accuracy: 0.2026 - recall_58: 1.0000 - precision_58: 0.2026\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.2004 - recall_58: 1.0000 - precision_58: 0.2004\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.2031 - recall_58: 1.0000 - precision_58: 0.2031\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7317 - accuracy: 0.2042 - recall_58: 1.0000 - precision_58: 0.2042\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7302 - accuracy: 0.2033 - recall_58: 1.0000 - precision_58: 0.2033\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.2016 - recall_58: 1.0000 - precision_58: 0.2016\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7269 - accuracy: 0.2022 - recall_58: 1.0000 - precision_58: 0.2022\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7256 - accuracy: 0.1997 - recall_58: 1.0000 - precision_58: 0.1997\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7239 - accuracy: 0.2007 - recall_58: 1.0000 - precision_58: 0.2007\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7222 - accuracy: 0.2018 - recall_58: 1.0000 - precision_58: 0.2018\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7206 - accuracy: 0.2018 - recall_58: 1.0000 - precision_58: 0.2018\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7191 - accuracy: 0.2015 - recall_58: 1.0000 - precision_58: 0.2015\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7172 - accuracy: 0.2049 - recall_58: 1.0000 - precision_58: 0.2049\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.2033 - recall_58: 1.0000 - precision_58: 0.2033\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7141 - accuracy: 0.2056 - recall_58: 1.0000 - precision_58: 0.2056\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7130 - accuracy: 0.2001 - recall_58: 1.0000 - precision_58: 0.2001\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7112 - accuracy: 0.2038 - recall_58: 1.0000 - precision_58: 0.2038\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7095 - accuracy: 0.2070 - recall_58: 1.0000 - precision_58: 0.2070\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7083 - accuracy: 0.2025 - recall_58: 1.0000 - precision_58: 0.2025\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.2054 - recall_58: 1.0000 - precision_58: 0.2054\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7052 - accuracy: 0.2048 - recall_58: 1.0000 - precision_58: 0.2048\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7039 - accuracy: 0.2010 - recall_58: 1.0000 - precision_58: 0.2010\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7025 - accuracy: 0.2009 - recall_58: 1.0000 - precision_58: 0.2009\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7011 - accuracy: 0.2000 - recall_58: 1.0000 - precision_58: 0.2000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6996 - accuracy: 0.2009 - recall_58: 1.0000 - precision_58: 0.2009\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657F8D9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6984 - accuracy: 0.2027 - recall_58: 1.0000 - precision_58: 0.2027\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7043 - accuracy: 0.2026 - recall_59: 1.0000 - precision_59: 0.2026\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7029 - accuracy: 0.2018 - recall_59: 1.0000 - precision_59: 0.2016\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7015 - accuracy: 0.2056 - recall_59: 0.9992 - precision_59: 0.2034\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.2143 - recall_59: 0.9885 - precision_59: 0.2056\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6989 - accuracy: 0.2321 - recall_59: 0.9721 - precision_59: 0.2059\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.2576 - recall_59: 0.9105 - precision_59: 0.2029\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.3056 - recall_59: 0.8493 - precision_59: 0.2048\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.3771 - recall_59: 0.7362 - precision_59: 0.2043\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.4547 - recall_59: 0.6236 - precision_59: 0.2103\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.5498 - recall_59: 0.4899 - precision_59: 0.2235\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.6230 - recall_59: 0.3466 - precision_59: 0.2264\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6900 - accuracy: 0.6933 - recall_59: 0.2427 - precision_59: 0.2398\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.7428 - recall_59: 0.1514 - precision_59: 0.2679\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.7774 - recall_59: 0.0874 - precision_59: 0.3221\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6863 - accuracy: 0.7914 - recall_59: 0.0378 - precision_59: 0.3825\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.7955 - recall_59: 0.0148 - precision_59: 0.4160\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.7986 - recall_59: 0.0058 - precision_59: 0.5250\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.7981 - recall_59: 0.0029 - precision_59: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6816 - accuracy: 0.7957 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6804 - accuracy: 0.7960 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.7952 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.7983 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.7972 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.7969 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.7994 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.7933 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6724 - accuracy: 0.7941 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.7995 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.7975 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.7988 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.7989 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.7970 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.7962 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7965 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.7951 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.7996 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7990 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.7974 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.8002 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.7972 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.7977 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.7933 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.7960 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.7962 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.7968 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.7942 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.7971 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.8004 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.7940 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.7981 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.7972 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.7956 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.7953 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.8003 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.8000 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6430 - accuracy: 0.7969 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.7960 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.7984 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6406 - accuracy: 0.7954 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.7968 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.7973 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.7953 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7955 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.7945 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.7958 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.7956 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7957 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.7992 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.7985 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.7990 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.7989 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.7992 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.7963 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.7999 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.7943 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6251 - accuracy: 0.8004 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7993 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.7964 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.7940 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.7978 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7966 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.7967 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.7958 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.7958 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7954 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7977 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.7990 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.7979 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.7994 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.7969 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.7993 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7972 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.7983 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7931 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6124 - accuracy: 0.7957 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.7990 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.7966 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.7979 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.7982 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7967 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE7EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.7977 - recall_59: 0.0000e+00 - precision_59: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6810 - accuracy: 0.7965 - recall_60: 0.0023 - precision_60: 0.2500\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6796 - accuracy: 0.7995 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.7971 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.7989 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.7990 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6745 - accuracy: 0.7986 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.7975 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.7989 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.7967 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.7954 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.7952 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.7951 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.8005 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.7979 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.7959 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.7969 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.7984 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.7964 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.7972 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.7964 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.7956 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.7983 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.7953 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.8003 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.7974 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.7974 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.7974 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.7979 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.7943 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.7979 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.7946 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.7998 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7956 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.7985 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.7999 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.7997 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.7968 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.7969 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6371 - accuracy: 0.8014 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.7996 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7947 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.7974 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.7976 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.7964 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.7980 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.7958 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6306 - accuracy: 0.7963 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.8009 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.7973 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.7999 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.8003 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.8008 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.7980 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.8008 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.7959 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6233 - accuracy: 0.7943 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7950 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.7970 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6211 - accuracy: 0.7935 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.7968 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6181 - accuracy: 0.7983 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.7961 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.7970 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.7982 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.7964 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.7944 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7963 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.7974 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.7982 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.7962 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.8005 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.7976 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.7988 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.7986 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6069 - accuracy: 0.7991 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.7991 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.7951 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.7980 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.7979 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6048 - accuracy: 0.7947 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.7955 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.7967 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.7970 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6017 - accuracy: 0.7959 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.7943 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.7985 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.7968 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7991 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7993 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.7940 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.7971 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7993 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.7978 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7961 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7983 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.7977 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5922 - accuracy: 0.7984 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.7994 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.8017 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.7942 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657C9E670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5904 - accuracy: 0.7973 - recall_60: 0.0000e+00 - precision_60: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7119 - accuracy: 0.5104 - recall_61: 0.5618 - precision_61: 0.2238\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7062 - accuracy: 0.5214 - recall_61: 0.5488 - precision_61: 0.2236\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6982 - accuracy: 0.5381 - recall_61: 0.5241 - precision_61: 0.2258\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5551 - recall_61: 0.5179 - precision_61: 0.2316\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5683 - recall_61: 0.4910 - precision_61: 0.2372\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.5862 - recall_61: 0.4775 - precision_61: 0.2341\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.6008 - recall_61: 0.4673 - precision_61: 0.2445\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.6096 - recall_61: 0.4613 - precision_61: 0.2496\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.6158 - recall_61: 0.4281 - precision_61: 0.2424\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.6245 - recall_61: 0.4264 - precision_61: 0.2512\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6381 - recall_61: 0.4156 - precision_61: 0.2565\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.6433 - recall_61: 0.3898 - precision_61: 0.2523\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6568 - recall_61: 0.3864 - precision_61: 0.2660\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.6705 - recall_61: 0.3889 - precision_61: 0.2758\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.6787 - recall_61: 0.3668 - precision_61: 0.2766\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6807 - recall_61: 0.3491 - precision_61: 0.2766\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6939 - recall_61: 0.3343 - precision_61: 0.2757\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.6965 - recall_61: 0.3361 - precision_61: 0.2843\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.7064 - recall_61: 0.3245 - precision_61: 0.2868\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7108 - recall_61: 0.3227 - precision_61: 0.3003\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.7206 - recall_61: 0.3153 - precision_61: 0.3123\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7258 - recall_61: 0.3103 - precision_61: 0.3138\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7267 - recall_61: 0.2991 - precision_61: 0.3229\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7308 - recall_61: 0.2805 - precision_61: 0.3169\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.7343 - recall_61: 0.2681 - precision_61: 0.3264\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.7413 - recall_61: 0.2680 - precision_61: 0.3285\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5799 - accuracy: 0.7404 - recall_61: 0.2484 - precision_61: 0.3233\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5750 - accuracy: 0.7506 - recall_61: 0.2432 - precision_61: 0.3412\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7536 - recall_61: 0.2339 - precision_61: 0.3433\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7552 - recall_61: 0.2224 - precision_61: 0.3432\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.7659 - recall_61: 0.2349 - precision_61: 0.3603\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7671 - recall_61: 0.2280 - precision_61: 0.3743\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7655 - recall_61: 0.2113 - precision_61: 0.3583\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7744 - recall_61: 0.2210 - precision_61: 0.3832\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7764 - recall_61: 0.2089 - precision_61: 0.3855\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7731 - recall_61: 0.1990 - precision_61: 0.3799\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7821 - recall_61: 0.2045 - precision_61: 0.4205\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7799 - recall_61: 0.1916 - precision_61: 0.4076\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7846 - recall_61: 0.1941 - precision_61: 0.4255\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7831 - recall_61: 0.1807 - precision_61: 0.4138\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7837 - recall_61: 0.1756 - precision_61: 0.4122\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7878 - recall_61: 0.1791 - precision_61: 0.4231\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7908 - recall_61: 0.1754 - precision_61: 0.4317\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5336 - accuracy: 0.7896 - recall_61: 0.1770 - precision_61: 0.4565\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7881 - recall_61: 0.1731 - precision_61: 0.4537\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7875 - recall_61: 0.1617 - precision_61: 0.4373\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7892 - recall_61: 0.1702 - precision_61: 0.4665\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5259 - accuracy: 0.7913 - recall_61: 0.1654 - precision_61: 0.4636\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7916 - recall_61: 0.1672 - precision_61: 0.4778\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7939 - recall_61: 0.1649 - precision_61: 0.4749\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7942 - recall_61: 0.1649 - precision_61: 0.4732\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5191 - accuracy: 0.7943 - recall_61: 0.1582 - precision_61: 0.4670\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7941 - recall_61: 0.1550 - precision_61: 0.4810\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7937 - recall_61: 0.1470 - precision_61: 0.4791\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7920 - recall_61: 0.1410 - precision_61: 0.4655\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7947 - recall_61: 0.1359 - precision_61: 0.4548\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7949 - recall_61: 0.1332 - precision_61: 0.4745\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7993 - recall_61: 0.1361 - precision_61: 0.4912\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7951 - recall_61: 0.1334 - precision_61: 0.5018\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7974 - recall_61: 0.1264 - precision_61: 0.4894\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7945 - recall_61: 0.1309 - precision_61: 0.5149\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7997 - recall_61: 0.1266 - precision_61: 0.4959\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7962 - recall_61: 0.1200 - precision_61: 0.5123\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7971 - recall_61: 0.1237 - precision_61: 0.5121\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5018 - accuracy: 0.8016 - recall_61: 0.1260 - precision_61: 0.5489\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.8057 - recall_61: 0.1247 - precision_61: 0.5468\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.8050 - recall_61: 0.1262 - precision_61: 0.5735\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7999 - recall_61: 0.1163 - precision_61: 0.5728\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.8016 - recall_61: 0.1172 - precision_61: 0.5516\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.8040 - recall_61: 0.1171 - precision_61: 0.5661\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7998 - recall_61: 0.1035 - precision_61: 0.5360\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4950 - accuracy: 0.8021 - recall_61: 0.1120 - precision_61: 0.5725\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.8036 - recall_61: 0.1141 - precision_61: 0.5759\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7998 - recall_61: 0.0975 - precision_61: 0.5495\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.8027 - recall_61: 0.1040 - precision_61: 0.5710\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.8007 - recall_61: 0.0973 - precision_61: 0.5649\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8045 - recall_61: 0.1037 - precision_61: 0.5919\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7982 - recall_61: 0.1019 - precision_61: 0.5792\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.8047 - recall_61: 0.1009 - precision_61: 0.6021\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4859 - accuracy: 0.8041 - recall_61: 0.0970 - precision_61: 0.5846\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.8040 - recall_61: 0.1030 - precision_61: 0.6135\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8045 - recall_61: 0.0998 - precision_61: 0.6147\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8077 - recall_61: 0.1032 - precision_61: 0.6210\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.8069 - recall_61: 0.1009 - precision_61: 0.6360\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.8037 - recall_61: 0.0957 - precision_61: 0.6249\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8072 - recall_61: 0.0948 - precision_61: 0.6397\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.8064 - recall_61: 0.0936 - precision_61: 0.6108\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7992 - recall_61: 0.0948 - precision_61: 0.6253\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.8033 - recall_61: 0.0890 - precision_61: 0.5982\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.8022 - recall_61: 0.0965 - precision_61: 0.6213\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.8037 - recall_61: 0.0966 - precision_61: 0.6389\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.8070 - recall_61: 0.0928 - precision_61: 0.6277\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.8076 - recall_61: 0.0951 - precision_61: 0.6192\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.8044 - recall_61: 0.0926 - precision_61: 0.6387\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.8072 - recall_61: 0.0955 - precision_61: 0.6609\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.8058 - recall_61: 0.0885 - precision_61: 0.6360\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.8068 - recall_61: 0.0940 - precision_61: 0.6648\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.8065 - recall_61: 0.0939 - precision_61: 0.6429\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.8053 - recall_61: 0.0923 - precision_61: 0.6434\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.8058 - recall_61: 0.0927 - precision_61: 0.6422\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D658032940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.8106 - recall_61: 0.1036 - precision_61: 0.7313\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7598 - accuracy: 0.4588 - recall_62: 0.3723 - precision_62: 0.1553\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7546 - accuracy: 0.4627 - recall_62: 0.3565 - precision_62: 0.1502\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7456 - accuracy: 0.4734 - recall_62: 0.3614 - precision_62: 0.1571\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7408 - accuracy: 0.4775 - recall_62: 0.3403 - precision_62: 0.1502\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7314 - accuracy: 0.4924 - recall_62: 0.3514 - precision_62: 0.1576\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7261 - accuracy: 0.4975 - recall_62: 0.3384 - precision_62: 0.1578\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.5073 - recall_62: 0.3336 - precision_62: 0.1602\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7141 - accuracy: 0.5159 - recall_62: 0.3263 - precision_62: 0.1591\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7065 - accuracy: 0.5298 - recall_62: 0.3180 - precision_62: 0.1609\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7002 - accuracy: 0.5383 - recall_62: 0.3158 - precision_62: 0.1616\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6951 - accuracy: 0.5450 - recall_62: 0.3009 - precision_62: 0.1628\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6903 - accuracy: 0.5544 - recall_62: 0.2929 - precision_62: 0.1624\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5647 - recall_62: 0.3012 - precision_62: 0.1729\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.5725 - recall_62: 0.2942 - precision_62: 0.1731\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.5849 - recall_62: 0.2900 - precision_62: 0.1780\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.5894 - recall_62: 0.2854 - precision_62: 0.1833\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.5984 - recall_62: 0.2894 - precision_62: 0.1802\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6050 - recall_62: 0.2712 - precision_62: 0.1822\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6167 - recall_62: 0.2613 - precision_62: 0.1880\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6178 - recall_62: 0.2511 - precision_62: 0.1801\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.6330 - recall_62: 0.2606 - precision_62: 0.1938\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6341 - recall_62: 0.2470 - precision_62: 0.1893\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6407 - recall_62: 0.2425 - precision_62: 0.1951\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6574 - recall_62: 0.2374 - precision_62: 0.1988\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.6599 - recall_62: 0.2294 - precision_62: 0.2034\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.6660 - recall_62: 0.2184 - precision_62: 0.2056\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6698 - recall_62: 0.2157 - precision_62: 0.2050\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.6817 - recall_62: 0.2198 - precision_62: 0.2097\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.6853 - recall_62: 0.2091 - precision_62: 0.2157\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6142 - accuracy: 0.6918 - recall_62: 0.2082 - precision_62: 0.2200\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6994 - recall_62: 0.2147 - precision_62: 0.2291\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.7033 - recall_62: 0.2075 - precision_62: 0.2370\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.7098 - recall_62: 0.2022 - precision_62: 0.2383\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.7156 - recall_62: 0.1947 - precision_62: 0.2447\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.7200 - recall_62: 0.1938 - precision_62: 0.2510\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.7220 - recall_62: 0.1873 - precision_62: 0.2599\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7343 - recall_62: 0.1881 - precision_62: 0.2704\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.7404 - recall_62: 0.1865 - precision_62: 0.2802\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.7430 - recall_62: 0.1839 - precision_62: 0.2885\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7427 - recall_62: 0.1688 - precision_62: 0.2795\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.7529 - recall_62: 0.1716 - precision_62: 0.2987\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7539 - recall_62: 0.1755 - precision_62: 0.3201\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.7574 - recall_62: 0.1657 - precision_62: 0.3114\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5741 - accuracy: 0.7587 - recall_62: 0.1697 - precision_62: 0.3263\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7637 - recall_62: 0.1619 - precision_62: 0.3269\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.7635 - recall_62: 0.1590 - precision_62: 0.3295\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7685 - recall_62: 0.1498 - precision_62: 0.3303\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.7698 - recall_62: 0.1556 - precision_62: 0.3470\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5626 - accuracy: 0.7732 - recall_62: 0.1507 - precision_62: 0.3553\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7756 - recall_62: 0.1507 - precision_62: 0.3713\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.7777 - recall_62: 0.1510 - precision_62: 0.3821\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7759 - recall_62: 0.1418 - precision_62: 0.3727\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7795 - recall_62: 0.1396 - precision_62: 0.3851\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7861 - recall_62: 0.1462 - precision_62: 0.4079\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.7822 - recall_62: 0.1443 - precision_62: 0.4086\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7887 - recall_62: 0.1457 - precision_62: 0.4290\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7874 - recall_62: 0.1317 - precision_62: 0.4203\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7885 - recall_62: 0.1280 - precision_62: 0.4250\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7900 - recall_62: 0.1235 - precision_62: 0.4276\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7895 - recall_62: 0.1229 - precision_62: 0.4234\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7898 - recall_62: 0.1207 - precision_62: 0.4334\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7863 - recall_62: 0.1155 - precision_62: 0.4279\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7848 - recall_62: 0.1108 - precision_62: 0.4192\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7887 - recall_62: 0.1086 - precision_62: 0.4190\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7914 - recall_62: 0.1121 - precision_62: 0.4475\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7914 - recall_62: 0.1052 - precision_62: 0.4503\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7899 - recall_62: 0.1039 - precision_62: 0.4500\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7928 - recall_62: 0.0966 - precision_62: 0.4386\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7915 - recall_62: 0.0883 - precision_62: 0.4224\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7909 - recall_62: 0.0946 - precision_62: 0.4563\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7885 - recall_62: 0.0846 - precision_62: 0.4287\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5235 - accuracy: 0.7936 - recall_62: 0.0912 - precision_62: 0.4454\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7932 - recall_62: 0.0897 - precision_62: 0.4564\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7904 - recall_62: 0.0850 - precision_62: 0.4315\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7896 - recall_62: 0.0782 - precision_62: 0.4070\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5129 - accuracy: 0.7995 - recall_62: 0.0881 - precision_62: 0.409 - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7940 - recall_62: 0.0834 - precision_62: 0.4254\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7943 - recall_62: 0.0839 - precision_62: 0.4577\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7943 - recall_62: 0.0768 - precision_62: 0.4350\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7946 - recall_62: 0.0758 - precision_62: 0.4479\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7944 - recall_62: 0.0776 - precision_62: 0.4608\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7949 - recall_62: 0.0747 - precision_62: 0.4652\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7960 - recall_62: 0.0776 - precision_62: 0.4793\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7977 - recall_62: 0.0700 - precision_62: 0.4660\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7966 - recall_62: 0.0732 - precision_62: 0.4637\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7902 - recall_62: 0.0703 - precision_62: 0.4579\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7950 - recall_62: 0.0675 - precision_62: 0.4623\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7980 - recall_62: 0.0667 - precision_62: 0.4609\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7957 - recall_62: 0.0652 - precision_62: 0.4629\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7973 - recall_62: 0.0650 - precision_62: 0.4549\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7927 - recall_62: 0.0633 - precision_62: 0.4469\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7941 - recall_62: 0.0607 - precision_62: 0.4356\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7978 - recall_62: 0.0628 - precision_62: 0.4676\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7916 - recall_62: 0.0567 - precision_62: 0.4392\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7949 - recall_62: 0.0623 - precision_62: 0.4571\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7924 - recall_62: 0.0578 - precision_62: 0.4452\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7982 - recall_62: 0.0564 - precision_62: 0.4681\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7927 - recall_62: 0.0608 - precision_62: 0.4741\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7966 - recall_62: 0.0542 - precision_62: 0.4440\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7946 - recall_62: 0.0520 - precision_62: 0.4426\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7976 - recall_62: 0.0482 - precision_62: 0.4409\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65960B430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 0.4943 - accuracy: 0.7990 - recall_62: 0.0657 - precision_62: 0.5254\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 2ms/step - loss: 0.7074 - accuracy: 0.5264 - recall_63: 0.5272 - precision_63: 0.2172\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7016 - accuracy: 0.5325 - recall_63: 0.5181 - precision_63: 0.2194\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5465 - recall_63: 0.5095 - precision_63: 0.2258\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5498 - recall_63: 0.4906 - precision_63: 0.2191\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6809 - accuracy: 0.5623 - recall_63: 0.4874 - precision_63: 0.2301\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.5719 - recall_63: 0.4624 - precision_63: 0.2251\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.5800 - recall_63: 0.4529 - precision_63: 0.2301\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.5862 - recall_63: 0.4524 - precision_63: 0.2350\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.5981 - recall_63: 0.4429 - precision_63: 0.2384\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6120 - recall_63: 0.4251 - precision_63: 0.2407\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.6208 - recall_63: 0.4316 - precision_63: 0.2505\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6428 - accuracy: 0.6331 - recall_63: 0.4201 - precision_63: 0.2528\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.6407 - recall_63: 0.4101 - precision_63: 0.2586\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6434 - recall_63: 0.3847 - precision_63: 0.2511\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6515 - recall_63: 0.3642 - precision_63: 0.2519\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.6649 - recall_63: 0.3782 - precision_63: 0.2678\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.6749 - recall_63: 0.3649 - precision_63: 0.2738\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6163 - accuracy: 0.6783 - recall_63: 0.3499 - precision_63: 0.2708\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6110 - accuracy: 0.6831 - recall_63: 0.3431 - precision_63: 0.2712\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6076 - accuracy: 0.6930 - recall_63: 0.3427 - precision_63: 0.2853\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.6971 - recall_63: 0.3304 - precision_63: 0.2779\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.7037 - recall_63: 0.3223 - precision_63: 0.2979\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7129 - recall_63: 0.3099 - precision_63: 0.2936\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.7165 - recall_63: 0.3124 - precision_63: 0.3099\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7208 - recall_63: 0.3006 - precision_63: 0.3095\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.7269 - recall_63: 0.2895 - precision_63: 0.3158\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5800 - accuracy: 0.7331 - recall_63: 0.2863 - precision_63: 0.3203\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7348 - recall_63: 0.2757 - precision_63: 0.3238\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.7435 - recall_63: 0.2728 - precision_63: 0.3391\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7452 - recall_63: 0.2615 - precision_63: 0.3276\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7526 - recall_63: 0.2639 - precision_63: 0.3462\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7552 - recall_63: 0.2540 - precision_63: 0.3454\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7596 - recall_63: 0.2510 - precision_63: 0.3687\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7642 - recall_63: 0.2565 - precision_63: 0.3761\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7632 - recall_63: 0.2457 - precision_63: 0.3743\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7646 - recall_63: 0.2327 - precision_63: 0.3694\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7745 - recall_63: 0.2538 - precision_63: 0.4015\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7699 - recall_63: 0.2288 - precision_63: 0.3950\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.7776 - recall_63: 0.2258 - precision_63: 0.4028\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7804 - recall_63: 0.2184 - precision_63: 0.4022\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7832 - recall_63: 0.2234 - precision_63: 0.4360\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7823 - recall_63: 0.2257 - precision_63: 0.4385\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7887 - recall_63: 0.2188 - precision_63: 0.4399\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7861 - recall_63: 0.2117 - precision_63: 0.4432\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7892 - recall_63: 0.2143 - precision_63: 0.4563\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7927 - recall_63: 0.2105 - precision_63: 0.4764\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7958 - recall_63: 0.2123 - precision_63: 0.4779\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7907 - recall_63: 0.1900 - precision_63: 0.4617\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7943 - recall_63: 0.1920 - precision_63: 0.4741\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7973 - recall_63: 0.1895 - precision_63: 0.5026\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7981 - recall_63: 0.1929 - precision_63: 0.4887\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7971 - recall_63: 0.1890 - precision_63: 0.4993\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.8009 - recall_63: 0.1858 - precision_63: 0.4972\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7987 - recall_63: 0.1809 - precision_63: 0.5112\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.8008 - recall_63: 0.1857 - precision_63: 0.5235\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7979 - recall_63: 0.1845 - precision_63: 0.5335\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.8012 - recall_63: 0.1808 - precision_63: 0.5333\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.8003 - recall_63: 0.1702 - precision_63: 0.5115\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7992 - recall_63: 0.1749 - precision_63: 0.5321\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.8035 - recall_63: 0.1752 - precision_63: 0.5299\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7992 - recall_63: 0.1659 - precision_63: 0.5180\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.8018 - recall_63: 0.1694 - precision_63: 0.5341\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.8000 - recall_63: 0.1635 - precision_63: 0.5322\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7980 - recall_63: 0.1614 - precision_63: 0.5392\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.8034 - recall_63: 0.1672 - precision_63: 0.5380\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.8005 - recall_63: 0.1545 - precision_63: 0.5314\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.8016 - recall_63: 0.1591 - precision_63: 0.5398\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.8044 - recall_63: 0.1592 - precision_63: 0.5551\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.8021 - recall_63: 0.1451 - precision_63: 0.5399\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.8007 - recall_63: 0.1459 - precision_63: 0.5500\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7984 - recall_63: 0.1474 - precision_63: 0.5577\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.8007 - recall_63: 0.1482 - precision_63: 0.5387\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.8002 - recall_63: 0.1442 - precision_63: 0.5360\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8012 - recall_63: 0.1435 - precision_63: 0.5492\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.8024 - recall_63: 0.1402 - precision_63: 0.5679\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.8050 - recall_63: 0.1411 - precision_63: 0.5573\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8014 - recall_63: 0.1383 - precision_63: 0.5619\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7993 - recall_63: 0.1318 - precision_63: 0.5596\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.8047 - recall_63: 0.1349 - precision_63: 0.5624\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.8045 - recall_63: 0.1333 - precision_63: 0.5581\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.8054 - recall_63: 0.1454 - precision_63: 0.6100\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.8030 - recall_63: 0.1623 - precision_63: 0.612 - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8045 - recall_63: 0.1443 - precision_63: 0.5909\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8061 - recall_63: 0.1348 - precision_63: 0.5778\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.8043 - recall_63: 0.1371 - precision_63: 0.5839\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.8052 - recall_63: 0.1359 - precision_63: 0.5920\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8081 - recall_63: 0.1350 - precision_63: 0.5926\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.8050 - recall_63: 0.1314 - precision_63: 0.5974\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8071 - recall_63: 0.1344 - precision_63: 0.6003\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8071 - recall_63: 0.1388 - precision_63: 0.6221\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.8065 - recall_63: 0.1284 - precision_63: 0.6330\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.8055 - recall_63: 0.1272 - precision_63: 0.6241\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.8040 - recall_63: 0.1283 - precision_63: 0.5948\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.8074 - recall_63: 0.1301 - precision_63: 0.5983\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.8091 - recall_63: 0.1320 - precision_63: 0.6194\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.8071 - recall_63: 0.1250 - precision_63: 0.6030\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8084 - recall_63: 0.1271 - precision_63: 0.6200\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.8056 - recall_63: 0.1258 - precision_63: 0.6215\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.8057 - recall_63: 0.1209 - precision_63: 0.5991\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.8040 - recall_63: 0.1181 - precision_63: 0.653 - 0s 4ms/step - loss: 0.4712 - accuracy: 0.8054 - recall_63: 0.1210 - precision_63: 0.6293\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.8087 - recall_63: 0.1222 - precision_63: 0.6356\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA1A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.8033 - recall_63: 0.1142 - precision_63: 0.5745\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6987 - accuracy: 0.4726 - recall_64: 0.4032 - precision_64: 0.1679\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.4909 - recall_64: 0.3705 - precision_64: 0.1630\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5086 - recall_64: 0.3330 - precision_64: 0.1582\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.5363 - recall_64: 0.3088 - precision_64: 0.1601\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.5587 - recall_64: 0.2826 - precision_64: 0.1607\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.5728 - recall_64: 0.2485 - precision_64: 0.1543\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.5938 - recall_64: 0.2200 - precision_64: 0.1517\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6182 - recall_64: 0.1930 - precision_64: 0.1523\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.6411 - recall_64: 0.1766 - precision_64: 0.1577\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.6585 - recall_64: 0.1441 - precision_64: 0.1512\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.6862 - recall_64: 0.1407 - precision_64: 0.1672\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6575 - accuracy: 0.7074 - recall_64: 0.1163 - precision_64: 0.1667\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.7148 - recall_64: 0.1034 - precision_64: 0.1747\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.7338 - recall_64: 0.0834 - precision_64: 0.1732\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6490 - accuracy: 0.7432 - recall_64: 0.0592 - precision_64: 0.1522\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.7573 - recall_64: 0.0563 - precision_64: 0.1912\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.7676 - recall_64: 0.0368 - precision_64: 0.1661\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.7756 - recall_64: 0.0324 - precision_64: 0.1979\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.7841 - recall_64: 0.0205 - precision_64: 0.1880\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7876 - recall_64: 0.0158 - precision_64: 0.2274\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.7969 - recall_64: 0.0110 - precision_64: 0.2815\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.7952 - recall_64: 0.0061 - precision_64: 0.2462\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.7990 - recall_64: 0.0029 - precision_64: 0.1928\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.8017 - recall_64: 8.4396e-04 - precision_64: 0.2500\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.7944 - recall_64: 0.0014 - precision_64: 0.3750\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6182 - accuracy: 0.7972 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.7999 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6140 - accuracy: 0.7955 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6107 - accuracy: 0.7986 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.7968 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.7967 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.7990 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6023 - accuracy: 0.7965 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.7956 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7999 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.7964 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7983 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5922 - accuracy: 0.7971 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.7987 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.7985 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.7988 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7930 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.7966 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7960 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7989 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.7980 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.7973 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7967 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.7967 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5711 - accuracy: 0.7967 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7992 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.8016 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7931 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7967 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7983 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.8012 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7994 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.7999 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7985 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.7979 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7991 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.7939 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7968 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7960 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7979 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.7973 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7972 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5464 - accuracy: 0.7972 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7999 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7982 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.8000 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5404 - accuracy: 0.7994 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5487 - accuracy: 0.7845 - recall_64: 0.0000e+00 - precision_64: 0.0000e+0 - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7942 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.8016 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5400 - accuracy: 0.7954 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5367 - accuracy: 0.7989 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7975 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7952 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7984 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7980 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7979 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7983 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7972 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5281 - accuracy: 0.7997 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7979 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7951 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.8015 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5261 - accuracy: 0.7975 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7942 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7970 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7954 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7985 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7958 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7936 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7955 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5210 - accuracy: 0.7959 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.8013 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7949 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7999 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7967 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C587310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5154 - accuracy: 0.7973 - recall_64: 0.0000e+00 - precision_64: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.7115 - accuracy: 0.4742 - recall_65: 0.3948 - precision_65: 0.1685\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7013 - accuracy: 0.4964 - recall_65: 0.3794 - precision_65: 0.1694\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.5056 - recall_65: 0.3463 - precision_65: 0.1650\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5252 - recall_65: 0.3346 - precision_65: 0.1649\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.5457 - recall_65: 0.3037 - precision_65: 0.1644\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.5672 - recall_65: 0.2930 - precision_65: 0.1728\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6641 - accuracy: 0.5852 - recall_65: 0.2740 - precision_65: 0.1716\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6012 - recall_65: 0.2510 - precision_65: 0.1704\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.6235 - recall_65: 0.2303 - precision_65: 0.1727\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6417 - recall_65: 0.2098 - precision_65: 0.1808\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6645 - recall_65: 0.1970 - precision_65: 0.1918\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.6882 - recall_65: 0.1776 - precision_65: 0.1925\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.7099 - recall_65: 0.1494 - precision_65: 0.1987\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.7236 - recall_65: 0.1308 - precision_65: 0.2102\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.7359 - recall_65: 0.1151 - precision_65: 0.2273\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.7560 - recall_65: 0.0941 - precision_65: 0.2336\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.7680 - recall_65: 0.0748 - precision_65: 0.2447\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.7749 - recall_65: 0.0599 - precision_65: 0.2449\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.7764 - recall_65: 0.0413 - precision_65: 0.2251\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7845 - recall_65: 0.0336 - precision_65: 0.2302\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.7868 - recall_65: 0.0272 - precision_65: 0.2343\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.7901 - recall_65: 0.0210 - precision_65: 0.2390\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7869 - recall_65: 0.0185 - precision_65: 0.2648\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.7900 - recall_65: 0.0100 - precision_65: 0.1752\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7893 - recall_65: 0.0060 - precision_65: 0.1341\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.7901 - recall_65: 0.0045 - precision_65: 0.1327\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.7923 - recall_65: 0.0020 - precision_65: 0.0704\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5672 - accuracy: 0.7941 - recall_65: 0.0015 - precision_65: 0.0647\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7948 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5611 - accuracy: 0.7948 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.7946 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7927 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5522 - accuracy: 0.7969 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7923 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7949 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7982 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7972 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7972 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.8002 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7978 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7974 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5368 - accuracy: 0.7939 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7988 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7975 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7973 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.7994 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7955 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7961 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7970 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7969 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7981 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7961 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7971 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7936 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.8012 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7957 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7943 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.7945 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7999 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.8000 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7983 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7965 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7988 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5019 - accuracy: 0.7995 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7958 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4938 - accuracy: 0.8025 - recall_65: 0.0000e+00 - precision_65: 0.0000e+0 - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7991 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7965 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7960 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7966 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7931 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7995 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7957 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7991 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7986 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7958 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7965 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7961 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7988 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.7968 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7982 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7995 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7982 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7980 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7964 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.8002 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7958 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7976 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 0.7993 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7967 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7986 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7965 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7953 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7964 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.8002 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7974 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.8007 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7994 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7980 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7989 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7956 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580321F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7977 - recall_65: 0.0000e+00 - precision_65: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7046 - accuracy: 0.4974 - recall_66: 0.4903 - precision_66: 0.2020\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6963 - accuracy: 0.5186 - recall_66: 0.4774 - precision_66: 0.2069\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.5281 - recall_66: 0.4577 - precision_66: 0.2039\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.5483 - recall_66: 0.4491 - precision_66: 0.2130\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6758 - accuracy: 0.5593 - recall_66: 0.4148 - precision_66: 0.2067\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6687 - accuracy: 0.5699 - recall_66: 0.3886 - precision_66: 0.2025\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.5834 - recall_66: 0.3639 - precision_66: 0.2036\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.5976 - recall_66: 0.3573 - precision_66: 0.2125\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.6069 - recall_66: 0.3332 - precision_66: 0.2045\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.6198 - recall_66: 0.3190 - precision_66: 0.2096\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6304 - recall_66: 0.3036 - precision_66: 0.2111\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.6448 - recall_66: 0.3029 - precision_66: 0.2211\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.6536 - recall_66: 0.2914 - precision_66: 0.2219\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.6584 - recall_66: 0.2635 - precision_66: 0.2187\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.6714 - recall_66: 0.2685 - precision_66: 0.2339\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.6824 - recall_66: 0.2387 - precision_66: 0.2340\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.6957 - recall_66: 0.2259 - precision_66: 0.2337\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.7019 - recall_66: 0.2118 - precision_66: 0.2359\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.7203 - recall_66: 0.2141 - precision_66: 0.2577\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.7247 - recall_66: 0.1950 - precision_66: 0.2614\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.7289 - recall_66: 0.1667 - precision_66: 0.2520\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.7396 - recall_66: 0.1629 - precision_66: 0.2653\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7446 - recall_66: 0.1490 - precision_66: 0.2652\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.7534 - recall_66: 0.1470 - precision_66: 0.2888\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.7596 - recall_66: 0.1294 - precision_66: 0.2894\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.7717 - recall_66: 0.1276 - precision_66: 0.3285\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.7773 - recall_66: 0.1072 - precision_66: 0.3122\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.7802 - recall_66: 0.0958 - precision_66: 0.3373\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5709 - accuracy: 0.7788 - recall_66: 0.0941 - precision_66: 0.3416\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5701 - accuracy: 0.7800 - recall_66: 0.0813 - precision_66: 0.3341\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.7838 - recall_66: 0.0803 - precision_66: 0.3399\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7828 - recall_66: 0.0768 - precision_66: 0.3468\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7832 - recall_66: 0.0714 - precision_66: 0.3583\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7850 - recall_66: 0.0642 - precision_66: 0.3466\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5536 - accuracy: 0.7863 - recall_66: 0.0595 - precision_66: 0.3435\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7882 - recall_66: 0.0606 - precision_66: 0.3632\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7880 - recall_66: 0.0602 - precision_66: 0.3867\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7934 - recall_66: 0.0600 - precision_66: 0.4117\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7964 - recall_66: 0.0545 - precision_66: 0.3830\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7902 - recall_66: 0.0518 - precision_66: 0.4087\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7915 - recall_66: 0.0461 - precision_66: 0.3581\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7933 - recall_66: 0.0472 - precision_66: 0.3781\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7911 - recall_66: 0.0477 - precision_66: 0.3839\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7887 - recall_66: 0.0392 - precision_66: 0.3741\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7958 - recall_66: 0.0393 - precision_66: 0.3946\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7925 - recall_66: 0.0383 - precision_66: 0.3734\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7932 - recall_66: 0.0392 - precision_66: 0.3992\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7924 - recall_66: 0.0380 - precision_66: 0.3934\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7914 - recall_66: 0.0291 - precision_66: 0.3310\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7941 - recall_66: 0.0253 - precision_66: 0.3172\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5217 - accuracy: 0.7915 - recall_66: 0.0245 - precision_66: 0.344 - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7913 - recall_66: 0.0238 - precision_66: 0.3232\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7895 - recall_66: 0.0231 - precision_66: 0.3102\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5194 - accuracy: 0.7930 - recall_66: 0.0240 - precision_66: 0.3334\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7942 - recall_66: 0.0196 - precision_66: 0.3155\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7931 - recall_66: 0.0226 - precision_66: 0.3700\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7942 - recall_66: 0.0196 - precision_66: 0.3286\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7939 - recall_66: 0.0178 - precision_66: 0.3093\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7938 - recall_66: 0.0156 - precision_66: 0.2985\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7930 - recall_66: 0.0167 - precision_66: 0.3280\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7958 - recall_66: 0.0138 - precision_66: 0.3018\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7918 - recall_66: 0.0137 - precision_66: 0.3131\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7932 - recall_66: 0.0156 - precision_66: 0.3355\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7939 - recall_66: 0.0145 - precision_66: 0.3266\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7929 - recall_66: 0.0159 - precision_66: 0.3713\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7973 - recall_66: 0.0134 - precision_66: 0.4032\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7980 - recall_66: 0.0142 - precision_66: 0.3933\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5022 - accuracy: 0.7963 - recall_66: 0.0135 - precision_66: 0.3968\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5018 - accuracy: 0.7955 - recall_66: 0.0116 - precision_66: 0.3997\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.7979 - recall_66: 0.0108 - precision_66: 0.3551\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7987 - recall_66: 0.0093 - precision_66: 0.3203\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7978 - recall_66: 0.0086 - precision_66: 0.3452\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7960 - recall_66: 0.0084 - precision_66: 0.3151\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7954 - recall_66: 0.0062 - precision_66: 0.2666\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7990 - recall_66: 0.0078 - precision_66: 0.3514\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7983 - recall_66: 0.0081 - precision_66: 0.3380\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7977 - recall_66: 0.0078 - precision_66: 0.3660\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7950 - recall_66: 0.0071 - precision_66: 0.3603\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7967 - recall_66: 0.0071 - precision_66: 0.3985\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.7956 - recall_66: 0.0091 - precision_66: 0.3924\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.8001 - recall_66: 0.0106 - precision_66: 0.4778\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7998 - recall_66: 0.0083 - precision_66: 0.4889\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4902 - accuracy: 0.7942 - recall_66: 0.0072 - precision_66: 0.3874\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7957 - recall_66: 0.0103 - precision_66: 0.4697\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.8013 - recall_66: 0.0096 - precision_66: 0.4942\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7968 - recall_66: 0.0109 - precision_66: 0.5040\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7969 - recall_66: 0.0097 - precision_66: 0.5179\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7979 - recall_66: 0.0082 - precision_66: 0.4250\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7993 - recall_66: 0.0110 - precision_66: 0.4926\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.8001 - recall_66: 0.0089 - precision_66: 0.4604\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7941 - recall_66: 0.0081 - precision_66: 0.4212\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7974 - recall_66: 0.0097 - precision_66: 0.5000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.7950 - recall_66: 0.0073 - precision_66: 0.600 - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7964 - recall_66: 0.0090 - precision_66: 0.5686\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.8011 - recall_66: 0.0092 - precision_66: 0.5385\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7972 - recall_66: 0.0108 - precision_66: 0.5677\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.8016 - recall_66: 0.0129 - precision_66: 0.6542\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7959 - recall_66: 0.0099 - precision_66: 0.5982\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7991 - recall_66: 0.0118 - precision_66: 0.6399\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7999 - recall_66: 0.0119 - precision_66: 0.6607\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7979 - recall_66: 0.0102 - precision_66: 0.5982\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7982 - recall_66: 0.0117 - precision_66: 0.6500\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580A58B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.4791 - accuracy: 0.7985 - recall_66: 0.0085 - precision_66: 0.8000\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7583 - accuracy: 0.4432 - recall_67: 0.3494 - precision_67: 0.1423\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7503 - accuracy: 0.4537 - recall_67: 0.3314 - precision_67: 0.1420\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.4677 - recall_67: 0.3208 - precision_67: 0.1423\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7325 - accuracy: 0.4760 - recall_67: 0.3057 - precision_67: 0.1407\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7266 - accuracy: 0.4844 - recall_67: 0.2838 - precision_67: 0.1334\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7159 - accuracy: 0.5025 - recall_67: 0.2650 - precision_67: 0.1326\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.5136 - recall_67: 0.2663 - precision_67: 0.1353\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7025 - accuracy: 0.5264 - recall_67: 0.2566 - precision_67: 0.1375\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.5387 - recall_67: 0.2492 - precision_67: 0.1408\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5506 - recall_67: 0.2361 - precision_67: 0.1388\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.5613 - recall_67: 0.2318 - precision_67: 0.1424\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.5730 - recall_67: 0.2212 - precision_67: 0.1412\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5805 - recall_67: 0.2116 - precision_67: 0.1428\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.5949 - recall_67: 0.2076 - precision_67: 0.1455\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.6007 - recall_67: 0.1905 - precision_67: 0.1403\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.6098 - recall_67: 0.1747 - precision_67: 0.1365\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6194 - recall_67: 0.1631 - precision_67: 0.1341\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6312 - recall_67: 0.1699 - precision_67: 0.1456\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6449 - recall_67: 0.1601 - precision_67: 0.1465\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6512 - recall_67: 0.1351 - precision_67: 0.1357\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6207 - accuracy: 0.6740 - recall_67: 0.1218 - precision_67: 0.135 - 0s 3ms/step - loss: 0.6271 - accuracy: 0.6619 - recall_67: 0.1227 - precision_67: 0.1319\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6629 - recall_67: 0.1161 - precision_67: 0.1325\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.6701 - recall_67: 0.1129 - precision_67: 0.1323\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.6770 - recall_67: 0.0981 - precision_67: 0.1249\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6900 - recall_67: 0.1015 - precision_67: 0.1377\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6975 - recall_67: 0.0962 - precision_67: 0.1390\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.6978 - recall_67: 0.0871 - precision_67: 0.1298\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.7061 - recall_67: 0.0844 - precision_67: 0.1414\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.7168 - recall_67: 0.0777 - precision_67: 0.1401\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.7205 - recall_67: 0.0774 - precision_67: 0.1474\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7266 - recall_67: 0.0648 - precision_67: 0.1300\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.7290 - recall_67: 0.0607 - precision_67: 0.1296\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.7371 - recall_67: 0.0615 - precision_67: 0.1452\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7400 - recall_67: 0.0573 - precision_67: 0.1467\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.7442 - recall_67: 0.0513 - precision_67: 0.1370\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7473 - recall_67: 0.0442 - precision_67: 0.1322\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7535 - recall_67: 0.0440 - precision_67: 0.1452\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.7542 - recall_67: 0.0414 - precision_67: 0.1363\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7525 - recall_67: 0.0363 - precision_67: 0.1271\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5639 - accuracy: 0.7633 - recall_67: 0.0368 - precision_67: 0.1426\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7640 - recall_67: 0.0304 - precision_67: 0.1251\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5609 - accuracy: 0.7638 - recall_67: 0.0340 - precision_67: 0.1545\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7658 - recall_67: 0.0284 - precision_67: 0.1311\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7703 - recall_67: 0.0291 - precision_67: 0.1446\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7739 - recall_67: 0.0246 - precision_67: 0.1424\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7733 - recall_67: 0.0244 - precision_67: 0.1525\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7739 - recall_67: 0.0221 - precision_67: 0.1467\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7803 - recall_67: 0.0190 - precision_67: 0.1523\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7782 - recall_67: 0.0191 - precision_67: 0.1476\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7829 - recall_67: 0.0193 - precision_67: 0.1507\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7812 - recall_67: 0.0160 - precision_67: 0.1357\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7816 - recall_67: 0.0150 - precision_67: 0.1510\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7865 - recall_67: 0.0129 - precision_67: 0.1414\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7865 - recall_67: 0.0143 - precision_67: 0.1662\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7864 - recall_67: 0.0085 - precision_67: 0.1205\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7866 - recall_67: 0.0089 - precision_67: 0.1246\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7879 - recall_67: 0.0092 - precision_67: 0.1335\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7849 - recall_67: 0.0081 - precision_67: 0.1236\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7939 - recall_67: 0.0091 - precision_67: 0.1613\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7871 - recall_67: 0.0050 - precision_67: 0.0922    \n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7870 - recall_67: 0.0056 - precision_67: 0.1224\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7910 - recall_67: 0.0060 - precision_67: 0.1362\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7917 - recall_67: 0.0072 - precision_67: 0.1629\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7937 - recall_67: 0.0073 - precision_67: 0.1682\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7942 - recall_67: 0.0066 - precision_67: 0.1932\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7934 - recall_67: 0.0050 - precision_67: 0.1662\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7914 - recall_67: 0.0059 - precision_67: 0.1868\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7908 - recall_67: 0.0059 - precision_67: 0.1905\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7885 - recall_67: 0.0073 - precision_67: 0.2285\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7936 - recall_67: 0.0036 - precision_67: 0.1288    \n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7961 - recall_67: 0.0048 - precision_67: 0.1873\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7943 - recall_67: 0.0046 - precision_67: 0.1850\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7892 - recall_67: 0.0045 - precision_67: 0.1995\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7950 - recall_67: 0.0052 - precision_67: 0.1971\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7938 - recall_67: 0.0043 - precision_67: 0.1661\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7920 - recall_67: 0.0051 - precision_67: 0.1901\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7941 - recall_67: 0.0046 - precision_67: 0.1951\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7914 - recall_67: 0.0051 - precision_67: 0.1846\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7968 - recall_67: 0.0043 - precision_67: 0.1941\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7963 - recall_67: 0.0043 - precision_67: 0.1917\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7966 - recall_67: 0.0040 - precision_67: 0.1938\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7957 - recall_67: 0.0046 - precision_67: 0.2164\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7936 - recall_67: 0.0036 - precision_67: 0.1954\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7997 - recall_67: 0.0037 - precision_67: 0.2034\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7937 - recall_67: 0.0039 - precision_67: 0.2332\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4946 - accuracy: 0.7949 - recall_67: 0.0046 - precision_67: 0.2644\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7945 - recall_67: 0.0057 - precision_67: 0.3167\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7962 - recall_67: 0.0033 - precision_67: 0.1979    \n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7992 - recall_67: 0.0045 - precision_67: 0.2693\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7948 - recall_67: 0.0054 - precision_67: 0.3021\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7984 - recall_67: 0.0065 - precision_67: 0.3345\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7960 - recall_67: 0.0054 - precision_67: 0.3885\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7961 - recall_67: 0.0051 - precision_67: 0.3917\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7991 - recall_67: 0.0063 - precision_67: 0.5058\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7961 - recall_67: 0.0077 - precision_67: 0.5527\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4847 - accuracy: 0.7994 - recall_67: 0.0044 - precision_67: 0.3419    \n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7964 - recall_67: 0.0071 - precision_67: 0.5444\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7982 - recall_67: 0.0060 - precision_67: 0.5000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7914 - recall_67: 0.0067 - precision_67: 0.5739\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7961 - recall_67: 0.0072 - precision_67: 0.5606\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D655258E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7961 - recall_67: 0.0021 - precision_67: 0.2000\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6775 - accuracy: 0.6080 - recall_68: 0.6427 - precision_68: 0.2898\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.6179 - recall_68: 0.6394 - precision_68: 0.2945\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.6205 - recall_68: 0.6422 - precision_68: 0.2965\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.6332 - recall_68: 0.6378 - precision_68: 0.3030\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.6319 - recall_68: 0.6204 - precision_68: 0.3018\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6382 - recall_68: 0.6167 - precision_68: 0.3043\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.6426 - recall_68: 0.6070 - precision_68: 0.3071\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.6512 - recall_68: 0.6094 - precision_68: 0.3200\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.6582 - recall_68: 0.5910 - precision_68: 0.3167\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.6639 - recall_68: 0.5900 - precision_68: 0.3208\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.6654 - recall_68: 0.5844 - precision_68: 0.3203\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.6713 - recall_68: 0.5870 - precision_68: 0.3274\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.6778 - recall_68: 0.5802 - precision_68: 0.3306\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6834 - recall_68: 0.5627 - precision_68: 0.3368\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.6948 - recall_68: 0.5685 - precision_68: 0.3442\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.6922 - recall_68: 0.5412 - precision_68: 0.3394\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6998 - recall_68: 0.5427 - precision_68: 0.3438\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.7028 - recall_68: 0.5471 - precision_68: 0.3520\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7008 - recall_68: 0.5315 - precision_68: 0.3480\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7062 - recall_68: 0.5267 - precision_68: 0.3527\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.7124 - recall_68: 0.5113 - precision_68: 0.3558\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7183 - recall_68: 0.5066 - precision_68: 0.3569\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7208 - recall_68: 0.5043 - precision_68: 0.3658\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7202 - recall_68: 0.4889 - precision_68: 0.3583\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7275 - recall_68: 0.4829 - precision_68: 0.3672\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7306 - recall_68: 0.4733 - precision_68: 0.3730\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7341 - recall_68: 0.4720 - precision_68: 0.3770\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5583 - accuracy: 0.7363 - recall_68: 0.4645 - precision_68: 0.3768\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7419 - recall_68: 0.4496 - precision_68: 0.3756\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.7393 - recall_68: 0.4416 - precision_68: 0.3784\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5507 - accuracy: 0.7405 - recall_68: 0.4250 - precision_68: 0.3819\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5493 - accuracy: 0.7442 - recall_68: 0.4260 - precision_68: 0.3900\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5462 - accuracy: 0.7485 - recall_68: 0.4221 - precision_68: 0.3941\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7517 - recall_68: 0.4159 - precision_68: 0.3906\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7527 - recall_68: 0.4034 - precision_68: 0.3953\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7557 - recall_68: 0.4061 - precision_68: 0.3967\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7607 - recall_68: 0.3983 - precision_68: 0.4177\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.7634 - recall_68: 0.3931 - precision_68: 0.4072\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7637 - recall_68: 0.3899 - precision_68: 0.4079\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5280 - accuracy: 0.7649 - recall_68: 0.3766 - precision_68: 0.4026\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7628 - recall_68: 0.3689 - precision_68: 0.4142\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7730 - recall_68: 0.3729 - precision_68: 0.4258\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7697 - recall_68: 0.3564 - precision_68: 0.4222\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7744 - recall_68: 0.3555 - precision_68: 0.4342\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7735 - recall_68: 0.3473 - precision_68: 0.4267\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7773 - recall_68: 0.3568 - precision_68: 0.4323\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7777 - recall_68: 0.3452 - precision_68: 0.4319\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.7753 - recall_68: 0.3412 - precision_68: 0.4395\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7787 - recall_68: 0.3425 - precision_68: 0.4405\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7799 - recall_68: 0.3275 - precision_68: 0.4382\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7807 - recall_68: 0.3158 - precision_68: 0.4367\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7762 - recall_68: 0.3012 - precision_68: 0.4304\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7800 - recall_68: 0.3062 - precision_68: 0.4251\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7805 - recall_68: 0.3046 - precision_68: 0.4354\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7824 - recall_68: 0.2964 - precision_68: 0.4438\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7821 - recall_68: 0.2870 - precision_68: 0.4384\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7812 - recall_68: 0.2866 - precision_68: 0.4506\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4964 - accuracy: 0.7852 - recall_68: 0.2868 - precision_68: 0.4468\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7854 - recall_68: 0.2865 - precision_68: 0.4508\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7855 - recall_68: 0.2859 - precision_68: 0.4524\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7876 - recall_68: 0.2710 - precision_68: 0.4488\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7882 - recall_68: 0.2725 - precision_68: 0.4642\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7886 - recall_68: 0.2656 - precision_68: 0.4499\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7902 - recall_68: 0.2753 - precision_68: 0.4659\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7933 - recall_68: 0.2642 - precision_68: 0.4760\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7931 - recall_68: 0.2606 - precision_68: 0.4853\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7889 - recall_68: 0.2561 - precision_68: 0.4739\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7891 - recall_68: 0.2523 - precision_68: 0.4733\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7932 - recall_68: 0.2455 - precision_68: 0.4770\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7957 - recall_68: 0.2419 - precision_68: 0.4793\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7943 - recall_68: 0.2462 - precision_68: 0.4823\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7935 - recall_68: 0.2336 - precision_68: 0.4775\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7922 - recall_68: 0.2248 - precision_68: 0.4753\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7923 - recall_68: 0.2193 - precision_68: 0.4884\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7918 - recall_68: 0.2110 - precision_68: 0.4674\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7944 - recall_68: 0.2063 - precision_68: 0.4755\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7957 - recall_68: 0.2137 - precision_68: 0.4819\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7972 - recall_68: 0.2165 - precision_68: 0.4976\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7979 - recall_68: 0.2088 - precision_68: 0.4998\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7961 - recall_68: 0.2041 - precision_68: 0.5087\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7949 - recall_68: 0.1972 - precision_68: 0.4902\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4653 - accuracy: 0.7960 - recall_68: 0.2015 - precision_68: 0.482 - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7956 - recall_68: 0.2019 - precision_68: 0.4904\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7973 - recall_68: 0.2034 - precision_68: 0.4982\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7982 - recall_68: 0.1951 - precision_68: 0.4903\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7970 - recall_68: 0.1932 - precision_68: 0.4908\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7951 - recall_68: 0.1982 - precision_68: 0.4965\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7969 - recall_68: 0.1926 - precision_68: 0.4977\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7960 - recall_68: 0.1854 - precision_68: 0.4882\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7999 - recall_68: 0.1870 - precision_68: 0.4937\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7961 - recall_68: 0.1939 - precision_68: 0.5064\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7989 - recall_68: 0.1908 - precision_68: 0.4996\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.8022 - recall_68: 0.1816 - precision_68: 0.5223\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7988 - recall_68: 0.1863 - precision_68: 0.5266\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7997 - recall_68: 0.1708 - precision_68: 0.5070\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7987 - recall_68: 0.1810 - precision_68: 0.5336\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7995 - recall_68: 0.1761 - precision_68: 0.5290\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7999 - recall_68: 0.1799 - precision_68: 0.5287\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.8023 - recall_68: 0.1726 - precision_68: 0.5345\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.8025 - recall_68: 0.1767 - precision_68: 0.5308\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.8058 - recall_68: 0.1731 - precision_68: 0.5435\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65B030D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7985 - recall_68: 0.1631 - precision_68: 0.5066\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7522 - accuracy: 0.4441 - recall_69: 0.3094 - precision_69: 0.1280\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7439 - accuracy: 0.4545 - recall_69: 0.3005 - precision_69: 0.1331\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.4696 - recall_69: 0.2827 - precision_69: 0.1311\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7231 - accuracy: 0.4891 - recall_69: 0.2555 - precision_69: 0.1249\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7144 - accuracy: 0.5030 - recall_69: 0.2401 - precision_69: 0.1231\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7083 - accuracy: 0.5176 - recall_69: 0.2230 - precision_69: 0.1252\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6982 - accuracy: 0.5347 - recall_69: 0.2092 - precision_69: 0.1187\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.5516 - recall_69: 0.2007 - precision_69: 0.1249\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5663 - recall_69: 0.1906 - precision_69: 0.1253\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.5836 - recall_69: 0.1902 - precision_69: 0.1323\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.5962 - recall_69: 0.1579 - precision_69: 0.1216\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6105 - recall_69: 0.1458 - precision_69: 0.1218\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6558 - accuracy: 0.6236 - recall_69: 0.1298 - precision_69: 0.1160\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.6375 - recall_69: 0.1256 - precision_69: 0.1195\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.6458 - recall_69: 0.1088 - precision_69: 0.1098\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.6590 - recall_69: 0.1124 - precision_69: 0.1254\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.6703 - recall_69: 0.1018 - precision_69: 0.1214\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.6840 - recall_69: 0.0839 - precision_69: 0.1141\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.6990 - recall_69: 0.0790 - precision_69: 0.1190\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.7132 - recall_69: 0.0772 - precision_69: 0.1287\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.7166 - recall_69: 0.0626 - precision_69: 0.1114\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.7260 - recall_69: 0.0674 - precision_69: 0.1348\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.7309 - recall_69: 0.0505 - precision_69: 0.1175\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.7387 - recall_69: 0.0425 - precision_69: 0.1107\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7459 - recall_69: 0.0431 - precision_69: 0.1238\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.7548 - recall_69: 0.0380 - precision_69: 0.1409\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7661 - recall_69: 0.0372 - precision_69: 0.1616\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5845 - accuracy: 0.7675 - recall_69: 0.0321 - precision_69: 0.1642\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7746 - recall_69: 0.0306 - precision_69: 0.1867\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.7778 - recall_69: 0.0226 - precision_69: 0.1503\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7824 - recall_69: 0.0225 - precision_69: 0.1753\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7801 - recall_69: 0.0191 - precision_69: 0.1730\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7844 - recall_69: 0.0189 - precision_69: 0.2056\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7900 - recall_69: 0.0153 - precision_69: 0.1765\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7871 - recall_69: 0.0159 - precision_69: 0.2088\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7845 - recall_69: 0.0078 - precision_69: 0.1366\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7876 - recall_69: 0.0085 - precision_69: 0.1624\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7922 - recall_69: 0.0066 - precision_69: 0.1341\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7932 - recall_69: 0.0042 - precision_69: 0.1205\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7928 - recall_69: 0.0046 - precision_69: 0.1404\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7997 - recall_69: 0.0039 - precision_69: 0.1526\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7946 - recall_69: 0.0044 - precision_69: 0.2119\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7948 - recall_69: 0.0011 - precision_69: 0.0833    \n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7977 - recall_69: 0.0023 - precision_69: 0.2389\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7969 - recall_69: 0.0029 - precision_69: 0.2750\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7961 - recall_69: 8.3660e-04 - precision_69: 0.1625\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7932 - recall_69: 5.2910e-04 - precision_69: 0.1000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.8036 - recall_69: 5.2910e-04 - precision_69: 0.1667\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7998 - recall_69: 5.2910e-04 - precision_69: 0.1667\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.8001 - recall_69: 0.0015 - precision_69: 0.3750\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.7956 - recall_69: 0.0014 - precision_69: 0.6250\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7956 - recall_69: 8.3660e-04 - precision_69: 0.3750\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7969 - recall_69: 8.3774e-04 - precision_69: 0.3750\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7954 - recall_69: 8.3398e-04 - precision_69: 0.3750\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.8014 - recall_69: 8.5044e-04 - precision_69: 0.3750\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7977 - recall_69: 0.0015 - precision_69: 0.4167\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7995 - recall_69: 8.3623e-04 - precision_69: 0.2500\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.8000 - recall_69: 8.3927e-04 - precision_69: 0.3750\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7979 - recall_69: 8.4199e-04 - precision_69: 0.3750\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7987 - recall_69: 0.0029 - precision_69: 0.6667\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.8000 - recall_69: 0.0014 - precision_69: 0.4583    \n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7936 - recall_69: 0.0014 - precision_69: 0.4583    \n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8000 - recall_69: 0.0017 - precision_69: 0.5833    \n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7989 - recall_69: 0.0023 - precision_69: 0.5000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.8003 - recall_69: 0.0045 - precision_69: 0.7000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.7946 - recall_69: 0.0028 - precision_69: 0.7167\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7987 - recall_69: 0.0031 - precision_69: 0.6125\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7965 - recall_69: 0.0037 - precision_69: 0.6167\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7963 - recall_69: 0.0036 - precision_69: 0.6083\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7997 - recall_69: 0.0027 - precision_69: 0.4583    \n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7989 - recall_69: 0.0043 - precision_69: 0.6875\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7946 - recall_69: 0.0062 - precision_69: 0.7292\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4902 - accuracy: 0.7977 - recall_69: 0.0048 - precision_69: 0.6292\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.7992 - recall_69: 0.0051 - precision_69: 0.5804\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7945 - recall_69: 0.0053 - precision_69: 0.7411\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7957 - recall_69: 0.0057 - precision_69: 0.5706\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7964 - recall_69: 0.0039 - precision_69: 0.4028    \n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.8016 - recall_69: 0.0055 - precision_69: 0.6007\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7981 - recall_69: 0.0048 - precision_69: 0.4849\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7973 - recall_69: 0.0059 - precision_69: 0.5813\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7993 - recall_69: 0.0069 - precision_69: 0.6000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7965 - recall_69: 0.0073 - precision_69: 0.6932\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.8002 - recall_69: 0.0086 - precision_69: 0.6667\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7999 - recall_69: 0.0083 - precision_69: 0.6543\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7975 - recall_69: 0.0091 - precision_69: 0.5865\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.8002 - recall_69: 0.0092 - precision_69: 0.6381\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.8005 - recall_69: 0.0095 - precision_69: 0.5893\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7966 - recall_69: 0.0099 - precision_69: 0.6591\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7994 - recall_69: 0.0101 - precision_69: 0.6250\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7973 - recall_69: 0.0099 - precision_69: 0.6458\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7964 - recall_69: 0.0090 - precision_69: 0.6381\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7974 - recall_69: 0.0123 - precision_69: 0.7128\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7998 - recall_69: 0.0100 - precision_69: 0.5875\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7970 - recall_69: 0.0116 - precision_69: 0.6752\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7989 - recall_69: 0.0117 - precision_69: 0.6383\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.8020 - recall_69: 0.0150 - precision_69: 0.7230\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7995 - recall_69: 0.0132 - precision_69: 0.6439\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7999 - recall_69: 0.0160 - precision_69: 0.6829\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.8002 - recall_69: 0.0191 - precision_69: 0.7536\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7969 - recall_69: 0.0194 - precision_69: 0.7431\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D655258F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7994 - recall_69: 0.0190 - precision_69: 0.6923\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.9147 - accuracy: 0.2028 - recall_70: 1.0000 - precision_70: 0.2028\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9047 - accuracy: 0.2014 - recall_70: 1.0000 - precision_70: 0.2014\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8920 - accuracy: 0.2053 - recall_70: 1.0000 - precision_70: 0.2053\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8840 - accuracy: 0.2011 - recall_70: 1.0000 - precision_70: 0.2011\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8725 - accuracy: 0.2041 - recall_70: 1.0000 - precision_70: 0.2041\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8642 - accuracy: 0.2010 - recall_70: 1.0000 - precision_70: 0.2010\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8542 - accuracy: 0.2022 - recall_70: 1.0000 - precision_70: 0.2022\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8439 - accuracy: 0.2045 - recall_70: 1.0000 - precision_70: 0.2045\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8365 - accuracy: 0.2007 - recall_70: 1.0000 - precision_70: 0.2007\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8278 - accuracy: 0.2006 - recall_70: 1.0000 - precision_70: 0.2006\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8198 - accuracy: 0.1994 - recall_70: 1.0000 - precision_70: 0.1994\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8106 - accuracy: 0.2021 - recall_70: 1.0000 - precision_70: 0.2021\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8018 - accuracy: 0.2047 - recall_70: 1.0000 - precision_70: 0.2047\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7951 - accuracy: 0.2011 - recall_70: 1.0000 - precision_70: 0.2011\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7874 - accuracy: 0.2016 - recall_70: 1.0000 - precision_70: 0.2016\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7794 - accuracy: 0.2038 - recall_70: 1.0000 - precision_70: 0.2038\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7727 - accuracy: 0.2021 - recall_70: 1.0000 - precision_70: 0.2021\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.2041 - recall_70: 1.0000 - precision_70: 0.2041\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7590 - accuracy: 0.2015 - recall_70: 1.0000 - precision_70: 0.2015\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7523 - accuracy: 0.2018 - recall_70: 1.0000 - precision_70: 0.2018\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7457 - accuracy: 0.2032 - recall_70: 1.0000 - precision_70: 0.2032\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7394 - accuracy: 0.2038 - recall_70: 1.0000 - precision_70: 0.2038\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.2033 - recall_70: 1.0000 - precision_70: 0.2033\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7279 - accuracy: 0.1999 - recall_70: 1.0000 - precision_70: 0.1999\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7222 - accuracy: 0.2001 - recall_70: 1.0000 - precision_70: 0.2001\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7164 - accuracy: 0.2029 - recall_70: 1.0000 - precision_70: 0.2029\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7108 - accuracy: 0.2054 - recall_70: 1.0000 - precision_70: 0.2054\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7056 - accuracy: 0.2046 - recall_70: 1.0000 - precision_70: 0.2046\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7005 - accuracy: 0.2031 - recall_70: 1.0000 - precision_70: 0.2031\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6955 - accuracy: 0.2446 - recall_70: 0.8757 - precision_70: 0.1954\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.7776 - recall_70: 0.0145 - precision_70: 0.1136\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.7958 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.7972 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.8034 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.7955 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.7992 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6637 - accuracy: 0.8110 - recall_70: 0.0000e+00 - precision_70: 0.0000e+0 - 0s 4ms/step - loss: 0.6639 - accuracy: 0.8028 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.7977 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.8002 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.7970 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.7984 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.7972 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6424 - accuracy: 0.7968 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.7992 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6359 - accuracy: 0.7990 - recall_70: 0.0000e+00 - precision_70: 0.0000e+0 - 0s 4ms/step - loss: 0.6354 - accuracy: 0.7985 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.7979 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.7994 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.8001 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6237 - accuracy: 0.7964 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.8000 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.7970 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.7999 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.7962 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.7985 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.7945 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.7978 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6028 - accuracy: 0.7959 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.7974 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.7984 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.7957 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.7958 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5919 - accuracy: 0.7956 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5887 - accuracy: 0.7984 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.8004 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.7969 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7967 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.7984 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5780 - accuracy: 0.8010 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.7980 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5764 - accuracy: 0.7972 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7967 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7941 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7984 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7956 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7947 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7952 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.7990 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.8008 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.7979 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.7970 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7964 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.7958 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7990 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7988 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7980 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7964 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.8020 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5537 - accuracy: 0.7947 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7988 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7992 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.8015 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5495 - accuracy: 0.7950 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7975 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7974 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.7977 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7979 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.8007 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7970 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.8005 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7974 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE79D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5403 - accuracy: 0.7973 - recall_70: 0.0000e+00 - precision_70: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7497 - accuracy: 0.2017 - recall_71: 1.0000 - precision_71: 0.2017\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7426 - accuracy: 0.2043 - recall_71: 1.0000 - precision_71: 0.2043\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7364 - accuracy: 0.2025 - recall_71: 1.0000 - precision_71: 0.2025\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7296 - accuracy: 0.2068 - recall_71: 1.0000 - precision_71: 0.2068\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7239 - accuracy: 0.2015 - recall_71: 1.0000 - precision_71: 0.2015\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7178 - accuracy: 0.2040 - recall_71: 1.0000 - precision_71: 0.2040\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.2033 - recall_71: 1.0000 - precision_71: 0.2033\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7065 - accuracy: 0.2020 - recall_71: 1.0000 - precision_71: 0.2020\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7009 - accuracy: 0.2047 - recall_71: 1.0000 - precision_71: 0.2047\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6957 - accuracy: 0.2257 - recall_71: 0.9440 - precision_71: 0.2000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.7990 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.7977 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.7972 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.7957 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7997 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.7989 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.7952 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.7989 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.8003 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.8010 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.7984 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.7979 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.7998 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.7965 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.7982 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.7958 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.7920 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6226 - accuracy: 0.7966 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.7955 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.7968 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.7977 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.7964 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.7968 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6048 - accuracy: 0.7985 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.7965 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7966 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.7965 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.7942 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5922 - accuracy: 0.7995 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.7932 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5933 - accuracy: 0.7870 - recall_71: 0.0000e+00 - precision_71: 0.0000e+0 - 0s 5ms/step - loss: 0.5899 - accuracy: 0.7943 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.7996 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7967 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.7982 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.7982 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.7953 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.8015 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7962 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7952 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7980 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7988 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7980 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7932 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.7928 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.7979 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7939 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.7955 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.7969 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.7955 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5580 - accuracy: 0.7951 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7957 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7972 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.7993 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7974 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7997 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7993 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5487 - accuracy: 0.7969 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7966 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.8025 - recall_71: 0.0000e+00 - precision_71: 0.0000e+0 - 0s 4ms/step - loss: 0.5445 - accuracy: 0.8000 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7977 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7966 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.8002 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7974 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5416 - accuracy: 0.7974 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.8007 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7952 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.8000 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5393 - accuracy: 0.7959 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.8024 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7972 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7960 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7958 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7958 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.8012 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7982 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7953 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7942 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7935 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7951 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7977 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7978 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7975 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7985 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7957 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7932 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7972 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7962 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.8031 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7972 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7983 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA1E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7977 - recall_71: 0.0000e+00 - precision_71: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5588 - accuracy: 0.7993 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.7992 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7978 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5547 - accuracy: 0.7991 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7991 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.7987 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.8004 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7955 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7954 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7986 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7963 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7976 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7994 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7959 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.8005 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7994 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7995 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.8028 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5378 - accuracy: 0.7994 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.7956 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7989 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7926 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7963 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.8013 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7958 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7983 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7975 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7965 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7960 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7953 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7961 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7958 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7967 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7970 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7967 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7983 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7981 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.8001 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7956 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7992 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7950 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7970 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7976 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7990 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.8009 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7957 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5256 - accuracy: 0.7932 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7964 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7999 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7976 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7976 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7957 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7965 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7984 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7964 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7984 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7969 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7978 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.8090 - recall_72: 0.0000e+00 - precision_72: 0.0000e+0 - 0s 3ms/step - loss: 0.5146 - accuracy: 0.8002 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7966 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7974 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7959 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.8014 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.7946 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8029 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7969 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7986 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7940 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7993 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7953 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7974 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7971 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7953 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7984 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7973 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7962 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7984 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7968 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7924 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.8004 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7990 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7989 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7966 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7996 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7946 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7964 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7968 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7978 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7964 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7990 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7964 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7948 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5062 - accuracy: 0.8009 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7958 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7959 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7982 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7972 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7958 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7998 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.8012 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A54820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5093 - accuracy: 0.7973 - recall_72: 0.0000e+00 - precision_72: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8377 - accuracy: 0.2036 - recall_73: 1.0000 - precision_73: 0.2036\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8322 - accuracy: 0.2058 - recall_73: 1.0000 - precision_73: 0.2058\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8285 - accuracy: 0.2032 - recall_73: 1.0000 - precision_73: 0.2032\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8233 - accuracy: 0.2039 - recall_73: 1.0000 - precision_73: 0.2039\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8188 - accuracy: 0.2025 - recall_73: 1.0000 - precision_73: 0.2025\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8134 - accuracy: 0.2059 - recall_73: 1.0000 - precision_73: 0.2059\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8105 - accuracy: 0.2008 - recall_73: 1.0000 - precision_73: 0.2008\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8050 - accuracy: 0.2043 - recall_73: 1.0000 - precision_73: 0.2043\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8019 - accuracy: 0.2008 - recall_73: 1.0000 - precision_73: 0.2008\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7971 - accuracy: 0.2019 - recall_73: 1.0000 - precision_73: 0.2019\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7935 - accuracy: 0.1995 - recall_73: 1.0000 - precision_73: 0.1995\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7889 - accuracy: 0.2008 - recall_73: 1.0000 - precision_73: 0.2008\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7831 - accuracy: 0.2074 - recall_73: 1.0000 - precision_73: 0.2074\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7799 - accuracy: 0.2043 - recall_73: 1.0000 - precision_73: 0.2043\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7755 - accuracy: 0.2051 - recall_73: 1.0000 - precision_73: 0.2051\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7722 - accuracy: 0.2036 - recall_73: 1.0000 - precision_73: 0.2036\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7680 - accuracy: 0.2043 - recall_73: 1.0000 - precision_73: 0.2043\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7642 - accuracy: 0.2042 - recall_73: 1.0000 - precision_73: 0.2042\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7614 - accuracy: 0.1998 - recall_73: 1.0000 - precision_73: 0.1998\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7575 - accuracy: 0.2013 - recall_73: 1.0000 - precision_73: 0.2013\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7532 - accuracy: 0.2045 - recall_73: 1.0000 - precision_73: 0.2045\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7494 - accuracy: 0.2040 - recall_73: 1.0000 - precision_73: 0.2035\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7465 - accuracy: 0.2032 - recall_73: 1.0000 - precision_73: 0.2016\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7428 - accuracy: 0.2066 - recall_73: 0.9969 - precision_73: 0.2039\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7392 - accuracy: 0.2076 - recall_73: 0.9935 - precision_73: 0.2033\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7363 - accuracy: 0.2075 - recall_73: 0.9901 - precision_73: 0.2010\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7332 - accuracy: 0.2130 - recall_73: 0.9816 - precision_73: 0.2025\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7298 - accuracy: 0.2166 - recall_73: 0.9625 - precision_73: 0.1991\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7265 - accuracy: 0.2260 - recall_73: 0.9417 - precision_73: 0.1994\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7229 - accuracy: 0.2331 - recall_73: 0.9167 - precision_73: 0.1981\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7201 - accuracy: 0.2458 - recall_73: 0.8822 - precision_73: 0.1967\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7171 - accuracy: 0.2639 - recall_73: 0.8474 - precision_73: 0.1950\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7138 - accuracy: 0.2820 - recall_73: 0.7928 - precision_73: 0.1932\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7112 - accuracy: 0.3008 - recall_73: 0.7504 - precision_73: 0.1895\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7081 - accuracy: 0.3268 - recall_73: 0.6826 - precision_73: 0.1847\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7056 - accuracy: 0.3494 - recall_73: 0.6123 - precision_73: 0.1791\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7022 - accuracy: 0.3883 - recall_73: 0.5408 - precision_73: 0.1755\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.4234 - recall_73: 0.4760 - precision_73: 0.1706\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6967 - accuracy: 0.4607 - recall_73: 0.4067 - precision_73: 0.1636\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.4941 - recall_73: 0.3458 - precision_73: 0.1574\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.5236 - recall_73: 0.2699 - precision_73: 0.1446\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5640 - recall_73: 0.2240 - precision_73: 0.1425\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5944 - recall_73: 0.1673 - precision_73: 0.1239\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.6252 - recall_73: 0.1387 - precision_73: 0.1258\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6812 - accuracy: 0.6590 - recall_73: 0.1179 - precision_73: 0.1290\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.6794 - recall_73: 0.0815 - precision_73: 0.1118\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6768 - accuracy: 0.7055 - recall_73: 0.0657 - precision_73: 0.106 - 0s 4ms/step - loss: 0.6765 - accuracy: 0.7070 - recall_73: 0.0615 - precision_73: 0.1073\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.7251 - recall_73: 0.0372 - precision_73: 0.0905\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.7450 - recall_73: 0.0260 - precision_73: 0.0831\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.7514 - recall_73: 0.0175 - precision_73: 0.0698\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.7638 - recall_73: 0.0129 - precision_73: 0.0684\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.7718 - recall_73: 0.0095 - precision_73: 0.0660\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.7805 - recall_73: 0.0031 - precision_73: 0.0341\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.7841 - recall_73: 8.3812e-04 - precision_73: 0.0131\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.7861 - recall_73: 8.3774e-04 - precision_73: 0.0193\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.7905 - recall_73: 8.3585e-04 - precision_73: 0.0341\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.7959 - recall_73: 5.2910e-04 - precision_73: 0.0385\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.7977 - recall_73: 0.0015 - precision_73: 0.4000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.7971 - recall_73: 0.0015 - precision_73: 0.3750\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.7972 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.7957 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.7995 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.7955 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.7980 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.7984 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7992 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.7987 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6343 - accuracy: 0.7942 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.7967 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.7975 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.7970 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.7964 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.7997 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.7990 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.7969 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.7949 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.7971 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6173 - accuracy: 0.7973 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.7968 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.8015 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.7982 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.7979 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6101 - accuracy: 0.7977 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.7967 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.7974 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.7979 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6053 - accuracy: 0.7962 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.7945 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.7949 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.7995 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.7968 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5996 - accuracy: 0.7947 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5980 - accuracy: 0.7950 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5961 - accuracy: 0.7970 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.8004 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.7969 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.7997 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.7963 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5897 - accuracy: 0.7990 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5890 - accuracy: 0.7981 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.7973 - recall_73: 0.0000e+00 - precision_73: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.9820 - accuracy: 0.2012 - recall_74: 1.0000 - precision_74: 0.2012\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9755 - accuracy: 0.2028 - recall_74: 1.0000 - precision_74: 0.2028\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9707 - accuracy: 0.2016 - recall_74: 1.0000 - precision_74: 0.2016\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9666 - accuracy: 0.1997 - recall_74: 1.0000 - precision_74: 0.1997\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9577 - accuracy: 0.2047 - recall_74: 1.0000 - precision_74: 0.2047\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9522 - accuracy: 0.2057 - recall_74: 1.0000 - precision_74: 0.2057\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9489 - accuracy: 0.2027 - recall_74: 1.0000 - precision_74: 0.2027\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9447 - accuracy: 0.2010 - recall_74: 1.0000 - precision_74: 0.2010\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9377 - accuracy: 0.2047 - recall_74: 1.0000 - precision_74: 0.2047\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9333 - accuracy: 0.2033 - recall_74: 1.0000 - precision_74: 0.2033\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9292 - accuracy: 0.2027 - recall_74: 1.0000 - precision_74: 0.2027\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9237 - accuracy: 0.2030 - recall_74: 1.0000 - precision_74: 0.2030\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9188 - accuracy: 0.2038 - recall_74: 1.0000 - precision_74: 0.2038\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9163 - accuracy: 0.1997 - recall_74: 1.0000 - precision_74: 0.1997\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9084 - accuracy: 0.2050 - recall_74: 1.0000 - precision_74: 0.2050\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9038 - accuracy: 0.2046 - recall_74: 1.0000 - precision_74: 0.2046\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9006 - accuracy: 0.2024 - recall_74: 1.0000 - precision_74: 0.2024\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8955 - accuracy: 0.2035 - recall_74: 1.0000 - precision_74: 0.2035\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8918 - accuracy: 0.2015 - recall_74: 1.0000 - precision_74: 0.2015\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8868 - accuracy: 0.2027 - recall_74: 1.0000 - precision_74: 0.2027\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8846 - accuracy: 0.1987 - recall_74: 1.0000 - precision_74: 0.1987\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8791 - accuracy: 0.2017 - recall_74: 1.0000 - precision_74: 0.2017\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8729 - accuracy: 0.2050 - recall_74: 1.0000 - precision_74: 0.2050\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.2032 - recall_74: 1.0000 - precision_74: 0.2032\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8646 - accuracy: 0.2050 - recall_74: 1.0000 - precision_74: 0.2050\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8600 - accuracy: 0.2060 - recall_74: 1.0000 - precision_74: 0.2060\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8581 - accuracy: 0.2014 - recall_74: 1.0000 - precision_74: 0.2014\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8545 - accuracy: 0.2002 - recall_74: 1.0000 - precision_74: 0.2002\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8499 - accuracy: 0.2013 - recall_74: 1.0000 - precision_74: 0.2013\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8453 - accuracy: 0.2035 - recall_74: 1.0000 - precision_74: 0.2035\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8410 - accuracy: 0.2037 - recall_74: 1.0000 - precision_74: 0.2037\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8385 - accuracy: 0.2008 - recall_74: 1.0000 - precision_74: 0.2008\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8346 - accuracy: 0.2012 - recall_74: 1.0000 - precision_74: 0.2012\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8297 - accuracy: 0.2035 - recall_74: 1.0000 - precision_74: 0.2035\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8267 - accuracy: 0.2022 - recall_74: 1.0000 - precision_74: 0.2022\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8224 - accuracy: 0.2040 - recall_74: 1.0000 - precision_74: 0.2040\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8192 - accuracy: 0.2028 - recall_74: 1.0000 - precision_74: 0.2028\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8150 - accuracy: 0.2045 - recall_74: 1.0000 - precision_74: 0.2045\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8107 - accuracy: 0.2057 - recall_74: 1.0000 - precision_74: 0.2057\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8106 - accuracy: 0.1973 - recall_74: 1.0000 - precision_74: 0.1973\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8055 - accuracy: 0.2012 - recall_74: 1.0000 - precision_74: 0.2012\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8021 - accuracy: 0.2015 - recall_74: 1.0000 - precision_74: 0.2015\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7981 - accuracy: 0.2034 - recall_74: 1.0000 - precision_74: 0.2034\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7945 - accuracy: 0.2040 - recall_74: 1.0000 - precision_74: 0.2040\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7917 - accuracy: 0.2024 - recall_74: 1.0000 - precision_74: 0.2024\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7882 - accuracy: 0.2032 - recall_74: 1.0000 - precision_74: 0.2032\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7856 - accuracy: 0.2011 - recall_74: 1.0000 - precision_74: 0.2011\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7812 - accuracy: 0.2058 - recall_74: 1.0000 - precision_74: 0.2058\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7788 - accuracy: 0.2024 - recall_74: 1.0000 - precision_74: 0.2024\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7753 - accuracy: 0.2048 - recall_74: 1.0000 - precision_74: 0.2048\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7736 - accuracy: 0.1998 - recall_74: 1.0000 - precision_74: 0.1998\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7693 - accuracy: 0.2044 - recall_74: 1.0000 - precision_74: 0.2044\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7656 - accuracy: 0.2062 - recall_74: 1.0000 - precision_74: 0.2062\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7639 - accuracy: 0.2025 - recall_74: 1.0000 - precision_74: 0.2025\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7604 - accuracy: 0.2047 - recall_74: 1.0000 - precision_74: 0.2047\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7577 - accuracy: 0.2032 - recall_74: 1.0000 - precision_74: 0.2032\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7547 - accuracy: 0.2032 - recall_74: 1.0000 - precision_74: 0.2032\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7520 - accuracy: 0.2028 - recall_74: 1.0000 - precision_74: 0.2028\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7496 - accuracy: 0.2008 - recall_74: 1.0000 - precision_74: 0.2008\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7464 - accuracy: 0.2037 - recall_74: 1.0000 - precision_74: 0.2037\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7443 - accuracy: 0.1996 - recall_74: 0.9992 - precision_74: 0.1996\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7411 - accuracy: 0.2031 - recall_74: 0.9992 - precision_74: 0.2032\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7386 - accuracy: 0.2013 - recall_74: 0.9977 - precision_74: 0.1999\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7359 - accuracy: 0.2059 - recall_74: 0.9959 - precision_74: 0.2030\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7327 - accuracy: 0.2110 - recall_74: 0.9885 - precision_74: 0.2060\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7302 - accuracy: 0.2155 - recall_74: 0.9876 - precision_74: 0.2057\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7282 - accuracy: 0.2168 - recall_74: 0.9834 - precision_74: 0.2020\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7251 - accuracy: 0.2286 - recall_74: 0.9804 - precision_74: 0.2088\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7228 - accuracy: 0.2384 - recall_74: 0.9741 - precision_74: 0.2079\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7208 - accuracy: 0.2515 - recall_74: 0.9659 - precision_74: 0.2109\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7182 - accuracy: 0.2682 - recall_74: 0.9607 - precision_74: 0.2119\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7154 - accuracy: 0.2855 - recall_74: 0.9430 - precision_74: 0.2180\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7134 - accuracy: 0.2976 - recall_74: 0.9282 - precision_74: 0.2148\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7109 - accuracy: 0.3220 - recall_74: 0.9081 - precision_74: 0.2179\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7086 - accuracy: 0.3410 - recall_74: 0.8977 - precision_74: 0.2200\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.3693 - recall_74: 0.8788 - precision_74: 0.2288\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7042 - accuracy: 0.3919 - recall_74: 0.8598 - precision_74: 0.2317\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7022 - accuracy: 0.4128 - recall_74: 0.8398 - precision_74: 0.2330\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7002 - accuracy: 0.4371 - recall_74: 0.8075 - precision_74: 0.2368\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.4659 - recall_74: 0.7834 - precision_74: 0.2448\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.4925 - recall_74: 0.7509 - precision_74: 0.2492\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5195 - recall_74: 0.7146 - precision_74: 0.2538\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5454 - recall_74: 0.6745 - precision_74: 0.2573\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5691 - recall_74: 0.6410 - precision_74: 0.2637\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.5772 - recall_74: 0.5979 - precision_74: 0.2651\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5916 - recall_74: 0.5359 - precision_74: 0.2600\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.6136 - recall_74: 0.4831 - precision_74: 0.2548\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.6356 - recall_74: 0.4452 - precision_74: 0.2664\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.6591 - recall_74: 0.4026 - precision_74: 0.2694\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.6790 - recall_74: 0.3703 - precision_74: 0.2839\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.6947 - recall_74: 0.3221 - precision_74: 0.2850\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.7118 - recall_74: 0.2987 - precision_74: 0.2881\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.7251 - recall_74: 0.2472 - precision_74: 0.2801\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.7428 - recall_74: 0.2239 - precision_74: 0.2935\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.7415 - recall_74: 0.1842 - precision_74: 0.2897\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.7567 - recall_74: 0.1587 - precision_74: 0.3099\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.7605 - recall_74: 0.1219 - precision_74: 0.2858\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.7746 - recall_74: 0.1165 - precision_74: 0.3422\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.7858 - recall_74: 0.0890 - precision_74: 0.3390\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.7853 - recall_74: 0.0634 - precision_74: 0.3401\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657F8D940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.6573 - accuracy: 0.7904 - recall_74: 0.0381 - precision_74: 0.3396\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.2535 - accuracy: 0.2022 - recall_75: 1.0000 - precision_75: 0.2022\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2467 - accuracy: 0.2012 - recall_75: 1.0000 - precision_75: 0.2012\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2342 - accuracy: 0.2044 - recall_75: 1.0000 - precision_75: 0.2044\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2284 - accuracy: 0.2021 - recall_75: 1.0000 - precision_75: 0.2021\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2177 - accuracy: 0.2044 - recall_75: 1.0000 - precision_75: 0.2044\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2131 - accuracy: 0.2012 - recall_75: 1.0000 - precision_75: 0.2012\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2114 - accuracy: 0.1961 - recall_75: 1.0000 - precision_75: 0.1961\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1947 - accuracy: 0.2036 - recall_75: 1.0000 - precision_75: 0.2036\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1864 - accuracy: 0.2035 - recall_75: 1.0000 - precision_75: 0.2035\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1802 - accuracy: 0.2027 - recall_75: 1.0000 - precision_75: 0.2027\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1747 - accuracy: 0.2005 - recall_75: 1.0000 - precision_75: 0.2005\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1681 - accuracy: 0.1996 - recall_75: 1.0000 - precision_75: 0.1996\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1582 - accuracy: 0.2015 - recall_75: 1.0000 - precision_75: 0.2015\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1501 - accuracy: 0.2024 - recall_75: 1.0000 - precision_75: 0.2024\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1403 - accuracy: 0.2042 - recall_75: 1.0000 - precision_75: 0.2042\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1331 - accuracy: 0.2042 - recall_75: 1.0000 - precision_75: 0.2042\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1298 - accuracy: 0.2007 - recall_75: 1.0000 - precision_75: 0.2007\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1173 - accuracy: 0.2056 - recall_75: 1.0000 - precision_75: 0.2056\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1124 - accuracy: 0.2034 - recall_75: 1.0000 - precision_75: 0.2034\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1042 - accuracy: 0.2048 - recall_75: 1.0000 - precision_75: 0.2048\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0969 - accuracy: 0.2050 - recall_75: 1.0000 - precision_75: 0.2050\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0951 - accuracy: 0.1999 - recall_75: 1.0000 - precision_75: 0.1999\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0818 - accuracy: 0.2065 - recall_75: 1.0000 - precision_75: 0.2065\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0815 - accuracy: 0.1999 - recall_75: 1.0000 - precision_75: 0.1999\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0740 - accuracy: 0.2007 - recall_75: 1.0000 - precision_75: 0.2007\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0689 - accuracy: 0.1991 - recall_75: 1.0000 - precision_75: 0.1991\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0584 - accuracy: 0.2035 - recall_75: 1.0000 - precision_75: 0.2035\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0515 - accuracy: 0.2036 - recall_75: 1.0000 - precision_75: 0.2036\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0471 - accuracy: 0.2019 - recall_75: 1.0000 - precision_75: 0.2019\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0370 - accuracy: 0.2059 - recall_75: 1.0000 - precision_75: 0.2059\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0347 - accuracy: 0.2016 - recall_75: 1.0000 - precision_75: 0.2016\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0269 - accuracy: 0.2033 - recall_75: 1.0000 - precision_75: 0.2033\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0202 - accuracy: 0.2044 - recall_75: 1.0000 - precision_75: 0.2044\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0152 - accuracy: 0.2028 - recall_75: 1.0000 - precision_75: 0.2028\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0121 - accuracy: 0.1995 - recall_75: 1.0000 - precision_75: 0.1995\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0032 - accuracy: 0.2032 - recall_75: 1.0000 - precision_75: 0.2032\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9990 - accuracy: 0.2011 - recall_75: 1.0000 - precision_75: 0.2011\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9934 - accuracy: 0.2007 - recall_75: 1.0000 - precision_75: 0.2007\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9861 - accuracy: 0.2033 - recall_75: 1.0000 - precision_75: 0.2033\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9806 - accuracy: 0.2029 - recall_75: 1.0000 - precision_75: 0.2029\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9742 - accuracy: 0.2042 - recall_75: 1.0000 - precision_75: 0.2042\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9724 - accuracy: 0.1993 - recall_75: 1.0000 - precision_75: 0.1993\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9635 - accuracy: 0.2039 - recall_75: 1.0000 - precision_75: 0.2039\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9595 - accuracy: 0.2021 - recall_75: 1.0000 - precision_75: 0.2021\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9528 - accuracy: 0.2039 - recall_75: 1.0000 - precision_75: 0.2039\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9490 - accuracy: 0.2022 - recall_75: 1.0000 - precision_75: 0.2022\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9446 - accuracy: 0.2006 - recall_75: 1.0000 - precision_75: 0.2006\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9388 - accuracy: 0.2010 - recall_75: 1.0000 - precision_75: 0.2010\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9322 - accuracy: 0.2037 - recall_75: 1.0000 - precision_75: 0.2037\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9278 - accuracy: 0.2032 - recall_75: 1.0000 - precision_75: 0.2032\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9221 - accuracy: 0.2044 - recall_75: 1.0000 - precision_75: 0.2044\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9160 - accuracy: 0.2060 - recall_75: 1.0000 - precision_75: 0.2060\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9119 - accuracy: 0.2049 - recall_75: 1.0000 - precision_75: 0.2049\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9078 - accuracy: 0.2037 - recall_75: 1.0000 - precision_75: 0.2037\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9032 - accuracy: 0.2035 - recall_75: 1.0000 - precision_75: 0.2035\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8994 - accuracy: 0.2017 - recall_75: 1.0000 - precision_75: 0.2017\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8947 - accuracy: 0.2020 - recall_75: 1.0000 - precision_75: 0.2020\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8904 - accuracy: 0.2014 - recall_75: 1.0000 - precision_75: 0.2014\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8858 - accuracy: 0.2017 - recall_75: 1.0000 - precision_75: 0.2017\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8814 - accuracy: 0.2018 - recall_75: 1.0000 - precision_75: 0.2018\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8774 - accuracy: 0.2016 - recall_75: 1.0000 - precision_75: 0.2016\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8717 - accuracy: 0.2029 - recall_75: 1.0000 - precision_75: 0.2029\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8678 - accuracy: 0.2033 - recall_75: 1.0000 - precision_75: 0.2033\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8646 - accuracy: 0.2006 - recall_75: 1.0000 - precision_75: 0.2006\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8587 - accuracy: 0.2040 - recall_75: 1.0000 - precision_75: 0.2040\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8558 - accuracy: 0.2022 - recall_75: 1.0000 - precision_75: 0.2022\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8512 - accuracy: 0.2030 - recall_75: 1.0000 - precision_75: 0.2030\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8478 - accuracy: 0.2012 - recall_75: 1.0000 - precision_75: 0.2012\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8418 - accuracy: 0.2060 - recall_75: 1.0000 - precision_75: 0.2060\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8399 - accuracy: 0.2016 - recall_75: 1.0000 - precision_75: 0.2016\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8357 - accuracy: 0.2016 - recall_75: 1.0000 - precision_75: 0.2016\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8306 - accuracy: 0.2042 - recall_75: 1.0000 - precision_75: 0.2042\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8278 - accuracy: 0.2024 - recall_75: 1.0000 - precision_75: 0.2024\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8235 - accuracy: 0.2037 - recall_75: 1.0000 - precision_75: 0.2037\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8201 - accuracy: 0.2028 - recall_75: 1.0000 - precision_75: 0.2028\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8169 - accuracy: 0.2015 - recall_75: 1.0000 - precision_75: 0.2015\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8125 - accuracy: 0.2037 - recall_75: 1.0000 - precision_75: 0.2037\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8102 - accuracy: 0.2006 - recall_75: 1.0000 - precision_75: 0.2006\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8080 - accuracy: 0.1990 - recall_75: 1.0000 - precision_75: 0.199 - 0s 3ms/step - loss: 0.8063 - accuracy: 0.2017 - recall_75: 1.0000 - precision_75: 0.2017\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8026 - accuracy: 0.2019 - recall_75: 1.0000 - precision_75: 0.2019\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7987 - accuracy: 0.2041 - recall_75: 1.0000 - precision_75: 0.2041\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7960 - accuracy: 0.2022 - recall_75: 1.0000 - precision_75: 0.2022\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7921 - accuracy: 0.2027 - recall_75: 1.0000 - precision_75: 0.2027\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7896 - accuracy: 0.1998 - recall_75: 1.0000 - precision_75: 0.1998\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7852 - accuracy: 0.2041 - recall_75: 1.0000 - precision_75: 0.2041\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7821 - accuracy: 0.2040 - recall_75: 1.0000 - precision_75: 0.2040\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7781 - accuracy: 0.2066 - recall_75: 1.0000 - precision_75: 0.2066\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7754 - accuracy: 0.2041 - recall_75: 1.0000 - precision_75: 0.2041\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7729 - accuracy: 0.2027 - recall_75: 1.0000 - precision_75: 0.2027\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7693 - accuracy: 0.2041 - recall_75: 1.0000 - precision_75: 0.2041\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7682 - accuracy: 0.1982 - recall_75: 1.0000 - precision_75: 0.1982\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7632 - accuracy: 0.2037 - recall_75: 1.0000 - precision_75: 0.2037\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7607 - accuracy: 0.2026 - recall_75: 1.0000 - precision_75: 0.2026\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7578 - accuracy: 0.2024 - recall_75: 1.0000 - precision_75: 0.2024\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7549 - accuracy: 0.2030 - recall_75: 1.0000 - precision_75: 0.2030\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7526 - accuracy: 0.2001 - recall_75: 1.0000 - precision_75: 0.2001\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7491 - accuracy: 0.2034 - recall_75: 1.0000 - precision_75: 0.2034\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7455 - accuracy: 0.2066 - recall_75: 1.0000 - precision_75: 0.2066\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7436 - accuracy: 0.2026 - recall_75: 1.0000 - precision_75: 0.2026\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7405 - accuracy: 0.2045 - recall_75: 1.0000 - precision_75: 0.2045\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580320D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7393 - accuracy: 0.2027 - recall_75: 1.0000 - precision_75: 0.2027\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8543 - accuracy: 0.4260 - recall_76: 0.3357 - precision_76: 0.1334\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8458 - accuracy: 0.4337 - recall_76: 0.3326 - precision_76: 0.1341\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8351 - accuracy: 0.4421 - recall_76: 0.3352 - precision_76: 0.1365\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8267 - accuracy: 0.4479 - recall_76: 0.3381 - precision_76: 0.1414\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8210 - accuracy: 0.4478 - recall_76: 0.3270 - precision_76: 0.1339\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8103 - accuracy: 0.4569 - recall_76: 0.3262 - precision_76: 0.1411\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8036 - accuracy: 0.4652 - recall_76: 0.3239 - precision_76: 0.1411\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7971 - accuracy: 0.4686 - recall_76: 0.3212 - precision_76: 0.1434\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7896 - accuracy: 0.4748 - recall_76: 0.3122 - precision_76: 0.1413\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7846 - accuracy: 0.4761 - recall_76: 0.3103 - precision_76: 0.1419\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7740 - accuracy: 0.4815 - recall_76: 0.3042 - precision_76: 0.1407\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7669 - accuracy: 0.4874 - recall_76: 0.3051 - precision_76: 0.1405\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7615 - accuracy: 0.4943 - recall_76: 0.2989 - precision_76: 0.1430\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7535 - accuracy: 0.5029 - recall_76: 0.2949 - precision_76: 0.1431\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7541 - accuracy: 0.5023 - recall_76: 0.2845 - precision_76: 0.1405\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7476 - accuracy: 0.5074 - recall_76: 0.2814 - precision_76: 0.1413\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7424 - accuracy: 0.5136 - recall_76: 0.2781 - precision_76: 0.1452\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7335 - accuracy: 0.5270 - recall_76: 0.2795 - precision_76: 0.1450\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7300 - accuracy: 0.5264 - recall_76: 0.2636 - precision_76: 0.1439\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7229 - accuracy: 0.5356 - recall_76: 0.2617 - precision_76: 0.1461\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7119 - accuracy: 0.5464 - recall_76: 0.2645 - precision_76: 0.1459\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7116 - accuracy: 0.5444 - recall_76: 0.2520 - precision_76: 0.1442\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7089 - accuracy: 0.5454 - recall_76: 0.2396 - precision_76: 0.1386\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.5577 - recall_76: 0.2469 - precision_76: 0.1509\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6962 - accuracy: 0.5666 - recall_76: 0.2353 - precision_76: 0.1463\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6903 - accuracy: 0.5740 - recall_76: 0.2404 - precision_76: 0.1531\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.5745 - recall_76: 0.2196 - precision_76: 0.1457\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5798 - recall_76: 0.2163 - precision_76: 0.1411\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.5894 - recall_76: 0.2101 - precision_76: 0.1425\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6758 - accuracy: 0.5928 - recall_76: 0.2109 - precision_76: 0.1444\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.6000 - recall_76: 0.2048 - precision_76: 0.1488\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.6060 - recall_76: 0.2045 - precision_76: 0.1486\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.6174 - recall_76: 0.1906 - precision_76: 0.1511\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6208 - recall_76: 0.1880 - precision_76: 0.1523\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.6298 - recall_76: 0.1897 - precision_76: 0.1550\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.6347 - recall_76: 0.1878 - precision_76: 0.1553\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6414 - recall_76: 0.1838 - precision_76: 0.1604\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6488 - recall_76: 0.1745 - precision_76: 0.1597\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6527 - recall_76: 0.1723 - precision_76: 0.1596\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6585 - recall_76: 0.1664 - precision_76: 0.1613\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6330 - accuracy: 0.6603 - recall_76: 0.1619 - precision_76: 0.1579\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6617 - recall_76: 0.1638 - precision_76: 0.1636\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.6676 - recall_76: 0.1592 - precision_76: 0.1672\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6708 - recall_76: 0.1546 - precision_76: 0.1658\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6766 - recall_76: 0.1580 - precision_76: 0.1698\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.6728 - recall_76: 0.1469 - precision_76: 0.1613\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6759 - recall_76: 0.1409 - precision_76: 0.1614\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.6827 - recall_76: 0.1455 - precision_76: 0.1727\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.6847 - recall_76: 0.1414 - precision_76: 0.1730\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6899 - recall_76: 0.1310 - precision_76: 0.1675\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.6973 - recall_76: 0.1270 - precision_76: 0.1705\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.7001 - recall_76: 0.1303 - precision_76: 0.1786\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5971 - accuracy: 0.7053 - recall_76: 0.1279 - precision_76: 0.1771\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7075 - recall_76: 0.1227 - precision_76: 0.1716\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.7051 - recall_76: 0.1240 - precision_76: 0.1813\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5904 - accuracy: 0.7158 - recall_76: 0.1258 - precision_76: 0.1893\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7123 - recall_76: 0.1176 - precision_76: 0.1837\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.7179 - recall_76: 0.1173 - precision_76: 0.1872\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5870 - accuracy: 0.7188 - recall_76: 0.1127 - precision_76: 0.1802\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.7240 - recall_76: 0.1117 - precision_76: 0.1907\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.7232 - recall_76: 0.1022 - precision_76: 0.1833\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.7300 - recall_76: 0.1058 - precision_76: 0.1938\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7299 - recall_76: 0.0988 - precision_76: 0.1843\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7354 - recall_76: 0.0999 - precision_76: 0.1950\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.7325 - recall_76: 0.0933 - precision_76: 0.1911\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7421 - recall_76: 0.0949 - precision_76: 0.1994\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7380 - recall_76: 0.0928 - precision_76: 0.1971\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7429 - recall_76: 0.0950 - precision_76: 0.2066\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.7478 - recall_76: 0.0953 - precision_76: 0.2193\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.7493 - recall_76: 0.0954 - precision_76: 0.2148\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.7526 - recall_76: 0.0927 - precision_76: 0.2246\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7458 - recall_76: 0.0792 - precision_76: 0.1987\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5600 - accuracy: 0.7512 - recall_76: 0.0807 - precision_76: 0.2134\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7527 - recall_76: 0.0822 - precision_76: 0.2124\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.7523 - recall_76: 0.0802 - precision_76: 0.2181\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7590 - recall_76: 0.0829 - precision_76: 0.2284\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.7570 - recall_76: 0.0744 - precision_76: 0.2178\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7555 - recall_76: 0.0729 - precision_76: 0.2137\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7612 - recall_76: 0.0781 - precision_76: 0.2283\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7600 - recall_76: 0.0740 - precision_76: 0.2252\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7646 - recall_76: 0.0735 - precision_76: 0.2307\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7654 - recall_76: 0.0707 - precision_76: 0.2296\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7644 - recall_76: 0.0683 - precision_76: 0.2302\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7686 - recall_76: 0.0689 - precision_76: 0.2458\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.7656 - recall_76: 0.0685 - precision_76: 0.2482\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7695 - recall_76: 0.0632 - precision_76: 0.2378\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5377 - accuracy: 0.7708 - recall_76: 0.0605 - precision_76: 0.2314\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7713 - recall_76: 0.0580 - precision_76: 0.2329\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7715 - recall_76: 0.0591 - precision_76: 0.2338\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7697 - recall_76: 0.0586 - precision_76: 0.2461\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7725 - recall_76: 0.0540 - precision_76: 0.2344\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7760 - recall_76: 0.0527 - precision_76: 0.2434\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7767 - recall_76: 0.0517 - precision_76: 0.2523\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7766 - recall_76: 0.0541 - precision_76: 0.2533\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.7734 - recall_76: 0.0532 - precision_76: 0.2570\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7817 - recall_76: 0.0561 - precision_76: 0.2711\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7793 - recall_76: 0.0498 - precision_76: 0.2589\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7811 - recall_76: 0.0517 - precision_76: 0.2626\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5221 - accuracy: 0.7813 - recall_76: 0.0497 - precision_76: 0.2715\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.7831 - recall_76: 0.0481 - precision_76: 0.2757\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C149E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5177 - accuracy: 0.7785 - recall_76: 0.0423 - precision_76: 0.2381\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7471 - accuracy: 0.4954 - recall_77: 0.4679 - precision_77: 0.1925\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7414 - accuracy: 0.5017 - recall_77: 0.4657 - precision_77: 0.1957\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7378 - accuracy: 0.5059 - recall_77: 0.4664 - precision_77: 0.1969\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7299 - accuracy: 0.5140 - recall_77: 0.4630 - precision_77: 0.1978\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7245 - accuracy: 0.5207 - recall_77: 0.4506 - precision_77: 0.1992\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7225 - accuracy: 0.5240 - recall_77: 0.4527 - precision_77: 0.2039\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7172 - accuracy: 0.5285 - recall_77: 0.4261 - precision_77: 0.1968\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7180 - accuracy: 0.5266 - recall_77: 0.4312 - precision_77: 0.1958\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7092 - accuracy: 0.5392 - recall_77: 0.4247 - precision_77: 0.2015\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7078 - accuracy: 0.5397 - recall_77: 0.4202 - precision_77: 0.2032\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7009 - accuracy: 0.5510 - recall_77: 0.4243 - precision_77: 0.2044\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6988 - accuracy: 0.5546 - recall_77: 0.4189 - precision_77: 0.2037\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.5572 - recall_77: 0.4058 - precision_77: 0.2017\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.5657 - recall_77: 0.4070 - precision_77: 0.2082\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5671 - recall_77: 0.3978 - precision_77: 0.2056\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5675 - recall_77: 0.3854 - precision_77: 0.2028\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.5686 - recall_77: 0.3765 - precision_77: 0.1972\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.5767 - recall_77: 0.3793 - precision_77: 0.2076\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6732 - accuracy: 0.5825 - recall_77: 0.3694 - precision_77: 0.2030\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.5904 - recall_77: 0.3754 - precision_77: 0.2096\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.5895 - recall_77: 0.3457 - precision_77: 0.2014\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.5857 - recall_77: 0.3363 - precision_77: 0.1966\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.5943 - recall_77: 0.3278 - precision_77: 0.1978\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.6042 - recall_77: 0.3375 - precision_77: 0.2090\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.6030 - recall_77: 0.3141 - precision_77: 0.1969\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6059 - recall_77: 0.3148 - precision_77: 0.2009\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.6137 - recall_77: 0.3065 - precision_77: 0.2006\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.6187 - recall_77: 0.3019 - precision_77: 0.2041\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6200 - recall_77: 0.2973 - precision_77: 0.2014\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6302 - recall_77: 0.2978 - precision_77: 0.2086\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.6293 - recall_77: 0.2893 - precision_77: 0.2112\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6370 - recall_77: 0.2883 - precision_77: 0.2110\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6314 - accuracy: 0.6355 - recall_77: 0.2739 - precision_77: 0.2020\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.6425 - recall_77: 0.2747 - precision_77: 0.2065\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.6452 - recall_77: 0.2705 - precision_77: 0.2112\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.6548 - recall_77: 0.2659 - precision_77: 0.2142\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.6550 - recall_77: 0.2621 - precision_77: 0.2142\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.6581 - recall_77: 0.2522 - precision_77: 0.2079\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.6613 - recall_77: 0.2542 - precision_77: 0.2170\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.6607 - recall_77: 0.2465 - precision_77: 0.2173\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6151 - accuracy: 0.6648 - recall_77: 0.2426 - precision_77: 0.2165\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.6712 - recall_77: 0.2365 - precision_77: 0.2159\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6743 - recall_77: 0.2376 - precision_77: 0.2201\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6078 - accuracy: 0.6701 - recall_77: 0.2243 - precision_77: 0.2091\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.6802 - recall_77: 0.2208 - precision_77: 0.2139\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6833 - recall_77: 0.2144 - precision_77: 0.2140\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6863 - recall_77: 0.2121 - precision_77: 0.2168\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.6874 - recall_77: 0.2043 - precision_77: 0.2140\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5988 - accuracy: 0.6849 - recall_77: 0.1858 - precision_77: 0.2019\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.6909 - recall_77: 0.1852 - precision_77: 0.2036\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.6933 - recall_77: 0.1870 - precision_77: 0.2122\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.6963 - recall_77: 0.1864 - precision_77: 0.2154\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.6962 - recall_77: 0.1770 - precision_77: 0.2057\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7001 - recall_77: 0.1746 - precision_77: 0.2099\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.7009 - recall_77: 0.1661 - precision_77: 0.2054\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.7019 - recall_77: 0.1702 - precision_77: 0.2073\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.7040 - recall_77: 0.1621 - precision_77: 0.2042\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7089 - recall_77: 0.1592 - precision_77: 0.2130\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.7126 - recall_77: 0.1668 - precision_77: 0.2268\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.7140 - recall_77: 0.1500 - precision_77: 0.2061\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.7200 - recall_77: 0.1483 - precision_77: 0.2185\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5763 - accuracy: 0.7171 - recall_77: 0.1378 - precision_77: 0.2094\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7200 - recall_77: 0.1341 - precision_77: 0.2100\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7216 - recall_77: 0.1270 - precision_77: 0.2032\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7256 - recall_77: 0.1292 - precision_77: 0.2169\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7285 - recall_77: 0.1308 - precision_77: 0.2224\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7314 - recall_77: 0.1193 - precision_77: 0.2138\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.7361 - recall_77: 0.1210 - precision_77: 0.2171\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7355 - recall_77: 0.1209 - precision_77: 0.2237\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.7389 - recall_77: 0.1187 - precision_77: 0.2222\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.7385 - recall_77: 0.1225 - precision_77: 0.2303\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7410 - recall_77: 0.1156 - precision_77: 0.2353\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7417 - recall_77: 0.1138 - precision_77: 0.2336\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5579 - accuracy: 0.7421 - recall_77: 0.1137 - precision_77: 0.2310\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.7468 - recall_77: 0.1093 - precision_77: 0.2351\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7496 - recall_77: 0.1068 - precision_77: 0.2363\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7529 - recall_77: 0.1093 - precision_77: 0.2436\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7508 - recall_77: 0.1019 - precision_77: 0.2365\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.7560 - recall_77: 0.0945 - precision_77: 0.2325\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7550 - recall_77: 0.0850 - precision_77: 0.2249\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7560 - recall_77: 0.0840 - precision_77: 0.2254\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.7562 - recall_77: 0.0792 - precision_77: 0.2294\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.7553 - recall_77: 0.0804 - precision_77: 0.2327\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7647 - recall_77: 0.0832 - precision_77: 0.2335\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7640 - recall_77: 0.0763 - precision_77: 0.2360\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7625 - recall_77: 0.0752 - precision_77: 0.2367\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5390 - accuracy: 0.7648 - recall_77: 0.0739 - precision_77: 0.2351\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7691 - recall_77: 0.0729 - precision_77: 0.2471\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7683 - recall_77: 0.0670 - precision_77: 0.2378\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7650 - recall_77: 0.0651 - precision_77: 0.2349\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5365 - accuracy: 0.7652 - recall_77: 0.0632 - precision_77: 0.2445\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7728 - recall_77: 0.0632 - precision_77: 0.2510\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7725 - recall_77: 0.0640 - precision_77: 0.2621\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7788 - recall_77: 0.0653 - precision_77: 0.2523\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7733 - recall_77: 0.0591 - precision_77: 0.2548\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7764 - recall_77: 0.0566 - precision_77: 0.2557\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7775 - recall_77: 0.0581 - precision_77: 0.2771\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5290 - accuracy: 0.7767 - recall_77: 0.0530 - precision_77: 0.2690\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7772 - recall_77: 0.0567 - precision_77: 0.2866\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7801 - recall_77: 0.0492 - precision_77: 0.2661\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7823 - recall_77: 0.0572 - precision_77: 0.3000\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7292 - accuracy: 0.5295 - recall_78: 0.5524 - precision_78: 0.2284\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.5334 - recall_78: 0.5370 - precision_78: 0.2243\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7150 - accuracy: 0.5396 - recall_78: 0.5463 - precision_78: 0.2323\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7113 - accuracy: 0.5393 - recall_78: 0.5374 - precision_78: 0.2318\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.5388 - recall_78: 0.5303 - precision_78: 0.2246\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.5476 - recall_78: 0.5151 - precision_78: 0.2263\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6975 - accuracy: 0.5547 - recall_78: 0.5285 - precision_78: 0.2322\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5599 - recall_78: 0.5273 - precision_78: 0.2337\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5616 - recall_78: 0.5223 - precision_78: 0.2374\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.5639 - recall_78: 0.4989 - precision_78: 0.2350\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5666 - recall_78: 0.4934 - precision_78: 0.2316\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.5712 - recall_78: 0.4945 - precision_78: 0.2374\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.5787 - recall_78: 0.4947 - precision_78: 0.2393\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.5802 - recall_78: 0.4939 - precision_78: 0.2408\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.5896 - recall_78: 0.4974 - precision_78: 0.2471\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.5932 - recall_78: 0.4777 - precision_78: 0.2442\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6015 - recall_78: 0.4730 - precision_78: 0.2487\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.6020 - recall_78: 0.4680 - precision_78: 0.2505\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.6080 - recall_78: 0.4639 - precision_78: 0.2464\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.6109 - recall_78: 0.4603 - precision_78: 0.2550\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6428 - accuracy: 0.6153 - recall_78: 0.4402 - precision_78: 0.2430\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.6172 - recall_78: 0.4500 - precision_78: 0.2532\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6249 - recall_78: 0.4431 - precision_78: 0.2538\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6330 - accuracy: 0.6242 - recall_78: 0.4320 - precision_78: 0.2521\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.6354 - recall_78: 0.4357 - precision_78: 0.2602\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6278 - accuracy: 0.6367 - recall_78: 0.4296 - precision_78: 0.2591\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6411 - recall_78: 0.4155 - precision_78: 0.2557\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.6524 - recall_78: 0.4104 - precision_78: 0.2616\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6187 - accuracy: 0.6516 - recall_78: 0.4053 - precision_78: 0.2643\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6158 - accuracy: 0.6589 - recall_78: 0.4008 - precision_78: 0.2708\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.6638 - recall_78: 0.4164 - precision_78: 0.2780\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.6652 - recall_78: 0.3965 - precision_78: 0.2745\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6705 - recall_78: 0.3875 - precision_78: 0.2775\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.6722 - recall_78: 0.3814 - precision_78: 0.2806\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.6763 - recall_78: 0.3782 - precision_78: 0.2764\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.6816 - recall_78: 0.3820 - precision_78: 0.2858\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.6847 - recall_78: 0.3732 - precision_78: 0.2891\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.6884 - recall_78: 0.3740 - precision_78: 0.2885\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.6883 - recall_78: 0.3596 - precision_78: 0.2856\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.6917 - recall_78: 0.3542 - precision_78: 0.2909\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.6972 - recall_78: 0.3492 - precision_78: 0.2961\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.6977 - recall_78: 0.3527 - precision_78: 0.2952\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7007 - recall_78: 0.3405 - precision_78: 0.2972\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7053 - recall_78: 0.3474 - precision_78: 0.3094\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7060 - recall_78: 0.3421 - precision_78: 0.3113\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.7081 - recall_78: 0.3308 - precision_78: 0.3010\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7167 - recall_78: 0.3346 - precision_78: 0.3175\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7180 - recall_78: 0.3295 - precision_78: 0.3137\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7225 - recall_78: 0.3303 - precision_78: 0.3224\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7251 - recall_78: 0.3173 - precision_78: 0.3118\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5660 - accuracy: 0.7245 - recall_78: 0.3264 - precision_78: 0.3248\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5626 - accuracy: 0.7293 - recall_78: 0.3149 - precision_78: 0.3245\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5590 - accuracy: 0.7351 - recall_78: 0.3073 - precision_78: 0.3364\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7333 - recall_78: 0.2974 - precision_78: 0.3308\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7387 - recall_78: 0.2931 - precision_78: 0.3327\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.7399 - recall_78: 0.2961 - precision_78: 0.3394\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.7443 - recall_78: 0.2935 - precision_78: 0.3478\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7508 - recall_78: 0.2927 - precision_78: 0.3514\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7468 - recall_78: 0.2853 - precision_78: 0.3505\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7471 - recall_78: 0.2726 - precision_78: 0.3449\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7565 - recall_78: 0.2764 - precision_78: 0.3555\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7555 - recall_78: 0.2717 - precision_78: 0.3612\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7587 - recall_78: 0.2676 - precision_78: 0.3588\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7570 - recall_78: 0.2638 - precision_78: 0.3635\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7567 - recall_78: 0.2491 - precision_78: 0.3583\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7580 - recall_78: 0.2499 - precision_78: 0.3559\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7641 - recall_78: 0.2492 - precision_78: 0.3657\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.7611 - recall_78: 0.2418 - precision_78: 0.3641\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7648 - recall_78: 0.2356 - precision_78: 0.3729\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7665 - recall_78: 0.2339 - precision_78: 0.3848\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7681 - recall_78: 0.2229 - precision_78: 0.3715\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7701 - recall_78: 0.2238 - precision_78: 0.3847\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7733 - recall_78: 0.2304 - precision_78: 0.3939\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7745 - recall_78: 0.2183 - precision_78: 0.3978\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7733 - recall_78: 0.2078 - precision_78: 0.3868\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7776 - recall_78: 0.1997 - precision_78: 0.3880\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7745 - recall_78: 0.1982 - precision_78: 0.3925\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5201 - accuracy: 0.7787 - recall_78: 0.2036 - precision_78: 0.3996\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7795 - recall_78: 0.1941 - precision_78: 0.3931\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7800 - recall_78: 0.1915 - precision_78: 0.4036\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7827 - recall_78: 0.1961 - precision_78: 0.4302\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7814 - recall_78: 0.1807 - precision_78: 0.4146\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7873 - recall_78: 0.1820 - precision_78: 0.4191\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7853 - recall_78: 0.1861 - precision_78: 0.4317\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7868 - recall_78: 0.1825 - precision_78: 0.4449\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7893 - recall_78: 0.1732 - precision_78: 0.4297\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7873 - recall_78: 0.1773 - precision_78: 0.4545\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7896 - recall_78: 0.1715 - precision_78: 0.4435\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7866 - recall_78: 0.1627 - precision_78: 0.4347\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7858 - recall_78: 0.1579 - precision_78: 0.4242\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7899 - recall_78: 0.1628 - precision_78: 0.4417\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7917 - recall_78: 0.1652 - precision_78: 0.4490\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7936 - recall_78: 0.1661 - precision_78: 0.4696\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7902 - recall_78: 0.1570 - precision_78: 0.4463\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7917 - recall_78: 0.1552 - precision_78: 0.4616\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7945 - recall_78: 0.1623 - precision_78: 0.4848\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7928 - recall_78: 0.1464 - precision_78: 0.4450\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7931 - recall_78: 0.1491 - precision_78: 0.4639\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7922 - recall_78: 0.1481 - precision_78: 0.4793\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7891 - recall_78: 0.1408 - precision_78: 0.4598\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE7AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7857 - recall_78: 0.1374 - precision_78: 0.4140\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8889 - accuracy: 0.4458 - recall_79: 0.3344 - precision_79: 0.1389\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8860 - accuracy: 0.4508 - recall_79: 0.3381 - precision_79: 0.1411\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8773 - accuracy: 0.4538 - recall_79: 0.3391 - precision_79: 0.1427\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8765 - accuracy: 0.4543 - recall_79: 0.3367 - precision_79: 0.1439\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8715 - accuracy: 0.4579 - recall_79: 0.3393 - precision_79: 0.1490\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8646 - accuracy: 0.4603 - recall_79: 0.3338 - precision_79: 0.1431\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8597 - accuracy: 0.4606 - recall_79: 0.3191 - precision_79: 0.1372\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.4653 - recall_79: 0.3231 - precision_79: 0.1391\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8526 - accuracy: 0.4640 - recall_79: 0.3112 - precision_79: 0.1347\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8490 - accuracy: 0.4642 - recall_79: 0.3046 - precision_79: 0.1352\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8409 - accuracy: 0.4711 - recall_79: 0.3149 - precision_79: 0.1420\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8361 - accuracy: 0.4712 - recall_79: 0.3172 - precision_79: 0.1412\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8310 - accuracy: 0.4768 - recall_79: 0.3111 - precision_79: 0.1426\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8283 - accuracy: 0.4786 - recall_79: 0.3035 - precision_79: 0.1416\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8220 - accuracy: 0.4805 - recall_79: 0.2994 - precision_79: 0.1367\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8196 - accuracy: 0.4817 - recall_79: 0.3050 - precision_79: 0.1407\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8143 - accuracy: 0.4852 - recall_79: 0.2979 - precision_79: 0.1390\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8052 - accuracy: 0.4936 - recall_79: 0.3011 - precision_79: 0.1412\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8072 - accuracy: 0.4892 - recall_79: 0.2904 - precision_79: 0.1384\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8023 - accuracy: 0.4904 - recall_79: 0.2837 - precision_79: 0.1377\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7944 - accuracy: 0.4993 - recall_79: 0.2952 - precision_79: 0.1437\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7930 - accuracy: 0.4944 - recall_79: 0.2750 - precision_79: 0.1350\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7882 - accuracy: 0.5022 - recall_79: 0.2822 - precision_79: 0.1384\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7881 - accuracy: 0.5041 - recall_79: 0.2722 - precision_79: 0.1361\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7881 - accuracy: 0.5012 - recall_79: 0.2689 - precision_79: 0.1364\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7779 - accuracy: 0.5103 - recall_79: 0.2603 - precision_79: 0.1373\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7722 - accuracy: 0.5144 - recall_79: 0.2748 - precision_79: 0.1394\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7707 - accuracy: 0.5144 - recall_79: 0.2701 - precision_79: 0.1362\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7707 - accuracy: 0.5158 - recall_79: 0.2686 - precision_79: 0.1397\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7640 - accuracy: 0.5203 - recall_79: 0.2707 - precision_79: 0.1435\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7612 - accuracy: 0.5209 - recall_79: 0.2649 - precision_79: 0.1408\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7626 - accuracy: 0.5225 - recall_79: 0.2524 - precision_79: 0.1368\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7572 - accuracy: 0.5246 - recall_79: 0.2496 - precision_79: 0.1363\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.5301 - recall_79: 0.2519 - precision_79: 0.1381\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7476 - accuracy: 0.5332 - recall_79: 0.2488 - precision_79: 0.1402\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7455 - accuracy: 0.5343 - recall_79: 0.2437 - precision_79: 0.1366\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7446 - accuracy: 0.5362 - recall_79: 0.2469 - precision_79: 0.1385\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7389 - accuracy: 0.5412 - recall_79: 0.2452 - precision_79: 0.1410\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7335 - accuracy: 0.5435 - recall_79: 0.2336 - precision_79: 0.1335\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7344 - accuracy: 0.5446 - recall_79: 0.2437 - precision_79: 0.1388\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.5525 - recall_79: 0.2401 - precision_79: 0.1420\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7267 - accuracy: 0.5517 - recall_79: 0.2369 - precision_79: 0.1389\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7284 - accuracy: 0.5508 - recall_79: 0.2336 - precision_79: 0.1407\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7215 - accuracy: 0.5566 - recall_79: 0.2332 - precision_79: 0.1409\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7194 - accuracy: 0.5591 - recall_79: 0.2232 - precision_79: 0.1365\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7161 - accuracy: 0.5616 - recall_79: 0.2263 - precision_79: 0.1409\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7139 - accuracy: 0.5631 - recall_79: 0.2275 - precision_79: 0.1404\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7108 - accuracy: 0.5683 - recall_79: 0.2238 - precision_79: 0.1437\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7058 - accuracy: 0.5732 - recall_79: 0.2284 - precision_79: 0.1455\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.5705 - recall_79: 0.2178 - precision_79: 0.1429\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7047 - accuracy: 0.5736 - recall_79: 0.2126 - precision_79: 0.1395\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6997 - accuracy: 0.5769 - recall_79: 0.2246 - precision_79: 0.1452\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.5806 - recall_79: 0.2157 - precision_79: 0.1423\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6965 - accuracy: 0.5829 - recall_79: 0.2067 - precision_79: 0.1390\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.5838 - recall_79: 0.2079 - precision_79: 0.1423\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5869 - recall_79: 0.1996 - precision_79: 0.1353\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.5885 - recall_79: 0.2057 - precision_79: 0.1418\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.5923 - recall_79: 0.2043 - precision_79: 0.1411\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6799 - accuracy: 0.6010 - recall_79: 0.2052 - precision_79: 0.1447\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.6014 - recall_79: 0.2053 - precision_79: 0.1492\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.6066 - recall_79: 0.1971 - precision_79: 0.1443\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.6091 - recall_79: 0.1907 - precision_79: 0.1451\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.6075 - recall_79: 0.1871 - precision_79: 0.1424\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.6063 - recall_79: 0.1847 - precision_79: 0.1439\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.6111 - recall_79: 0.1800 - precision_79: 0.1394\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.6182 - recall_79: 0.1809 - precision_79: 0.1436\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6665 - accuracy: 0.6143 - recall_79: 0.1840 - precision_79: 0.1428\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.6137 - recall_79: 0.1693 - precision_79: 0.1363\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.6269 - recall_79: 0.1778 - precision_79: 0.1441\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.6215 - recall_79: 0.1708 - precision_79: 0.1422\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6265 - recall_79: 0.1608 - precision_79: 0.1352\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.6242 - recall_79: 0.1616 - precision_79: 0.1381\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.6293 - recall_79: 0.1629 - precision_79: 0.1424\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.6323 - recall_79: 0.1570 - precision_79: 0.1395\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6406 - recall_79: 0.1660 - precision_79: 0.1478\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.6405 - recall_79: 0.1562 - precision_79: 0.1417\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.6423 - recall_79: 0.1543 - precision_79: 0.1447\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6446 - recall_79: 0.1427 - precision_79: 0.1353\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6401 - accuracy: 0.6508 - recall_79: 0.1451 - precision_79: 0.1400\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6468 - recall_79: 0.1415 - precision_79: 0.1404\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.6524 - recall_79: 0.1405 - precision_79: 0.1416\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6544 - recall_79: 0.1432 - precision_79: 0.1497\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.6554 - recall_79: 0.1463 - precision_79: 0.1484\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.6616 - recall_79: 0.1433 - precision_79: 0.1506\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6663 - recall_79: 0.1429 - precision_79: 0.1493\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6671 - recall_79: 0.1369 - precision_79: 0.1444\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6697 - recall_79: 0.1366 - precision_79: 0.1519\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6258 - accuracy: 0.6712 - recall_79: 0.1421 - precision_79: 0.1566\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.6698 - recall_79: 0.1265 - precision_79: 0.1446\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.6740 - recall_79: 0.1363 - precision_79: 0.1501\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6726 - recall_79: 0.1276 - precision_79: 0.1455\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6785 - recall_79: 0.1280 - precision_79: 0.1508\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6768 - recall_79: 0.1227 - precision_79: 0.1462\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6179 - accuracy: 0.6780 - recall_79: 0.1207 - precision_79: 0.1464\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.6821 - recall_79: 0.1214 - precision_79: 0.1505\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6805 - recall_79: 0.1195 - precision_79: 0.1476\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6118 - accuracy: 0.6868 - recall_79: 0.1219 - precision_79: 0.1548\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6851 - recall_79: 0.1182 - precision_79: 0.1513\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.6886 - recall_79: 0.1173 - precision_79: 0.1493\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6909 - recall_79: 0.1131 - precision_79: 0.1473\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FBDCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.7014 - recall_79: 0.1036 - precision_79: 0.1522\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6989 - accuracy: 0.5572 - recall_80: 0.6763 - precision_80: 0.2630\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6948 - accuracy: 0.5632 - recall_80: 0.6626 - precision_80: 0.2646\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5727 - recall_80: 0.6725 - precision_80: 0.2754\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5668 - recall_80: 0.6626 - precision_80: 0.2702\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.5707 - recall_80: 0.6568 - precision_80: 0.2719\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.5758 - recall_80: 0.6565 - precision_80: 0.2727\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.5825 - recall_80: 0.6536 - precision_80: 0.2726\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.5869 - recall_80: 0.6410 - precision_80: 0.2732\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.5926 - recall_80: 0.6475 - precision_80: 0.2823\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.5940 - recall_80: 0.6384 - precision_80: 0.2788\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.5939 - recall_80: 0.6325 - precision_80: 0.2804\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.5983 - recall_80: 0.6317 - precision_80: 0.2828\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.6061 - recall_80: 0.6410 - precision_80: 0.2888\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6023 - recall_80: 0.6240 - precision_80: 0.2816\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.6104 - recall_80: 0.6250 - precision_80: 0.2901\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.6130 - recall_80: 0.6147 - precision_80: 0.2881\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6189 - recall_80: 0.6045 - precision_80: 0.2914\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6198 - recall_80: 0.5943 - precision_80: 0.2867\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6255 - recall_80: 0.5982 - precision_80: 0.2944\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6290 - recall_80: 0.5945 - precision_80: 0.2946\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6335 - recall_80: 0.5912 - precision_80: 0.2962\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.6342 - recall_80: 0.5767 - precision_80: 0.2955\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.6360 - recall_80: 0.5755 - precision_80: 0.2856\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.6450 - recall_80: 0.5864 - precision_80: 0.3068\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.6475 - recall_80: 0.5725 - precision_80: 0.3020\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6447 - recall_80: 0.5601 - precision_80: 0.2997\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6501 - recall_80: 0.5634 - precision_80: 0.3010\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.6542 - recall_80: 0.5731 - precision_80: 0.3103\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.6521 - recall_80: 0.5505 - precision_80: 0.3057\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.6607 - recall_80: 0.5587 - precision_80: 0.3122\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6129 - accuracy: 0.6588 - recall_80: 0.5447 - precision_80: 0.3058\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6101 - accuracy: 0.6645 - recall_80: 0.5455 - precision_80: 0.3115\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6654 - recall_80: 0.5380 - precision_80: 0.3132\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.6695 - recall_80: 0.5467 - precision_80: 0.3117\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.6691 - recall_80: 0.5325 - precision_80: 0.3154\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.6728 - recall_80: 0.5329 - precision_80: 0.3189\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.6774 - recall_80: 0.5297 - precision_80: 0.3173\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.6748 - recall_80: 0.5206 - precision_80: 0.3161\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.6820 - recall_80: 0.5211 - precision_80: 0.3208\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.6835 - recall_80: 0.5096 - precision_80: 0.3235\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.6868 - recall_80: 0.5101 - precision_80: 0.3289\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.6919 - recall_80: 0.5177 - precision_80: 0.3347\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.6908 - recall_80: 0.5021 - precision_80: 0.3297\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.6942 - recall_80: 0.5087 - precision_80: 0.3384\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.6945 - recall_80: 0.4962 - precision_80: 0.3289\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.6980 - recall_80: 0.4970 - precision_80: 0.3300\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.7009 - recall_80: 0.4977 - precision_80: 0.3440\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.7014 - recall_80: 0.4903 - precision_80: 0.3403\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7068 - recall_80: 0.4879 - precision_80: 0.3465\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7066 - recall_80: 0.4791 - precision_80: 0.3442\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5724 - accuracy: 0.7128 - recall_80: 0.4816 - precision_80: 0.3482\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7082 - recall_80: 0.4599 - precision_80: 0.3338\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.7103 - recall_80: 0.4720 - precision_80: 0.3495\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.7090 - recall_80: 0.4584 - precision_80: 0.3325\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7147 - recall_80: 0.4698 - precision_80: 0.3469\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7132 - recall_80: 0.4526 - precision_80: 0.3429\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7223 - recall_80: 0.4540 - precision_80: 0.3564\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7212 - recall_80: 0.4584 - precision_80: 0.3563\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7237 - recall_80: 0.4553 - precision_80: 0.3555\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7273 - recall_80: 0.4508 - precision_80: 0.3608\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7311 - recall_80: 0.4563 - precision_80: 0.3636\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7337 - recall_80: 0.4555 - precision_80: 0.3713\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7344 - recall_80: 0.4476 - precision_80: 0.3778\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.7341 - recall_80: 0.4446 - precision_80: 0.3722\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7366 - recall_80: 0.4421 - precision_80: 0.3736\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7385 - recall_80: 0.4456 - precision_80: 0.3772\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7414 - recall_80: 0.4370 - precision_80: 0.3857\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7450 - recall_80: 0.4464 - precision_80: 0.3857\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7504 - recall_80: 0.4360 - precision_80: 0.3954\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7471 - recall_80: 0.4299 - precision_80: 0.3849\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7528 - recall_80: 0.4278 - precision_80: 0.3937\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7528 - recall_80: 0.4270 - precision_80: 0.4016\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7559 - recall_80: 0.4255 - precision_80: 0.4010\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7536 - recall_80: 0.4204 - precision_80: 0.3929\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7552 - recall_80: 0.4127 - precision_80: 0.3983\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7550 - recall_80: 0.4166 - precision_80: 0.4056\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7568 - recall_80: 0.4070 - precision_80: 0.3907\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7622 - recall_80: 0.4185 - precision_80: 0.4118\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7612 - recall_80: 0.4134 - precision_80: 0.4204\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7619 - recall_80: 0.4090 - precision_80: 0.4187\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7660 - recall_80: 0.4063 - precision_80: 0.4182\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7653 - recall_80: 0.4033 - precision_80: 0.4122\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7643 - recall_80: 0.3940 - precision_80: 0.4141\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7654 - recall_80: 0.3986 - precision_80: 0.4246\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7679 - recall_80: 0.4006 - precision_80: 0.4322\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7701 - recall_80: 0.3973 - precision_80: 0.4310\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7672 - recall_80: 0.3894 - precision_80: 0.4234\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7739 - recall_80: 0.3961 - precision_80: 0.4368\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7760 - recall_80: 0.3931 - precision_80: 0.4396\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7763 - recall_80: 0.3821 - precision_80: 0.4311\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7755 - recall_80: 0.3878 - precision_80: 0.4500\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7755 - recall_80: 0.3732 - precision_80: 0.4430\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7816 - recall_80: 0.3708 - precision_80: 0.4405\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7794 - recall_80: 0.3812 - precision_80: 0.4529\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5213 - accuracy: 0.7750 - recall_80: 0.3799 - precision_80: 0.440 - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7798 - recall_80: 0.3745 - precision_80: 0.4475\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7815 - recall_80: 0.3770 - precision_80: 0.4537\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7813 - recall_80: 0.3659 - precision_80: 0.4520\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7824 - recall_80: 0.3634 - precision_80: 0.4483\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7824 - recall_80: 0.3602 - precision_80: 0.4467\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7843 - recall_80: 0.3630 - precision_80: 0.4606\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D658032F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5172 - accuracy: 0.7763 - recall_80: 0.3453 - precision_80: 0.4335\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7435 - accuracy: 0.5032 - recall_81: 0.4892 - precision_81: 0.2026\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7398 - accuracy: 0.5073 - recall_81: 0.4838 - precision_81: 0.2026\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7369 - accuracy: 0.5067 - recall_81: 0.4899 - precision_81: 0.2042\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7300 - accuracy: 0.5175 - recall_81: 0.4803 - precision_81: 0.2045\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7280 - accuracy: 0.5170 - recall_81: 0.4733 - precision_81: 0.2044\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7223 - accuracy: 0.5208 - recall_81: 0.4718 - precision_81: 0.2031\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7216 - accuracy: 0.5239 - recall_81: 0.4651 - precision_81: 0.2052\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7144 - accuracy: 0.5289 - recall_81: 0.4576 - precision_81: 0.2031\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7131 - accuracy: 0.5278 - recall_81: 0.4476 - precision_81: 0.2005\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.5429 - recall_81: 0.4565 - precision_81: 0.2120\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.5398 - recall_81: 0.4446 - precision_81: 0.2075\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7019 - accuracy: 0.5440 - recall_81: 0.4466 - precision_81: 0.2075\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.5481 - recall_81: 0.4477 - precision_81: 0.2114\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5510 - recall_81: 0.4360 - precision_81: 0.2094\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5527 - recall_81: 0.4262 - precision_81: 0.2081\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.5603 - recall_81: 0.4341 - precision_81: 0.2162\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.5617 - recall_81: 0.4142 - precision_81: 0.2074\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.5661 - recall_81: 0.4237 - precision_81: 0.2134\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.5711 - recall_81: 0.4133 - precision_81: 0.2136\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6745 - accuracy: 0.5737 - recall_81: 0.4115 - precision_81: 0.2121\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.5820 - recall_81: 0.4179 - precision_81: 0.2219\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6643 - accuracy: 0.5886 - recall_81: 0.4109 - precision_81: 0.2188\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.5848 - recall_81: 0.4057 - precision_81: 0.2198\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.5896 - recall_81: 0.3924 - precision_81: 0.2191\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6566 - accuracy: 0.5964 - recall_81: 0.3982 - precision_81: 0.2249\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.5959 - recall_81: 0.3842 - precision_81: 0.2187\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6080 - recall_81: 0.3863 - precision_81: 0.2233\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6039 - recall_81: 0.3806 - precision_81: 0.2207\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6122 - recall_81: 0.3792 - precision_81: 0.2265\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6176 - recall_81: 0.3769 - precision_81: 0.2295\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.6163 - recall_81: 0.3692 - precision_81: 0.2296\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.6200 - recall_81: 0.3678 - precision_81: 0.2314\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6278 - recall_81: 0.3636 - precision_81: 0.2336\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.6315 - recall_81: 0.3646 - precision_81: 0.2367\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.6347 - recall_81: 0.3546 - precision_81: 0.2390\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6291 - accuracy: 0.6373 - recall_81: 0.3573 - precision_81: 0.2424\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6407 - recall_81: 0.3510 - precision_81: 0.2428\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.6432 - recall_81: 0.3398 - precision_81: 0.2340\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6498 - recall_81: 0.3297 - precision_81: 0.2347\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.6495 - recall_81: 0.3309 - precision_81: 0.2333\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.6588 - recall_81: 0.3310 - precision_81: 0.2400\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6558 - recall_81: 0.3215 - precision_81: 0.2348\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6099 - accuracy: 0.6649 - recall_81: 0.3161 - precision_81: 0.2490\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6683 - recall_81: 0.3083 - precision_81: 0.2432\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6081 - accuracy: 0.6687 - recall_81: 0.3163 - precision_81: 0.2498\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.6713 - recall_81: 0.3113 - precision_81: 0.2531\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.6749 - recall_81: 0.2977 - precision_81: 0.2478\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.6781 - recall_81: 0.3079 - precision_81: 0.2567\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6008 - accuracy: 0.6805 - recall_81: 0.2945 - precision_81: 0.2486\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6826 - recall_81: 0.2991 - precision_81: 0.2624\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5974 - accuracy: 0.6868 - recall_81: 0.2963 - precision_81: 0.2642\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.6947 - recall_81: 0.2952 - precision_81: 0.2672\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.6952 - recall_81: 0.2833 - precision_81: 0.2564\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.6962 - recall_81: 0.2865 - precision_81: 0.2658\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.6948 - recall_81: 0.2811 - precision_81: 0.2632\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.6985 - recall_81: 0.2797 - precision_81: 0.2722\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.7049 - recall_81: 0.2692 - precision_81: 0.2722\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7076 - recall_81: 0.2780 - precision_81: 0.2742\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.7119 - recall_81: 0.2702 - precision_81: 0.2742\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.7108 - recall_81: 0.2712 - precision_81: 0.2852\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.7107 - recall_81: 0.2552 - precision_81: 0.2760\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7177 - recall_81: 0.2485 - precision_81: 0.2770\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5720 - accuracy: 0.7234 - recall_81: 0.2462 - precision_81: 0.2823\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7222 - recall_81: 0.2387 - precision_81: 0.2805\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7242 - recall_81: 0.2394 - precision_81: 0.2866\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7233 - recall_81: 0.2232 - precision_81: 0.2732\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7343 - recall_81: 0.2369 - precision_81: 0.2982\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.7385 - recall_81: 0.2356 - precision_81: 0.3049\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7308 - recall_81: 0.2185 - precision_81: 0.2866\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7369 - recall_81: 0.2266 - precision_81: 0.3002\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7364 - recall_81: 0.2257 - precision_81: 0.3039\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7386 - recall_81: 0.2210 - precision_81: 0.3008\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.7416 - recall_81: 0.2223 - precision_81: 0.3060\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7446 - recall_81: 0.2210 - precision_81: 0.3066\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7456 - recall_81: 0.2241 - precision_81: 0.3182\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7469 - recall_81: 0.2155 - precision_81: 0.3231\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.7473 - recall_81: 0.2091 - precision_81: 0.3140\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5492 - accuracy: 0.7526 - recall_81: 0.2157 - precision_81: 0.3273\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7531 - recall_81: 0.2178 - precision_81: 0.3401\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7522 - recall_81: 0.2146 - precision_81: 0.3313\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7513 - recall_81: 0.2082 - precision_81: 0.3302\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.7544 - recall_81: 0.2053 - precision_81: 0.3390\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7587 - recall_81: 0.2080 - precision_81: 0.3431\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7555 - recall_81: 0.1921 - precision_81: 0.3334\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7612 - recall_81: 0.1878 - precision_81: 0.3256\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7648 - recall_81: 0.1987 - precision_81: 0.3530\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7658 - recall_81: 0.1926 - precision_81: 0.3438\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7635 - recall_81: 0.2015 - precision_81: 0.3551\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7641 - recall_81: 0.1789 - precision_81: 0.3404\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7597 - recall_81: 0.1815 - precision_81: 0.3396\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5344 - accuracy: 0.7641 - recall_81: 0.1813 - precision_81: 0.3408\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7649 - recall_81: 0.1886 - precision_81: 0.3555\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5308 - accuracy: 0.7678 - recall_81: 0.1854 - precision_81: 0.3629\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7672 - recall_81: 0.1753 - precision_81: 0.3488\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7683 - recall_81: 0.1669 - precision_81: 0.3419\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.7730 - recall_81: 0.1761 - precision_81: 0.3572\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7688 - recall_81: 0.1703 - precision_81: 0.3593\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7674 - recall_81: 0.1644 - precision_81: 0.3471\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7709 - recall_81: 0.1687 - precision_81: 0.3665\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7731 - recall_81: 0.1618 - precision_81: 0.3657\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D658032310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5277 - accuracy: 0.7685 - recall_81: 0.1607 - precision_81: 0.3470\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7005 - accuracy: 0.4209 - recall_82: 0.4002 - precision_82: 0.1489\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6983 - accuracy: 0.4366 - recall_82: 0.3805 - precision_82: 0.1527\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6966 - accuracy: 0.4434 - recall_82: 0.3419 - precision_82: 0.1381\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.4588 - recall_82: 0.3378 - precision_82: 0.1459\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.4786 - recall_82: 0.2979 - precision_82: 0.1349\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.4976 - recall_82: 0.2913 - precision_82: 0.1379\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.5173 - recall_82: 0.2638 - precision_82: 0.1386\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5343 - recall_82: 0.2460 - precision_82: 0.1346\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.5551 - recall_82: 0.2320 - precision_82: 0.1407\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.5688 - recall_82: 0.2133 - precision_82: 0.1388\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6814 - accuracy: 0.5937 - recall_82: 0.2028 - precision_82: 0.1437\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.6155 - recall_82: 0.1767 - precision_82: 0.1404\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.6323 - recall_82: 0.1594 - precision_82: 0.1392\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.6465 - recall_82: 0.1438 - precision_82: 0.1384\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6744 - accuracy: 0.6627 - recall_82: 0.1344 - precision_82: 0.1437\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.6775 - recall_82: 0.1240 - precision_82: 0.1450\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6706 - accuracy: 0.6886 - recall_82: 0.1061 - precision_82: 0.1435\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.7019 - recall_82: 0.0996 - precision_82: 0.1496\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.7161 - recall_82: 0.0961 - precision_82: 0.1655\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.7333 - recall_82: 0.0697 - precision_82: 0.1402\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.7412 - recall_82: 0.0594 - precision_82: 0.1430\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6621 - accuracy: 0.7489 - recall_82: 0.0497 - precision_82: 0.1449\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.7532 - recall_82: 0.0429 - precision_82: 0.1453\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.7652 - recall_82: 0.0345 - precision_82: 0.1417\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.7666 - recall_82: 0.0339 - precision_82: 0.1637\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.7774 - recall_82: 0.0273 - precision_82: 0.1763\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.7799 - recall_82: 0.0223 - precision_82: 0.1708\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6522 - accuracy: 0.7890 - recall_82: 0.0227 - precision_82: 0.2457\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.7897 - recall_82: 0.0142 - precision_82: 0.1982\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.7919 - recall_82: 0.0123 - precision_82: 0.2396\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.7903 - recall_82: 0.0095 - precision_82: 0.2667\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.7942 - recall_82: 0.0065 - precision_82: 0.3750\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.7936 - recall_82: 0.0020 - precision_82: 0.1516\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.7961 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.7987 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.7984 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7980 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.7962 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.7986 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.8012 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6352 - accuracy: 0.7946 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.7973 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.7982 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6311 - accuracy: 0.7976 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6297 - accuracy: 0.7967 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.7978 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6251 - accuracy: 0.8020 - recall_82: 0.0000e+00 - precision_82: 0.0000e+0 - 0s 3ms/step - loss: 0.6264 - accuracy: 0.7985 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6252 - accuracy: 0.7992 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7975 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.8006 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.7968 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.7987 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7985 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.7977 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.8004 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.7990 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.8002 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7974 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.7964 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.7988 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.7985 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6095 - accuracy: 0.7977 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6089 - accuracy: 0.7977 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6069 - accuracy: 0.7996 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.7971 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.7946 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.7986 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6038 - accuracy: 0.7970 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.7917 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.7994 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.7989 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6003 - accuracy: 0.7957 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.7975 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.7959 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.7990 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.8026 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.8006 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7985 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5943 - accuracy: 0.7952 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.7995 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5903 - accuracy: 0.8002 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.7952 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.7947 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5897 - accuracy: 0.7954 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5874 - accuracy: 0.7988 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.8002 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.7979 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5847 - accuracy: 0.7990 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.7986 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.7977 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.7980 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7970 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.7946 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7951 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.7979 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7990 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.7971 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7964 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7938 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.7949 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65CA28670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5755 - accuracy: 0.7973 - recall_82: 0.0000e+00 - precision_82: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7473 - accuracy: 0.5137 - recall_83: 0.5752 - precision_83: 0.2246\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7356 - accuracy: 0.5213 - recall_83: 0.5660 - precision_83: 0.2297\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7244 - accuracy: 0.5303 - recall_83: 0.5564 - precision_83: 0.2299\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7189 - accuracy: 0.5323 - recall_83: 0.5468 - precision_83: 0.2302\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7107 - accuracy: 0.5421 - recall_83: 0.5351 - precision_83: 0.2275\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.5462 - recall_83: 0.5395 - precision_83: 0.2330\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6957 - accuracy: 0.5533 - recall_83: 0.5312 - precision_83: 0.2332\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.5680 - recall_83: 0.5280 - precision_83: 0.2429\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.5729 - recall_83: 0.5153 - precision_83: 0.2397\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.5792 - recall_83: 0.5105 - precision_83: 0.2438\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.5929 - recall_83: 0.5038 - precision_83: 0.2510\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.5944 - recall_83: 0.4956 - precision_83: 0.2485\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6031 - recall_83: 0.4877 - precision_83: 0.2514\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6111 - recall_83: 0.4852 - precision_83: 0.2589\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6176 - recall_83: 0.4791 - precision_83: 0.2561\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6203 - recall_83: 0.4618 - precision_83: 0.2560\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.6238 - recall_83: 0.4510 - precision_83: 0.2579\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6343 - recall_83: 0.4431 - precision_83: 0.2632\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6155 - accuracy: 0.6368 - recall_83: 0.4389 - precision_83: 0.2574\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.6451 - recall_83: 0.4307 - precision_83: 0.2681\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6484 - recall_83: 0.4211 - precision_83: 0.2693\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6013 - accuracy: 0.6562 - recall_83: 0.4177 - precision_83: 0.2712\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5979 - accuracy: 0.6623 - recall_83: 0.4062 - precision_83: 0.2747\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5915 - accuracy: 0.6713 - recall_83: 0.3995 - precision_83: 0.2777\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.6769 - recall_83: 0.3945 - precision_83: 0.2865\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5803 - accuracy: 0.6880 - recall_83: 0.3951 - precision_83: 0.2975\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.6881 - recall_83: 0.3803 - precision_83: 0.2962\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.6868 - recall_83: 0.3605 - precision_83: 0.2829\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.6965 - recall_83: 0.3585 - precision_83: 0.2919\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7025 - recall_83: 0.3549 - precision_83: 0.3012\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.7040 - recall_83: 0.3420 - precision_83: 0.3033\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7149 - recall_83: 0.3401 - precision_83: 0.3099\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7089 - recall_83: 0.3248 - precision_83: 0.2998\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.7124 - recall_83: 0.3174 - precision_83: 0.3037\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7241 - recall_83: 0.3228 - precision_83: 0.3102\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5470 - accuracy: 0.7269 - recall_83: 0.3080 - precision_83: 0.3171\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7338 - recall_83: 0.3183 - precision_83: 0.3310\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7365 - recall_83: 0.3121 - precision_83: 0.3348\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7326 - recall_83: 0.3046 - precision_83: 0.3288\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7363 - recall_83: 0.2895 - precision_83: 0.3280\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7377 - recall_83: 0.2798 - precision_83: 0.3267\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7404 - recall_83: 0.2788 - precision_83: 0.3308\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.7485 - recall_83: 0.2811 - precision_83: 0.3477\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7506 - recall_83: 0.2756 - precision_83: 0.3507\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7503 - recall_83: 0.2637 - precision_83: 0.3564\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7460 - recall_83: 0.2427 - precision_83: 0.3350\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7497 - recall_83: 0.2368 - precision_83: 0.3372\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7531 - recall_83: 0.2364 - precision_83: 0.3408\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7561 - recall_83: 0.2280 - precision_83: 0.3393\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7546 - recall_83: 0.2353 - precision_83: 0.3555\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7636 - recall_83: 0.2293 - precision_83: 0.3657\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7639 - recall_83: 0.2340 - precision_83: 0.3691\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7589 - recall_83: 0.2263 - precision_83: 0.3609\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7649 - recall_83: 0.2200 - precision_83: 0.3577\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7661 - recall_83: 0.2223 - precision_83: 0.3707\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7647 - recall_83: 0.2158 - precision_83: 0.3671\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7685 - recall_83: 0.2119 - precision_83: 0.3737\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7687 - recall_83: 0.2186 - precision_83: 0.3798\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7685 - recall_83: 0.2100 - precision_83: 0.3759\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7702 - recall_83: 0.2097 - precision_83: 0.3947\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7720 - recall_83: 0.2048 - precision_83: 0.3804\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7741 - recall_83: 0.1990 - precision_83: 0.3841\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7712 - recall_83: 0.1954 - precision_83: 0.3802\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7720 - recall_83: 0.1958 - precision_83: 0.3857\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7726 - recall_83: 0.1962 - precision_83: 0.3921\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7769 - recall_83: 0.1970 - precision_83: 0.4071\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7771 - recall_83: 0.2010 - precision_83: 0.3961\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7802 - recall_83: 0.1862 - precision_83: 0.3911\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7824 - recall_83: 0.1920 - precision_83: 0.4091\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7804 - recall_83: 0.1904 - precision_83: 0.4077\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7796 - recall_83: 0.1843 - precision_83: 0.4084\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7800 - recall_83: 0.1816 - precision_83: 0.4205\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7832 - recall_83: 0.1844 - precision_83: 0.4302\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7845 - recall_83: 0.1746 - precision_83: 0.4191\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7842 - recall_83: 0.1787 - precision_83: 0.4256\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7872 - recall_83: 0.1787 - precision_83: 0.4384\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7885 - recall_83: 0.1799 - precision_83: 0.4441\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7922 - recall_83: 0.1759 - precision_83: 0.4498\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7865 - recall_83: 0.1664 - precision_83: 0.4364\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7892 - recall_83: 0.1674 - precision_83: 0.4512\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7882 - recall_83: 0.1723 - precision_83: 0.4694\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7937 - recall_83: 0.1748 - precision_83: 0.4630\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7890 - recall_83: 0.1659 - precision_83: 0.4661\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7931 - recall_83: 0.1704 - precision_83: 0.4641\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7913 - recall_83: 0.1593 - precision_83: 0.4432\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7933 - recall_83: 0.1676 - precision_83: 0.4805\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4784 - accuracy: 0.7935 - recall_83: 0.1761 - precision_83: 0.4853\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7922 - recall_83: 0.1628 - precision_83: 0.4582\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7938 - recall_83: 0.1634 - precision_83: 0.4722\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7943 - recall_83: 0.1620 - precision_83: 0.4807\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7945 - recall_83: 0.1635 - precision_83: 0.4712\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7967 - recall_83: 0.1670 - precision_83: 0.4804\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7955 - recall_83: 0.1723 - precision_83: 0.4961\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7911 - recall_83: 0.1576 - precision_83: 0.4856\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.7920 - recall_83: 0.1604 - precision_83: 0.4965\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7974 - recall_83: 0.1583 - precision_83: 0.4871\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7959 - recall_83: 0.1584 - precision_83: 0.4893\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7944 - recall_83: 0.1436 - precision_83: 0.4607\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7965 - recall_83: 0.1552 - precision_83: 0.4827\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7942 - recall_83: 0.1487 - precision_83: 0.4929\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657C9E790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.8003 - recall_83: 0.1525 - precision_83: 0.5217\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6966 - accuracy: 0.4600 - recall_84: 0.4074 - precision_84: 0.1659\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6948 - accuracy: 0.4829 - recall_84: 0.3737 - precision_84: 0.1678\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.5106 - recall_84: 0.3249 - precision_84: 0.1555\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6915 - accuracy: 0.5338 - recall_84: 0.2834 - precision_84: 0.1518\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5588 - recall_84: 0.2534 - precision_84: 0.1489\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5745 - recall_84: 0.2150 - precision_84: 0.1422\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5997 - recall_84: 0.1909 - precision_84: 0.1431\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.6251 - recall_84: 0.1753 - precision_84: 0.1496\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6830 - accuracy: 0.6471 - recall_84: 0.1506 - precision_84: 0.1433\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.6665 - recall_84: 0.1327 - precision_84: 0.1415\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.6810 - recall_84: 0.1078 - precision_84: 0.1318\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.7000 - recall_84: 0.0919 - precision_84: 0.1375\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.7180 - recall_84: 0.0869 - precision_84: 0.1548\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.7317 - recall_84: 0.0700 - precision_84: 0.1524\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.7428 - recall_84: 0.0564 - precision_84: 0.1484\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6723 - accuracy: 0.7570 - recall_84: 0.0489 - precision_84: 0.1651\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.7675 - recall_84: 0.0297 - precision_84: 0.1369\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.7772 - recall_84: 0.0226 - precision_84: 0.1436\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.7792 - recall_84: 0.0167 - precision_84: 0.1441\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.7864 - recall_84: 0.0150 - precision_84: 0.1721\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.7894 - recall_84: 0.0086 - precision_84: 0.1751\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.7925 - recall_84: 0.0073 - precision_84: 0.1922\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.7941 - recall_84: 0.0037 - precision_84: 0.1900\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.7962 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.7988 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6575 - accuracy: 0.8003 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.7949 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6547 - accuracy: 0.8011 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.7986 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.7979 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.7941 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.7963 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.7971 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.7995 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.8019 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.7952 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.7978 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.7969 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.7931 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7967 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.7940 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.7954 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.7948 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6355 - accuracy: 0.7971 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.7948 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6333 - accuracy: 0.7969 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.7943 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.7994 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.7952 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.8000 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.7964 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.7981 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.7999 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.7938 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.7939 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.7981 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.7975 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.7981 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.7973 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6187 - accuracy: 0.7964 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.7987 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6175 - accuracy: 0.7948 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.7950 - recall_84: 0.0000e+00 - precision_84: 0.0000e+0 - 0s 4ms/step - loss: 0.6158 - accuracy: 0.7969 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6153 - accuracy: 0.7948 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.7994 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6133 - accuracy: 0.7958 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.7996 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.7986 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.7996 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.7989 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.7943 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.7953 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6058 - accuracy: 0.7993 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.7989 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6043 - accuracy: 0.7988 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.7959 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.7964 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.7955 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7977 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.7958 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.7976 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.7946 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.7979 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5968 - accuracy: 0.7989 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7996 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7978 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.7969 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5940 - accuracy: 0.7985 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.7959 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.8005 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.7975 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.7946 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5903 - accuracy: 0.7979 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7971 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.7971 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.7976 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.7984 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.7955 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.7991 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5865 - accuracy: 0.7953 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5CD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5846 - accuracy: 0.7973 - recall_84: 0.0000e+00 - precision_84: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5544 - accuracy: 0.7934 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5522 - accuracy: 0.7960 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7980 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.7985 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.8034 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7949 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5485 - accuracy: 0.7974 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5466 - accuracy: 0.7994 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7967 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.7939 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7969 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7975 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7964 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.7966 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.8002 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7956 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5457 - accuracy: 0.7943 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5423 - accuracy: 0.7984 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7975 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7985 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.8010 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7959 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5397 - accuracy: 0.7989 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.8000 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.7992 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7972 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5365 - accuracy: 0.8009 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7973 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7989 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7982 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7940 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.7964 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7998 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7978 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7969 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7972 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5352 - accuracy: 0.7973 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.8000 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7963 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7992 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7984 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7976 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7982 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7979 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.7998 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.7966 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7970 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7992 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.7972 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7979 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7963 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7949 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7964 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7964 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7964 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7976 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7978 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7953 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7997 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7986 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.8000 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7973 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7962 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.8021 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.8012 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7950 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.8013 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7950 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5254 - accuracy: 0.7975 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7961 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7980 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5259 - accuracy: 0.7960 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7941 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7995 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7992 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7982 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7999 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7978 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7987 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5133 - accuracy: 0.8080 - recall_85: 0.0000e+00 - precision_85: 0.0000e+0 - 0s 4ms/step - loss: 0.5204 - accuracy: 0.8002 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7991 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7974 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.7967 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5204 - accuracy: 0.7992 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.8021 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7959 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7980 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7952 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7962 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7978 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7987 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7995 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7969 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7972 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7955 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7992 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7995 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5197 - accuracy: 0.7971 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.7982 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.7984 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580A50D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7973 - recall_85: 0.0000e+00 - precision_85: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5387 - accuracy: 0.7960 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7997 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7966 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7976 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7946 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7987 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7977 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7980 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.8002 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7985 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7957 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5386 - accuracy: 0.7920 - recall_86: 0.0000e+00 - precision_86: 0.0000e+0 - 0s 5ms/step - loss: 0.5355 - accuracy: 0.7959 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7978 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7967 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7975 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7965 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7983 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5324 - accuracy: 0.7978 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7958 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7962 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7930 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7967 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5333 - accuracy: 0.7950 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7944 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7973 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7975 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7995 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7969 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7974 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7965 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7976 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7955 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7990 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7965 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7962 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7974 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7989 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7941 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.8012 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7967 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7983 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7975 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.7992 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7983 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.7967 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7958 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7969 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7988 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7960 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7947 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7920 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7941 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7985 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7956 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7983 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7987 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7972 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7954 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.8010 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7977 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7975 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.8005 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7958 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7963 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.7885 - recall_86: 0.0000e+00 - precision_86: 0.0000e+0 - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7952 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7977 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7975 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7993 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7971 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7960 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.8009 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5200 - accuracy: 0.7990 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7977 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7959 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7978 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.7973 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5204 - accuracy: 0.7977 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5207 - accuracy: 0.7972 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7967 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7997 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7963 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7965 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7952 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5197 - accuracy: 0.7973 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7957 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.7966 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7978 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7955 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.7957 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.7982 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7980 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7999 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7982 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7970 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7999 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.8000 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7978 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7974 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5200 - accuracy: 0.7950 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7983 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D658391670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5172 - accuracy: 0.7977 - recall_86: 0.0000e+00 - precision_86: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.6156 - recall_87: 0.4877 - precision_87: 0.2633\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.8003 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.7993 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.7959 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.7991 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.7982 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6758 - accuracy: 0.7984 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.7961 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.7933 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.7962 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.7999 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.7969 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.7943 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.7976 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.7948 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6532 - accuracy: 0.8004 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.7953 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.8007 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.7966 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.7961 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.7967 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.7946 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6380 - accuracy: 0.7998 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.7956 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.7991 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.7998 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.7966 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.7961 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6269 - accuracy: 0.7968 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.7986 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.7951 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.7969 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.7977 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6177 - accuracy: 0.7981 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.7948 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.7963 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6129 - accuracy: 0.7972 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.7966 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.7978 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6041 - accuracy: 0.8105 - recall_87: 0.0000e+00 - precision_87: 0.0000e+0 - 0s 4ms/step - loss: 0.6073 - accuracy: 0.8001 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.7976 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.7974 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6043 - accuracy: 0.7953 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6017 - accuracy: 0.7986 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6012 - accuracy: 0.7960 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5992 - accuracy: 0.7974 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5978 - accuracy: 0.7976 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.7989 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.7961 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7966 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.7958 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7980 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5900 - accuracy: 0.7974 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.7952 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.7988 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7982 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7976 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.7962 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5836 - accuracy: 0.7957 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.8006 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5840 - accuracy: 0.7905 - recall_87: 0.0000e+00 - precision_87: 0.0000e+0 - 0s 4ms/step - loss: 0.5818 - accuracy: 0.7948 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5800 - accuracy: 0.7964 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7969 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7981 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7973 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7943 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7981 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5753 - accuracy: 0.7933 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5738 - accuracy: 0.7943 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5703 - accuracy: 0.7991 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5708 - accuracy: 0.7964 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7993 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7937 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.7964 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7969 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.7969 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7975 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5644 - accuracy: 0.7968 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5635 - accuracy: 0.7967 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7968 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.7971 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.7966 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7951 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.7988 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.8009 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.7986 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7967 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.7962 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.8014 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7996 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7980 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5511 - accuracy: 0.8008 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.7978 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7992 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7983 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.7947 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5489 - accuracy: 0.7989 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7968 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7976 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7971 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657C9E430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5477 - accuracy: 0.7973 - recall_87: 0.0000e+00 - precision_87: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.0655 - accuracy: 0.2051 - recall_88: 1.0000 - precision_88: 0.2051\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0439 - accuracy: 0.2032 - recall_88: 1.0000 - precision_88: 0.2032\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0233 - accuracy: 0.2008 - recall_88: 1.0000 - precision_88: 0.2008\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0021 - accuracy: 0.2005 - recall_88: 1.0000 - precision_88: 0.2005\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9781 - accuracy: 0.2048 - recall_88: 1.0000 - precision_88: 0.2048\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9610 - accuracy: 0.2010 - recall_88: 1.0000 - precision_88: 0.2010\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9425 - accuracy: 0.2006 - recall_88: 1.0000 - precision_88: 0.2006\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9220 - accuracy: 0.2045 - recall_88: 1.0000 - precision_88: 0.2045\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9062 - accuracy: 0.2017 - recall_88: 1.0000 - precision_88: 0.2017\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8876 - accuracy: 0.2049 - recall_88: 1.0000 - precision_88: 0.2049\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8713 - accuracy: 0.2056 - recall_88: 1.0000 - precision_88: 0.2056\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8568 - accuracy: 0.2043 - recall_88: 1.0000 - precision_88: 0.2043\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8432 - accuracy: 0.2018 - recall_88: 1.0000 - precision_88: 0.2018\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8284 - accuracy: 0.2034 - recall_88: 1.0000 - precision_88: 0.2034\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8144 - accuracy: 0.2053 - recall_88: 1.0000 - precision_88: 0.2053\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8032 - accuracy: 0.2003 - recall_88: 1.0000 - precision_88: 0.2003\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7904 - accuracy: 0.2015 - recall_88: 1.0000 - precision_88: 0.2015\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7794 - accuracy: 0.1992 - recall_88: 1.0000 - precision_88: 0.1992\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7671 - accuracy: 0.2041 - recall_88: 1.0000 - precision_88: 0.2041\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7568 - accuracy: 0.2021 - recall_88: 1.0000 - precision_88: 0.2021\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7466 - accuracy: 0.2016 - recall_88: 1.0000 - precision_88: 0.2016\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7364 - accuracy: 0.2040 - recall_88: 1.0000 - precision_88: 0.2040\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7272 - accuracy: 0.2026 - recall_88: 1.0000 - precision_88: 0.2026\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7184 - accuracy: 0.2000 - recall_88: 1.0000 - precision_88: 0.2000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7097 - accuracy: 0.2022 - recall_88: 1.0000 - precision_88: 0.2020\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7015 - accuracy: 0.2514 - recall_88: 0.9722 - precision_88: 0.2081\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.4806 - recall_88: 0.7904 - precision_88: 0.2516\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6860 - accuracy: 0.7346 - recall_88: 0.3180 - precision_88: 0.3311\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.7975 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.7969 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.7978 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.7961 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.7965 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.7966 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.7996 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.7967 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.7948 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.7932 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.8009 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.7980 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6117 - accuracy: 0.7999 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.7975 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.7992 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.7955 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.7994 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.7987 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.7990 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5853 - accuracy: 0.8013 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7982 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7988 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.7963 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.7975 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.8017 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.7957 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.7992 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7980 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7974 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7995 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.8002 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7961 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7932 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7955 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.7957 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7967 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7987 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7969 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.8009 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7956 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7984 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7965 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7955 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7980 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7976 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7995 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7942 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7967 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7989 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7955 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7964 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7989 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7972 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7961 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5275 - accuracy: 0.7967 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7987 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7962 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7988 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7991 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7947 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7968 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7960 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7992 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.8003 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7981 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7964 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7992 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7961 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7988 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7981 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5180 - accuracy: 0.7960 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7970 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D658032550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5156 - accuracy: 0.7973 - recall_88: 0.0000e+00 - precision_88: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.1409 - accuracy: 0.2037 - recall_89: 1.0000 - precision_89: 0.2037\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.1116 - accuracy: 0.2027 - recall_89: 1.0000 - precision_89: 0.2027\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0816 - accuracy: 0.2035 - recall_89: 1.0000 - precision_89: 0.2035\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0536 - accuracy: 0.2039 - recall_89: 1.0000 - precision_89: 0.2039\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0303 - accuracy: 0.2003 - recall_89: 1.0000 - precision_89: 0.2003\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0005 - accuracy: 0.2059 - recall_89: 1.0000 - precision_89: 0.2059\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9796 - accuracy: 0.2016 - recall_89: 1.0000 - precision_89: 0.2016\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9557 - accuracy: 0.2025 - recall_89: 1.0000 - precision_89: 0.2025\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9350 - accuracy: 0.2007 - recall_89: 1.0000 - precision_89: 0.2007\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9130 - accuracy: 0.2026 - recall_89: 1.0000 - precision_89: 0.2026\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8944 - accuracy: 0.2005 - recall_89: 1.0000 - precision_89: 0.2005\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8736 - accuracy: 0.2042 - recall_89: 1.0000 - precision_89: 0.2042\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8545 - accuracy: 0.2063 - recall_89: 1.0000 - precision_89: 0.2063\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8387 - accuracy: 0.2036 - recall_89: 1.0000 - precision_89: 0.2036\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8234 - accuracy: 0.2017 - recall_89: 1.0000 - precision_89: 0.2017\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8079 - accuracy: 0.2024 - recall_89: 1.0000 - precision_89: 0.2024\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7934 - accuracy: 0.2020 - recall_89: 1.0000 - precision_89: 0.2020\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7801 - accuracy: 0.2002 - recall_89: 1.0000 - precision_89: 0.2002\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7667 - accuracy: 0.2020 - recall_89: 1.0000 - precision_89: 0.2020\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7540 - accuracy: 0.2030 - recall_89: 1.0000 - precision_89: 0.2030\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.2020 - recall_89: 1.0000 - precision_89: 0.2020\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7312 - accuracy: 0.2017 - recall_89: 1.0000 - precision_89: 0.2017\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7206 - accuracy: 0.2010 - recall_89: 1.0000 - precision_89: 0.2010\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7101 - accuracy: 0.2058 - recall_89: 1.0000 - precision_89: 0.2058\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7006 - accuracy: 0.2052 - recall_89: 0.9703 - precision_89: 0.1982\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6916 - accuracy: 0.6063 - recall_89: 0.1327 - precision_89: 0.1054\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6830 - accuracy: 0.7953 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.7967 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.7994 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.7943 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.8003 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.7938 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.7981 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.7965 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.7993 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.7978 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.7947 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.7987 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.8020 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.7976 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7950 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7989 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.7990 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7979 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7987 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5793 - accuracy: 0.7982 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.7955 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7971 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5710 - accuracy: 0.7965 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.7995 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5633 - accuracy: 0.8003 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5630 - accuracy: 0.7965 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.7954 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7998 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7976 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7974 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7993 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.7973 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7996 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7995 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7970 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.8006 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7988 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7975 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7973 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5374 - accuracy: 0.7967 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7973 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7940 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7978 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7972 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7967 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7979 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7957 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7990 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7965 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7925 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.7987 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7998 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7940 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7932 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7978 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.8008 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7942 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7992 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7978 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7968 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7983 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7974 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.8018 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7992 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7987 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7972 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7982 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7970 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7977 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.7962 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7958 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7970 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7982 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7951 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FBD5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7977 - recall_89: 0.0000e+00 - precision_89: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.7971 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7971 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7984 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7985 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7960 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7943 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7948 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7999 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7948 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7963 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7966 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7969 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7993 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7998 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7969 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7967 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7973 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.8011 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7946 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7977 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.8001 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7954 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7950 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7966 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7973 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.8018 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.8002 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7963 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5080 - accuracy: 0.7942 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7983 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7971 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7985 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7966 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.7980 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.8006 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7968 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7991 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7961 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7943 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7948 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7959 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7974 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7973 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7963 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7966 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7957 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7962 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7995 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7918 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7952 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.7996 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7965 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7964 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7966 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7966 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7939 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7933 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7961 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7969 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7974 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7978 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7976 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.7870 - recall_90: 0.0000e+00 - precision_90: 0.0000e+0 - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7946 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7984 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7979 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7960 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7976 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.7978 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5023 - accuracy: 0.7983 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7953 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7988 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7959 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7997 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7943 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7986 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7979 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.8006 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7979 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7996 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7971 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7976 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7981 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7993 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.8009 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7949 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7963 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7969 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7995 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7957 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7974 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7984 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7978 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5010 - accuracy: 0.7993 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7968 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.8008 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7924 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.8003 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7985 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7961 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7963 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A540D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5038 - accuracy: 0.7973 - recall_90: 0.0000e+00 - precision_90: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.7313 - accuracy: 0.5130 - recall_91: 0.4255 - precision_91: 0.1860\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7167 - accuracy: 0.5387 - recall_91: 0.4149 - precision_91: 0.1961\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7082 - accuracy: 0.5586 - recall_91: 0.4032 - precision_91: 0.2045\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.5698 - recall_91: 0.3713 - precision_91: 0.1999\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5875 - recall_91: 0.3453 - precision_91: 0.1981\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6768 - accuracy: 0.5993 - recall_91: 0.3247 - precision_91: 0.2010\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.6105 - recall_91: 0.3059 - precision_91: 0.1970\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.6232 - recall_91: 0.2986 - precision_91: 0.2014\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.6249 - recall_91: 0.2774 - precision_91: 0.1996\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6373 - recall_91: 0.2605 - precision_91: 0.1994\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6486 - recall_91: 0.2483 - precision_91: 0.2065\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6275 - accuracy: 0.6643 - recall_91: 0.2452 - precision_91: 0.2155\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6211 - accuracy: 0.6725 - recall_91: 0.2339 - precision_91: 0.2183\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6784 - recall_91: 0.2234 - precision_91: 0.2152\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6084 - accuracy: 0.6862 - recall_91: 0.2087 - precision_91: 0.2122\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.6990 - recall_91: 0.2062 - precision_91: 0.2254\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.7087 - recall_91: 0.1915 - precision_91: 0.2335\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.7157 - recall_91: 0.1786 - precision_91: 0.2358\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.7245 - recall_91: 0.1784 - precision_91: 0.2477\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.7367 - recall_91: 0.1709 - precision_91: 0.2607\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.7403 - recall_91: 0.1605 - precision_91: 0.2636\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7491 - recall_91: 0.1493 - precision_91: 0.2786\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.7529 - recall_91: 0.1455 - precision_91: 0.2886\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7588 - recall_91: 0.1295 - precision_91: 0.2896\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7650 - recall_91: 0.1245 - precision_91: 0.3128\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7710 - recall_91: 0.1168 - precision_91: 0.3127\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7746 - recall_91: 0.0985 - precision_91: 0.3057\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7797 - recall_91: 0.0999 - precision_91: 0.3321\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.7822 - recall_91: 0.0980 - precision_91: 0.3706\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7850 - recall_91: 0.0824 - precision_91: 0.3581\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7844 - recall_91: 0.0789 - precision_91: 0.3714\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5369 - accuracy: 0.7871 - recall_91: 0.0737 - precision_91: 0.3842\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7931 - recall_91: 0.0773 - precision_91: 0.4212\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7952 - recall_91: 0.0727 - precision_91: 0.4179\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7948 - recall_91: 0.0695 - precision_91: 0.4186\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7963 - recall_91: 0.0651 - precision_91: 0.4160\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7893 - recall_91: 0.0654 - precision_91: 0.4548\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7956 - recall_91: 0.0634 - precision_91: 0.4595\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7980 - recall_91: 0.0638 - precision_91: 0.4791\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7953 - recall_91: 0.0611 - precision_91: 0.4950\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7961 - recall_91: 0.0555 - precision_91: 0.4668\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7995 - recall_91: 0.0584 - precision_91: 0.4746\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7981 - recall_91: 0.0563 - precision_91: 0.5052\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7969 - recall_91: 0.0554 - precision_91: 0.5185\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7982 - recall_91: 0.0544 - precision_91: 0.5303\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.7955 - recall_91: 0.0506 - precision_91: 0.5047\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.8005 - recall_91: 0.0529 - precision_91: 0.5383\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7956 - recall_91: 0.0504 - precision_91: 0.5104\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.8008 - recall_91: 0.0523 - precision_91: 0.5185\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7967 - recall_91: 0.0544 - precision_91: 0.5464\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7963 - recall_91: 0.0526 - precision_91: 0.5537\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7973 - recall_91: 0.0440 - precision_91: 0.5050\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4967 - accuracy: 0.7975 - recall_91: 0.0511 - precision_91: 0.5468\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7973 - recall_91: 0.0449 - precision_91: 0.5022\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7978 - recall_91: 0.0445 - precision_91: 0.5053\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7962 - recall_91: 0.0405 - precision_91: 0.5004\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7978 - recall_91: 0.0463 - precision_91: 0.5620\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7988 - recall_91: 0.0463 - precision_91: 0.5240\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.8012 - recall_91: 0.0473 - precision_91: 0.5486\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7989 - recall_91: 0.0507 - precision_91: 0.5561\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7977 - recall_91: 0.0466 - precision_91: 0.5436\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.8026 - recall_91: 0.0487 - precision_91: 0.5791\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.8022 - recall_91: 0.0472 - precision_91: 0.5627\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.8010 - recall_91: 0.0489 - precision_91: 0.5783\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7986 - recall_91: 0.0529 - precision_91: 0.6014\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.8011 - recall_91: 0.0502 - precision_91: 0.5935\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7980 - recall_91: 0.0490 - precision_91: 0.5872\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.8005 - recall_91: 0.0500 - precision_91: 0.5772\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.8002 - recall_91: 0.0471 - precision_91: 0.5801\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.8013 - recall_91: 0.0526 - precision_91: 0.6033\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.8016 - recall_91: 0.0479 - precision_91: 0.5947\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.8033 - recall_91: 0.0460 - precision_91: 0.5620\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.8002 - recall_91: 0.0474 - precision_91: 0.5847\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4772 - accuracy: 0.7981 - recall_91: 0.0532 - precision_91: 0.6062\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.8018 - recall_91: 0.0507 - precision_91: 0.6119\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.8025 - recall_91: 0.0516 - precision_91: 0.5942\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8037 - recall_91: 0.0565 - precision_91: 0.6298\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.8016 - recall_91: 0.0522 - precision_91: 0.5963\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.8063 - recall_91: 0.0535 - precision_91: 0.6051\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8013 - recall_91: 0.0576 - precision_91: 0.6394\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7995 - recall_91: 0.0529 - precision_91: 0.5889\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.8006 - recall_91: 0.0546 - precision_91: 0.6225\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.8000 - recall_91: 0.0568 - precision_91: 0.6455\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.8009 - recall_91: 0.0603 - precision_91: 0.6675\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.8000 - recall_91: 0.0532 - precision_91: 0.6523\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.8030 - recall_91: 0.0643 - precision_91: 0.6780\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.8041 - recall_91: 0.0638 - precision_91: 0.6471\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.8034 - recall_91: 0.0593 - precision_91: 0.6300\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.8016 - recall_91: 0.0621 - precision_91: 0.6316\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.8029 - recall_91: 0.0678 - precision_91: 0.6732\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.8033 - recall_91: 0.0723 - precision_91: 0.6788\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.8012 - recall_91: 0.0648 - precision_91: 0.6453\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.8050 - recall_91: 0.0609 - precision_91: 0.6196\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.8024 - recall_91: 0.0717 - precision_91: 0.6889\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.8064 - recall_91: 0.0650 - precision_91: 0.6822\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.8020 - recall_91: 0.0692 - precision_91: 0.6802\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.8038 - recall_91: 0.0668 - precision_91: 0.6611\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.8118 - recall_91: 0.0726 - precision_91: 0.6851\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.8029 - recall_91: 0.0705 - precision_91: 0.6626\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8075 - recall_91: 0.0743 - precision_91: 0.6746\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657F8D670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.8111 - recall_91: 0.1015 - precision_91: 0.7500\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7102 - accuracy: 0.5004 - recall_92: 0.5772 - precision_92: 0.2210\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6964 - accuracy: 0.5192 - recall_92: 0.5592 - precision_92: 0.2269\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.5394 - recall_92: 0.5505 - precision_92: 0.2326\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6688 - accuracy: 0.5556 - recall_92: 0.5070 - precision_92: 0.2276\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.5802 - recall_92: 0.4819 - precision_92: 0.2361\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.5999 - recall_92: 0.4616 - precision_92: 0.2421\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.6286 - recall_92: 0.4460 - precision_92: 0.2587\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.6515 - recall_92: 0.4120 - precision_92: 0.2637\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.6704 - recall_92: 0.3879 - precision_92: 0.2739\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.6901 - recall_92: 0.3616 - precision_92: 0.2871\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5974 - accuracy: 0.7059 - recall_92: 0.3488 - precision_92: 0.3041\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7202 - recall_92: 0.3299 - precision_92: 0.3187\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7331 - recall_92: 0.3024 - precision_92: 0.3245\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5749 - accuracy: 0.7453 - recall_92: 0.2835 - precision_92: 0.3404\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7594 - recall_92: 0.2724 - precision_92: 0.3672\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7661 - recall_92: 0.2552 - precision_92: 0.3870\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7691 - recall_92: 0.2415 - precision_92: 0.3971\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7791 - recall_92: 0.2328 - precision_92: 0.4113\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7846 - recall_92: 0.2204 - precision_92: 0.4344\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7882 - recall_92: 0.2098 - precision_92: 0.4560\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7884 - recall_92: 0.2031 - precision_92: 0.4733\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7956 - recall_92: 0.1961 - precision_92: 0.5006\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7966 - recall_92: 0.1822 - precision_92: 0.4981\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7984 - recall_92: 0.1673 - precision_92: 0.4991\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.8029 - recall_92: 0.1703 - precision_92: 0.5208\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.8014 - recall_92: 0.1651 - precision_92: 0.5416\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.8035 - recall_92: 0.1635 - precision_92: 0.5699\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.8075 - recall_92: 0.1514 - precision_92: 0.5734\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.8053 - recall_92: 0.1507 - precision_92: 0.6126\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.8036 - recall_92: 0.1326 - precision_92: 0.5978\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.8061 - recall_92: 0.1394 - precision_92: 0.6312\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.8066 - recall_92: 0.1355 - precision_92: 0.6484\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.8124 - recall_92: 0.1267 - precision_92: 0.6354\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.8087 - recall_92: 0.1280 - precision_92: 0.6708\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.8089 - recall_92: 0.1135 - precision_92: 0.6479\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.8127 - recall_92: 0.1230 - precision_92: 0.6821\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8109 - recall_92: 0.1174 - precision_92: 0.6940\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.8103 - recall_92: 0.1156 - precision_92: 0.7084\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.8101 - recall_92: 0.1097 - precision_92: 0.6908\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.8078 - recall_92: 0.1070 - precision_92: 0.6974\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.8114 - recall_92: 0.1091 - precision_92: 0.6892\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.8093 - recall_92: 0.1116 - precision_92: 0.7090\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.8104 - recall_92: 0.1106 - precision_92: 0.7245\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.8096 - recall_92: 0.1053 - precision_92: 0.7283\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.8131 - recall_92: 0.1050 - precision_92: 0.7512\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.8150 - recall_92: 0.1108 - precision_92: 0.7281\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.8079 - recall_92: 0.1068 - precision_92: 0.7282\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.8096 - recall_92: 0.1013 - precision_92: 0.7258\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8104 - recall_92: 0.0990 - precision_92: 0.7407\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8118 - recall_92: 0.0950 - precision_92: 0.7354\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.8069 - recall_92: 0.0935 - precision_92: 0.7283\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.8087 - recall_92: 0.0953 - precision_92: 0.7530\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.8139 - recall_92: 0.0960 - precision_92: 0.7408\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.8074 - recall_92: 0.0980 - precision_92: 0.7388\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.8120 - recall_92: 0.0969 - precision_92: 0.7425\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.8105 - recall_92: 0.0978 - precision_92: 0.7286\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8093 - recall_92: 0.0935 - precision_92: 0.7188\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.8104 - recall_92: 0.0954 - precision_92: 0.7403\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.8119 - recall_92: 0.1012 - precision_92: 0.7497\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.8069 - recall_92: 0.0950 - precision_92: 0.7430\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.8128 - recall_92: 0.1032 - precision_92: 0.7629\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.8064 - recall_92: 0.0950 - precision_92: 0.7297\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.8103 - recall_92: 0.1003 - precision_92: 0.7376\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.8082 - recall_92: 0.0967 - precision_92: 0.7647\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.8113 - recall_92: 0.0925 - precision_92: 0.7412\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.8132 - recall_92: 0.1031 - precision_92: 0.7770\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.8158 - recall_92: 0.1029 - precision_92: 0.7882\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.8106 - recall_92: 0.1016 - precision_92: 0.7619\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.8128 - recall_92: 0.1048 - precision_92: 0.7589\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8161 - recall_92: 0.1066 - precision_92: 0.7763\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.8104 - recall_92: 0.1043 - precision_92: 0.7544\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.8124 - recall_92: 0.1030 - precision_92: 0.7569\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.8097 - recall_92: 0.1043 - precision_92: 0.7265\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.8126 - recall_92: 0.1053 - precision_92: 0.7609\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.8075 - recall_92: 0.1062 - precision_92: 0.7840\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.8090 - recall_92: 0.1101 - precision_92: 0.7607\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8137 - recall_92: 0.1082 - precision_92: 0.7681\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.8122 - recall_92: 0.1136 - precision_92: 0.7593\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8151 - recall_92: 0.1190 - precision_92: 0.7674\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8158 - recall_92: 0.1155 - precision_92: 0.7603\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8129 - recall_92: 0.1198 - precision_92: 0.7709\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.8137 - recall_92: 0.1152 - precision_92: 0.7483\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.8099 - recall_92: 0.1135 - precision_92: 0.7626\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.8120 - recall_92: 0.1121 - precision_92: 0.7507\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.8137 - recall_92: 0.1153 - precision_92: 0.7637\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8131 - recall_92: 0.1214 - precision_92: 0.7651\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.8141 - recall_92: 0.1227 - precision_92: 0.7532\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8127 - recall_92: 0.1264 - precision_92: 0.7680\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8152 - recall_92: 0.1282 - precision_92: 0.7768\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8183 - recall_92: 0.1283 - precision_92: 0.7708\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8162 - recall_92: 0.1233 - precision_92: 0.7709\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8145 - recall_92: 0.1320 - precision_92: 0.7694\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.8191 - recall_92: 0.1298 - precision_92: 0.7822\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8126 - recall_92: 0.1261 - precision_92: 0.7647\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8148 - recall_92: 0.1269 - precision_92: 0.7634\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8191 - recall_92: 0.1400 - precision_92: 0.7616\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8140 - recall_92: 0.1303 - precision_92: 0.7500\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8141 - recall_92: 0.1341 - precision_92: 0.7590\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8193 - recall_92: 0.1441 - precision_92: 0.7820\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.8164 - recall_92: 0.1441 - precision_92: 0.7704\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659ABC1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.4395 - accuracy: 0.8153 - recall_92: 0.1356 - precision_92: 0.7356\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7163 - accuracy: 0.5314 - recall_93: 0.5593 - precision_93: 0.2292\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7091 - accuracy: 0.5402 - recall_93: 0.5449 - precision_93: 0.2286\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6982 - accuracy: 0.5497 - recall_93: 0.5304 - precision_93: 0.2337\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5615 - recall_93: 0.5150 - precision_93: 0.2303\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.5784 - recall_93: 0.5139 - precision_93: 0.2395\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.5926 - recall_93: 0.5069 - precision_93: 0.2520\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6543 - accuracy: 0.6044 - recall_93: 0.4990 - precision_93: 0.2548\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6222 - recall_93: 0.4860 - precision_93: 0.2605\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.6270 - recall_93: 0.4795 - precision_93: 0.2688\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.6376 - recall_93: 0.4721 - precision_93: 0.2760\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.6458 - recall_93: 0.4560 - precision_93: 0.2737\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6139 - accuracy: 0.6622 - recall_93: 0.4510 - precision_93: 0.2832\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6696 - recall_93: 0.4269 - precision_93: 0.2857\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.6787 - recall_93: 0.4188 - precision_93: 0.2963\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5948 - accuracy: 0.6880 - recall_93: 0.4183 - precision_93: 0.3030\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5884 - accuracy: 0.6982 - recall_93: 0.4053 - precision_93: 0.3121\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.7043 - recall_93: 0.3898 - precision_93: 0.3188\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.7088 - recall_93: 0.3787 - precision_93: 0.3207\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.7153 - recall_93: 0.3542 - precision_93: 0.3173\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5673 - accuracy: 0.7204 - recall_93: 0.3579 - precision_93: 0.3320\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7319 - recall_93: 0.3344 - precision_93: 0.3294\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7409 - recall_93: 0.3321 - precision_93: 0.3500\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.7446 - recall_93: 0.3380 - precision_93: 0.3577\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7529 - recall_93: 0.3339 - precision_93: 0.3795\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7554 - recall_93: 0.3162 - precision_93: 0.3841\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7614 - recall_93: 0.3197 - precision_93: 0.3931\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7696 - recall_93: 0.3212 - precision_93: 0.3964\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7706 - recall_93: 0.3113 - precision_93: 0.4054\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7725 - recall_93: 0.2929 - precision_93: 0.4157\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7772 - recall_93: 0.2938 - precision_93: 0.4175\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7759 - recall_93: 0.2804 - precision_93: 0.4223\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7838 - recall_93: 0.2763 - precision_93: 0.4423\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7841 - recall_93: 0.2732 - precision_93: 0.4497\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7848 - recall_93: 0.2597 - precision_93: 0.4436\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7897 - recall_93: 0.2605 - precision_93: 0.4663\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7904 - recall_93: 0.2599 - precision_93: 0.4633\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7901 - recall_93: 0.2523 - precision_93: 0.4779\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7933 - recall_93: 0.2456 - precision_93: 0.4768\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7931 - recall_93: 0.2452 - precision_93: 0.4872\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7969 - recall_93: 0.2361 - precision_93: 0.4961\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7977 - recall_93: 0.2281 - precision_93: 0.5071\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7999 - recall_93: 0.2270 - precision_93: 0.5125\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7963 - recall_93: 0.2167 - precision_93: 0.5100\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.8007 - recall_93: 0.2092 - precision_93: 0.5094\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.8008 - recall_93: 0.2160 - precision_93: 0.5187\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4862 - accuracy: 0.8030 - recall_93: 0.2103 - precision_93: 0.5404\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.8005 - recall_93: 0.1871 - precision_93: 0.5217\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4832 - accuracy: 0.8023 - recall_93: 0.1962 - precision_93: 0.5374\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.8033 - recall_93: 0.1900 - precision_93: 0.5425\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.8076 - recall_93: 0.1887 - precision_93: 0.5563\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.8064 - recall_93: 0.1940 - precision_93: 0.5658\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.8071 - recall_93: 0.1888 - precision_93: 0.5674\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.8069 - recall_93: 0.1860 - precision_93: 0.5861\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.8128 - recall_93: 0.1858 - precision_93: 0.5928\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.8140 - recall_93: 0.1875 - precision_93: 0.5968\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.8086 - recall_93: 0.1843 - precision_93: 0.5946\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.8095 - recall_93: 0.1728 - precision_93: 0.5941\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.8082 - recall_93: 0.1742 - precision_93: 0.6009\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.8137 - recall_93: 0.1731 - precision_93: 0.6283\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.8115 - recall_93: 0.1727 - precision_93: 0.6089\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.8125 - recall_93: 0.1673 - precision_93: 0.6270\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.8105 - recall_93: 0.1645 - precision_93: 0.6285\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.8120 - recall_93: 0.1635 - precision_93: 0.6292\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.8112 - recall_93: 0.1707 - precision_93: 0.6350\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.8159 - recall_93: 0.1698 - precision_93: 0.6607\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.8171 - recall_93: 0.1695 - precision_93: 0.6630\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.8162 - recall_93: 0.1633 - precision_93: 0.6366\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.8140 - recall_93: 0.1571 - precision_93: 0.6195\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.8158 - recall_93: 0.1668 - precision_93: 0.6665\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.8146 - recall_93: 0.1625 - precision_93: 0.6930\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.8131 - recall_93: 0.1648 - precision_93: 0.6733\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.8127 - recall_93: 0.1568 - precision_93: 0.6605\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.8147 - recall_93: 0.1573 - precision_93: 0.6519\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.8122 - recall_93: 0.1584 - precision_93: 0.6454\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.8162 - recall_93: 0.1657 - precision_93: 0.6938\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.8166 - recall_93: 0.1693 - precision_93: 0.6693\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.8153 - recall_93: 0.1652 - precision_93: 0.7016\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.8143 - recall_93: 0.1621 - precision_93: 0.6962\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.8162 - recall_93: 0.1618 - precision_93: 0.7056\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.8164 - recall_93: 0.1610 - precision_93: 0.6700\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8180 - recall_93: 0.1585 - precision_93: 0.7084\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8166 - recall_93: 0.1547 - precision_93: 0.7025\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.8151 - recall_93: 0.1586 - precision_93: 0.6952\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.8174 - recall_93: 0.1625 - precision_93: 0.7045\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.8158 - recall_93: 0.1586 - precision_93: 0.6932\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8133 - recall_93: 0.1570 - precision_93: 0.7023\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.8159 - recall_93: 0.1630 - precision_93: 0.6942\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.8185 - recall_93: 0.1619 - precision_93: 0.6801\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.8136 - recall_93: 0.1498 - precision_93: 0.6926\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8129 - recall_93: 0.1568 - precision_93: 0.6822\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8149 - recall_93: 0.1528 - precision_93: 0.6769\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8146 - recall_93: 0.1567 - precision_93: 0.7057\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8184 - recall_93: 0.1608 - precision_93: 0.6934\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.8112 - recall_93: 0.1667 - precision_93: 0.7116\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4431 - accuracy: 0.8140 - recall_93: 0.1602 - precision_93: 0.717 - 0s 3ms/step - loss: 0.4418 - accuracy: 0.8156 - recall_93: 0.1584 - precision_93: 0.6936\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8193 - recall_93: 0.1631 - precision_93: 0.6986\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.8159 - recall_93: 0.1567 - precision_93: 0.6897\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8157 - recall_93: 0.1617 - precision_93: 0.6996\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.8179 - recall_93: 0.1521 - precision_93: 0.6920\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8149 - recall_93: 0.1560 - precision_93: 0.6907\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA1940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.8041 - recall_93: 0.1374 - precision_93: 0.5702\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.9029 - accuracy: 0.2006 - recall_94: 1.0000 - precision_94: 0.2006\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8971 - accuracy: 0.1991 - recall_94: 1.0000 - precision_94: 0.1991\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8887 - accuracy: 0.2026 - recall_94: 1.0000 - precision_94: 0.2026\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8796 - accuracy: 0.2079 - recall_94: 1.0000 - precision_94: 0.2079\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8769 - accuracy: 0.2008 - recall_94: 1.0000 - precision_94: 0.2008\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8708 - accuracy: 0.2009 - recall_94: 1.0000 - precision_94: 0.2009\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8634 - accuracy: 0.2037 - recall_94: 1.0000 - precision_94: 0.2037\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8563 - accuracy: 0.2061 - recall_94: 1.0000 - precision_94: 0.2061\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8524 - accuracy: 0.2020 - recall_94: 1.0000 - precision_94: 0.2020\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8450 - accuracy: 0.2060 - recall_94: 1.0000 - precision_94: 0.2060\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8406 - accuracy: 0.2030 - recall_94: 1.0000 - precision_94: 0.2030\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8354 - accuracy: 0.2025 - recall_94: 1.0000 - precision_94: 0.2025\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8289 - accuracy: 0.2051 - recall_94: 1.0000 - precision_94: 0.2051\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8245 - accuracy: 0.2025 - recall_94: 1.0000 - precision_94: 0.2025\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8213 - accuracy: 0.1971 - recall_94: 1.0000 - precision_94: 0.1971\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8143 - accuracy: 0.2026 - recall_94: 1.0000 - precision_94: 0.2026\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8086 - accuracy: 0.2047 - recall_94: 1.0000 - precision_94: 0.2047\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8039 - accuracy: 0.2040 - recall_94: 1.0000 - precision_94: 0.2040\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7998 - accuracy: 0.2016 - recall_94: 1.0000 - precision_94: 0.2016\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7942 - accuracy: 0.2047 - recall_94: 1.0000 - precision_94: 0.2047\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7911 - accuracy: 0.1990 - recall_94: 1.0000 - precision_94: 0.1990\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7855 - accuracy: 0.2030 - recall_94: 1.0000 - precision_94: 0.2030\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7811 - accuracy: 0.2030 - recall_94: 1.0000 - precision_94: 0.2030\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7775 - accuracy: 0.1996 - recall_94: 1.0000 - precision_94: 0.1996\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7725 - accuracy: 0.2023 - recall_94: 1.0000 - precision_94: 0.2023\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7686 - accuracy: 0.2007 - recall_94: 1.0000 - precision_94: 0.2007\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7639 - accuracy: 0.2030 - recall_94: 1.0000 - precision_94: 0.2030\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7593 - accuracy: 0.2053 - recall_94: 1.0000 - precision_94: 0.2053\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7562 - accuracy: 0.2004 - recall_94: 1.0000 - precision_94: 0.2004\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7515 - accuracy: 0.2042 - recall_94: 1.0000 - precision_94: 0.2042\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.2029 - recall_94: 1.0000 - precision_94: 0.2029\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7440 - accuracy: 0.2033 - recall_94: 1.0000 - precision_94: 0.2033\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7398 - accuracy: 0.2053 - recall_94: 1.0000 - precision_94: 0.2053\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.2020 - recall_94: 1.0000 - precision_94: 0.2020\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7330 - accuracy: 0.2015 - recall_94: 1.0000 - precision_94: 0.2015\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7293 - accuracy: 0.2018 - recall_94: 1.0000 - precision_94: 0.2018\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7256 - accuracy: 0.2036 - recall_94: 1.0000 - precision_94: 0.2036\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7223 - accuracy: 0.2020 - recall_94: 1.0000 - precision_94: 0.2020\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7192 - accuracy: 0.1991 - recall_94: 1.0000 - precision_94: 0.1991\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7154 - accuracy: 0.2042 - recall_94: 1.0000 - precision_94: 0.2042\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7123 - accuracy: 0.2018 - recall_94: 1.0000 - precision_94: 0.2018\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7089 - accuracy: 0.2052 - recall_94: 1.0000 - precision_94: 0.2052\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7058 - accuracy: 0.2041 - recall_94: 1.0000 - precision_94: 0.2041\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7027 - accuracy: 0.2030 - recall_94: 1.0000 - precision_94: 0.2030\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6996 - accuracy: 0.2038 - recall_94: 1.0000 - precision_94: 0.2038\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6966 - accuracy: 0.2081 - recall_94: 0.9800 - precision_94: 0.2007\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.3545 - recall_94: 0.6373 - precision_94: 0.180 - 0s 4ms/step - loss: 0.6937 - accuracy: 0.4239 - recall_94: 0.5233 - precision_94: 0.1796\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.7631 - recall_94: 0.0317 - precision_94: 0.1261\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.7975 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.7951 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.7974 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6796 - accuracy: 0.8005 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.7999 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.7969 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.7957 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.7956 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.7984 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.7901 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.7950 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.7952 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6575 - accuracy: 0.7952 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6554 - accuracy: 0.7945 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.7990 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6506 - accuracy: 0.7969 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6486 - accuracy: 0.7960 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.8005 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.7969 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.7949 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.7997 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.7956 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.7935 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.7969 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.7982 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.7949 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.8009 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6263 - accuracy: 0.7992 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6237 - accuracy: 0.8024 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.7984 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7945 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.7995 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7973 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.7965 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.7988 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.7982 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.7946 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.7956 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6099 - accuracy: 0.7935 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6071 - accuracy: 0.7974 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.8002 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.7980 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.8002 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.7977 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.7964 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.7971 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.7977 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7987 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5961 - accuracy: 0.7940 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5937 - accuracy: 0.7969 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7935 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.7984 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7973 - recall_94: 0.0000e+00 - precision_94: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7072 - accuracy: 0.2017 - recall_95: 1.0000 - precision_95: 0.2017\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7032 - accuracy: 0.2058 - recall_95: 1.0000 - precision_95: 0.2058\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6996 - accuracy: 0.2018 - recall_95: 1.0000 - precision_95: 0.2018\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6959 - accuracy: 0.2330 - recall_95: 0.8851 - precision_95: 0.1946\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5963 - recall_95: 0.1836 - precision_95: 0.1381\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.7947 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.8000 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.7954 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.7975 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.7977 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7982 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6692 - accuracy: 0.7972 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.8007 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6633 - accuracy: 0.7968 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.7986 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.8055 - recall_95: 0.0000e+00 - precision_95: 0.0000e+0 - 0s 4ms/step - loss: 0.6572 - accuracy: 0.7997 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.7995 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.7933 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6491 - accuracy: 0.7981 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.7964 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.7959 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.7985 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.7980 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.7987 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.8010 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.8004 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.7979 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6277 - accuracy: 0.7958 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.7964 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.7990 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.7965 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.7966 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6172 - accuracy: 0.7956 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.7965 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.8013 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7954 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.8002 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.8004 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.7977 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.8013 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6007 - accuracy: 0.8000 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7974 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.7979 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5974 - accuracy: 0.7953 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.7977 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.7955 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.7954 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.7990 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.7960 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.7961 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.7954 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.7956 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.7958 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7963 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.7978 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7972 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7970 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.8000 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.7958 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.7968 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5744 - accuracy: 0.7943 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.7948 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5702 - accuracy: 0.7979 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7993 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7998 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7982 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7972 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7988 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.7935 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7954 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5611 - accuracy: 0.7988 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.7972 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5606 - accuracy: 0.7965 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5603 - accuracy: 0.7954 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.7955 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7967 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7970 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.7985 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7968 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5543 - accuracy: 0.7965 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5535 - accuracy: 0.7965 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7942 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7990 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7958 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7948 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7995 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5472 - accuracy: 0.7988 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7981 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7958 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7992 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.7945 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.7955 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5451 - accuracy: 0.7958 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7974 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7968 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7989 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7960 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.8011 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7960 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7928 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580323A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7977 - recall_95: 0.0000e+00 - precision_95: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5084 - accuracy: 0.7968 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7979 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7947 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7949 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7963 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7981 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7989 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7978 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7958 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7983 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7997 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7969 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7962 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7969 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5076 - accuracy: 0.7969 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7931 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7963 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.8019 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7957 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7970 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7953 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7971 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7951 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7961 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7973 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7974 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.8014 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.7976 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7948 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7995 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7969 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7993 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7971 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7983 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7988 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.8004 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7994 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.8001 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7980 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7941 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7983 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5078 - accuracy: 0.7959 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7997 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7985 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7971 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7984 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7986 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7995 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7989 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.8025 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.8015 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7982 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7953 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5060 - accuracy: 0.7971 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7966 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7944 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7992 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7970 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7951 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7957 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7996 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7953 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7998 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7998 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.8009 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7978 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7951 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7998 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7963 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7992 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.8020 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.8006 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7964 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7955 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7976 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.8013 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7982 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7981 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7993 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7971 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7996 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7961 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7993 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7979 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7983 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7946 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7979 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.8003 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7946 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7960 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7950 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7966 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7994 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7958 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.8004 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7993 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7965 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7984 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7966 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.8002 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C659F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7973 - recall_96: 0.0000e+00 - precision_96: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7777 - accuracy: 0.4765 - recall_97: 0.4261 - precision_97: 0.1742\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7626 - accuracy: 0.4889 - recall_97: 0.4210 - precision_97: 0.1777\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7509 - accuracy: 0.4975 - recall_97: 0.4212 - precision_97: 0.1825\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7402 - accuracy: 0.5052 - recall_97: 0.4009 - precision_97: 0.1737\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7277 - accuracy: 0.5167 - recall_97: 0.3797 - precision_97: 0.1807\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7173 - accuracy: 0.5252 - recall_97: 0.3787 - precision_97: 0.1827\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7079 - accuracy: 0.5319 - recall_97: 0.3619 - precision_97: 0.1790\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6951 - accuracy: 0.5433 - recall_97: 0.3634 - precision_97: 0.1807\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5571 - recall_97: 0.3548 - precision_97: 0.1851\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.5688 - recall_97: 0.3456 - precision_97: 0.1900\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.5753 - recall_97: 0.3285 - precision_97: 0.1845\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.5902 - recall_97: 0.3254 - precision_97: 0.1948\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.6011 - recall_97: 0.3246 - precision_97: 0.1982\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.6076 - recall_97: 0.3109 - precision_97: 0.1996\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.6225 - recall_97: 0.3021 - precision_97: 0.2030\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.6285 - recall_97: 0.2957 - precision_97: 0.2089\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.6408 - recall_97: 0.2812 - precision_97: 0.2151\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.6509 - recall_97: 0.2662 - precision_97: 0.2074\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.6647 - recall_97: 0.2673 - precision_97: 0.2227\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6088 - accuracy: 0.6711 - recall_97: 0.2578 - precision_97: 0.2241\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6042 - accuracy: 0.6818 - recall_97: 0.2459 - precision_97: 0.2337\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.6911 - recall_97: 0.2382 - precision_97: 0.2356\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.6926 - recall_97: 0.2290 - precision_97: 0.2354\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.6983 - recall_97: 0.2100 - precision_97: 0.2350\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.7097 - recall_97: 0.2011 - precision_97: 0.2363\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7139 - recall_97: 0.1989 - precision_97: 0.2462\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7183 - recall_97: 0.1925 - precision_97: 0.2501\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.7209 - recall_97: 0.1792 - precision_97: 0.2475\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5686 - accuracy: 0.7343 - recall_97: 0.1800 - precision_97: 0.2707\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7383 - recall_97: 0.1757 - precision_97: 0.2802\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7447 - recall_97: 0.1546 - precision_97: 0.2636\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.7524 - recall_97: 0.1565 - precision_97: 0.2838\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.7543 - recall_97: 0.1609 - precision_97: 0.2980\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5552 - accuracy: 0.7532 - recall_97: 0.1420 - precision_97: 0.2972\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7583 - recall_97: 0.1381 - precision_97: 0.2896\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.7606 - recall_97: 0.1372 - precision_97: 0.3009\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7625 - recall_97: 0.1290 - precision_97: 0.3044\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.7656 - recall_97: 0.1332 - precision_97: 0.3174\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7670 - recall_97: 0.1206 - precision_97: 0.3051\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7704 - recall_97: 0.1202 - precision_97: 0.3127\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7747 - recall_97: 0.1169 - precision_97: 0.3276\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7762 - recall_97: 0.1119 - precision_97: 0.3324\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7751 - recall_97: 0.1045 - precision_97: 0.3298\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7777 - recall_97: 0.1076 - precision_97: 0.3462\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7808 - recall_97: 0.0992 - precision_97: 0.3546\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5212 - accuracy: 0.7835 - recall_97: 0.0965 - precision_97: 0.3588\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7857 - recall_97: 0.1008 - precision_97: 0.3812\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7860 - recall_97: 0.0957 - precision_97: 0.3731\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5158 - accuracy: 0.7863 - recall_97: 0.0939 - precision_97: 0.3959\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7863 - recall_97: 0.0891 - precision_97: 0.3882\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7918 - recall_97: 0.0818 - precision_97: 0.3759\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7857 - recall_97: 0.0809 - precision_97: 0.3874\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7908 - recall_97: 0.0772 - precision_97: 0.3885\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7892 - recall_97: 0.0727 - precision_97: 0.3818\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7905 - recall_97: 0.0704 - precision_97: 0.3980\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5029 - accuracy: 0.7909 - recall_97: 0.0687 - precision_97: 0.3888\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7917 - recall_97: 0.0654 - precision_97: 0.4245\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7921 - recall_97: 0.0572 - precision_97: 0.3798\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7950 - recall_97: 0.0589 - precision_97: 0.4227\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7885 - recall_97: 0.0553 - precision_97: 0.4167\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7938 - recall_97: 0.0579 - precision_97: 0.4573\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7914 - recall_97: 0.0528 - precision_97: 0.4338\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7990 - recall_97: 0.0528 - precision_97: 0.4426\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7911 - recall_97: 0.0485 - precision_97: 0.4304\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7922 - recall_97: 0.0495 - precision_97: 0.4346\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7960 - recall_97: 0.0483 - precision_97: 0.4583\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7983 - recall_97: 0.0481 - precision_97: 0.4650\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7986 - recall_97: 0.0484 - precision_97: 0.5158\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7966 - recall_97: 0.0488 - precision_97: 0.4844\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7996 - recall_97: 0.0412 - precision_97: 0.4918\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7914 - recall_97: 0.0409 - precision_97: 0.4777\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.8031 - recall_97: 0.0433 - precision_97: 0.5051\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7984 - recall_97: 0.0408 - precision_97: 0.5244\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7937 - recall_97: 0.0375 - precision_97: 0.5131\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7980 - recall_97: 0.0346 - precision_97: 0.4797\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7991 - recall_97: 0.0361 - precision_97: 0.5353\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7970 - recall_97: 0.0304 - precision_97: 0.4919\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7980 - recall_97: 0.0337 - precision_97: 0.5286\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.8005 - recall_97: 0.0320 - precision_97: 0.5605\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7958 - recall_97: 0.0239 - precision_97: 0.4693\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.8013 - recall_97: 0.0254 - precision_97: 0.5100\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7943 - recall_97: 0.0243 - precision_97: 0.5387\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7999 - recall_97: 0.0248 - precision_97: 0.5077\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7967 - recall_97: 0.0198 - precision_97: 0.4583\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7978 - recall_97: 0.0200 - precision_97: 0.5012\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.8018 - recall_97: 0.0175 - precision_97: 0.5071\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7983 - recall_97: 0.0182 - precision_97: 0.5514\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7974 - recall_97: 0.0147 - precision_97: 0.4533\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7983 - recall_97: 0.0160 - precision_97: 0.5086\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.8009 - recall_97: 0.0178 - precision_97: 0.5292\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7987 - recall_97: 0.0158 - precision_97: 0.5197\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7990 - recall_97: 0.0140 - precision_97: 0.5138\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7961 - recall_97: 0.0127 - precision_97: 0.5257\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7993 - recall_97: 0.0153 - precision_97: 0.5644\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.8026 - recall_97: 0.0143 - precision_97: 0.5519\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7983 - recall_97: 0.0137 - precision_97: 0.5973\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7964 - recall_97: 0.0127 - precision_97: 0.5369\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7941 - recall_97: 0.0115 - precision_97: 0.5065\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7992 - recall_97: 0.0124 - precision_97: 0.5334\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7949 - recall_97: 0.0107 - precision_97: 0.5352\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657F8D940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.8003 - recall_97: 0.0169 - precision_97: 0.8889\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7098 - accuracy: 0.5377 - recall_98: 0.6499 - precision_98: 0.2545\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7014 - accuracy: 0.5465 - recall_98: 0.6195 - precision_98: 0.2506\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.5566 - recall_98: 0.6106 - precision_98: 0.2557\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.5645 - recall_98: 0.5998 - precision_98: 0.2547\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.5772 - recall_98: 0.5967 - precision_98: 0.2615\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.5835 - recall_98: 0.5685 - precision_98: 0.2624\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.5939 - recall_98: 0.5498 - precision_98: 0.2636\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.5968 - recall_98: 0.5434 - precision_98: 0.2617\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6095 - recall_98: 0.5378 - precision_98: 0.2711\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.6206 - recall_98: 0.5108 - precision_98: 0.2681\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6360 - accuracy: 0.6232 - recall_98: 0.5044 - precision_98: 0.2672\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6381 - recall_98: 0.4981 - precision_98: 0.2789\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.6459 - recall_98: 0.4892 - precision_98: 0.2807\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.6455 - recall_98: 0.4637 - precision_98: 0.2800\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.6606 - recall_98: 0.4583 - precision_98: 0.2867\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.6703 - recall_98: 0.4583 - precision_98: 0.2958\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.6775 - recall_98: 0.4377 - precision_98: 0.2965\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.6856 - recall_98: 0.4164 - precision_98: 0.3016\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.6876 - recall_98: 0.3920 - precision_98: 0.2964\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.7004 - recall_98: 0.3953 - precision_98: 0.3151\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.7093 - recall_98: 0.3882 - precision_98: 0.3174\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.7128 - recall_98: 0.3730 - precision_98: 0.3206\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5732 - accuracy: 0.7201 - recall_98: 0.3617 - precision_98: 0.3247\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7269 - recall_98: 0.3482 - precision_98: 0.3361\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.7210 - recall_98: 0.3286 - precision_98: 0.333 - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7259 - recall_98: 0.3267 - precision_98: 0.3312\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7389 - recall_98: 0.3225 - precision_98: 0.3383\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7376 - recall_98: 0.3088 - precision_98: 0.3354\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7470 - recall_98: 0.3044 - precision_98: 0.3457\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7454 - recall_98: 0.2898 - precision_98: 0.3471\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7525 - recall_98: 0.2797 - precision_98: 0.3609\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7614 - recall_98: 0.2680 - precision_98: 0.3550\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7607 - recall_98: 0.2611 - precision_98: 0.3651\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7654 - recall_98: 0.2613 - precision_98: 0.3923\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5394 - accuracy: 0.7699 - recall_98: 0.2341 - precision_98: 0.3796\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7724 - recall_98: 0.2330 - precision_98: 0.3903\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7793 - recall_98: 0.2337 - precision_98: 0.4047\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7783 - recall_98: 0.2213 - precision_98: 0.4125\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7768 - recall_98: 0.2095 - precision_98: 0.4180\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7813 - recall_98: 0.2020 - precision_98: 0.4169\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7802 - recall_98: 0.1883 - precision_98: 0.4133\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7887 - recall_98: 0.1991 - precision_98: 0.4394\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7841 - recall_98: 0.1772 - precision_98: 0.4189\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7888 - recall_98: 0.1731 - precision_98: 0.4326\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5171 - accuracy: 0.7872 - recall_98: 0.1734 - precision_98: 0.4343\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7914 - recall_98: 0.1709 - precision_98: 0.4583\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7964 - recall_98: 0.1760 - precision_98: 0.4732\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7956 - recall_98: 0.1641 - precision_98: 0.4686\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7933 - recall_98: 0.1652 - precision_98: 0.4843\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7970 - recall_98: 0.1620 - precision_98: 0.4875\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7991 - recall_98: 0.1627 - precision_98: 0.4961\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7961 - recall_98: 0.1527 - precision_98: 0.4978\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7981 - recall_98: 0.1481 - precision_98: 0.5096\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8027 - recall_98: 0.1544 - precision_98: 0.5203\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.8000 - recall_98: 0.1502 - precision_98: 0.5202\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7940 - recall_98: 0.1349 - precision_98: 0.4892\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7954 - recall_98: 0.1302 - precision_98: 0.4908\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7978 - recall_98: 0.1238 - precision_98: 0.4962\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8010 - recall_98: 0.1318 - precision_98: 0.5304\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.8006 - recall_98: 0.1262 - precision_98: 0.5289\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.8017 - recall_98: 0.1333 - precision_98: 0.5546\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.8059 - recall_98: 0.1283 - precision_98: 0.5492\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.8031 - recall_98: 0.1295 - precision_98: 0.5460\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.8055 - recall_98: 0.1179 - precision_98: 0.5238\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.8020 - recall_98: 0.1216 - precision_98: 0.5791\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.8059 - recall_98: 0.1236 - precision_98: 0.5777\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.8043 - recall_98: 0.1180 - precision_98: 0.5781\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.8022 - recall_98: 0.1152 - precision_98: 0.5924\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.8050 - recall_98: 0.1111 - precision_98: 0.5798\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.8030 - recall_98: 0.1139 - precision_98: 0.5793\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.8002 - recall_98: 0.1079 - precision_98: 0.5456\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.8030 - recall_98: 0.1086 - precision_98: 0.5739\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4796 - accuracy: 0.8023 - recall_98: 0.1112 - precision_98: 0.5688\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.8023 - recall_98: 0.1034 - precision_98: 0.5573\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8021 - recall_98: 0.1046 - precision_98: 0.5959\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.8057 - recall_98: 0.1135 - precision_98: 0.5917\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.8050 - recall_98: 0.1126 - precision_98: 0.6129\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.8066 - recall_98: 0.1068 - precision_98: 0.6026\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.8059 - recall_98: 0.1099 - precision_98: 0.6054\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.8030 - recall_98: 0.1053 - precision_98: 0.5983\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.8024 - recall_98: 0.1105 - precision_98: 0.6147\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.8041 - recall_98: 0.1083 - precision_98: 0.6171\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.8059 - recall_98: 0.1035 - precision_98: 0.6156\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.8097 - recall_98: 0.1119 - precision_98: 0.6365\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.8049 - recall_98: 0.1027 - precision_98: 0.6086\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.8068 - recall_98: 0.1095 - precision_98: 0.6460\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.8076 - recall_98: 0.1054 - precision_98: 0.6355\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.8045 - recall_98: 0.1082 - precision_98: 0.6411\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.8069 - recall_98: 0.1078 - precision_98: 0.6412\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.8073 - recall_98: 0.1069 - precision_98: 0.6645\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.8059 - recall_98: 0.1033 - precision_98: 0.6401\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.8045 - recall_98: 0.1041 - precision_98: 0.6511\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.8042 - recall_98: 0.1082 - precision_98: 0.6579\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.8097 - recall_98: 0.0994 - precision_98: 0.6510\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.8077 - recall_98: 0.1020 - precision_98: 0.6387\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.8079 - recall_98: 0.1099 - precision_98: 0.6862\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.8117 - recall_98: 0.1080 - precision_98: 0.6878\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.8086 - recall_98: 0.1058 - precision_98: 0.6810\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.8128 - recall_98: 0.1063 - precision_98: 0.6787\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.8090 - recall_98: 0.1060 - precision_98: 0.6783\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.8079 - recall_98: 0.1081 - precision_98: 0.6966\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.8067 - recall_98: 0.1038 - precision_98: 0.6364\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7308 - accuracy: 0.4307 - recall_99: 0.3619 - precision_99: 0.1409\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7258 - accuracy: 0.4426 - recall_99: 0.3505 - precision_99: 0.1397\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.4548 - recall_99: 0.3510 - precision_99: 0.1465\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7169 - accuracy: 0.4633 - recall_99: 0.3319 - precision_99: 0.1438\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7144 - accuracy: 0.4672 - recall_99: 0.3223 - precision_99: 0.1421\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7082 - accuracy: 0.4827 - recall_99: 0.3162 - precision_99: 0.1421\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7055 - accuracy: 0.4881 - recall_99: 0.3068 - precision_99: 0.1425\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7007 - accuracy: 0.4980 - recall_99: 0.2993 - precision_99: 0.1453\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.5068 - recall_99: 0.2847 - precision_99: 0.1435\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.5161 - recall_99: 0.2796 - precision_99: 0.1448\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.5285 - recall_99: 0.2681 - precision_99: 0.1447\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5366 - recall_99: 0.2578 - precision_99: 0.1439\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.5421 - recall_99: 0.2424 - precision_99: 0.1369\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6796 - accuracy: 0.5577 - recall_99: 0.2340 - precision_99: 0.1426\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6768 - accuracy: 0.5639 - recall_99: 0.2153 - precision_99: 0.1364\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.5779 - recall_99: 0.2093 - precision_99: 0.1372\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.5813 - recall_99: 0.2044 - precision_99: 0.1403\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.5955 - recall_99: 0.1883 - precision_99: 0.1353\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.6101 - recall_99: 0.1789 - precision_99: 0.1371\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.6220 - recall_99: 0.1703 - precision_99: 0.1413\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.6302 - recall_99: 0.1706 - precision_99: 0.1474\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.6402 - recall_99: 0.1582 - precision_99: 0.1444\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.6530 - recall_99: 0.1328 - precision_99: 0.1343\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.6612 - recall_99: 0.1359 - precision_99: 0.1435\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6711 - recall_99: 0.1270 - precision_99: 0.1455\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6775 - recall_99: 0.1076 - precision_99: 0.1378\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.6923 - recall_99: 0.1094 - precision_99: 0.1463\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.7031 - recall_99: 0.1094 - precision_99: 0.1560\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.7075 - recall_99: 0.0958 - precision_99: 0.1512\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.7192 - recall_99: 0.0959 - precision_99: 0.1586\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6316 - accuracy: 0.7248 - recall_99: 0.0889 - precision_99: 0.1705\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.7313 - recall_99: 0.0810 - precision_99: 0.1704\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.7315 - recall_99: 0.0750 - precision_99: 0.1698\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.7440 - recall_99: 0.0708 - precision_99: 0.1685\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.7491 - recall_99: 0.0662 - precision_99: 0.1756\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6198 - accuracy: 0.7504 - recall_99: 0.0647 - precision_99: 0.1850\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.7516 - recall_99: 0.0536 - precision_99: 0.1620\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.7575 - recall_99: 0.0562 - precision_99: 0.1884\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6121 - accuracy: 0.7639 - recall_99: 0.0543 - precision_99: 0.1986\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.7620 - recall_99: 0.0481 - precision_99: 0.1937\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.7689 - recall_99: 0.0455 - precision_99: 0.1931\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6075 - accuracy: 0.7675 - recall_99: 0.0531 - precision_99: 0.231 - 0s 4ms/step - loss: 0.6069 - accuracy: 0.7688 - recall_99: 0.0470 - precision_99: 0.2087\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.7678 - recall_99: 0.0427 - precision_99: 0.1955\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.7748 - recall_99: 0.0457 - precision_99: 0.2323\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.7755 - recall_99: 0.0416 - precision_99: 0.2239\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.7771 - recall_99: 0.0368 - precision_99: 0.2364\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7809 - recall_99: 0.0407 - precision_99: 0.2560\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.7829 - recall_99: 0.0325 - precision_99: 0.2291\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.7847 - recall_99: 0.0373 - precision_99: 0.2793\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.7862 - recall_99: 0.0319 - precision_99: 0.2678\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5893 - accuracy: 0.7867 - recall_99: 0.0297 - precision_99: 0.2821\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.7905 - recall_99: 0.0281 - precision_99: 0.3021\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.7950 - recall_99: 0.0289 - precision_99: 0.3457\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.7932 - recall_99: 0.0251 - precision_99: 0.3184\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7919 - recall_99: 0.0201 - precision_99: 0.2955\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7920 - recall_99: 0.0208 - precision_99: 0.3386\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7958 - recall_99: 0.0167 - precision_99: 0.2982\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.7977 - recall_99: 0.0158 - precision_99: 0.3101\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5754 - accuracy: 0.7956 - recall_99: 0.0138 - precision_99: 0.3027\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.7926 - recall_99: 0.0112 - precision_99: 0.2912\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.7905 - recall_99: 0.0125 - precision_99: 0.3559\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5699 - accuracy: 0.7979 - recall_99: 0.0092 - precision_99: 0.2986\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7960 - recall_99: 0.0097 - precision_99: 0.3434\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.8005 - recall_99: 0.0108 - precision_99: 0.4509\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7964 - recall_99: 0.0091 - precision_99: 0.3625\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7946 - recall_99: 0.0096 - precision_99: 0.3767\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7988 - recall_99: 0.0120 - precision_99: 0.4684\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7957 - recall_99: 0.0079 - precision_99: 0.4821\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7943 - recall_99: 0.0096 - precision_99: 0.6607\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.8020 - recall_99: 0.0092 - precision_99: 0.5937\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.8008 - recall_99: 0.0052 - precision_99: 0.6111\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7992 - recall_99: 0.0061 - precision_99: 0.4821\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7991 - recall_99: 0.0036 - precision_99: 0.4375    \n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5549 - accuracy: 0.7972 - recall_99: 0.0057 - precision_99: 0.6667\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7978 - recall_99: 0.0057 - precision_99: 0.8071\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7965 - recall_99: 0.0042 - precision_99: 0.6696\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.7956 - recall_99: 0.0025 - precision_99: 0.4500    \n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.8010 - recall_99: 0.0015 - precision_99: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7992 - recall_99: 8.3966e-04 - precision_99: 0.7500\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7966 - recall_99: 0.0014 - precision_99: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7988 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7952 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.7960 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.8003 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7979 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7956 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7997 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5405 - accuracy: 0.7949 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.7993 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7965 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7988 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7954 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7963 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.8001 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7931 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7946 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7963 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7994 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7966 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5279 - accuracy: 0.7976 - recall_99: 0.0000e+00 - precision_99: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657C9E820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.7977 - recall_99: 0.0021 - precision_99: 1.0000\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8292 - accuracy: 0.5209 - recall_100: 0.5700 - precision_100: 0.2234\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8159 - accuracy: 0.5320 - recall_100: 0.5740 - precision_100: 0.2354\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8001 - accuracy: 0.5395 - recall_100: 0.5582 - precision_100: 0.2299\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7907 - accuracy: 0.5430 - recall_100: 0.5422 - precision_100: 0.2339\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7707 - accuracy: 0.5570 - recall_100: 0.5482 - precision_100: 0.2402\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7616 - accuracy: 0.5601 - recall_100: 0.5254 - precision_100: 0.2348\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7579 - accuracy: 0.5638 - recall_100: 0.5182 - precision_100: 0.2413\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7454 - accuracy: 0.5692 - recall_100: 0.5135 - precision_100: 0.2404\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7323 - accuracy: 0.5760 - recall_100: 0.4968 - precision_100: 0.2400\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7236 - accuracy: 0.5824 - recall_100: 0.4883 - precision_100: 0.2374\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7131 - accuracy: 0.5886 - recall_100: 0.4800 - precision_100: 0.2410\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.5930 - recall_100: 0.4723 - precision_100: 0.2388\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.5959 - recall_100: 0.4609 - precision_100: 0.2391\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.6076 - recall_100: 0.4543 - precision_100: 0.2458\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.6116 - recall_100: 0.4467 - precision_100: 0.2456\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6202 - recall_100: 0.4427 - precision_100: 0.2492\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.6202 - recall_100: 0.4334 - precision_100: 0.2484\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6312 - recall_100: 0.4184 - precision_100: 0.2537\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.6386 - recall_100: 0.4012 - precision_100: 0.2542\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6367 - recall_100: 0.3936 - precision_100: 0.2499\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.6458 - recall_100: 0.3860 - precision_100: 0.2581\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.6560 - recall_100: 0.3836 - precision_100: 0.2633\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6631 - recall_100: 0.3677 - precision_100: 0.2640\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.6704 - recall_100: 0.3646 - precision_100: 0.2655\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.6723 - recall_100: 0.3606 - precision_100: 0.2668\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.6790 - recall_100: 0.3476 - precision_100: 0.2700\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.6825 - recall_100: 0.3354 - precision_100: 0.2747\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.6895 - recall_100: 0.3242 - precision_100: 0.2759\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.6946 - recall_100: 0.3258 - precision_100: 0.2833\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.6988 - recall_100: 0.3115 - precision_100: 0.2769\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7064 - recall_100: 0.3018 - precision_100: 0.2859\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7061 - recall_100: 0.2873 - precision_100: 0.2768\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7060 - recall_100: 0.2711 - precision_100: 0.2752\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7089 - recall_100: 0.2687 - precision_100: 0.2760\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7190 - recall_100: 0.2618 - precision_100: 0.2825\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7167 - recall_100: 0.2432 - precision_100: 0.2770\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7203 - recall_100: 0.2446 - precision_100: 0.2860\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7284 - recall_100: 0.2328 - precision_100: 0.2868\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7273 - recall_100: 0.2332 - precision_100: 0.2914\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7339 - recall_100: 0.2219 - precision_100: 0.2909\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7343 - recall_100: 0.2133 - precision_100: 0.2913\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7409 - recall_100: 0.2157 - precision_100: 0.2940\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7393 - recall_100: 0.2005 - precision_100: 0.2920\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7440 - recall_100: 0.1971 - precision_100: 0.2985\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7449 - recall_100: 0.1872 - precision_100: 0.2960\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7463 - recall_100: 0.1772 - precision_100: 0.2958\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7470 - recall_100: 0.1651 - precision_100: 0.2894\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7538 - recall_100: 0.1666 - precision_100: 0.3048\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7553 - recall_100: 0.1647 - precision_100: 0.3112\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7586 - recall_100: 0.1608 - precision_100: 0.3127\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7633 - recall_100: 0.1602 - precision_100: 0.3224\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7576 - recall_100: 0.1497 - precision_100: 0.3099\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7595 - recall_100: 0.1457 - precision_100: 0.3179\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7609 - recall_100: 0.1459 - precision_100: 0.3076\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.7596 - recall_100: 0.1391 - precision_100: 0.3217\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7635 - recall_100: 0.1304 - precision_100: 0.3084\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7676 - recall_100: 0.1288 - precision_100: 0.3139\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7657 - recall_100: 0.1303 - precision_100: 0.3220\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7690 - recall_100: 0.1271 - precision_100: 0.3273\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7704 - recall_100: 0.1245 - precision_100: 0.3339\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7713 - recall_100: 0.1242 - precision_100: 0.3353\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4926 - accuracy: 0.7723 - recall_100: 0.1117 - precision_100: 0.3180\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.7711 - recall_100: 0.1072 - precision_100: 0.3120\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7746 - recall_100: 0.1065 - precision_100: 0.3259\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7732 - recall_100: 0.1048 - precision_100: 0.3163\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7783 - recall_100: 0.1068 - precision_100: 0.3216\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7771 - recall_100: 0.1168 - precision_100: 0.3453\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7743 - recall_100: 0.1032 - precision_100: 0.3276\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7751 - recall_100: 0.0967 - precision_100: 0.3187\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7767 - recall_100: 0.0981 - precision_100: 0.3259\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7782 - recall_100: 0.1017 - precision_100: 0.3429\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7767 - recall_100: 0.1033 - precision_100: 0.3532\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.7777 - recall_100: 0.1021 - precision_100: 0.3429\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7801 - recall_100: 0.0971 - precision_100: 0.3442\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7857 - recall_100: 0.0964 - precision_100: 0.3523\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7809 - recall_100: 0.0956 - precision_100: 0.3602\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7814 - recall_100: 0.0923 - precision_100: 0.3601\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4809 - accuracy: 0.7817 - recall_100: 0.0954 - precision_100: 0.3564\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7861 - recall_100: 0.0956 - precision_100: 0.3688\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7839 - recall_100: 0.0957 - precision_100: 0.3810\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7861 - recall_100: 0.0984 - precision_100: 0.3886\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7882 - recall_100: 0.0971 - precision_100: 0.4001\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7884 - recall_100: 0.0924 - precision_100: 0.4009\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7880 - recall_100: 0.0947 - precision_100: 0.4070\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7837 - recall_100: 0.0842 - precision_100: 0.3748\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7860 - recall_100: 0.0893 - precision_100: 0.3843\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7845 - recall_100: 0.0863 - precision_100: 0.3787\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7871 - recall_100: 0.0832 - precision_100: 0.3781\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7887 - recall_100: 0.0893 - precision_100: 0.3882\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7877 - recall_100: 0.0895 - precision_100: 0.3996\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7896 - recall_100: 0.0851 - precision_100: 0.4084\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7891 - recall_100: 0.0852 - precision_100: 0.3939\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7906 - recall_100: 0.0800 - precision_100: 0.3984\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7896 - recall_100: 0.0901 - precision_100: 0.4223\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7896 - recall_100: 0.0818 - precision_100: 0.4116\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7887 - recall_100: 0.0832 - precision_100: 0.4096\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7926 - recall_100: 0.0794 - precision_100: 0.4109\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7949 - recall_100: 0.0897 - precision_100: 0.4457\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7907 - recall_100: 0.0890 - precision_100: 0.4443\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7962 - recall_100: 0.0906 - precision_100: 0.4450\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7909 - recall_100: 0.0761 - precision_100: 0.4138\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6943 - accuracy: 0.5585 - recall_101: 0.6005 - precision_101: 0.2494\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.5622 - recall_101: 0.6009 - precision_101: 0.2537\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.5629 - recall_101: 0.5845 - precision_101: 0.2518\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5678 - recall_101: 0.5827 - precision_101: 0.2564\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6806 - accuracy: 0.5697 - recall_101: 0.5738 - precision_101: 0.2541\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6773 - accuracy: 0.5774 - recall_101: 0.5670 - precision_101: 0.2544\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6747 - accuracy: 0.5829 - recall_101: 0.5618 - precision_101: 0.2565\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6701 - accuracy: 0.5872 - recall_101: 0.5550 - precision_101: 0.2588\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6667 - accuracy: 0.5929 - recall_101: 0.5492 - precision_101: 0.2592\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.5930 - recall_101: 0.5453 - precision_101: 0.2620\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6632 - accuracy: 0.5918 - recall_101: 0.5244 - precision_101: 0.2557\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.5963 - recall_101: 0.5225 - precision_101: 0.2574\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.6009 - recall_101: 0.5167 - precision_101: 0.2583\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.6086 - recall_101: 0.5160 - precision_101: 0.2650\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.6137 - recall_101: 0.5103 - precision_101: 0.2632\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6208 - recall_101: 0.5085 - precision_101: 0.2655\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.6221 - recall_101: 0.5033 - precision_101: 0.2665\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.6270 - recall_101: 0.5014 - precision_101: 0.2755\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.6287 - recall_101: 0.4837 - precision_101: 0.2746\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6376 - recall_101: 0.4901 - precision_101: 0.2764\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6358 - recall_101: 0.4715 - precision_101: 0.2719\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6407 - recall_101: 0.4680 - precision_101: 0.2768\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6275 - accuracy: 0.6450 - recall_101: 0.4726 - precision_101: 0.2775\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6276 - accuracy: 0.6461 - recall_101: 0.4660 - precision_101: 0.2766\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6213 - accuracy: 0.6540 - recall_101: 0.4710 - precision_101: 0.2859\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6183 - accuracy: 0.6567 - recall_101: 0.4615 - precision_101: 0.2878\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.6541 - recall_101: 0.4539 - precision_101: 0.2808\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6593 - recall_101: 0.4505 - precision_101: 0.2854\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.6610 - recall_101: 0.4534 - precision_101: 0.2890\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.6641 - recall_101: 0.4452 - precision_101: 0.2902\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6690 - recall_101: 0.4399 - precision_101: 0.2871\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6710 - recall_101: 0.4334 - precision_101: 0.2871\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.6751 - recall_101: 0.4229 - precision_101: 0.2911\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6746 - recall_101: 0.4171 - precision_101: 0.2947\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.6802 - recall_101: 0.4187 - precision_101: 0.2911\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5981 - accuracy: 0.6812 - recall_101: 0.4078 - precision_101: 0.2931\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.6853 - recall_101: 0.4139 - precision_101: 0.3032\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5938 - accuracy: 0.6907 - recall_101: 0.4105 - precision_101: 0.3008\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.6933 - recall_101: 0.4094 - precision_101: 0.3109\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.6947 - recall_101: 0.4007 - precision_101: 0.3112\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.6932 - recall_101: 0.3913 - precision_101: 0.3029\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5854 - accuracy: 0.7016 - recall_101: 0.3995 - precision_101: 0.3132\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.7024 - recall_101: 0.3903 - precision_101: 0.3145\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5830 - accuracy: 0.7053 - recall_101: 0.3790 - precision_101: 0.3095\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7125 - recall_101: 0.3923 - precision_101: 0.3239\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.7112 - recall_101: 0.3835 - precision_101: 0.3304\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.7193 - recall_101: 0.3828 - precision_101: 0.3244\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7179 - recall_101: 0.3751 - precision_101: 0.3307\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7215 - recall_101: 0.3666 - precision_101: 0.3264\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7225 - recall_101: 0.3648 - precision_101: 0.3362\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.7229 - recall_101: 0.3621 - precision_101: 0.3325\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5665 - accuracy: 0.7269 - recall_101: 0.3652 - precision_101: 0.3411\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7278 - recall_101: 0.3501 - precision_101: 0.3288\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7277 - recall_101: 0.3498 - precision_101: 0.3335\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.7301 - recall_101: 0.3502 - precision_101: 0.3423\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7339 - recall_101: 0.3426 - precision_101: 0.3381\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7328 - recall_101: 0.3271 - precision_101: 0.3390\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7381 - recall_101: 0.3374 - precision_101: 0.3439\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5590 - accuracy: 0.7358 - recall_101: 0.3326 - precision_101: 0.3432\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7416 - recall_101: 0.3302 - precision_101: 0.3559\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.7412 - recall_101: 0.3306 - precision_101: 0.3574\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5520 - accuracy: 0.7408 - recall_101: 0.3190 - precision_101: 0.3521\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7454 - recall_101: 0.3203 - precision_101: 0.3575\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7522 - recall_101: 0.3201 - precision_101: 0.3680\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7509 - recall_101: 0.3100 - precision_101: 0.3565\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7553 - recall_101: 0.3124 - precision_101: 0.3713\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.7566 - recall_101: 0.3163 - precision_101: 0.3798\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7576 - recall_101: 0.3090 - precision_101: 0.3808\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7604 - recall_101: 0.3115 - precision_101: 0.3892\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7569 - recall_101: 0.3035 - precision_101: 0.3787\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7589 - recall_101: 0.2988 - precision_101: 0.3830\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7582 - recall_101: 0.2975 - precision_101: 0.3855\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7618 - recall_101: 0.2935 - precision_101: 0.3874\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7597 - recall_101: 0.2840 - precision_101: 0.3797\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7632 - recall_101: 0.2903 - precision_101: 0.3800\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7615 - recall_101: 0.2739 - precision_101: 0.3740\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5330 - accuracy: 0.7596 - recall_101: 0.2705 - precision_101: 0.3815\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7626 - recall_101: 0.2658 - precision_101: 0.3785\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7630 - recall_101: 0.2640 - precision_101: 0.3875\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7679 - recall_101: 0.2695 - precision_101: 0.3914\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7690 - recall_101: 0.2649 - precision_101: 0.3998\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7688 - recall_101: 0.2591 - precision_101: 0.3938\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7723 - recall_101: 0.2622 - precision_101: 0.4065\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7707 - recall_101: 0.2470 - precision_101: 0.3850\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7761 - recall_101: 0.2576 - precision_101: 0.4088\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7715 - recall_101: 0.2492 - precision_101: 0.4030\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.7703 - recall_101: 0.2439 - precision_101: 0.3979\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7765 - recall_101: 0.2544 - precision_101: 0.4085\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7803 - recall_101: 0.2563 - precision_101: 0.4146\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7776 - recall_101: 0.2528 - precision_101: 0.4286\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7784 - recall_101: 0.2441 - precision_101: 0.4265\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7759 - recall_101: 0.2353 - precision_101: 0.4203\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7780 - recall_101: 0.2275 - precision_101: 0.4080\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7786 - recall_101: 0.2359 - precision_101: 0.4259\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7779 - recall_101: 0.2274 - precision_101: 0.4154\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7796 - recall_101: 0.2298 - precision_101: 0.4258\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7783 - recall_101: 0.2207 - precision_101: 0.4181\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7797 - recall_101: 0.2245 - precision_101: 0.4285\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7854 - recall_101: 0.2342 - precision_101: 0.4434\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7816 - recall_101: 0.2128 - precision_101: 0.4155\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA1DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7823 - recall_101: 0.2394 - precision_101: 0.4313\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.5356 - recall_102: 0.6001 - precision_102: 0.2445\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5449 - recall_102: 0.5932 - precision_102: 0.2433\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.5585 - recall_102: 0.5698 - precision_102: 0.2435\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6806 - accuracy: 0.5660 - recall_102: 0.5591 - precision_102: 0.2454\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.5711 - recall_102: 0.5338 - precision_102: 0.2461\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.5929 - recall_102: 0.5314 - precision_102: 0.2611\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.5997 - recall_102: 0.5088 - precision_102: 0.2550\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.6082 - recall_102: 0.5145 - precision_102: 0.2632\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.6169 - recall_102: 0.5069 - precision_102: 0.2652\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6263 - recall_102: 0.4932 - precision_102: 0.2684\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6282 - recall_102: 0.4738 - precision_102: 0.2644\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.6393 - recall_102: 0.4735 - precision_102: 0.2776\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6407 - accuracy: 0.6436 - recall_102: 0.4463 - precision_102: 0.2731\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6364 - accuracy: 0.6519 - recall_102: 0.4289 - precision_102: 0.2716\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6334 - accuracy: 0.6542 - recall_102: 0.4158 - precision_102: 0.2706\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6298 - accuracy: 0.6654 - recall_102: 0.4179 - precision_102: 0.2852\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6743 - recall_102: 0.4013 - precision_102: 0.2839\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.6787 - recall_102: 0.3836 - precision_102: 0.2804\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.6847 - recall_102: 0.3750 - precision_102: 0.2825\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.6872 - recall_102: 0.3632 - precision_102: 0.2913\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.6919 - recall_102: 0.3505 - precision_102: 0.2879\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.7000 - recall_102: 0.3386 - precision_102: 0.2919\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.7078 - recall_102: 0.3356 - precision_102: 0.3057\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.7115 - recall_102: 0.3454 - precision_102: 0.318 - 0s 3ms/step - loss: 0.6020 - accuracy: 0.7117 - recall_102: 0.3282 - precision_102: 0.3068\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.7147 - recall_102: 0.3154 - precision_102: 0.3076\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7271 - recall_102: 0.3034 - precision_102: 0.3099\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.7262 - recall_102: 0.2910 - precision_102: 0.3173\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.7304 - recall_102: 0.2899 - precision_102: 0.3178\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7357 - recall_102: 0.2765 - precision_102: 0.3159\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5874 - accuracy: 0.7395 - recall_102: 0.2679 - precision_102: 0.3258\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5851 - accuracy: 0.7412 - recall_102: 0.2641 - precision_102: 0.3349\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7458 - recall_102: 0.2570 - precision_102: 0.3352\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.7486 - recall_102: 0.2481 - precision_102: 0.3463\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.7541 - recall_102: 0.2313 - precision_102: 0.3421\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5737 - accuracy: 0.7558 - recall_102: 0.2358 - precision_102: 0.3414\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5716 - accuracy: 0.7632 - recall_102: 0.2365 - precision_102: 0.3689\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.7638 - recall_102: 0.2232 - precision_102: 0.3573\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7637 - recall_102: 0.2026 - precision_102: 0.3626\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7647 - recall_102: 0.1979 - precision_102: 0.3647\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7718 - recall_102: 0.1990 - precision_102: 0.3651\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7729 - recall_102: 0.1966 - precision_102: 0.3785\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7745 - recall_102: 0.1928 - precision_102: 0.3757\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7732 - recall_102: 0.1784 - precision_102: 0.3793\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7759 - recall_102: 0.1724 - precision_102: 0.3782\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7788 - recall_102: 0.1661 - precision_102: 0.3935\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7763 - recall_102: 0.1500 - precision_102: 0.3572\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7788 - recall_102: 0.1508 - precision_102: 0.3699\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.7769 - recall_102: 0.1462 - precision_102: 0.3804\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.7837 - recall_102: 0.1475 - precision_102: 0.4070\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7842 - recall_102: 0.1381 - precision_102: 0.3930\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.7814 - recall_102: 0.1357 - precision_102: 0.3878\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7885 - recall_102: 0.1399 - precision_102: 0.4212\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7851 - recall_102: 0.1288 - precision_102: 0.4084\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5388 - accuracy: 0.7879 - recall_102: 0.1342 - precision_102: 0.4283\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5383 - accuracy: 0.7880 - recall_102: 0.1309 - precision_102: 0.4390\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7840 - recall_102: 0.1133 - precision_102: 0.4133\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7897 - recall_102: 0.1113 - precision_102: 0.4152\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7899 - recall_102: 0.1060 - precision_102: 0.4087\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7941 - recall_102: 0.1255 - precision_102: 0.4513\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7906 - recall_102: 0.1069 - precision_102: 0.4330\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7891 - recall_102: 0.1017 - precision_102: 0.4245\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.7902 - recall_102: 0.1026 - precision_102: 0.4422\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7889 - recall_102: 0.0981 - precision_102: 0.4465\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7959 - recall_102: 0.0963 - precision_102: 0.4511\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.7897 - recall_102: 0.0897 - precision_102: 0.4316\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7952 - recall_102: 0.0908 - precision_102: 0.4487\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7966 - recall_102: 0.0836 - precision_102: 0.4209\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7890 - recall_102: 0.0799 - precision_102: 0.4288\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7946 - recall_102: 0.0860 - precision_102: 0.4402\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7918 - recall_102: 0.0799 - precision_102: 0.4396\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7921 - recall_102: 0.0803 - precision_102: 0.4415\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7959 - recall_102: 0.0811 - precision_102: 0.4881\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7936 - recall_102: 0.0797 - precision_102: 0.4426\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7930 - recall_102: 0.0743 - precision_102: 0.4407\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7946 - recall_102: 0.0766 - precision_102: 0.4732\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7959 - recall_102: 0.0742 - precision_102: 0.4515\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7947 - recall_102: 0.0718 - precision_102: 0.4597\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7914 - recall_102: 0.0696 - precision_102: 0.4540\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7945 - recall_102: 0.0699 - precision_102: 0.4560\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7953 - recall_102: 0.0621 - precision_102: 0.4237\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5117 - accuracy: 0.7955 - recall_102: 0.0681 - precision_102: 0.518 - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7947 - recall_102: 0.0634 - precision_102: 0.4598\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7952 - recall_102: 0.0646 - precision_102: 0.4464\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7951 - recall_102: 0.0585 - precision_102: 0.4507\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7965 - recall_102: 0.0621 - precision_102: 0.4489\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5053 - accuracy: 0.7951 - recall_102: 0.0592 - precision_102: 0.4610\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7926 - recall_102: 0.0551 - precision_102: 0.4448\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5048 - accuracy: 0.7959 - recall_102: 0.0592 - precision_102: 0.4782\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7946 - recall_102: 0.0572 - precision_102: 0.4527\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7947 - recall_102: 0.0555 - precision_102: 0.4530\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7971 - recall_102: 0.0542 - precision_102: 0.4578\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7969 - recall_102: 0.0514 - precision_102: 0.4621\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7950 - recall_102: 0.0523 - precision_102: 0.4859\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4975 - accuracy: 0.7999 - recall_102: 0.0546 - precision_102: 0.4957\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7951 - recall_102: 0.0487 - precision_102: 0.4845\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7949 - recall_102: 0.0473 - precision_102: 0.4553\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7961 - recall_102: 0.0542 - precision_102: 0.5174\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7940 - recall_102: 0.0465 - precision_102: 0.4664\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4960 - accuracy: 0.8008 - recall_102: 0.0510 - precision_102: 0.5278\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4969 - accuracy: 0.7961 - recall_102: 0.0455 - precision_102: 0.5047\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4990 - accuracy: 0.7941 - recall_102: 0.0458 - precision_102: 0.5060\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D658032310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7968 - recall_102: 0.0423 - precision_102: 0.4878\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.9552 - accuracy: 0.2003 - recall_103: 1.0000 - precision_103: 0.2003\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9393 - accuracy: 0.2009 - recall_103: 1.0000 - precision_103: 0.2009\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9219 - accuracy: 0.2036 - recall_103: 1.0000 - precision_103: 0.2036\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9059 - accuracy: 0.2055 - recall_103: 1.0000 - precision_103: 0.2055\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8925 - accuracy: 0.2043 - recall_103: 1.0000 - precision_103: 0.2043\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8791 - accuracy: 0.2028 - recall_103: 1.0000 - precision_103: 0.2028\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8660 - accuracy: 0.2031 - recall_103: 1.0000 - precision_103: 0.2031\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8522 - accuracy: 0.2050 - recall_103: 1.0000 - precision_103: 0.2050\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8416 - accuracy: 0.2011 - recall_103: 1.0000 - precision_103: 0.2011\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8301 - accuracy: 0.2009 - recall_103: 1.0000 - precision_103: 0.2009\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8185 - accuracy: 0.2008 - recall_103: 1.0000 - precision_103: 0.2008\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8085 - accuracy: 0.1970 - recall_103: 1.0000 - precision_103: 0.1970\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7959 - accuracy: 0.2028 - recall_103: 1.0000 - precision_103: 0.2028\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7859 - accuracy: 0.2016 - recall_103: 1.0000 - precision_103: 0.2016\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7759 - accuracy: 0.2034 - recall_103: 1.0000 - precision_103: 0.2034\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7662 - accuracy: 0.2037 - recall_103: 1.0000 - precision_103: 0.2037\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7572 - accuracy: 0.2024 - recall_103: 1.0000 - precision_103: 0.2019\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7483 - accuracy: 0.2079 - recall_103: 1.0000 - precision_103: 0.2051\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.2126 - recall_103: 0.9903 - precision_103: 0.2031\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7316 - accuracy: 0.2316 - recall_103: 0.9664 - precision_103: 0.2049\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7238 - accuracy: 0.2517 - recall_103: 0.9049 - precision_103: 0.2003\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7161 - accuracy: 0.2899 - recall_103: 0.8560 - precision_103: 0.2049\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7091 - accuracy: 0.3306 - recall_103: 0.7791 - precision_103: 0.2011\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7018 - accuracy: 0.3857 - recall_103: 0.6760 - precision_103: 0.2018\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6951 - accuracy: 0.4498 - recall_103: 0.5166 - precision_103: 0.1905\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5330 - recall_103: 0.3356 - precision_103: 0.1694\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.6220 - recall_103: 0.1900 - precision_103: 0.1541\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.7073 - recall_103: 0.0895 - precision_103: 0.1424\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.7567 - recall_103: 0.0268 - precision_103: 0.1088\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.7865 - recall_103: 0.0052 - precision_103: 0.0859\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.7953 - recall_103: 0.0014 - precision_103: 0.1399\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.7969 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.7970 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6432 - accuracy: 0.8005 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.7977 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.7979 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6305 - accuracy: 0.7983 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.7988 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.7997 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.7969 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.7930 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.7980 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.7968 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.7965 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.7977 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.8001 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.7962 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.7964 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.7965 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5863 - accuracy: 0.7972 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.7995 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7970 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.7959 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7989 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.7964 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5732 - accuracy: 0.7952 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7983 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7987 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7999 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.7965 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.7949 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.7967 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7963 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7981 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.8008 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7949 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7964 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7940 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7949 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7974 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7954 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7988 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7952 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7978 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7941 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7955 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7990 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7961 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.8004 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7992 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5375 - accuracy: 0.7951 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7992 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.8015 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7976 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7960 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.8009 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7994 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7977 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7975 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7979 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7988 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7978 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7979 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7969 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7962 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7985 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7960 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7981 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.8012 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7950 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE7EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7973 - recall_103: 0.0000e+00 - precision_103: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5415 - accuracy: 0.7965 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7987 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7981 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7983 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7965 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7953 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.8005 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7967 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5348 - accuracy: 0.7953 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7966 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5351 - accuracy: 0.7928 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7967 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7983 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.8012 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7958 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.8002 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7977 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7954 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7985 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7955 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7963 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7982 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7989 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7940 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7973 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.8003 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7963 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.8000 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7953 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7946 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7965 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7980 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7996 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7997 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7987 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7952 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7995 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7977 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7996 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7964 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7952 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.8014 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7941 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7953 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7970 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7990 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7991 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7951 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7980 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7915 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7993 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7986 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7978 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7951 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7952 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7943 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7960 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7932 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7967 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7980 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7987 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7953 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7968 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7978 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7966 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7965 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7985 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7969 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7995 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7973 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7976 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7982 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.8008 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.7987 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7965 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5091 - accuracy: 0.7952 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.8015 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7945 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7975 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7953 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7970 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7983 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7973 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7994 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5068 - accuracy: 0.7965 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7965 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7973 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7973 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.8011 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7964 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.8017 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7995 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7952 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7980 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7990 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5158 - accuracy: 0.7875 - recall_104: 0.0000e+00 - precision_104: 0.0000e+0 - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7950 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7975 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7985 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5023 - accuracy: 0.7990 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7937 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE7D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7977 - recall_104: 0.0000e+00 - precision_104: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5098 - accuracy: 0.7959 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7964 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7989 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7952 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7989 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.8003 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7983 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7962 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7979 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7978 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7984 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7994 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7940 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7975 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7958 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7963 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.8005 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7969 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7962 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7947 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7993 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7974 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7949 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7982 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.7977 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7951 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7945 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7987 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7964 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7954 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7989 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7943 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7964 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7959 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7960 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.8018 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7993 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7948 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7971 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7966 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7958 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7989 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7948 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7986 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7959 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.8004 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.7966 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7975 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7964 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7996 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7979 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7972 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7987 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7951 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7963 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7999 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5094 - accuracy: 0.7957 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.8004 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7951 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7948 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7988 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5077 - accuracy: 0.7970 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7953 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7986 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7946 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7991 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7991 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7987 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7949 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7963 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7988 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7960 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7989 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7993 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7999 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7954 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7962 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7973 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7980 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7977 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7964 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7931 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.8011 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7941 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7972 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7991 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7958 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7998 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7994 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7955 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7987 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7996 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7996 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7990 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7983 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7952 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7976 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7961 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7952 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7944 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580329D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7973 - recall_105: 0.0000e+00 - precision_105: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6793 - accuracy: 0.5640 - recall_106: 0.6319 - precision_106: 0.2626\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6765 - accuracy: 0.5654 - recall_106: 0.6234 - precision_106: 0.2612\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.5726 - recall_106: 0.6198 - precision_106: 0.2621\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.5764 - recall_106: 0.6111 - precision_106: 0.2605\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6651 - accuracy: 0.5832 - recall_106: 0.6027 - precision_106: 0.2668\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.5964 - recall_106: 0.6122 - precision_106: 0.2730\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.5959 - recall_106: 0.5934 - precision_106: 0.2718\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.6058 - recall_106: 0.5920 - precision_106: 0.2792\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.6058 - recall_106: 0.5714 - precision_106: 0.2711\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.6145 - recall_106: 0.5812 - precision_106: 0.2789\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.6211 - recall_106: 0.5730 - precision_106: 0.2876\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6261 - recall_106: 0.5610 - precision_106: 0.2824\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.6316 - recall_106: 0.5430 - precision_106: 0.2859\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6420 - recall_106: 0.5510 - precision_106: 0.2925\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6468 - recall_106: 0.5399 - precision_106: 0.2954\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.6529 - recall_106: 0.5220 - precision_106: 0.3005\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.6588 - recall_106: 0.5175 - precision_106: 0.3039\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.6583 - recall_106: 0.5085 - precision_106: 0.2988\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6171 - accuracy: 0.6653 - recall_106: 0.5022 - precision_106: 0.3027\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6150 - accuracy: 0.6672 - recall_106: 0.4825 - precision_106: 0.2938\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6131 - accuracy: 0.6770 - recall_106: 0.4860 - precision_106: 0.3119\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.6837 - recall_106: 0.4772 - precision_106: 0.3125\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6881 - recall_106: 0.4691 - precision_106: 0.3155\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.6897 - recall_106: 0.4659 - precision_106: 0.3193\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6971 - recall_106: 0.4545 - precision_106: 0.3168\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.6976 - recall_106: 0.4431 - precision_106: 0.3193\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.7023 - recall_106: 0.4350 - precision_106: 0.3192\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7008 - recall_106: 0.4344 - precision_106: 0.3267\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.7026 - recall_106: 0.4137 - precision_106: 0.3223\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.7133 - recall_106: 0.4231 - precision_106: 0.3347\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.7176 - recall_106: 0.4234 - precision_106: 0.3396\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7248 - recall_106: 0.4108 - precision_106: 0.3445\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.7210 - recall_106: 0.3940 - precision_106: 0.3432\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7295 - recall_106: 0.3908 - precision_106: 0.3472\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.7261 - recall_106: 0.3842 - precision_106: 0.3440\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.7311 - recall_106: 0.3664 - precision_106: 0.3418\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.7339 - recall_106: 0.3720 - precision_106: 0.3585\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5685 - accuracy: 0.7419 - recall_106: 0.3706 - precision_106: 0.3628\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7380 - recall_106: 0.3598 - precision_106: 0.3566\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.7400 - recall_106: 0.3527 - precision_106: 0.3676\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7463 - recall_106: 0.3567 - precision_106: 0.3594\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7443 - recall_106: 0.3440 - precision_106: 0.3630\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7471 - recall_106: 0.3468 - precision_106: 0.3754\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7555 - recall_106: 0.3425 - precision_106: 0.3854\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7535 - recall_106: 0.3362 - precision_106: 0.3770\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7552 - recall_106: 0.3197 - precision_106: 0.3791\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7625 - recall_106: 0.3181 - precision_106: 0.3855\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7651 - recall_106: 0.3214 - precision_106: 0.3916\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7634 - recall_106: 0.3055 - precision_106: 0.3944\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7683 - recall_106: 0.3020 - precision_106: 0.3999\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7657 - recall_106: 0.2984 - precision_106: 0.4010\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5470 - accuracy: 0.7723 - recall_106: 0.2939 - precision_106: 0.4075\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7723 - recall_106: 0.2973 - precision_106: 0.4132\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7760 - recall_106: 0.2884 - precision_106: 0.4130\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7777 - recall_106: 0.2854 - precision_106: 0.4294\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7793 - recall_106: 0.2782 - precision_106: 0.4285\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7813 - recall_106: 0.2840 - precision_106: 0.4432\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.7812 - recall_106: 0.2799 - precision_106: 0.4511\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7820 - recall_106: 0.2695 - precision_106: 0.4323\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7810 - recall_106: 0.2593 - precision_106: 0.4196\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7866 - recall_106: 0.2771 - precision_106: 0.4579\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.7852 - recall_106: 0.2539 - precision_106: 0.4415\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7864 - recall_106: 0.2479 - precision_106: 0.4466\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5299 - accuracy: 0.7881 - recall_106: 0.2463 - precision_106: 0.4504\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7891 - recall_106: 0.2379 - precision_106: 0.4532\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7895 - recall_106: 0.2460 - precision_106: 0.4675\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7852 - recall_106: 0.2282 - precision_106: 0.4548\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5251 - accuracy: 0.7918 - recall_106: 0.2297 - precision_106: 0.4740\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7917 - recall_106: 0.2238 - precision_106: 0.4643\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7909 - recall_106: 0.2283 - precision_106: 0.4767\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7921 - recall_106: 0.2199 - precision_106: 0.4747\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5227 - accuracy: 0.7924 - recall_106: 0.2179 - precision_106: 0.4709\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7951 - recall_106: 0.2200 - precision_106: 0.4821\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7984 - recall_106: 0.2176 - precision_106: 0.4926\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7967 - recall_106: 0.2211 - precision_106: 0.4971\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7980 - recall_106: 0.2127 - precision_106: 0.4890\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7964 - recall_106: 0.2076 - precision_106: 0.4913\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7937 - recall_106: 0.2012 - precision_106: 0.4834\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5128 - accuracy: 0.7994 - recall_106: 0.2034 - precision_106: 0.4986\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7987 - recall_106: 0.1977 - precision_106: 0.5037\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7984 - recall_106: 0.1975 - precision_106: 0.5006\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7981 - recall_106: 0.1981 - precision_106: 0.5010\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7995 - recall_106: 0.1971 - precision_106: 0.5032\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7978 - recall_106: 0.1860 - precision_106: 0.5011\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.8009 - recall_106: 0.1878 - precision_106: 0.5175\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.8025 - recall_106: 0.1912 - precision_106: 0.5160\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.8036 - recall_106: 0.1938 - precision_106: 0.5345\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.8012 - recall_106: 0.1904 - precision_106: 0.5323\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.8026 - recall_106: 0.1848 - precision_106: 0.5283\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8004 - recall_106: 0.1791 - precision_106: 0.5310\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.8027 - recall_106: 0.1753 - precision_106: 0.5306\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.8047 - recall_106: 0.1811 - precision_106: 0.5508\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.8034 - recall_106: 0.1696 - precision_106: 0.5345\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5056 - accuracy: 0.8025 - recall_106: 0.1683 - precision_106: 0.511 - 0s 4ms/step - loss: 0.5031 - accuracy: 0.8043 - recall_106: 0.1713 - precision_106: 0.5366\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8064 - recall_106: 0.1750 - precision_106: 0.5609\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.8060 - recall_106: 0.1719 - precision_106: 0.5599\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.8086 - recall_106: 0.1661 - precision_106: 0.5532\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.8066 - recall_106: 0.1676 - precision_106: 0.5534\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.8050 - recall_106: 0.1707 - precision_106: 0.5775\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.8076 - recall_106: 0.1663 - precision_106: 0.5662\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6552585E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.8055 - recall_106: 0.1734 - precision_106: 0.5655\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7489 - accuracy: 0.4581 - recall_107: 0.4425 - precision_107: 0.1721\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7481 - accuracy: 0.4554 - recall_107: 0.4223 - precision_107: 0.1648\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7417 - accuracy: 0.4643 - recall_107: 0.4253 - precision_107: 0.1671\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7377 - accuracy: 0.4671 - recall_107: 0.4295 - precision_107: 0.1719\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7350 - accuracy: 0.4751 - recall_107: 0.4114 - precision_107: 0.1692\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7329 - accuracy: 0.4761 - recall_107: 0.4152 - precision_107: 0.1732\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7302 - accuracy: 0.4790 - recall_107: 0.4071 - precision_107: 0.1755\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7264 - accuracy: 0.4777 - recall_107: 0.3920 - precision_107: 0.1639\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7229 - accuracy: 0.4850 - recall_107: 0.4023 - precision_107: 0.1714\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7184 - accuracy: 0.4918 - recall_107: 0.3924 - precision_107: 0.1718\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7162 - accuracy: 0.4958 - recall_107: 0.3905 - precision_107: 0.1752\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7116 - accuracy: 0.5026 - recall_107: 0.3769 - precision_107: 0.1712\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7097 - accuracy: 0.5036 - recall_107: 0.3651 - precision_107: 0.1643\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.5089 - recall_107: 0.3820 - precision_107: 0.1793\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7033 - accuracy: 0.5113 - recall_107: 0.3531 - precision_107: 0.1645\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7021 - accuracy: 0.5106 - recall_107: 0.3600 - precision_107: 0.1722\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.5187 - recall_107: 0.3540 - precision_107: 0.1711\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5223 - recall_107: 0.3428 - precision_107: 0.1681\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5230 - recall_107: 0.3310 - precision_107: 0.1653\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.5319 - recall_107: 0.3211 - precision_107: 0.1627\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.5345 - recall_107: 0.3209 - precision_107: 0.1663\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.5425 - recall_107: 0.3155 - precision_107: 0.1675\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.5443 - recall_107: 0.3106 - precision_107: 0.1692\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.5465 - recall_107: 0.3111 - precision_107: 0.1664\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.5569 - recall_107: 0.3026 - precision_107: 0.1689\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.5591 - recall_107: 0.3023 - precision_107: 0.1706\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.5630 - recall_107: 0.2926 - precision_107: 0.1699\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6670 - accuracy: 0.5739 - recall_107: 0.2833 - precision_107: 0.1701\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.5755 - recall_107: 0.2756 - precision_107: 0.1678\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.5820 - recall_107: 0.2692 - precision_107: 0.1723\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.5849 - recall_107: 0.2659 - precision_107: 0.1649\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.5917 - recall_107: 0.2540 - precision_107: 0.1660\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.5945 - recall_107: 0.2472 - precision_107: 0.1643\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.5994 - recall_107: 0.2443 - precision_107: 0.1672\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6076 - recall_107: 0.2437 - precision_107: 0.1681\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.6162 - recall_107: 0.2452 - precision_107: 0.1759\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6147 - recall_107: 0.2202 - precision_107: 0.1634\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.6183 - recall_107: 0.2194 - precision_107: 0.1657\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6197 - recall_107: 0.2147 - precision_107: 0.1647\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6266 - recall_107: 0.2138 - precision_107: 0.1677\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.6359 - recall_107: 0.2097 - precision_107: 0.1713\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.6364 - recall_107: 0.2066 - precision_107: 0.1740\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6391 - recall_107: 0.1926 - precision_107: 0.1673\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6444 - recall_107: 0.1891 - precision_107: 0.1688\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.6518 - recall_107: 0.1836 - precision_107: 0.1668\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.6574 - recall_107: 0.1903 - precision_107: 0.1789\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.6599 - recall_107: 0.1761 - precision_107: 0.1710\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.6608 - recall_107: 0.1725 - precision_107: 0.1698\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.6650 - recall_107: 0.1655 - precision_107: 0.1725\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.6739 - recall_107: 0.1662 - precision_107: 0.1714\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.6712 - recall_107: 0.1544 - precision_107: 0.1659\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.6790 - recall_107: 0.1581 - precision_107: 0.1740\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.6758 - recall_107: 0.1499 - precision_107: 0.1709\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.6807 - recall_107: 0.1509 - precision_107: 0.1779\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.6853 - recall_107: 0.1424 - precision_107: 0.1755\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6946 - recall_107: 0.1385 - precision_107: 0.1748\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.7009 - recall_107: 0.1374 - precision_107: 0.1799\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6961 - recall_107: 0.1188 - precision_107: 0.1579\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6034 - accuracy: 0.7073 - recall_107: 0.1251 - precision_107: 0.1745\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7068 - recall_107: 0.1123 - precision_107: 0.1649\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6022 - accuracy: 0.7095 - recall_107: 0.1177 - precision_107: 0.1758\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.7131 - recall_107: 0.1116 - precision_107: 0.1693\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.7158 - recall_107: 0.1072 - precision_107: 0.1729\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7211 - recall_107: 0.1129 - precision_107: 0.1859\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7197 - recall_107: 0.1025 - precision_107: 0.1761\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7258 - recall_107: 0.1051 - precision_107: 0.1809\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.7260 - recall_107: 0.0990 - precision_107: 0.1781\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7264 - recall_107: 0.0921 - precision_107: 0.1712\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.7288 - recall_107: 0.0917 - precision_107: 0.1783\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.7299 - recall_107: 0.0796 - precision_107: 0.1632\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.7361 - recall_107: 0.0909 - precision_107: 0.1832\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.7394 - recall_107: 0.0835 - precision_107: 0.1784\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7371 - recall_107: 0.0831 - precision_107: 0.1835\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5838 - accuracy: 0.7414 - recall_107: 0.0771 - precision_107: 0.1742\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5845 - accuracy: 0.7418 - recall_107: 0.0796 - precision_107: 0.1937\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.7471 - recall_107: 0.0777 - precision_107: 0.1904\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.7430 - recall_107: 0.0736 - precision_107: 0.1851\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.7482 - recall_107: 0.0683 - precision_107: 0.1857\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7502 - recall_107: 0.0719 - precision_107: 0.1965\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7511 - recall_107: 0.0668 - precision_107: 0.1856\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.7551 - recall_107: 0.0665 - precision_107: 0.1970\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7591 - recall_107: 0.0586 - precision_107: 0.1856\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7602 - recall_107: 0.0633 - precision_107: 0.2053\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.7654 - recall_107: 0.0623 - precision_107: 0.2126\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5705 - accuracy: 0.7657 - recall_107: 0.0692 - precision_107: 0.2220\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7665 - recall_107: 0.0647 - precision_107: 0.2279\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5707 - accuracy: 0.7627 - recall_107: 0.0618 - precision_107: 0.2277\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.7668 - recall_107: 0.0588 - precision_107: 0.2261\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7652 - recall_107: 0.0542 - precision_107: 0.2067\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.7680 - recall_107: 0.0601 - precision_107: 0.2287\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5638 - accuracy: 0.7679 - recall_107: 0.0543 - precision_107: 0.2133\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.7691 - recall_107: 0.0537 - precision_107: 0.2180\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7700 - recall_107: 0.0510 - precision_107: 0.2181\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7715 - recall_107: 0.0493 - precision_107: 0.2169\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7706 - recall_107: 0.0521 - precision_107: 0.2380\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7738 - recall_107: 0.0448 - precision_107: 0.2069\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5588 - accuracy: 0.7740 - recall_107: 0.0450 - precision_107: 0.2185\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5581 - accuracy: 0.7736 - recall_107: 0.0446 - precision_107: 0.2195\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.7762 - recall_107: 0.0457 - precision_107: 0.2424\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7800 - recall_107: 0.0428 - precision_107: 0.2360\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5CC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 0.5599 - accuracy: 0.7805 - recall_107: 0.0360 - precision_107: 0.2297\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7371 - accuracy: 0.4751 - recall_108: 0.3907 - precision_108: 0.1626\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7334 - accuracy: 0.4829 - recall_108: 0.3883 - precision_108: 0.1682\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7269 - accuracy: 0.4912 - recall_108: 0.3810 - precision_108: 0.1669\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7244 - accuracy: 0.4977 - recall_108: 0.3813 - precision_108: 0.1716\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7190 - accuracy: 0.5024 - recall_108: 0.3694 - precision_108: 0.1668\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7146 - accuracy: 0.5092 - recall_108: 0.3710 - precision_108: 0.1678\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7103 - accuracy: 0.5140 - recall_108: 0.3459 - precision_108: 0.1639\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7059 - accuracy: 0.5256 - recall_108: 0.3536 - precision_108: 0.1719\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.5287 - recall_108: 0.3459 - precision_108: 0.1709\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.5379 - recall_108: 0.3438 - precision_108: 0.1761\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5492 - recall_108: 0.3621 - precision_108: 0.1834\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5569 - recall_108: 0.3348 - precision_108: 0.1771\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.5585 - recall_108: 0.3370 - precision_108: 0.1831\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.5657 - recall_108: 0.3406 - precision_108: 0.1894\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.5730 - recall_108: 0.3362 - precision_108: 0.1891\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.5770 - recall_108: 0.3292 - precision_108: 0.1920\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.5859 - recall_108: 0.3156 - precision_108: 0.1890\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.5856 - recall_108: 0.3137 - precision_108: 0.1836\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6628 - accuracy: 0.5951 - recall_108: 0.3078 - precision_108: 0.1905\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.6044 - recall_108: 0.3128 - precision_108: 0.1969\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6530 - accuracy: 0.6130 - recall_108: 0.3052 - precision_108: 0.1975\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.6222 - recall_108: 0.3101 - precision_108: 0.2055\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6228 - recall_108: 0.3054 - precision_108: 0.2054\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.6258 - recall_108: 0.2898 - precision_108: 0.2033\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6364 - recall_108: 0.2966 - precision_108: 0.2162\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.6391 - recall_108: 0.2902 - precision_108: 0.2150\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.6435 - recall_108: 0.2739 - precision_108: 0.2102\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6501 - recall_108: 0.2789 - precision_108: 0.2221\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.6540 - recall_108: 0.2725 - precision_108: 0.2231\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.6661 - recall_108: 0.2743 - precision_108: 0.2268\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.6685 - recall_108: 0.2696 - precision_108: 0.2257\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6242 - accuracy: 0.6740 - recall_108: 0.2653 - precision_108: 0.250 - 0s 4ms/step - loss: 0.6219 - accuracy: 0.6743 - recall_108: 0.2666 - precision_108: 0.2385\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6176 - accuracy: 0.6772 - recall_108: 0.2707 - precision_108: 0.2388\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.6779 - recall_108: 0.2489 - precision_108: 0.2291\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.6809 - recall_108: 0.2453 - precision_108: 0.2338\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.6892 - recall_108: 0.2509 - precision_108: 0.2448\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.6906 - recall_108: 0.2469 - precision_108: 0.2381\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.6933 - recall_108: 0.2321 - precision_108: 0.2351\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.6976 - recall_108: 0.2367 - precision_108: 0.2440\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.6972 - recall_108: 0.2244 - precision_108: 0.2385\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.7015 - recall_108: 0.2214 - precision_108: 0.2390\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.7073 - recall_108: 0.2306 - precision_108: 0.2488\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.7114 - recall_108: 0.2273 - precision_108: 0.2545\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7099 - recall_108: 0.2241 - precision_108: 0.2532\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7132 - recall_108: 0.2145 - precision_108: 0.2543\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7175 - recall_108: 0.2115 - precision_108: 0.2540\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5877 - accuracy: 0.7177 - recall_108: 0.2004 - precision_108: 0.2540\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.7205 - recall_108: 0.2086 - precision_108: 0.2617\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7230 - recall_108: 0.2114 - precision_108: 0.2742\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5801 - accuracy: 0.7263 - recall_108: 0.2048 - precision_108: 0.2665\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5798 - accuracy: 0.7263 - recall_108: 0.1934 - precision_108: 0.2647\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7319 - recall_108: 0.2009 - precision_108: 0.2779\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7322 - recall_108: 0.1953 - precision_108: 0.2680\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7341 - recall_108: 0.1877 - precision_108: 0.2761\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7382 - recall_108: 0.1829 - precision_108: 0.2751\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.7405 - recall_108: 0.1840 - precision_108: 0.2867\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7409 - recall_108: 0.1758 - precision_108: 0.2795\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7476 - recall_108: 0.1740 - precision_108: 0.2916\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.7474 - recall_108: 0.1710 - precision_108: 0.2843\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7469 - recall_108: 0.1690 - precision_108: 0.2867\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7480 - recall_108: 0.1715 - precision_108: 0.2872\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7515 - recall_108: 0.1650 - precision_108: 0.2836\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7485 - recall_108: 0.1621 - precision_108: 0.2856\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7487 - recall_108: 0.1639 - precision_108: 0.2984\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7527 - recall_108: 0.1564 - precision_108: 0.2857\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7548 - recall_108: 0.1593 - precision_108: 0.2933\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7530 - recall_108: 0.1567 - precision_108: 0.2965\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.7534 - recall_108: 0.1532 - precision_108: 0.2916\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7537 - recall_108: 0.1491 - precision_108: 0.2951\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7561 - recall_108: 0.1457 - precision_108: 0.2950\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7558 - recall_108: 0.1500 - precision_108: 0.3028\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7619 - recall_108: 0.1535 - precision_108: 0.3110\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7633 - recall_108: 0.1487 - precision_108: 0.3169\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7649 - recall_108: 0.1495 - precision_108: 0.3079\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7556 - recall_108: 0.1346 - precision_108: 0.3062\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7633 - recall_108: 0.1339 - precision_108: 0.2948\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7607 - recall_108: 0.1322 - precision_108: 0.2969\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7636 - recall_108: 0.1327 - precision_108: 0.3022\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7625 - recall_108: 0.1327 - precision_108: 0.3189\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7693 - recall_108: 0.1320 - precision_108: 0.3127\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7654 - recall_108: 0.1302 - precision_108: 0.3237\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7673 - recall_108: 0.1323 - precision_108: 0.3311\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7691 - recall_108: 0.1240 - precision_108: 0.3170\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7695 - recall_108: 0.1213 - precision_108: 0.3268\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7693 - recall_108: 0.1208 - precision_108: 0.3141\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7735 - recall_108: 0.1268 - precision_108: 0.3374\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7749 - recall_108: 0.1171 - precision_108: 0.3141\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7694 - recall_108: 0.1146 - precision_108: 0.3222\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7754 - recall_108: 0.1174 - precision_108: 0.3323\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7750 - recall_108: 0.1087 - precision_108: 0.3182\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7738 - recall_108: 0.1083 - precision_108: 0.3281\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5208 - accuracy: 0.7789 - recall_108: 0.1214 - precision_108: 0.3614\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7728 - recall_108: 0.1111 - precision_108: 0.3540\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7762 - recall_108: 0.1094 - precision_108: 0.3484\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.7812 - recall_108: 0.1081 - precision_108: 0.3479\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7796 - recall_108: 0.1095 - precision_108: 0.3515\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7811 - recall_108: 0.1076 - precision_108: 0.3676\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7792 - recall_108: 0.1033 - precision_108: 0.3489\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7800 - recall_108: 0.0996 - precision_108: 0.3544\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5169 - accuracy: 0.7790 - recall_108: 0.0977 - precision_108: 0.3528\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580A5AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7801 - recall_108: 0.1163 - precision_108: 0.3667\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6724 - accuracy: 0.5819 - recall_109: 0.6659 - precision_109: 0.2749\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.5954 - recall_109: 0.6561 - precision_109: 0.2811\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6124 - recall_109: 0.6259 - precision_109: 0.2920\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6323 - recall_109: 0.6133 - precision_109: 0.3001\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6318 - accuracy: 0.6449 - recall_109: 0.6030 - precision_109: 0.3055\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.6585 - recall_109: 0.5811 - precision_109: 0.3108\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6140 - accuracy: 0.6721 - recall_109: 0.5541 - precision_109: 0.3228\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.6814 - recall_109: 0.5370 - precision_109: 0.3248\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.6900 - recall_109: 0.5020 - precision_109: 0.3263\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.6965 - recall_109: 0.4868 - precision_109: 0.3313\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.7059 - recall_109: 0.4726 - precision_109: 0.3371\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5796 - accuracy: 0.7182 - recall_109: 0.4594 - precision_109: 0.3481\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5749 - accuracy: 0.7184 - recall_109: 0.4258 - precision_109: 0.3441\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5676 - accuracy: 0.7305 - recall_109: 0.4047 - precision_109: 0.3516\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7362 - recall_109: 0.4016 - precision_109: 0.3602\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7412 - recall_109: 0.3869 - precision_109: 0.3654\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7499 - recall_109: 0.3741 - precision_109: 0.3791\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7553 - recall_109: 0.3537 - precision_109: 0.3847\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7590 - recall_109: 0.3451 - precision_109: 0.3851\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7635 - recall_109: 0.3359 - precision_109: 0.3945\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7656 - recall_109: 0.3110 - precision_109: 0.3985\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7666 - recall_109: 0.3031 - precision_109: 0.3954\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7712 - recall_109: 0.2925 - precision_109: 0.4135\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7752 - recall_109: 0.2867 - precision_109: 0.4213\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7765 - recall_109: 0.2756 - precision_109: 0.4164\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7782 - recall_109: 0.2647 - precision_109: 0.4349\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7795 - recall_109: 0.2536 - precision_109: 0.4334\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7862 - recall_109: 0.2495 - precision_109: 0.4413\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7865 - recall_109: 0.2401 - precision_109: 0.4482\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7844 - recall_109: 0.2285 - precision_109: 0.4481\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7877 - recall_109: 0.2215 - precision_109: 0.4463\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7889 - recall_109: 0.2237 - precision_109: 0.4605\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7941 - recall_109: 0.2195 - precision_109: 0.4704\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.7875 - recall_109: 0.2028 - precision_109: 0.4626\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7917 - recall_109: 0.1995 - precision_109: 0.4576\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.7926 - recall_109: 0.1987 - precision_109: 0.4737\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7938 - recall_109: 0.2023 - precision_109: 0.4808\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7944 - recall_109: 0.1865 - precision_109: 0.4766\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7943 - recall_109: 0.1830 - precision_109: 0.4828\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7918 - recall_109: 0.1811 - precision_109: 0.4616\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7893 - recall_109: 0.1691 - precision_109: 0.4675\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7939 - recall_109: 0.1647 - precision_109: 0.4731\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7924 - recall_109: 0.1572 - precision_109: 0.4789\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7948 - recall_109: 0.1544 - precision_109: 0.4801\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7958 - recall_109: 0.1574 - precision_109: 0.4809\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7973 - recall_109: 0.1607 - precision_109: 0.4959\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7926 - recall_109: 0.1463 - precision_109: 0.4767\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7946 - recall_109: 0.1389 - precision_109: 0.4899\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7980 - recall_109: 0.1418 - precision_109: 0.5081\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.7954 - recall_109: 0.1358 - precision_109: 0.4834\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7955 - recall_109: 0.1274 - precision_109: 0.4754\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7977 - recall_109: 0.1273 - precision_109: 0.5000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7971 - recall_109: 0.1251 - precision_109: 0.4932\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.8021 - recall_109: 0.1283 - precision_109: 0.5051\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7980 - recall_109: 0.1232 - precision_109: 0.5098\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7977 - recall_109: 0.1239 - precision_109: 0.5353\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7987 - recall_109: 0.1277 - precision_109: 0.5411\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.8012 - recall_109: 0.1208 - precision_109: 0.5368\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.8045 - recall_109: 0.1184 - precision_109: 0.5457\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.8051 - recall_109: 0.1166 - precision_109: 0.5577\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.8021 - recall_109: 0.1166 - precision_109: 0.5551\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.8023 - recall_109: 0.1167 - precision_109: 0.5543\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.8008 - recall_109: 0.1120 - precision_109: 0.5609\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8006 - recall_109: 0.1081 - precision_109: 0.5501\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.8010 - recall_109: 0.1079 - precision_109: 0.5567\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.8020 - recall_109: 0.1190 - precision_109: 0.5783\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.8024 - recall_109: 0.1127 - precision_109: 0.5854\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8036 - recall_109: 0.1021 - precision_109: 0.5728\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7991 - recall_109: 0.1036 - precision_109: 0.5592\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4527 - accuracy: 0.8080 - recall_109: 0.0977 - precision_109: 0.535 - 0s 4ms/step - loss: 0.4562 - accuracy: 0.8039 - recall_109: 0.1023 - precision_109: 0.5683\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.8044 - recall_109: 0.1052 - precision_109: 0.5907\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.8071 - recall_109: 0.1003 - precision_109: 0.5833\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7989 - recall_109: 0.1034 - precision_109: 0.5980\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8081 - recall_109: 0.0963 - precision_109: 0.5942\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.8036 - recall_109: 0.1019 - precision_109: 0.5838\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.8063 - recall_109: 0.1023 - precision_109: 0.6088\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.8043 - recall_109: 0.1028 - precision_109: 0.5810\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.8020 - recall_109: 0.1002 - precision_109: 0.5952\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.8008 - recall_109: 0.0982 - precision_109: 0.5967\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.8062 - recall_109: 0.1014 - precision_109: 0.5982\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8029 - recall_109: 0.0936 - precision_109: 0.5864\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.8025 - recall_109: 0.0999 - precision_109: 0.6122\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.8034 - recall_109: 0.1009 - precision_109: 0.6122\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8042 - recall_109: 0.1040 - precision_109: 0.6072\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8059 - recall_109: 0.0985 - precision_109: 0.5849\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8016 - recall_109: 0.0918 - precision_109: 0.5807\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8040 - recall_109: 0.0886 - precision_109: 0.5983\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.8055 - recall_109: 0.0969 - precision_109: 0.5941\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8035 - recall_109: 0.1019 - precision_109: 0.6179\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.8060 - recall_109: 0.0961 - precision_109: 0.6207\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.8047 - recall_109: 0.0956 - precision_109: 0.6092\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8012 - recall_109: 0.0965 - precision_109: 0.6037\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8039 - recall_109: 0.0922 - precision_109: 0.6256\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8080 - recall_109: 0.0955 - precision_109: 0.5953\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8048 - recall_109: 0.0925 - precision_109: 0.6209\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.8026 - recall_109: 0.1003 - precision_109: 0.6171\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.8034 - recall_109: 0.0913 - precision_109: 0.6064\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8048 - recall_109: 0.0954 - precision_109: 0.6193\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.8066 - recall_109: 0.0953 - precision_109: 0.6193\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.8079 - recall_109: 0.1028 - precision_109: 0.6204\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C6AF4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.4364 - accuracy: 0.8025 - recall_109: 0.1121 - precision_109: 0.5638\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7083 - accuracy: 0.4988 - recall_110: 0.4860 - precision_110: 0.1983\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7021 - accuracy: 0.5099 - recall_110: 0.4836 - precision_110: 0.2058\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6974 - accuracy: 0.5154 - recall_110: 0.4573 - precision_110: 0.1993\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5235 - recall_110: 0.4484 - precision_110: 0.1994\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5406 - recall_110: 0.4461 - precision_110: 0.2069\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.5492 - recall_110: 0.4344 - precision_110: 0.2084\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6776 - accuracy: 0.5591 - recall_110: 0.4160 - precision_110: 0.2059\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.5660 - recall_110: 0.4122 - precision_110: 0.2109\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.5759 - recall_110: 0.3995 - precision_110: 0.2134\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.5918 - recall_110: 0.3971 - precision_110: 0.2212\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.6002 - recall_110: 0.3832 - precision_110: 0.2223\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6561 - accuracy: 0.6050 - recall_110: 0.3824 - precision_110: 0.211 - 0s 4ms/step - loss: 0.6558 - accuracy: 0.6070 - recall_110: 0.3703 - precision_110: 0.2172\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.6163 - recall_110: 0.3440 - precision_110: 0.2141\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.6253 - recall_110: 0.3318 - precision_110: 0.2220\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6430 - recall_110: 0.3335 - precision_110: 0.2284\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.6526 - recall_110: 0.3266 - precision_110: 0.2390\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.6600 - recall_110: 0.3076 - precision_110: 0.2361\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6706 - recall_110: 0.2994 - precision_110: 0.2449\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.6817 - recall_110: 0.3047 - precision_110: 0.2564\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6876 - recall_110: 0.2951 - precision_110: 0.2630\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6985 - recall_110: 0.2800 - precision_110: 0.2692\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.7135 - recall_110: 0.2744 - precision_110: 0.2801\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.7143 - recall_110: 0.2670 - precision_110: 0.2822\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6124 - accuracy: 0.7235 - recall_110: 0.2585 - precision_110: 0.2936\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.7228 - recall_110: 0.2382 - precision_110: 0.2858\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.7316 - recall_110: 0.2386 - precision_110: 0.3060\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.7351 - recall_110: 0.2259 - precision_110: 0.2951\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7415 - recall_110: 0.2136 - precision_110: 0.2959\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.7423 - recall_110: 0.2023 - precision_110: 0.2994\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.7466 - recall_110: 0.1913 - precision_110: 0.3026\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.7482 - recall_110: 0.1897 - precision_110: 0.3093\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.7582 - recall_110: 0.1947 - precision_110: 0.3358\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.7610 - recall_110: 0.1781 - precision_110: 0.3364\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5832 - accuracy: 0.7709 - recall_110: 0.1740 - precision_110: 0.3447\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.7672 - recall_110: 0.1707 - precision_110: 0.3496\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.7729 - recall_110: 0.1744 - precision_110: 0.3752\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.7759 - recall_110: 0.1656 - precision_110: 0.3803\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.7764 - recall_110: 0.1595 - precision_110: 0.3916\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.7790 - recall_110: 0.1494 - precision_110: 0.3922\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7837 - recall_110: 0.1509 - precision_110: 0.4018\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5681 - accuracy: 0.7845 - recall_110: 0.1473 - precision_110: 0.4103\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.7825 - recall_110: 0.1291 - precision_110: 0.4013\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7841 - recall_110: 0.1256 - precision_110: 0.3975\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7906 - recall_110: 0.1279 - precision_110: 0.4298\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7899 - recall_110: 0.1225 - precision_110: 0.4413\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.7916 - recall_110: 0.1093 - precision_110: 0.4318\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.7935 - recall_110: 0.1133 - precision_110: 0.464 - 0s 4ms/step - loss: 0.5556 - accuracy: 0.7910 - recall_110: 0.1059 - precision_110: 0.4406\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7919 - recall_110: 0.1041 - precision_110: 0.4603\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7925 - recall_110: 0.0974 - precision_110: 0.4341\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7901 - recall_110: 0.0938 - precision_110: 0.4653\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7918 - recall_110: 0.0863 - precision_110: 0.4443\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7924 - recall_110: 0.0923 - precision_110: 0.4627\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7962 - recall_110: 0.0864 - precision_110: 0.4565\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7967 - recall_110: 0.0822 - precision_110: 0.4617\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7951 - recall_110: 0.0814 - precision_110: 0.4584\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7941 - recall_110: 0.0785 - precision_110: 0.4618\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7943 - recall_110: 0.0779 - precision_110: 0.4783\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7952 - recall_110: 0.0753 - precision_110: 0.4611\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7977 - recall_110: 0.0762 - precision_110: 0.4967\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7992 - recall_110: 0.0694 - precision_110: 0.4575\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7958 - recall_110: 0.0723 - precision_110: 0.5097\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7952 - recall_110: 0.0653 - precision_110: 0.4733\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7985 - recall_110: 0.0667 - precision_110: 0.4695\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.8003 - recall_110: 0.0707 - precision_110: 0.5361\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7990 - recall_110: 0.0656 - precision_110: 0.5145\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7967 - recall_110: 0.0611 - precision_110: 0.4834\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.7998 - recall_110: 0.0635 - precision_110: 0.4943\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.7961 - recall_110: 0.0570 - precision_110: 0.4787\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5203 - accuracy: 0.7992 - recall_110: 0.0525 - precision_110: 0.4926\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7930 - recall_110: 0.0530 - precision_110: 0.4893\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7983 - recall_110: 0.0567 - precision_110: 0.5387\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7997 - recall_110: 0.0545 - precision_110: 0.5503\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7993 - recall_110: 0.0573 - precision_110: 0.5968\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7999 - recall_110: 0.0599 - precision_110: 0.5870\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7986 - recall_110: 0.0573 - precision_110: 0.6083\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.8019 - recall_110: 0.0558 - precision_110: 0.5731\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.8011 - recall_110: 0.0576 - precision_110: 0.5909\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7982 - recall_110: 0.0539 - precision_110: 0.5838\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.8019 - recall_110: 0.0518 - precision_110: 0.5860\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7996 - recall_110: 0.0517 - precision_110: 0.6036\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.8018 - recall_110: 0.0531 - precision_110: 0.5769\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.8002 - recall_110: 0.0614 - precision_110: 0.6614\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.8003 - recall_110: 0.0564 - precision_110: 0.6408\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.8033 - recall_110: 0.0548 - precision_110: 0.6206\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.8003 - recall_110: 0.0541 - precision_110: 0.6478\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.8004 - recall_110: 0.0590 - precision_110: 0.6594\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8007 - recall_110: 0.0503 - precision_110: 0.6063\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8048 - recall_110: 0.0548 - precision_110: 0.6417\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.8023 - recall_110: 0.0566 - precision_110: 0.6649\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.8018 - recall_110: 0.0518 - precision_110: 0.6291\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7955 - recall_110: 0.0512 - precision_110: 0.6203\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7992 - recall_110: 0.0515 - precision_110: 0.6266\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.8005 - recall_110: 0.0524 - precision_110: 0.6476\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.8041 - recall_110: 0.0502 - precision_110: 0.6334\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.8009 - recall_110: 0.0511 - precision_110: 0.6493\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.8014 - recall_110: 0.0506 - precision_110: 0.6524\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.8036 - recall_110: 0.0495 - precision_110: 0.6144\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.8026 - recall_110: 0.0541 - precision_110: 0.6481\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.8020 - recall_110: 0.0513 - precision_110: 0.6419\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.8008 - recall_110: 0.0498 - precision_110: 0.6202\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580329D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.8045 - recall_110: 0.0508 - precision_110: 0.7500\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7870 - accuracy: 0.4067 - recall_111: 0.2399 - precision_111: 0.0982\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7809 - accuracy: 0.4139 - recall_111: 0.2285 - precision_111: 0.0971\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7710 - accuracy: 0.4267 - recall_111: 0.2251 - precision_111: 0.0976\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7652 - accuracy: 0.4345 - recall_111: 0.2198 - precision_111: 0.0982\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7594 - accuracy: 0.4459 - recall_111: 0.2026 - precision_111: 0.0974\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7533 - accuracy: 0.4551 - recall_111: 0.1951 - precision_111: 0.0952\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7474 - accuracy: 0.4637 - recall_111: 0.1854 - precision_111: 0.0935\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.4637 - recall_111: 0.1747 - precision_111: 0.0893\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7376 - accuracy: 0.4759 - recall_111: 0.1647 - precision_111: 0.0856\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7313 - accuracy: 0.4858 - recall_111: 0.1677 - precision_111: 0.0908\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7257 - accuracy: 0.4927 - recall_111: 0.1536 - precision_111: 0.0840\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7200 - accuracy: 0.5022 - recall_111: 0.1460 - precision_111: 0.0854\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7146 - accuracy: 0.5070 - recall_111: 0.1456 - precision_111: 0.0834\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.5207 - recall_111: 0.1275 - precision_111: 0.0804\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7039 - accuracy: 0.5337 - recall_111: 0.1265 - precision_111: 0.0813\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6982 - accuracy: 0.5430 - recall_111: 0.1246 - precision_111: 0.0814\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6946 - accuracy: 0.5528 - recall_111: 0.1153 - precision_111: 0.0794\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5626 - recall_111: 0.1059 - precision_111: 0.0756\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.5676 - recall_111: 0.0927 - precision_111: 0.0693\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.5726 - recall_111: 0.0912 - precision_111: 0.0716\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6768 - accuracy: 0.5876 - recall_111: 0.0905 - precision_111: 0.0726\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.5966 - recall_111: 0.0821 - precision_111: 0.0709\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6030 - recall_111: 0.0714 - precision_111: 0.0635\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.6093 - recall_111: 0.0733 - precision_111: 0.0698\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6168 - recall_111: 0.0644 - precision_111: 0.0645\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6276 - recall_111: 0.0626 - precision_111: 0.0641\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6373 - recall_111: 0.0599 - precision_111: 0.0657\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6506 - accuracy: 0.6424 - recall_111: 0.0552 - precision_111: 0.0624\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.6552 - recall_111: 0.0493 - precision_111: 0.0623\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.6658 - recall_111: 0.0503 - precision_111: 0.0665\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.6744 - recall_111: 0.0418 - precision_111: 0.0605\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6779 - recall_111: 0.0397 - precision_111: 0.0603\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6894 - recall_111: 0.0393 - precision_111: 0.0675\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6978 - recall_111: 0.0371 - precision_111: 0.0670\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.7038 - recall_111: 0.0339 - precision_111: 0.0658\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.7097 - recall_111: 0.0274 - precision_111: 0.0569\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.7177 - recall_111: 0.0279 - precision_111: 0.0625\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.7212 - recall_111: 0.0291 - precision_111: 0.0660\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.7289 - recall_111: 0.0219 - precision_111: 0.0564\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6165 - accuracy: 0.7304 - recall_111: 0.0214 - precision_111: 0.0597\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.7348 - recall_111: 0.0218 - precision_111: 0.0649\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6129 - accuracy: 0.7353 - recall_111: 0.0139 - precision_111: 0.0448\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.7467 - recall_111: 0.0148 - precision_111: 0.0529\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.7540 - recall_111: 0.0159 - precision_111: 0.0616\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.7576 - recall_111: 0.0118 - precision_111: 0.0502\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.7597 - recall_111: 0.0111 - precision_111: 0.0522\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.7661 - recall_111: 0.0128 - precision_111: 0.0663\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.7644 - recall_111: 0.0097 - precision_111: 0.0536\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7670 - recall_111: 0.0099 - precision_111: 0.0616\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.7744 - recall_111: 0.0082 - precision_111: 0.0571\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.7747 - recall_111: 0.0085 - precision_111: 0.0588\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.7791 - recall_111: 0.0047 - precision_111: 0.0422\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7806 - recall_111: 0.0055 - precision_111: 0.0537\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.7807 - recall_111: 0.0035 - precision_111: 0.0352\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7833 - recall_111: 0.0044 - precision_111: 0.0533\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.7806 - recall_111: 0.0029 - precision_111: 0.0360\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.7853 - recall_111: 0.0023 - precision_111: 0.0355\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.7819 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.7867 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7868 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7861 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7901 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7917 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5679 - accuracy: 0.7908 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5698 - accuracy: 0.7888 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5636 - accuracy: 0.7932 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7915 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.7945 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7928 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.7956 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7952 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7948 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7951 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7943 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7997 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.7963 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7986 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7953 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7955 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.7998 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7968 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5435 - accuracy: 0.7985 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7980 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7950 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7972 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7983 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.8001 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7958 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7957 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7968 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7986 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.8004 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7994 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7988 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7979 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7939 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.7969 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7953 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7981 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7984 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE7EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.7973 - recall_111: 0.0000e+00 - precision_111: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7615 - accuracy: 0.4579 - recall_112: 0.4577 - precision_112: 0.1770\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7588 - accuracy: 0.4650 - recall_112: 0.4486 - precision_112: 0.1767\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7563 - accuracy: 0.4688 - recall_112: 0.4598 - precision_112: 0.1809\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.4777 - recall_112: 0.4515 - precision_112: 0.1805\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7503 - accuracy: 0.4773 - recall_112: 0.4450 - precision_112: 0.1794\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.4772 - recall_112: 0.4313 - precision_112: 0.1748\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.4821 - recall_112: 0.4394 - precision_112: 0.1846\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7414 - accuracy: 0.4897 - recall_112: 0.4429 - precision_112: 0.1821\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7416 - accuracy: 0.4842 - recall_112: 0.4215 - precision_112: 0.1777\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7415 - accuracy: 0.4880 - recall_112: 0.4270 - precision_112: 0.1805\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7360 - accuracy: 0.4960 - recall_112: 0.4307 - precision_112: 0.1837\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7325 - accuracy: 0.4986 - recall_112: 0.4296 - precision_112: 0.1827\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7307 - accuracy: 0.4991 - recall_112: 0.4118 - precision_112: 0.1782\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7297 - accuracy: 0.5036 - recall_112: 0.4207 - precision_112: 0.1864\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7262 - accuracy: 0.5118 - recall_112: 0.4188 - precision_112: 0.1891\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7233 - accuracy: 0.5123 - recall_112: 0.4185 - precision_112: 0.1883\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7211 - accuracy: 0.5156 - recall_112: 0.4151 - precision_112: 0.1899\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7191 - accuracy: 0.5216 - recall_112: 0.4157 - precision_112: 0.1861\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7183 - accuracy: 0.5219 - recall_112: 0.4161 - precision_112: 0.1889\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7155 - accuracy: 0.5284 - recall_112: 0.4159 - precision_112: 0.1944\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7128 - accuracy: 0.5293 - recall_112: 0.4170 - precision_112: 0.1910\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7128 - accuracy: 0.5299 - recall_112: 0.4062 - precision_112: 0.1916\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7077 - accuracy: 0.5376 - recall_112: 0.4113 - precision_112: 0.1939\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7050 - accuracy: 0.5385 - recall_112: 0.4010 - precision_112: 0.197 - 0s 4ms/step - loss: 0.7063 - accuracy: 0.5379 - recall_112: 0.4001 - precision_112: 0.1928\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7060 - accuracy: 0.5379 - recall_112: 0.4056 - precision_112: 0.1935\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7039 - accuracy: 0.5405 - recall_112: 0.3945 - precision_112: 0.1983\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7021 - accuracy: 0.5436 - recall_112: 0.3889 - precision_112: 0.1899\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7007 - accuracy: 0.5465 - recall_112: 0.3894 - precision_112: 0.1917\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6954 - accuracy: 0.5529 - recall_112: 0.3849 - precision_112: 0.1953\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6953 - accuracy: 0.5526 - recall_112: 0.3818 - precision_112: 0.1938\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5635 - recall_112: 0.3964 - precision_112: 0.2001\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.5593 - recall_112: 0.3745 - precision_112: 0.1990\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5643 - recall_112: 0.3737 - precision_112: 0.2005\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5627 - recall_112: 0.3704 - precision_112: 0.1976\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5676 - recall_112: 0.3768 - precision_112: 0.2011\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.5699 - recall_112: 0.3652 - precision_112: 0.1941\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.5748 - recall_112: 0.3679 - precision_112: 0.2006\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.5798 - recall_112: 0.3678 - precision_112: 0.2021\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.5811 - recall_112: 0.3675 - precision_112: 0.2045\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.5836 - recall_112: 0.3648 - precision_112: 0.2007\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.5827 - recall_112: 0.3645 - precision_112: 0.2021\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6726 - accuracy: 0.5839 - recall_112: 0.3636 - precision_112: 0.2070\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.5874 - recall_112: 0.3570 - precision_112: 0.2071\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.5882 - recall_112: 0.3552 - precision_112: 0.2052\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.5934 - recall_112: 0.3472 - precision_112: 0.2044\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6635 - accuracy: 0.5978 - recall_112: 0.3527 - precision_112: 0.2056\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.5983 - recall_112: 0.3404 - precision_112: 0.2041\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.5999 - recall_112: 0.3325 - precision_112: 0.2033\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.6031 - recall_112: 0.3408 - precision_112: 0.2078\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.6103 - recall_112: 0.3391 - precision_112: 0.2120\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6547 - accuracy: 0.6149 - recall_112: 0.3407 - precision_112: 0.2102\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.6176 - recall_112: 0.3313 - precision_112: 0.2119\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.6163 - recall_112: 0.3399 - precision_112: 0.2083\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.6166 - recall_112: 0.3306 - precision_112: 0.2118\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6158 - recall_112: 0.3239 - precision_112: 0.2108\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6174 - recall_112: 0.3305 - precision_112: 0.2161\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6466 - accuracy: 0.6245 - recall_112: 0.3200 - precision_112: 0.2099\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.6262 - recall_112: 0.3220 - precision_112: 0.2190\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.6242 - recall_112: 0.3119 - precision_112: 0.2106\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6280 - recall_112: 0.3150 - precision_112: 0.2181\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.6343 - recall_112: 0.3208 - precision_112: 0.2258\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.6391 - recall_112: 0.3207 - precision_112: 0.2283\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6363 - accuracy: 0.6450 - recall_112: 0.3350 - precision_112: 0.229 - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6391 - recall_112: 0.3168 - precision_112: 0.2220\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.6403 - recall_112: 0.3077 - precision_112: 0.2228\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6434 - recall_112: 0.3046 - precision_112: 0.2232\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6448 - recall_112: 0.3059 - precision_112: 0.2240\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6319 - accuracy: 0.6498 - recall_112: 0.2997 - precision_112: 0.2240\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6546 - recall_112: 0.3026 - precision_112: 0.2253\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.6595 - recall_112: 0.2952 - precision_112: 0.2329\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.6620 - recall_112: 0.3002 - precision_112: 0.2325\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.6646 - recall_112: 0.2863 - precision_112: 0.2268\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6643 - recall_112: 0.2884 - precision_112: 0.2351\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.6667 - recall_112: 0.2865 - precision_112: 0.2369\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6237 - accuracy: 0.6673 - recall_112: 0.2868 - precision_112: 0.2407\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6220 - accuracy: 0.6714 - recall_112: 0.2863 - precision_112: 0.2402\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.6748 - recall_112: 0.2843 - precision_112: 0.2414\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6193 - accuracy: 0.6773 - recall_112: 0.2792 - precision_112: 0.2420\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.6774 - recall_112: 0.2703 - precision_112: 0.2351\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.6790 - recall_112: 0.2734 - precision_112: 0.2398\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6146 - accuracy: 0.6830 - recall_112: 0.2666 - precision_112: 0.2456\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6119 - accuracy: 0.6874 - recall_112: 0.2671 - precision_112: 0.2485\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.6862 - recall_112: 0.2616 - precision_112: 0.2483\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6142 - accuracy: 0.6851 - recall_112: 0.2561 - precision_112: 0.2450\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6904 - recall_112: 0.2557 - precision_112: 0.2423\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6956 - recall_112: 0.2618 - precision_112: 0.2545\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.6969 - recall_112: 0.2532 - precision_112: 0.2477\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6057 - accuracy: 0.6990 - recall_112: 0.2532 - precision_112: 0.2496\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.7015 - recall_112: 0.2517 - precision_112: 0.2542\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.6976 - recall_112: 0.2463 - precision_112: 0.2546\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.7042 - recall_112: 0.2432 - precision_112: 0.2576\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6033 - accuracy: 0.7040 - recall_112: 0.2362 - precision_112: 0.2512\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.7058 - recall_112: 0.2368 - precision_112: 0.2542\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.7038 - recall_112: 0.2273 - precision_112: 0.2499\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.7056 - recall_112: 0.2314 - precision_112: 0.2535\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5974 - accuracy: 0.7125 - recall_112: 0.2325 - precision_112: 0.2554\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7122 - recall_112: 0.2213 - precision_112: 0.2530\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.7151 - recall_112: 0.2234 - precision_112: 0.2604\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.7209 - recall_112: 0.2282 - precision_112: 0.2657\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.7171 - recall_112: 0.2119 - precision_112: 0.2514\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.7161 - recall_112: 0.2156 - precision_112: 0.2657\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A548B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.7279 - recall_112: 0.2326 - precision_112: 0.2880\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6823 - accuracy: 0.5843 - recall_113: 0.6374 - precision_113: 0.2694\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6804 - accuracy: 0.5842 - recall_113: 0.6249 - precision_113: 0.2722\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.5816 - recall_113: 0.6133 - precision_113: 0.2669\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6796 - accuracy: 0.5823 - recall_113: 0.6143 - precision_113: 0.2711\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6767 - accuracy: 0.5855 - recall_113: 0.6147 - precision_113: 0.2701\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.5899 - recall_113: 0.6127 - precision_113: 0.2728\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.5950 - recall_113: 0.6176 - precision_113: 0.2749\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.5983 - recall_113: 0.6092 - precision_113: 0.2746\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6669 - accuracy: 0.5973 - recall_113: 0.6016 - precision_113: 0.2761\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.5984 - recall_113: 0.5997 - precision_113: 0.2727\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.5987 - recall_113: 0.6072 - precision_113: 0.2725\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.6007 - recall_113: 0.5929 - precision_113: 0.2751\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6032 - recall_113: 0.6026 - precision_113: 0.2791\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.6067 - recall_113: 0.5925 - precision_113: 0.2806\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.6053 - recall_113: 0.5794 - precision_113: 0.2765\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.6051 - recall_113: 0.5720 - precision_113: 0.2729\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.6095 - recall_113: 0.5722 - precision_113: 0.2733\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.6113 - recall_113: 0.5790 - precision_113: 0.2803\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6551 - accuracy: 0.6130 - recall_113: 0.5839 - precision_113: 0.2834\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6197 - recall_113: 0.5698 - precision_113: 0.2830\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.6182 - recall_113: 0.5728 - precision_113: 0.2852\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.6210 - recall_113: 0.5652 - precision_113: 0.2809\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6492 - accuracy: 0.6212 - recall_113: 0.5670 - precision_113: 0.2843\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.6246 - recall_113: 0.5652 - precision_113: 0.2862\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6322 - recall_113: 0.5606 - precision_113: 0.2880\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6266 - recall_113: 0.5706 - precision_113: 0.2913\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.6331 - recall_113: 0.5716 - precision_113: 0.2896\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6355 - recall_113: 0.5643 - precision_113: 0.2914\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.6369 - recall_113: 0.5519 - precision_113: 0.2929\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.6373 - recall_113: 0.5529 - precision_113: 0.2894\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6413 - recall_113: 0.5571 - precision_113: 0.2993\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.6451 - recall_113: 0.5609 - precision_113: 0.3013\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6449 - recall_113: 0.5482 - precision_113: 0.2963\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6437 - recall_113: 0.5516 - precision_113: 0.2972\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6407 - recall_113: 0.5352 - precision_113: 0.2956\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6467 - recall_113: 0.5461 - precision_113: 0.2984\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6294 - accuracy: 0.6481 - recall_113: 0.5379 - precision_113: 0.2982\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6491 - recall_113: 0.5354 - precision_113: 0.2959\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6450 - recall_113: 0.5214 - precision_113: 0.2920\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6372 - accuracy: 0.6420 - recall_113: 0.5254 - precision_113: 0.294 - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6490 - recall_113: 0.5276 - precision_113: 0.2976\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.6531 - recall_113: 0.5266 - precision_113: 0.2975\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.6597 - recall_113: 0.5162 - precision_113: 0.2999\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.6568 - recall_113: 0.5142 - precision_113: 0.3002\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.6573 - recall_113: 0.5247 - precision_113: 0.3043\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.6610 - recall_113: 0.5098 - precision_113: 0.3006\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.6645 - recall_113: 0.5168 - precision_113: 0.3067\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.6656 - recall_113: 0.5097 - precision_113: 0.3147\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.6681 - recall_113: 0.5136 - precision_113: 0.3031\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6137 - accuracy: 0.6700 - recall_113: 0.5186 - precision_113: 0.3056\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6137 - accuracy: 0.6667 - recall_113: 0.4994 - precision_113: 0.3006\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.6680 - recall_113: 0.5008 - precision_113: 0.3048\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.6719 - recall_113: 0.5028 - precision_113: 0.3060\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.6721 - recall_113: 0.5018 - precision_113: 0.3178\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.6724 - recall_113: 0.5025 - precision_113: 0.3078\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6775 - recall_113: 0.5025 - precision_113: 0.3186\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.6780 - recall_113: 0.5000 - precision_113: 0.3146\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6763 - recall_113: 0.4907 - precision_113: 0.3136\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6041 - accuracy: 0.6825 - recall_113: 0.4939 - precision_113: 0.319 - 0s 3ms/step - loss: 0.6045 - accuracy: 0.6825 - recall_113: 0.4905 - precision_113: 0.3169\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6077 - accuracy: 0.6766 - recall_113: 0.4788 - precision_113: 0.3065\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.6838 - recall_113: 0.4826 - precision_113: 0.3157\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.6887 - recall_113: 0.4703 - precision_113: 0.3150\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.6846 - recall_113: 0.4720 - precision_113: 0.3168\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.6886 - recall_113: 0.4763 - precision_113: 0.3172\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6001 - accuracy: 0.6851 - recall_113: 0.4670 - precision_113: 0.3201\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.6928 - recall_113: 0.4738 - precision_113: 0.3213\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.6901 - recall_113: 0.4637 - precision_113: 0.3199\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.6966 - recall_113: 0.4664 - precision_113: 0.3225\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5951 - accuracy: 0.6905 - recall_113: 0.4609 - precision_113: 0.3186\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.6987 - recall_113: 0.4685 - precision_113: 0.3298\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5960 - accuracy: 0.6921 - recall_113: 0.4565 - precision_113: 0.3242\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.6976 - recall_113: 0.4627 - precision_113: 0.3290\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.6969 - recall_113: 0.4532 - precision_113: 0.3242\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.7004 - recall_113: 0.4566 - precision_113: 0.3283\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.7000 - recall_113: 0.4561 - precision_113: 0.3341\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.7037 - recall_113: 0.4483 - precision_113: 0.3324\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5887 - accuracy: 0.7013 - recall_113: 0.4481 - precision_113: 0.3258\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.7041 - recall_113: 0.4533 - precision_113: 0.3368\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5845 - accuracy: 0.7051 - recall_113: 0.4475 - precision_113: 0.3324\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.7095 - recall_113: 0.4473 - precision_113: 0.3321\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7092 - recall_113: 0.4449 - precision_113: 0.3336\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.7109 - recall_113: 0.4345 - precision_113: 0.3361\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.7117 - recall_113: 0.4257 - precision_113: 0.3357\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.7141 - recall_113: 0.4382 - precision_113: 0.3360\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.7174 - recall_113: 0.4263 - precision_113: 0.3407\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.7185 - recall_113: 0.4227 - precision_113: 0.3369\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7179 - recall_113: 0.4307 - precision_113: 0.3466\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7184 - recall_113: 0.4283 - precision_113: 0.3426\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.7157 - recall_113: 0.4079 - precision_113: 0.3411\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.7208 - recall_113: 0.4171 - precision_113: 0.3459\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7260 - recall_113: 0.4157 - precision_113: 0.3486\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5699 - accuracy: 0.7276 - recall_113: 0.4200 - precision_113: 0.3474\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7237 - recall_113: 0.4156 - precision_113: 0.3531\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7261 - recall_113: 0.4149 - precision_113: 0.3483\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7219 - recall_113: 0.3984 - precision_113: 0.3397\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7277 - recall_113: 0.4101 - precision_113: 0.3566\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7243 - recall_113: 0.4075 - precision_113: 0.3391\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5691 - accuracy: 0.7239 - recall_113: 0.3964 - precision_113: 0.3482\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.7265 - recall_113: 0.3890 - precision_113: 0.3405\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5665 - accuracy: 0.7278 - recall_113: 0.3996 - precision_113: 0.3494\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7288 - recall_113: 0.3944 - precision_113: 0.3530\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C85F3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5625 - accuracy: 0.7347 - recall_113: 0.3771 - precision_113: 0.3539\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7840 - accuracy: 0.4627 - recall_114: 0.4365 - precision_114: 0.1719\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7814 - accuracy: 0.4668 - recall_114: 0.4347 - precision_114: 0.1723\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7826 - accuracy: 0.4657 - recall_114: 0.4266 - precision_114: 0.1724\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7766 - accuracy: 0.4705 - recall_114: 0.4308 - precision_114: 0.1750\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7781 - accuracy: 0.4658 - recall_114: 0.4235 - precision_114: 0.1697\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7745 - accuracy: 0.4734 - recall_114: 0.4333 - precision_114: 0.1747\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7749 - accuracy: 0.4724 - recall_114: 0.4338 - precision_114: 0.1733\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7716 - accuracy: 0.4738 - recall_114: 0.4276 - precision_114: 0.1748\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7713 - accuracy: 0.4743 - recall_114: 0.4222 - precision_114: 0.1753\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7694 - accuracy: 0.4727 - recall_114: 0.4127 - precision_114: 0.1705\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7678 - accuracy: 0.4784 - recall_114: 0.4203 - precision_114: 0.1764\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7651 - accuracy: 0.4801 - recall_114: 0.4211 - precision_114: 0.1767\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7623 - accuracy: 0.4816 - recall_114: 0.4183 - precision_114: 0.1724\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7601 - accuracy: 0.4858 - recall_114: 0.4234 - precision_114: 0.1741\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7609 - accuracy: 0.4817 - recall_114: 0.4155 - precision_114: 0.1717\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7592 - accuracy: 0.4867 - recall_114: 0.4181 - precision_114: 0.1782\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7576 - accuracy: 0.4839 - recall_114: 0.4106 - precision_114: 0.1715\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7567 - accuracy: 0.4853 - recall_114: 0.4151 - precision_114: 0.1743\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7548 - accuracy: 0.4919 - recall_114: 0.4057 - precision_114: 0.1781\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7544 - accuracy: 0.4902 - recall_114: 0.4049 - precision_114: 0.1747\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7512 - accuracy: 0.4960 - recall_114: 0.4243 - precision_114: 0.180 - 0s 4ms/step - loss: 0.7513 - accuracy: 0.4938 - recall_114: 0.4114 - precision_114: 0.1769\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7475 - accuracy: 0.4981 - recall_114: 0.4110 - precision_114: 0.1780\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7502 - accuracy: 0.4936 - recall_114: 0.3943 - precision_114: 0.1732\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7502 - accuracy: 0.4944 - recall_114: 0.3949 - precision_114: 0.1737\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7505 - accuracy: 0.4916 - recall_114: 0.3942 - precision_114: 0.1727\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7459 - accuracy: 0.4979 - recall_114: 0.3896 - precision_114: 0.1726\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7427 - accuracy: 0.5006 - recall_114: 0.3994 - precision_114: 0.1756\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7449 - accuracy: 0.4998 - recall_114: 0.3994 - precision_114: 0.1770\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7391 - accuracy: 0.5076 - recall_114: 0.4011 - precision_114: 0.1793\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7402 - accuracy: 0.5030 - recall_114: 0.4087 - precision_114: 0.1781\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7353 - accuracy: 0.5088 - recall_114: 0.3984 - precision_114: 0.1801\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.5127 - recall_114: 0.3914 - precision_114: 0.1790\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7342 - accuracy: 0.5122 - recall_114: 0.3856 - precision_114: 0.1756\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.5168 - recall_114: 0.4002 - precision_114: 0.1869\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.5119 - recall_114: 0.3757 - precision_114: 0.1725\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7298 - accuracy: 0.5195 - recall_114: 0.3947 - precision_114: 0.1794\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7309 - accuracy: 0.5189 - recall_114: 0.3778 - precision_114: 0.1779\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7300 - accuracy: 0.5160 - recall_114: 0.3755 - precision_114: 0.1758\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7262 - accuracy: 0.5251 - recall_114: 0.3887 - precision_114: 0.1840\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7275 - accuracy: 0.5212 - recall_114: 0.3899 - precision_114: 0.1847\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7199 - accuracy: 0.5323 - recall_114: 0.3920 - precision_114: 0.1879\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7252 - accuracy: 0.5242 - recall_114: 0.3802 - precision_114: 0.1826\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7210 - accuracy: 0.5283 - recall_114: 0.3750 - precision_114: 0.1780\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7197 - accuracy: 0.5314 - recall_114: 0.3832 - precision_114: 0.1841\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7181 - accuracy: 0.5318 - recall_114: 0.3716 - precision_114: 0.1816\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7187 - accuracy: 0.5309 - recall_114: 0.3681 - precision_114: 0.1826\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7184 - accuracy: 0.5319 - recall_114: 0.3683 - precision_114: 0.1820\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.5396 - recall_114: 0.3782 - precision_114: 0.1847\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7161 - accuracy: 0.5339 - recall_114: 0.3616 - precision_114: 0.1790\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7146 - accuracy: 0.5378 - recall_114: 0.3715 - precision_114: 0.1831\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7150 - accuracy: 0.5379 - recall_114: 0.3651 - precision_114: 0.1812\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7086 - accuracy: 0.5443 - recall_114: 0.3629 - precision_114: 0.1825\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.5476 - recall_114: 0.3640 - precision_114: 0.1861\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7086 - accuracy: 0.5412 - recall_114: 0.3512 - precision_114: 0.1768\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7067 - accuracy: 0.5457 - recall_114: 0.3524 - precision_114: 0.1809\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.5437 - recall_114: 0.3534 - precision_114: 0.1833\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7059 - accuracy: 0.5457 - recall_114: 0.3436 - precision_114: 0.1738\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7013 - accuracy: 0.5497 - recall_114: 0.3549 - precision_114: 0.1829\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7008 - accuracy: 0.5545 - recall_114: 0.3537 - precision_114: 0.1902\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7008 - accuracy: 0.5522 - recall_114: 0.3495 - precision_114: 0.1833\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7035 - accuracy: 0.5479 - recall_114: 0.3384 - precision_114: 0.1742\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6974 - accuracy: 0.5550 - recall_114: 0.3487 - precision_114: 0.1849\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6954 - accuracy: 0.5604 - recall_114: 0.3473 - precision_114: 0.1853\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6986 - accuracy: 0.5575 - recall_114: 0.3404 - precision_114: 0.1850\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6957 - accuracy: 0.5575 - recall_114: 0.3511 - precision_114: 0.1853\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5663 - recall_114: 0.3570 - precision_114: 0.1926\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.5661 - recall_114: 0.3462 - precision_114: 0.1877\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6922 - accuracy: 0.5679 - recall_114: 0.3330 - precision_114: 0.1830\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5646 - recall_114: 0.3397 - precision_114: 0.1868\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6915 - accuracy: 0.5636 - recall_114: 0.3288 - precision_114: 0.1838\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.5693 - recall_114: 0.3407 - precision_114: 0.1898\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.5704 - recall_114: 0.3386 - precision_114: 0.1868\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5718 - recall_114: 0.3358 - precision_114: 0.1871\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5716 - recall_114: 0.3386 - precision_114: 0.1923\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6851 - accuracy: 0.5722 - recall_114: 0.3262 - precision_114: 0.1818\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.5761 - recall_114: 0.3352 - precision_114: 0.1889\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.5771 - recall_114: 0.3306 - precision_114: 0.1898\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6836 - accuracy: 0.5727 - recall_114: 0.3286 - precision_114: 0.1843\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6778 - accuracy: 0.5825 - recall_114: 0.3203 - precision_114: 0.176 - 0s 4ms/step - loss: 0.6796 - accuracy: 0.5787 - recall_114: 0.3276 - precision_114: 0.1863\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.5776 - recall_114: 0.3254 - precision_114: 0.1877\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6775 - accuracy: 0.5806 - recall_114: 0.3251 - precision_114: 0.1877\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.5816 - recall_114: 0.3259 - precision_114: 0.1904\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.5792 - recall_114: 0.3218 - precision_114: 0.1908\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.5835 - recall_114: 0.3124 - precision_114: 0.1855\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.5918 - recall_114: 0.3283 - precision_114: 0.1929\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.5844 - recall_114: 0.3185 - precision_114: 0.1873\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5850 - recall_114: 0.3097 - precision_114: 0.1878\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.5941 - recall_114: 0.3208 - precision_114: 0.1936\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.5888 - recall_114: 0.3115 - precision_114: 0.1906\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.5909 - recall_114: 0.3194 - precision_114: 0.1918\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.5927 - recall_114: 0.3143 - precision_114: 0.1949\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.5947 - recall_114: 0.3148 - precision_114: 0.1967\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.5942 - recall_114: 0.3134 - precision_114: 0.1908\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.5996 - recall_114: 0.3061 - precision_114: 0.1950\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.5987 - recall_114: 0.2993 - precision_114: 0.1878\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.6042 - recall_114: 0.3078 - precision_114: 0.1979\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.5998 - recall_114: 0.3041 - precision_114: 0.1922\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.5976 - recall_114: 0.2988 - precision_114: 0.1879\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.6015 - recall_114: 0.3045 - precision_114: 0.1942\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6035 - recall_114: 0.2924 - precision_114: 0.1937\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.6641 - accuracy: 0.5997 - recall_114: 0.2854 - precision_114: 0.1847\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7560 - accuracy: 0.4279 - recall_115: 0.3320 - precision_115: 0.1330\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7500 - accuracy: 0.4410 - recall_115: 0.3216 - precision_115: 0.1349\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.4443 - recall_115: 0.2951 - precision_115: 0.1263\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.4594 - recall_115: 0.2933 - precision_115: 0.1296\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7293 - accuracy: 0.4740 - recall_115: 0.2866 - precision_115: 0.1304\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7242 - accuracy: 0.4820 - recall_115: 0.2726 - precision_115: 0.1280\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7151 - accuracy: 0.4963 - recall_115: 0.2621 - precision_115: 0.1288\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.5105 - recall_115: 0.2472 - precision_115: 0.1283\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7055 - accuracy: 0.5185 - recall_115: 0.2318 - precision_115: 0.1268\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.5295 - recall_115: 0.2426 - precision_115: 0.1342\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.5444 - recall_115: 0.2107 - precision_115: 0.1222\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5572 - recall_115: 0.2007 - precision_115: 0.1259\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5646 - recall_115: 0.1905 - precision_115: 0.1222\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.5767 - recall_115: 0.1832 - precision_115: 0.1267\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.5877 - recall_115: 0.1836 - precision_115: 0.1316\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.5968 - recall_115: 0.1672 - precision_115: 0.1264\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.6080 - recall_115: 0.1568 - precision_115: 0.1271\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.6178 - recall_115: 0.1542 - precision_115: 0.1295\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.6329 - recall_115: 0.1482 - precision_115: 0.1362\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.6445 - recall_115: 0.1456 - precision_115: 0.1383\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.6518 - recall_115: 0.1391 - precision_115: 0.1422\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6589 - recall_115: 0.1355 - precision_115: 0.1433\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.6691 - recall_115: 0.1237 - precision_115: 0.1436\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.6793 - recall_115: 0.1249 - precision_115: 0.1518\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6895 - recall_115: 0.1234 - precision_115: 0.1576\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.7023 - recall_115: 0.1186 - precision_115: 0.1658\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6247 - accuracy: 0.7039 - recall_115: 0.1102 - precision_115: 0.1605\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.7140 - recall_115: 0.1091 - precision_115: 0.1729\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6194 - accuracy: 0.7134 - recall_115: 0.0991 - precision_115: 0.1675\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.7223 - recall_115: 0.0896 - precision_115: 0.1608\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.7276 - recall_115: 0.0866 - precision_115: 0.1671\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.7332 - recall_115: 0.0838 - precision_115: 0.1707\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.7345 - recall_115: 0.0781 - precision_115: 0.1704\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.7405 - recall_115: 0.0707 - precision_115: 0.1659\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.7409 - recall_115: 0.0677 - precision_115: 0.1651\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.7450 - recall_115: 0.0615 - precision_115: 0.1662\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.7582 - recall_115: 0.0656 - precision_115: 0.2008\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.7568 - recall_115: 0.0581 - precision_115: 0.1823\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.7609 - recall_115: 0.0566 - precision_115: 0.1909\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.7663 - recall_115: 0.0534 - precision_115: 0.1904\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5831 - accuracy: 0.7680 - recall_115: 0.0454 - precision_115: 0.1729\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7640 - recall_115: 0.0446 - precision_115: 0.1814\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7672 - recall_115: 0.0390 - precision_115: 0.1711\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5796 - accuracy: 0.7677 - recall_115: 0.0346 - precision_115: 0.1705\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5750 - accuracy: 0.7713 - recall_115: 0.0339 - precision_115: 0.1691\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7692 - recall_115: 0.0307 - precision_115: 0.1547\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7708 - recall_115: 0.0273 - precision_115: 0.1522\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7743 - recall_115: 0.0286 - precision_115: 0.1598\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7775 - recall_115: 0.0288 - precision_115: 0.1795\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7765 - recall_115: 0.0260 - precision_115: 0.1688\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.7813 - recall_115: 0.0290 - precision_115: 0.2006\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.7821 - recall_115: 0.0256 - precision_115: 0.1852\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7818 - recall_115: 0.0273 - precision_115: 0.2023\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.7848 - recall_115: 0.0254 - precision_115: 0.1977\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.7882 - recall_115: 0.0212 - precision_115: 0.2026\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7837 - recall_115: 0.0185 - precision_115: 0.1754\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7821 - recall_115: 0.0168 - precision_115: 0.1815\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7840 - recall_115: 0.0147 - precision_115: 0.1604\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7888 - recall_115: 0.0147 - precision_115: 0.1916\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7850 - recall_115: 0.0127 - precision_115: 0.1750\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7874 - recall_115: 0.0119 - precision_115: 0.1738\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7892 - recall_115: 0.0119 - precision_115: 0.1810\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7910 - recall_115: 0.0132 - precision_115: 0.2023\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7922 - recall_115: 0.0148 - precision_115: 0.2374\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7888 - recall_115: 0.0084 - precision_115: 0.1643\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7904 - recall_115: 0.0087 - precision_115: 0.1780\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7916 - recall_115: 0.0082 - precision_115: 0.1633\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7948 - recall_115: 0.0113 - precision_115: 0.2698\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7947 - recall_115: 0.0111 - precision_115: 0.2459\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7919 - recall_115: 0.0078 - precision_115: 0.2001\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7932 - recall_115: 0.0077 - precision_115: 0.2482\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7978 - recall_115: 0.0085 - precision_115: 0.2803\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7955 - recall_115: 0.0086 - precision_115: 0.3108\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7929 - recall_115: 0.0070 - precision_115: 0.2903\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7943 - recall_115: 0.0077 - precision_115: 0.3105\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7974 - recall_115: 0.0065 - precision_115: 0.2813\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7951 - recall_115: 0.0083 - precision_115: 0.3779\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7978 - recall_115: 0.0056 - precision_115: 0.3213    \n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7990 - recall_115: 0.0078 - precision_115: 0.4142\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7984 - recall_115: 0.0062 - precision_115: 0.4440\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7972 - recall_115: 0.0071 - precision_115: 0.4092\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5165 - accuracy: 0.7986 - recall_115: 0.0060 - precision_115: 0.3768\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7957 - recall_115: 0.0065 - precision_115: 0.4083\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7925 - recall_115: 0.0070 - precision_115: 0.4143\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5070 - accuracy: 0.8070 - recall_115: 0.0078 - precision_115: 0.500 - 0s 4ms/step - loss: 0.5121 - accuracy: 0.8004 - recall_115: 0.0064 - precision_115: 0.4558\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7973 - recall_115: 0.0066 - precision_115: 0.4287\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7953 - recall_115: 0.0065 - precision_115: 0.4515\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5086 - accuracy: 0.8011 - recall_115: 0.0061 - precision_115: 0.5224\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7949 - recall_115: 0.0062 - precision_115: 0.4583\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7955 - recall_115: 0.0047 - precision_115: 0.3833\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7960 - recall_115: 0.0074 - precision_115: 0.5750\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7965 - recall_115: 0.0074 - precision_115: 0.5530\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7982 - recall_115: 0.0069 - precision_115: 0.5591\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7981 - recall_115: 0.0061 - precision_115: 0.5312\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.8000 - recall_115: 0.0067 - precision_115: 0.5889\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7984 - recall_115: 0.0034 - precision_115: 0.3681\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7966 - recall_115: 0.0043 - precision_115: 0.3874\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7951 - recall_115: 0.0045 - precision_115: 0.4472\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7995 - recall_115: 0.0043 - precision_115: 0.5417\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.7949 - recall_115: 0.0045 - precision_115: 0.5000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6596520D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.4995 - accuracy: 0.7965 - recall_115: 0.0000e+00 - precision_115: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8092 - accuracy: 0.4879 - recall_116: 0.4691 - precision_116: 0.1899\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8021 - accuracy: 0.4896 - recall_116: 0.4584 - precision_116: 0.1829\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7839 - accuracy: 0.5012 - recall_116: 0.4542 - precision_116: 0.1927\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7773 - accuracy: 0.5055 - recall_116: 0.4487 - precision_116: 0.1932\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7645 - accuracy: 0.5182 - recall_116: 0.4470 - precision_116: 0.1973\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7535 - accuracy: 0.5273 - recall_116: 0.4377 - precision_116: 0.2011\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7469 - accuracy: 0.5291 - recall_116: 0.4232 - precision_116: 0.1948\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7341 - accuracy: 0.5396 - recall_116: 0.4117 - precision_116: 0.1975\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7223 - accuracy: 0.5541 - recall_116: 0.4271 - precision_116: 0.2087\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7122 - accuracy: 0.5633 - recall_116: 0.4166 - precision_116: 0.2107\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.5689 - recall_116: 0.4005 - precision_116: 0.2100\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6966 - accuracy: 0.5837 - recall_116: 0.4041 - precision_116: 0.2184\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5878 - recall_116: 0.3910 - precision_116: 0.2200\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6768 - accuracy: 0.6043 - recall_116: 0.3927 - precision_116: 0.2264\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.6078 - recall_116: 0.3904 - precision_116: 0.2254\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.6197 - recall_116: 0.3768 - precision_116: 0.2272\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.6233 - recall_116: 0.3845 - precision_116: 0.2316\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6505 - accuracy: 0.6303 - recall_116: 0.3657 - precision_116: 0.2378\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.6369 - recall_116: 0.3604 - precision_116: 0.2400\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.6470 - recall_116: 0.3517 - precision_116: 0.2462\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6511 - recall_116: 0.3501 - precision_116: 0.2431\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.6616 - recall_116: 0.3458 - precision_116: 0.2494\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.6648 - recall_116: 0.3354 - precision_116: 0.2531\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.6672 - recall_116: 0.3328 - precision_116: 0.2571\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6706 - recall_116: 0.3357 - precision_116: 0.2627\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6035 - accuracy: 0.6735 - recall_116: 0.3170 - precision_116: 0.2553\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6006 - accuracy: 0.6774 - recall_116: 0.3127 - precision_116: 0.2609\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6852 - recall_116: 0.3135 - precision_116: 0.2608\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.6888 - recall_116: 0.3050 - precision_116: 0.2663\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.6960 - recall_116: 0.3052 - precision_116: 0.2686\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.6986 - recall_116: 0.3028 - precision_116: 0.2797\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5759 - accuracy: 0.7004 - recall_116: 0.2928 - precision_116: 0.2722\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.7044 - recall_116: 0.2895 - precision_116: 0.2755\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7093 - recall_116: 0.2881 - precision_116: 0.2836\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5602 - accuracy: 0.7194 - recall_116: 0.2897 - precision_116: 0.2966\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7200 - recall_116: 0.2663 - precision_116: 0.2885\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7205 - recall_116: 0.2707 - precision_116: 0.2964\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7293 - recall_116: 0.2586 - precision_116: 0.2972\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7339 - recall_116: 0.2547 - precision_116: 0.3095\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7345 - recall_116: 0.2587 - precision_116: 0.3095\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7368 - recall_116: 0.2433 - precision_116: 0.3103\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7462 - recall_116: 0.2605 - precision_116: 0.3366\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7415 - recall_116: 0.2394 - precision_116: 0.3176\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7521 - recall_116: 0.2475 - precision_116: 0.3441\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7524 - recall_116: 0.2350 - precision_116: 0.3361\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7527 - recall_116: 0.2249 - precision_116: 0.3447\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7540 - recall_116: 0.2264 - precision_116: 0.3477\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7568 - recall_116: 0.2230 - precision_116: 0.3544\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7621 - recall_116: 0.2289 - precision_116: 0.3706\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7661 - recall_116: 0.2212 - precision_116: 0.3730\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7672 - recall_116: 0.2114 - precision_116: 0.3636\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5035 - accuracy: 0.7860 - recall_116: 0.2252 - precision_116: 0.376 - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7766 - recall_116: 0.2176 - precision_116: 0.3834\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7671 - recall_116: 0.2124 - precision_116: 0.3828\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7722 - recall_116: 0.2105 - precision_116: 0.3912\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7774 - recall_116: 0.2031 - precision_116: 0.4076\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7798 - recall_116: 0.2073 - precision_116: 0.4043\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7814 - recall_116: 0.2040 - precision_116: 0.4109\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7847 - recall_116: 0.2025 - precision_116: 0.4225\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7846 - recall_116: 0.2055 - precision_116: 0.4351\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7837 - recall_116: 0.2039 - precision_116: 0.4459\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7880 - recall_116: 0.1929 - precision_116: 0.4336\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7824 - recall_116: 0.1929 - precision_116: 0.4491\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7896 - recall_116: 0.1966 - precision_116: 0.4710\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.7893 - recall_116: 0.1934 - precision_116: 0.4564\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7906 - recall_116: 0.1862 - precision_116: 0.4657\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7908 - recall_116: 0.1864 - precision_116: 0.4718\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7897 - recall_116: 0.1856 - precision_116: 0.4716\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7917 - recall_116: 0.1838 - precision_116: 0.4789\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7963 - recall_116: 0.1777 - precision_116: 0.4845\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7931 - recall_116: 0.1707 - precision_116: 0.4822\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7925 - recall_116: 0.1628 - precision_116: 0.4725\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7966 - recall_116: 0.1704 - precision_116: 0.4928\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7958 - recall_116: 0.1683 - precision_116: 0.4908\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7975 - recall_116: 0.1727 - precision_116: 0.4981\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.8026 - recall_116: 0.1689 - precision_116: 0.4994\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.8006 - recall_116: 0.1778 - precision_116: 0.5171\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7985 - recall_116: 0.1669 - precision_116: 0.5112\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7968 - recall_116: 0.1664 - precision_116: 0.5178\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.8028 - recall_116: 0.1737 - precision_116: 0.5333\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7990 - recall_116: 0.1615 - precision_116: 0.5252\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4699 - accuracy: 0.8025 - recall_116: 0.1556 - precision_116: 0.543 - 0s 4ms/step - loss: 0.4693 - accuracy: 0.8029 - recall_116: 0.1586 - precision_116: 0.5388\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7987 - recall_116: 0.1516 - precision_116: 0.5260\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.8006 - recall_116: 0.1544 - precision_116: 0.5410\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.8015 - recall_116: 0.1574 - precision_116: 0.5345\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.8015 - recall_116: 0.1538 - precision_116: 0.5457\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.8054 - recall_116: 0.1571 - precision_116: 0.5433\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.8004 - recall_116: 0.1529 - precision_116: 0.5307\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.8006 - recall_116: 0.1475 - precision_116: 0.5337\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.8023 - recall_116: 0.1486 - precision_116: 0.5440\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.8055 - recall_116: 0.1559 - precision_116: 0.5669\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.8033 - recall_116: 0.1463 - precision_116: 0.5615\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7983 - recall_116: 0.1430 - precision_116: 0.5528\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.8075 - recall_116: 0.1587 - precision_116: 0.5858\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.8011 - recall_116: 0.1500 - precision_116: 0.5485\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.8029 - recall_116: 0.1450 - precision_116: 0.5669\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.8063 - recall_116: 0.1475 - precision_116: 0.5759\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.8090 - recall_116: 0.1527 - precision_116: 0.5710\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.8041 - recall_116: 0.1525 - precision_116: 0.5804\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.8061 - recall_116: 0.1521 - precision_116: 0.5698\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.8071 - recall_116: 0.1491 - precision_116: 0.5756\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A54AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.8054 - recall_116: 0.1441 - precision_116: 0.5763\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7540 - accuracy: 0.5035 - recall_117: 0.5325 - precision_117: 0.2140\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7451 - accuracy: 0.5132 - recall_117: 0.5431 - precision_117: 0.2137\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7367 - accuracy: 0.5202 - recall_117: 0.5288 - precision_117: 0.2180\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7290 - accuracy: 0.5270 - recall_117: 0.5210 - precision_117: 0.2201\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7255 - accuracy: 0.5249 - recall_117: 0.4960 - precision_117: 0.2103\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7191 - accuracy: 0.5338 - recall_117: 0.5066 - precision_117: 0.2182\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7096 - accuracy: 0.5378 - recall_117: 0.4819 - precision_117: 0.2140\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7020 - accuracy: 0.5430 - recall_117: 0.4830 - precision_117: 0.2180\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6991 - accuracy: 0.5495 - recall_117: 0.4653 - precision_117: 0.2143\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.5608 - recall_117: 0.4726 - precision_117: 0.2239\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.5666 - recall_117: 0.4647 - precision_117: 0.2193\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6818 - accuracy: 0.5653 - recall_117: 0.4533 - precision_117: 0.2223\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.5737 - recall_117: 0.4416 - precision_117: 0.2224\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.5811 - recall_117: 0.4407 - precision_117: 0.2260\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.5946 - recall_117: 0.4421 - precision_117: 0.2362\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.6009 - recall_117: 0.4363 - precision_117: 0.2375\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.6120 - recall_117: 0.4331 - precision_117: 0.2381\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.6089 - recall_117: 0.4248 - precision_117: 0.2409\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.6228 - recall_117: 0.4144 - precision_117: 0.2435\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6180 - recall_117: 0.4001 - precision_117: 0.2386\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.6300 - recall_117: 0.4011 - precision_117: 0.2463\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6363 - recall_117: 0.3831 - precision_117: 0.2438\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.6370 - recall_117: 0.3843 - precision_117: 0.2458\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6433 - recall_117: 0.3795 - precision_117: 0.2445\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6513 - recall_117: 0.3724 - precision_117: 0.2551\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.6514 - recall_117: 0.3549 - precision_117: 0.2448\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.6599 - recall_117: 0.3513 - precision_117: 0.2521\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.6677 - recall_117: 0.3455 - precision_117: 0.2571\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.6696 - recall_117: 0.3434 - precision_117: 0.2598\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6759 - recall_117: 0.3417 - precision_117: 0.2642\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.6847 - recall_117: 0.3324 - precision_117: 0.2689\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.6840 - recall_117: 0.3371 - precision_117: 0.2757\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.6852 - recall_117: 0.3255 - precision_117: 0.2756\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.6966 - recall_117: 0.3287 - precision_117: 0.2853\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.7001 - recall_117: 0.3155 - precision_117: 0.2853\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7020 - recall_117: 0.3132 - precision_117: 0.2845\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5793 - accuracy: 0.7027 - recall_117: 0.3050 - precision_117: 0.2826\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.7104 - recall_117: 0.2996 - precision_117: 0.2888\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.7143 - recall_117: 0.2969 - precision_117: 0.2940\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7158 - recall_117: 0.2794 - precision_117: 0.2884\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.7189 - recall_117: 0.2815 - precision_117: 0.2942\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.7217 - recall_117: 0.2645 - precision_117: 0.2863\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.7274 - recall_117: 0.2726 - precision_117: 0.3033\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7331 - recall_117: 0.2770 - precision_117: 0.3078\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7296 - recall_117: 0.2594 - precision_117: 0.3031\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7317 - recall_117: 0.2681 - precision_117: 0.3207\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7378 - recall_117: 0.2574 - precision_117: 0.3039\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7382 - recall_117: 0.2580 - precision_117: 0.3174\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7424 - recall_117: 0.2515 - precision_117: 0.3208\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7434 - recall_117: 0.2504 - precision_117: 0.3274\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7501 - recall_117: 0.2488 - precision_117: 0.3377\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7501 - recall_117: 0.2381 - precision_117: 0.3270\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7504 - recall_117: 0.2311 - precision_117: 0.3175\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7533 - recall_117: 0.2249 - precision_117: 0.3276\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7574 - recall_117: 0.2231 - precision_117: 0.3474\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.7573 - recall_117: 0.2247 - precision_117: 0.3307\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7594 - recall_117: 0.2290 - precision_117: 0.3574\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7580 - recall_117: 0.2165 - precision_117: 0.3491\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.7644 - recall_117: 0.2162 - precision_117: 0.3524\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7663 - recall_117: 0.2133 - precision_117: 0.3599\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7646 - recall_117: 0.2151 - precision_117: 0.3711\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7652 - recall_117: 0.2086 - precision_117: 0.3735\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7687 - recall_117: 0.1985 - precision_117: 0.3611\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7701 - recall_117: 0.2039 - precision_117: 0.3879\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7683 - recall_117: 0.1953 - precision_117: 0.3683\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7740 - recall_117: 0.1931 - precision_117: 0.3731\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7716 - recall_117: 0.1936 - precision_117: 0.3755\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7751 - recall_117: 0.1936 - precision_117: 0.3834\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7744 - recall_117: 0.1832 - precision_117: 0.3790\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5115 - accuracy: 0.7743 - recall_117: 0.1730 - precision_117: 0.3789\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7726 - recall_117: 0.1814 - precision_117: 0.3866\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7784 - recall_117: 0.1755 - precision_117: 0.3796\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7738 - recall_117: 0.1706 - precision_117: 0.3790\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7764 - recall_117: 0.1668 - precision_117: 0.3806\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7763 - recall_117: 0.1706 - precision_117: 0.3896\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7779 - recall_117: 0.1730 - precision_117: 0.3983\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7769 - recall_117: 0.1671 - precision_117: 0.3856\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7791 - recall_117: 0.1602 - precision_117: 0.3814\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7811 - recall_117: 0.1648 - precision_117: 0.3977\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7796 - recall_117: 0.1603 - precision_117: 0.3886\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7807 - recall_117: 0.1599 - precision_117: 0.4044\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7819 - recall_117: 0.1550 - precision_117: 0.4032\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7832 - recall_117: 0.1541 - precision_117: 0.3937\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7850 - recall_117: 0.1560 - precision_117: 0.4154\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7826 - recall_117: 0.1524 - precision_117: 0.4088\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7880 - recall_117: 0.1638 - precision_117: 0.4422\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7863 - recall_117: 0.1546 - precision_117: 0.4213\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7874 - recall_117: 0.1535 - precision_117: 0.4197\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7906 - recall_117: 0.1568 - precision_117: 0.4362\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7843 - recall_117: 0.1587 - precision_117: 0.4581\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7896 - recall_117: 0.1514 - precision_117: 0.4436\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7905 - recall_117: 0.1590 - precision_117: 0.4588\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7915 - recall_117: 0.1519 - precision_117: 0.4401\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7923 - recall_117: 0.1544 - precision_117: 0.4402\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7909 - recall_117: 0.1551 - precision_117: 0.4537\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7920 - recall_117: 0.1536 - precision_117: 0.4582\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7955 - recall_117: 0.1580 - precision_117: 0.4795\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7922 - recall_117: 0.1509 - precision_117: 0.4743\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7954 - recall_117: 0.1480 - precision_117: 0.4731\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7968 - recall_117: 0.1474 - precision_117: 0.4779\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FBDD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7831 - recall_117: 0.1226 - precision_117: 0.3893\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5275 - accuracy: 0.8005 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7989 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7967 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7987 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.7962 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7986 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7972 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7961 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.8017 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7974 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7952 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7918 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7989 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7985 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7959 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7991 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7967 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7984 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.8011 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.8011 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.7965 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.7895 - recall_118: 0.0000e+00 - precision_118: 0.0000e+0 - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7947 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5219 - accuracy: 0.7951 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7986 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7967 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7952 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7989 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7963 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.8008 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7985 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7970 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7954 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7982 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.7946 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7940 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7990 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7971 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7941 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7999 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7972 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7989 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7979 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7990 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7955 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7983 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.8010 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5106 - accuracy: 0.7992 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7949 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7989 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5090 - accuracy: 0.8000 - recall_118: 0.0000e+00 - precision_118: 0.0000e+0 - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7985 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7959 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7960 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7970 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7982 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7981 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7982 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8006 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7935 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7979 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7969 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.8000 - recall_118: 0.0000e+00 - precision_118: 0.0000e+0 - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7987 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7978 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7960 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7950 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7954 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.8022 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7975 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.7968 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7987 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7952 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7945 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5077 - accuracy: 0.7972 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7971 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7967 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7969 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7980 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.7982 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7992 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7935 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7934 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7977 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7988 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7960 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7983 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7992 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.8010 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7984 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7984 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7957 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7987 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7959 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7988 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7952 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7997 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7985 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7991 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.7969 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7976 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.8004 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7989 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C85FEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7973 - recall_118: 0.0000e+00 - precision_118: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6780 - accuracy: 0.7246 - recall_119: 0.0598 - precision_119: 0.1269\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.7639 - recall_119: 0.0224 - precision_119: 0.1056\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.7848 - recall_119: 0.0081 - precision_119: 0.1016\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.7952 - recall_119: 0.0014 - precision_119: 0.1571\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.7991 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6552 - accuracy: 0.7997 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.7963 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.7973 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.8002 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.7940 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.7988 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.8008 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.7972 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.7975 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.7998 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.7956 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.7968 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.7982 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.7943 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7997 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.7935 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.7975 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7955 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.7964 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.7955 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.7982 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.7989 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7990 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7982 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7945 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7997 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7958 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7969 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7995 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7953 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7985 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7992 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7981 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.8000 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7986 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.8020 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7955 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.8000 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7964 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.7981 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.8003 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.8001 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7962 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.8017 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5553 - accuracy: 0.7950 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7950 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7970 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7962 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.7963 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7978 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7987 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7969 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7997 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7973 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7972 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7967 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7953 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7971 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7997 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7936 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7978 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7978 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7958 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5370 - accuracy: 0.7965 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.7965 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.7940 - recall_119: 0.0000e+00 - precision_119: 0.0000e+0 - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7966 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.8011 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7990 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7956 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.8009 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7950 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7986 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7964 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7968 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7965 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.7968 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.8003 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7951 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7980 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7963 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7967 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7943 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7940 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7992 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7994 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7977 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.8002 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.7992 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.7984 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5236 - accuracy: 0.7967 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.7935 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.8012 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7956 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7960 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7940 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA1F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5206 - accuracy: 0.7977 - recall_119: 0.0000e+00 - precision_119: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6992 - accuracy: 0.4435 - recall_120: 0.6304 - precision_120: 0.2117\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.4886 - recall_120: 0.5486 - precision_120: 0.2105\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5478 - recall_120: 0.4790 - precision_120: 0.2176\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.5843 - recall_120: 0.4070 - precision_120: 0.2183\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.6254 - recall_120: 0.3282 - precision_120: 0.2141\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.6617 - recall_120: 0.2654 - precision_120: 0.2212\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.6937 - recall_120: 0.1980 - precision_120: 0.2227\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.7200 - recall_120: 0.1498 - precision_120: 0.2212\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.7395 - recall_120: 0.1027 - precision_120: 0.2141\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.7660 - recall_120: 0.0771 - precision_120: 0.2375\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.7749 - recall_120: 0.0402 - precision_120: 0.2096\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.7880 - recall_120: 0.0377 - precision_120: 0.3032\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6534 - accuracy: 0.7952 - recall_120: 0.0176 - precision_120: 0.3123\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.7956 - recall_120: 0.0088 - precision_120: 0.3295\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.7970 - recall_120: 0.0044 - precision_120: 0.3884\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.7996 - recall_120: 0.0014 - precision_120: 0.3333    \n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.7997 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.7979 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.7948 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7961 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.7939 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.7989 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.7961 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.7989 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.7994 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.8005 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.7979 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.7944 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6113 - accuracy: 0.7941 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.7954 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.7988 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.7966 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.8006 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.7974 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5982 - accuracy: 0.7955 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.8004 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.8004 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.7974 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5887 - accuracy: 0.8011 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5890 - accuracy: 0.7953 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5863 - accuracy: 0.7983 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.8008 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7993 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7968 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.7989 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.8003 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7990 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7948 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.7974 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.7915 - recall_120: 0.0000e+00 - precision_120: 0.0000e+0 - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7959 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7989 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7974 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.7969 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.8002 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7973 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.7994 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.8015 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7958 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7969 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7981 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5588 - accuracy: 0.7977 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.8009 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7989 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7956 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7949 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5541 - accuracy: 0.7967 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.8015 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7974 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5518 - accuracy: 0.7959 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.8001 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7957 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7979 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7982 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7982 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7960 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7952 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7956 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7973 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7976 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7965 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.8001 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7967 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7965 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.7982 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7963 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7966 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7974 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7944 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.8011 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.8000 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.8000 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7951 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7987 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7975 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7949 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7981 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7978 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7991 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7969 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.8002 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FBD160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7973 - recall_120: 0.0000e+00 - precision_120: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.0671 - accuracy: 0.2027 - recall_121: 1.0000 - precision_121: 0.2027\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0647 - accuracy: 0.2022 - recall_121: 1.0000 - precision_121: 0.2022\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0594 - accuracy: 0.2048 - recall_121: 1.0000 - precision_121: 0.2048\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0577 - accuracy: 0.2035 - recall_121: 1.0000 - precision_121: 0.2035\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0574 - accuracy: 0.2008 - recall_121: 1.0000 - precision_121: 0.2008\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0543 - accuracy: 0.2011 - recall_121: 1.0000 - precision_121: 0.2011\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0521 - accuracy: 0.2004 - recall_121: 1.0000 - precision_121: 0.2004\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0466 - accuracy: 0.2034 - recall_121: 1.0000 - precision_121: 0.2034\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0416 - accuracy: 0.2059 - recall_121: 1.0000 - precision_121: 0.2059\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0411 - accuracy: 0.2034 - recall_121: 1.0000 - precision_121: 0.2034\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0420 - accuracy: 0.1991 - recall_121: 1.0000 - precision_121: 0.1991\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0375 - accuracy: 0.2011 - recall_121: 1.0000 - precision_121: 0.2011\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0310 - accuracy: 0.2056 - recall_121: 1.0000 - precision_121: 0.2056\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0289 - accuracy: 0.2050 - recall_121: 1.0000 - precision_121: 0.2050\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0282 - accuracy: 0.2026 - recall_121: 1.0000 - precision_121: 0.2026\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0261 - accuracy: 0.2019 - recall_121: 1.0000 - precision_121: 0.2019\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0219 - accuracy: 0.2037 - recall_121: 1.0000 - precision_121: 0.2037\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0221 - accuracy: 0.2002 - recall_121: 1.0000 - precision_121: 0.2002\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0159 - accuracy: 0.2046 - recall_121: 1.0000 - precision_121: 0.2046\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0143 - accuracy: 0.2033 - recall_121: 1.0000 - precision_121: 0.2033\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0103 - accuracy: 0.2050 - recall_121: 1.0000 - precision_121: 0.2050\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0090 - accuracy: 0.2035 - recall_121: 1.0000 - precision_121: 0.2035\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0058 - accuracy: 0.2042 - recall_121: 1.0000 - precision_121: 0.2042\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.2030 - recall_121: 1.0000 - precision_121: 0.203 - 0s 4ms/step - loss: 1.0047 - accuracy: 0.2023 - recall_121: 1.0000 - precision_121: 0.2023\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9989 - accuracy: 0.2065 - recall_121: 1.0000 - precision_121: 0.2065\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9998 - accuracy: 0.2021 - recall_121: 1.0000 - precision_121: 0.2021\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9955 - accuracy: 0.2044 - recall_121: 1.0000 - precision_121: 0.2044\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9939 - accuracy: 0.2031 - recall_121: 1.0000 - precision_121: 0.2031\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9906 - accuracy: 0.2041 - recall_121: 1.0000 - precision_121: 0.2041\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9886 - accuracy: 0.2035 - recall_121: 1.0000 - precision_121: 0.2035\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9868 - accuracy: 0.2026 - recall_121: 1.0000 - precision_121: 0.2026\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9816 - accuracy: 0.2063 - recall_121: 1.0000 - precision_121: 0.2063\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9823 - accuracy: 0.2021 - recall_121: 1.0000 - precision_121: 0.2021\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9830 - accuracy: 0.1978 - recall_121: 1.0000 - precision_121: 0.1978\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9785 - accuracy: 0.2006 - recall_121: 1.0000 - precision_121: 0.2006\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9753 - accuracy: 0.2017 - recall_121: 1.0000 - precision_121: 0.2017\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9690 - accuracy: 0.2071 - recall_121: 1.0000 - precision_121: 0.2071\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9686 - accuracy: 0.2043 - recall_121: 1.0000 - precision_121: 0.2043\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9665 - accuracy: 0.2040 - recall_121: 1.0000 - precision_121: 0.2040\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9652 - accuracy: 0.2025 - recall_121: 1.0000 - precision_121: 0.2025\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9631 - accuracy: 0.2021 - recall_121: 1.0000 - precision_121: 0.2021\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9592 - accuracy: 0.2045 - recall_121: 1.0000 - precision_121: 0.2045\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9582 - accuracy: 0.2025 - recall_121: 1.0000 - precision_121: 0.2025\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9560 - accuracy: 0.2023 - recall_121: 1.0000 - precision_121: 0.2023\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9546 - accuracy: 0.2010 - recall_121: 1.0000 - precision_121: 0.2010\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9511 - accuracy: 0.2027 - recall_121: 1.0000 - precision_121: 0.2027\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9461 - accuracy: 0.2067 - recall_121: 1.0000 - precision_121: 0.2067\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9450 - accuracy: 0.2050 - recall_121: 1.0000 - precision_121: 0.2050\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9441 - accuracy: 0.2030 - recall_121: 1.0000 - precision_121: 0.2030\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9412 - accuracy: 0.2040 - recall_121: 1.0000 - precision_121: 0.2040\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9405 - accuracy: 0.2016 - recall_121: 1.0000 - precision_121: 0.2016\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9377 - accuracy: 0.2025 - recall_121: 1.0000 - precision_121: 0.2025\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9336 - accuracy: 0.2056 - recall_121: 1.0000 - precision_121: 0.2056\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9342 - accuracy: 0.2011 - recall_121: 1.0000 - precision_121: 0.2011\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9326 - accuracy: 0.2003 - recall_121: 1.0000 - precision_121: 0.2003\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9291 - accuracy: 0.2023 - recall_121: 1.0000 - precision_121: 0.2023\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9241 - accuracy: 0.2070 - recall_121: 1.0000 - precision_121: 0.2070\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9253 - accuracy: 0.2016 - recall_121: 1.0000 - precision_121: 0.2016\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9222 - accuracy: 0.2032 - recall_121: 1.0000 - precision_121: 0.2032\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9216 - accuracy: 0.2008 - recall_121: 1.0000 - precision_121: 0.2008\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9170 - accuracy: 0.2049 - recall_121: 1.0000 - precision_121: 0.2049\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9151 - accuracy: 0.2045 - recall_121: 1.0000 - precision_121: 0.2045\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9140 - accuracy: 0.2029 - recall_121: 1.0000 - precision_121: 0.2029\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9104 - accuracy: 0.2054 - recall_121: 1.0000 - precision_121: 0.2054\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9106 - accuracy: 0.2016 - recall_121: 1.0000 - precision_121: 0.2016\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9088 - accuracy: 0.2011 - recall_121: 1.0000 - precision_121: 0.2011\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.8971 - accuracy: 0.2185 - recall_121: 1.0000 - precision_121: 0.218 - 0s 3ms/step - loss: 0.9037 - accuracy: 0.2064 - recall_121: 1.0000 - precision_121: 0.2064\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9024 - accuracy: 0.2051 - recall_121: 1.0000 - precision_121: 0.2051\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9006 - accuracy: 0.2049 - recall_121: 1.0000 - precision_121: 0.2049\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8995 - accuracy: 0.2032 - recall_121: 1.0000 - precision_121: 0.2032\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8959 - accuracy: 0.2061 - recall_121: 1.0000 - precision_121: 0.2061\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8945 - accuracy: 0.2050 - recall_121: 1.0000 - precision_121: 0.2050\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8951 - accuracy: 0.2003 - recall_121: 1.0000 - precision_121: 0.2003\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8901 - accuracy: 0.2059 - recall_121: 1.0000 - precision_121: 0.2059\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8894 - accuracy: 0.2036 - recall_121: 1.0000 - precision_121: 0.2036\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8903 - accuracy: 0.1983 - recall_121: 1.0000 - precision_121: 0.1983\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8872 - accuracy: 0.2005 - recall_121: 1.0000 - precision_121: 0.2005\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8832 - accuracy: 0.2044 - recall_121: 1.0000 - precision_121: 0.2044\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8804 - accuracy: 0.2060 - recall_121: 1.0000 - precision_121: 0.2060\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8818 - accuracy: 0.1998 - recall_121: 1.0000 - precision_121: 0.1998\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8775 - accuracy: 0.2045 - recall_121: 1.0000 - precision_121: 0.2045\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8759 - accuracy: 0.2040 - recall_121: 1.0000 - precision_121: 0.2040\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8764 - accuracy: 0.1991 - recall_121: 1.0000 - precision_121: 0.1991\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8722 - accuracy: 0.2038 - recall_121: 1.0000 - precision_121: 0.2038\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8729 - accuracy: 0.1987 - recall_121: 1.0000 - precision_121: 0.1987\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8713 - accuracy: 0.1982 - recall_121: 1.0000 - precision_121: 0.1982\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8666 - accuracy: 0.2042 - recall_121: 1.0000 - precision_121: 0.2042\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8641 - accuracy: 0.2056 - recall_121: 1.0000 - precision_121: 0.2056\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8644 - accuracy: 0.2013 - recall_121: 1.0000 - precision_121: 0.2013\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8626 - accuracy: 0.2011 - recall_121: 1.0000 - precision_121: 0.2011\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8583 - accuracy: 0.2065 - recall_121: 1.0000 - precision_121: 0.2065\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8577 - accuracy: 0.2040 - recall_121: 1.0000 - precision_121: 0.2040\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8582 - accuracy: 0.1992 - recall_121: 1.0000 - precision_121: 0.1992\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8528 - accuracy: 0.2071 - recall_121: 1.0000 - precision_121: 0.2071\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8534 - accuracy: 0.2021 - recall_121: 1.0000 - precision_121: 0.2021\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8512 - accuracy: 0.2030 - recall_121: 1.0000 - precision_121: 0.2030\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8492 - accuracy: 0.2036 - recall_121: 1.0000 - precision_121: 0.2036\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8485 - accuracy: 0.2012 - recall_121: 1.0000 - precision_121: 0.2012\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8472 - accuracy: 0.2003 - recall_121: 1.0000 - precision_121: 0.2003\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8454 - accuracy: 0.2005 - recall_121: 1.0000 - precision_121: 0.2005\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6599AC160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.8430 - accuracy: 0.2027 - recall_121: 1.0000 - precision_121: 0.2027\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6476 - accuracy: 0.7973 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6469 - accuracy: 0.7977 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.7967 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.7981 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.7973 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.7937 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6438 - accuracy: 0.7960 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6431 - accuracy: 0.7966 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.7963 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.7980 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.7994 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.7973 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.8013 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.7973 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.7940 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.7962 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.7970 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7958 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.7959 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.7934 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.7975 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.7954 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.7986 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.7980 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.7975 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6325 - accuracy: 0.7937 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.7969 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.7957 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.8005 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.7982 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.7952 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.7986 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.7988 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.7983 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.7951 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.7962 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.7965 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.7952 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.7963 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.7965 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.7985 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.7958 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.7945 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6233 - accuracy: 0.7905 - recall_122: 0.0000e+00 - precision_122: 0.0000e+0 - 0s 4ms/step - loss: 0.6219 - accuracy: 0.7953 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.7970 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6195 - accuracy: 0.8000 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.7917 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.7998 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6187 - accuracy: 0.7971 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.7953 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.7979 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.7972 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.7930 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.7965 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.7970 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.7965 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.7943 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.7968 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7929 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.7953 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6129 - accuracy: 0.7957 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.7962 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6116 - accuracy: 0.7967 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.7955 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.7960 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6098 - accuracy: 0.7978 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6089 - accuracy: 0.7989 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.7973 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.7968 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6086 - accuracy: 0.7955 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.8006 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.7981 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.7985 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.7952 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.8000 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.7998 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.7992 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.8002 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.7965 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.7978 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6027 - accuracy: 0.7979 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6030 - accuracy: 0.7958 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6028 - accuracy: 0.7952 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6010 - accuracy: 0.7988 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.7992 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.7935 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.7977 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.7957 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.7982 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7970 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7989 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.7918 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.7938 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7991 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.7990 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.7990 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.7957 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5957 - accuracy: 0.7968 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.7992 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.8022 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580328B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.7977 - recall_122: 0.0000e+00 - precision_122: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7859 - accuracy: 0.2051 - recall_123: 1.0000 - precision_123: 0.2051\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7845 - accuracy: 0.2054 - recall_123: 1.0000 - precision_123: 0.2054\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7839 - accuracy: 0.2026 - recall_123: 1.0000 - precision_123: 0.2026\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7824 - accuracy: 0.2033 - recall_123: 1.0000 - precision_123: 0.2033\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7823 - accuracy: 0.1989 - recall_123: 1.0000 - precision_123: 0.1989\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7808 - accuracy: 0.1994 - recall_123: 1.0000 - precision_123: 0.1994\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7779 - accuracy: 0.2059 - recall_123: 1.0000 - precision_123: 0.2059\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7789 - accuracy: 0.1967 - recall_123: 1.0000 - precision_123: 0.1967\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7765 - accuracy: 0.2012 - recall_123: 1.0000 - precision_123: 0.2012\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7756 - accuracy: 0.1997 - recall_123: 1.0000 - precision_123: 0.1997\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7740 - accuracy: 0.2007 - recall_123: 1.0000 - precision_123: 0.2007\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7728 - accuracy: 0.2002 - recall_123: 1.0000 - precision_123: 0.2002\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7714 - accuracy: 0.2009 - recall_123: 1.0000 - precision_123: 0.2009\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7704 - accuracy: 0.1999 - recall_123: 1.0000 - precision_123: 0.1999\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7682 - accuracy: 0.2039 - recall_123: 1.0000 - precision_123: 0.2039\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7671 - accuracy: 0.2036 - recall_123: 1.0000 - precision_123: 0.2036\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7663 - accuracy: 0.2014 - recall_123: 1.0000 - precision_123: 0.2014\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7650 - accuracy: 0.2017 - recall_123: 1.0000 - precision_123: 0.2017\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7641 - accuracy: 0.2006 - recall_123: 1.0000 - precision_123: 0.2006\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7620 - accuracy: 0.2046 - recall_123: 1.0000 - precision_123: 0.2046\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7608 - accuracy: 0.2041 - recall_123: 1.0000 - precision_123: 0.2041\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7603 - accuracy: 0.2020 - recall_123: 1.0000 - precision_123: 0.202 - 0s 4ms/step - loss: 0.7602 - accuracy: 0.2016 - recall_123: 1.0000 - precision_123: 0.2016\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7597 - accuracy: 0.1981 - recall_123: 1.0000 - precision_123: 0.1981\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7574 - accuracy: 0.2036 - recall_123: 1.0000 - precision_123: 0.2036\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7563 - accuracy: 0.2027 - recall_123: 1.0000 - precision_123: 0.2027\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7546 - accuracy: 0.2054 - recall_123: 1.0000 - precision_123: 0.2054\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7539 - accuracy: 0.2031 - recall_123: 1.0000 - precision_123: 0.2031\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.1997 - recall_123: 1.0000 - precision_123: 0.1997\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7522 - accuracy: 0.1998 - recall_123: 1.0000 - precision_123: 0.1998\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7510 - accuracy: 0.1999 - recall_123: 1.0000 - precision_123: 0.1999\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.2007 - recall_123: 1.0000 - precision_123: 0.2007\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7484 - accuracy: 0.2014 - recall_123: 1.0000 - precision_123: 0.2014\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7470 - accuracy: 0.2029 - recall_123: 1.0000 - precision_123: 0.2029\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7464 - accuracy: 0.1997 - recall_123: 1.0000 - precision_123: 0.1997\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7452 - accuracy: 0.2000 - recall_123: 1.0000 - precision_123: 0.2000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7440 - accuracy: 0.2007 - recall_123: 1.0000 - precision_123: 0.2007\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7426 - accuracy: 0.2021 - recall_123: 1.0000 - precision_123: 0.2021\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7412 - accuracy: 0.2041 - recall_123: 1.0000 - precision_123: 0.2041\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7403 - accuracy: 0.2028 - recall_123: 1.0000 - precision_123: 0.2028\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7392 - accuracy: 0.2026 - recall_123: 1.0000 - precision_123: 0.2026\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7385 - accuracy: 0.1999 - recall_123: 1.0000 - precision_123: 0.1999\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7374 - accuracy: 0.2003 - recall_123: 1.0000 - precision_123: 0.2003\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7358 - accuracy: 0.2040 - recall_123: 1.0000 - precision_123: 0.2040\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.2027 - recall_123: 1.0000 - precision_123: 0.2027\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7340 - accuracy: 0.2013 - recall_123: 1.0000 - precision_123: 0.2013\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7328 - accuracy: 0.2023 - recall_123: 1.0000 - precision_123: 0.2023\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7318 - accuracy: 0.2021 - recall_123: 1.0000 - precision_123: 0.2021\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7307 - accuracy: 0.2020 - recall_123: 1.0000 - precision_123: 0.2020\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7295 - accuracy: 0.2031 - recall_123: 1.0000 - precision_123: 0.2031\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7286 - accuracy: 0.2022 - recall_123: 1.0000 - precision_123: 0.2022\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7276 - accuracy: 0.2020 - recall_123: 1.0000 - precision_123: 0.2020\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7263 - accuracy: 0.2040 - recall_123: 1.0000 - precision_123: 0.2040\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7252 - accuracy: 0.2045 - recall_123: 1.0000 - precision_123: 0.2045\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7243 - accuracy: 0.2036 - recall_123: 1.0000 - precision_123: 0.2036\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7234 - accuracy: 0.2016 - recall_123: 1.0000 - precision_123: 0.2016\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7224 - accuracy: 0.2015 - recall_123: 1.0000 - precision_123: 0.2015\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7225 - accuracy: 0.1915 - recall_123: 1.0000 - precision_123: 0.191 - 0s 5ms/step - loss: 0.7216 - accuracy: 0.1998 - recall_123: 1.0000 - precision_123: 0.1998\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.2052 - recall_123: 1.0000 - precision_123: 0.2052\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.2016 - recall_123: 1.0000 - precision_123: 0.2016\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7185 - accuracy: 0.2013 - recall_123: 1.0000 - precision_123: 0.2013\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.2029 - recall_123: 1.0000 - precision_123: 0.2029\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7164 - accuracy: 0.2029 - recall_123: 1.0000 - precision_123: 0.2029\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7152 - accuracy: 0.2054 - recall_123: 1.0000 - precision_123: 0.2054\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7143 - accuracy: 0.2042 - recall_123: 1.0000 - precision_123: 0.2042\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7135 - accuracy: 0.2021 - recall_123: 1.0000 - precision_123: 0.2021\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.2073 - recall_123: 1.0000 - precision_123: 0.2073\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7116 - accuracy: 0.2011 - recall_123: 1.0000 - precision_123: 0.2011\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.2005 - recall_123: 1.0000 - precision_123: 0.2005\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7095 - accuracy: 0.2033 - recall_123: 1.0000 - precision_123: 0.2033\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7086 - accuracy: 0.2029 - recall_123: 1.0000 - precision_123: 0.2029\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7076 - accuracy: 0.2037 - recall_123: 1.0000 - precision_123: 0.2037\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7068 - accuracy: 0.2026 - recall_123: 1.0000 - precision_123: 0.2026\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7058 - accuracy: 0.2027 - recall_123: 1.0000 - precision_123: 0.2027\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7049 - accuracy: 0.2039 - recall_123: 1.0000 - precision_123: 0.2039\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7040 - accuracy: 0.2022 - recall_123: 1.0000 - precision_123: 0.2022\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7030 - accuracy: 0.2034 - recall_123: 1.0000 - precision_123: 0.2034\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7021 - accuracy: 0.2032 - recall_123: 1.0000 - precision_123: 0.2032\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7012 - accuracy: 0.2012 - recall_123: 1.0000 - precision_123: 0.2012\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7003 - accuracy: 0.2024 - recall_123: 1.0000 - precision_123: 0.2024\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.2041 - recall_123: 1.0000 - precision_123: 0.2041\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6984 - accuracy: 0.2072 - recall_123: 1.0000 - precision_123: 0.2072\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6977 - accuracy: 0.2004 - recall_123: 1.0000 - precision_123: 0.2004\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6967 - accuracy: 0.2003 - recall_123: 1.0000 - precision_123: 0.2003\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.2041 - recall_123: 1.0000 - precision_123: 0.2041\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.2120 - recall_123: 0.9864 - precision_123: 0.2060\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.2748 - recall_123: 0.8782 - precision_123: 0.2019\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4827 - recall_123: 0.5920 - precision_123: 0.2150\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.6976 - recall_123: 0.2452 - precision_123: 0.2454\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.7869 - recall_123: 0.0220 - precision_123: 0.2318\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.7986 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.7999 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.7954 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.7986 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.7958 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.7994 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.7990 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.7880 - recall_123: 0.0000e+00 - precision_123: 0.0000e+0 - 0s 3ms/step - loss: 0.6849 - accuracy: 0.7953 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.7993 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.7919 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.7986 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.6817 - accuracy: 0.7973 - recall_123: 0.0000e+00 - precision_123: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7197 - accuracy: 0.5280 - recall_124: 0.4757 - precision_124: 0.2071\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7142 - accuracy: 0.5354 - recall_124: 0.4733 - precision_124: 0.2105\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7100 - accuracy: 0.5406 - recall_124: 0.4481 - precision_124: 0.2044\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7045 - accuracy: 0.5416 - recall_124: 0.4280 - precision_124: 0.2021\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6979 - accuracy: 0.5501 - recall_124: 0.4187 - precision_124: 0.2069\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5572 - recall_124: 0.3997 - precision_124: 0.1967\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.5616 - recall_124: 0.3917 - precision_124: 0.2028\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.5653 - recall_124: 0.3714 - precision_124: 0.1951\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.5846 - recall_124: 0.3791 - precision_124: 0.2107\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.5890 - recall_124: 0.3604 - precision_124: 0.2054\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.5952 - recall_124: 0.3494 - precision_124: 0.2053\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6066 - recall_124: 0.3448 - precision_124: 0.2106\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.6157 - recall_124: 0.3343 - precision_124: 0.2158\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6510 - accuracy: 0.6216 - recall_124: 0.3236 - precision_124: 0.2132\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.6211 - recall_124: 0.3069 - precision_124: 0.2125\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6435 - accuracy: 0.6348 - recall_124: 0.3108 - precision_124: 0.2145\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.6381 - recall_124: 0.3000 - precision_124: 0.2229\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6335 - accuracy: 0.6479 - recall_124: 0.2903 - precision_124: 0.2154\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6460 - recall_124: 0.2750 - precision_124: 0.2130\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.6555 - recall_124: 0.2731 - precision_124: 0.2148\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.6611 - recall_124: 0.2668 - precision_124: 0.2215\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.6657 - recall_124: 0.2636 - precision_124: 0.2203\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.6710 - recall_124: 0.2419 - precision_124: 0.2210\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.6738 - recall_124: 0.2386 - precision_124: 0.2239\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.6842 - recall_124: 0.2397 - precision_124: 0.2277\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6023 - accuracy: 0.6948 - recall_124: 0.2313 - precision_124: 0.2321\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6037 - accuracy: 0.6901 - recall_124: 0.2149 - precision_124: 0.2239\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.6936 - recall_124: 0.2123 - precision_124: 0.2241\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7002 - recall_124: 0.1961 - precision_124: 0.2223\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.7047 - recall_124: 0.1906 - precision_124: 0.2250\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7047 - recall_124: 0.1799 - precision_124: 0.2239\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7094 - recall_124: 0.1691 - precision_124: 0.2185\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5873 - accuracy: 0.7146 - recall_124: 0.1620 - precision_124: 0.2229\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.7218 - recall_124: 0.1498 - precision_124: 0.2182\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.7249 - recall_124: 0.1430 - precision_124: 0.2238\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5777 - accuracy: 0.7306 - recall_124: 0.1363 - precision_124: 0.2239\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7363 - recall_124: 0.1351 - precision_124: 0.2331\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7385 - recall_124: 0.1225 - precision_124: 0.2278\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7434 - recall_124: 0.1185 - precision_124: 0.2352\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7486 - recall_124: 0.1085 - precision_124: 0.2327\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7485 - recall_124: 0.1011 - precision_124: 0.2347\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5648 - accuracy: 0.7542 - recall_124: 0.1013 - precision_124: 0.2486\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.7590 - recall_124: 0.0958 - precision_124: 0.2519\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5583 - accuracy: 0.7615 - recall_124: 0.0853 - precision_124: 0.2397\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7644 - recall_124: 0.0795 - precision_124: 0.2426\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5547 - accuracy: 0.7688 - recall_124: 0.0703 - precision_124: 0.2375\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7704 - recall_124: 0.0750 - precision_124: 0.2639\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7727 - recall_124: 0.0681 - precision_124: 0.2443\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5523 - accuracy: 0.7704 - recall_124: 0.0637 - precision_124: 0.2616\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7805 - recall_124: 0.0623 - precision_124: 0.2791\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7761 - recall_124: 0.0637 - precision_124: 0.2908\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.7815 - recall_124: 0.0604 - precision_124: 0.3002\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5434 - accuracy: 0.7836 - recall_124: 0.0572 - precision_124: 0.3100\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7834 - recall_124: 0.0539 - precision_124: 0.3109\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5393 - accuracy: 0.7878 - recall_124: 0.0557 - precision_124: 0.3506\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5391 - accuracy: 0.7869 - recall_124: 0.0492 - precision_124: 0.3392\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7910 - recall_124: 0.0489 - precision_124: 0.3687\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7922 - recall_124: 0.0454 - precision_124: 0.3692\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7937 - recall_124: 0.0415 - precision_124: 0.3807\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.7933 - recall_124: 0.0407 - precision_124: 0.3853\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7891 - recall_124: 0.0401 - precision_124: 0.4072\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7947 - recall_124: 0.0379 - precision_124: 0.4066\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7963 - recall_124: 0.0400 - precision_124: 0.4738\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7969 - recall_124: 0.0350 - precision_124: 0.4862\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7958 - recall_124: 0.0330 - precision_124: 0.4926\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7943 - recall_124: 0.0309 - precision_124: 0.5031\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7950 - recall_124: 0.0290 - precision_124: 0.4907\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5203 - accuracy: 0.8017 - recall_124: 0.0305 - precision_124: 0.5324\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7968 - recall_124: 0.0290 - precision_124: 0.6211\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7990 - recall_124: 0.0261 - precision_124: 0.6574\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.8033 - recall_124: 0.0287 - precision_124: 0.7217\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7995 - recall_124: 0.0264 - precision_124: 0.7456\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.8008 - recall_124: 0.0220 - precision_124: 0.6867\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.8017 - recall_124: 0.0280 - precision_124: 0.7291\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.8029 - recall_124: 0.0236 - precision_124: 0.7465\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.8014 - recall_124: 0.0222 - precision_124: 0.7079\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5111 - accuracy: 0.8013 - recall_124: 0.0225 - precision_124: 0.7287\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7989 - recall_124: 0.0196 - precision_124: 0.7636\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7980 - recall_124: 0.0187 - precision_124: 0.7864\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.8007 - recall_124: 0.0195 - precision_124: 0.8469\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.8017 - recall_124: 0.0152 - precision_124: 0.7447\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.8002 - recall_124: 0.0148 - precision_124: 0.7123\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7982 - recall_124: 0.0115 - precision_124: 0.6949\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.8020 - recall_124: 0.0126 - precision_124: 0.7976\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7992 - recall_124: 0.0143 - precision_124: 0.8591\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5016 - accuracy: 0.8031 - recall_124: 0.0118 - precision_124: 0.7901\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.8006 - recall_124: 0.0123 - precision_124: 0.8831\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.8002 - recall_124: 0.0108 - precision_124: 0.9003\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7986 - recall_124: 0.0134 - precision_124: 0.8276\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5007 - accuracy: 0.8013 - recall_124: 0.0100 - precision_124: 0.9295\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.7999 - recall_124: 0.0112 - precision_124: 0.9295\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7989 - recall_124: 0.0082 - precision_124: 0.8507\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.8009 - recall_124: 0.0086 - precision_124: 0.9167\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.7985 - recall_124: 0.0097 - precision_124: 0.8730\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7987 - recall_124: 0.0091 - precision_124: 0.9167\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4981 - accuracy: 0.7987 - recall_124: 0.0088 - precision_124: 0.9132\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.8012 - recall_124: 0.0083 - precision_124: 0.8507\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7997 - recall_124: 0.0095 - precision_124: 0.8715\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7975 - recall_124: 0.0091 - precision_124: 0.9167\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7973 - recall_124: 0.0065 - precision_124: 0.8869\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657C9E820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7973 - recall_124: 0.0021 - precision_124: 0.5000\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7404 - accuracy: 0.4663 - recall_125: 0.4869 - precision_125: 0.1857\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7336 - accuracy: 0.4708 - recall_125: 0.4846 - precision_125: 0.1874\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7266 - accuracy: 0.4790 - recall_125: 0.4835 - precision_125: 0.1902\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7189 - accuracy: 0.4855 - recall_125: 0.4684 - precision_125: 0.1903\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7147 - accuracy: 0.4909 - recall_125: 0.4578 - precision_125: 0.1898\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7092 - accuracy: 0.4964 - recall_125: 0.4579 - precision_125: 0.1955\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7048 - accuracy: 0.5048 - recall_125: 0.4450 - precision_125: 0.1908\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6994 - accuracy: 0.5095 - recall_125: 0.4395 - precision_125: 0.1883\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.5238 - recall_125: 0.4327 - precision_125: 0.1949\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.5342 - recall_125: 0.4248 - precision_125: 0.1969\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.5343 - recall_125: 0.4094 - precision_125: 0.1914\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.5454 - recall_125: 0.4055 - precision_125: 0.1966\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.5513 - recall_125: 0.3857 - precision_125: 0.1939\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.5574 - recall_125: 0.3750 - precision_125: 0.1932\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.5741 - recall_125: 0.3713 - precision_125: 0.2016\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.5825 - recall_125: 0.3725 - precision_125: 0.203 - 0s 4ms/step - loss: 0.6570 - accuracy: 0.5818 - recall_125: 0.3715 - precision_125: 0.2043\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6543 - accuracy: 0.5876 - recall_125: 0.3619 - precision_125: 0.2101\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.5992 - recall_125: 0.3498 - precision_125: 0.2111\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6445 - accuracy: 0.6053 - recall_125: 0.3407 - precision_125: 0.2069\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.6156 - recall_125: 0.3434 - precision_125: 0.2158\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.6198 - recall_125: 0.3287 - precision_125: 0.2172\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.6359 - recall_125: 0.3315 - precision_125: 0.2294\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.6423 - recall_125: 0.3019 - precision_125: 0.2174\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.6440 - recall_125: 0.2977 - precision_125: 0.2214\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6178 - accuracy: 0.6650 - recall_125: 0.3127 - precision_125: 0.230 - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6603 - recall_125: 0.3023 - precision_125: 0.2320\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.6637 - recall_125: 0.2852 - precision_125: 0.2306\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.6678 - recall_125: 0.2833 - precision_125: 0.2433\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.6760 - recall_125: 0.2736 - precision_125: 0.2406\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.6808 - recall_125: 0.2523 - precision_125: 0.2300\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.6870 - recall_125: 0.2465 - precision_125: 0.2293\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.6933 - recall_125: 0.2333 - precision_125: 0.2332\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.7026 - recall_125: 0.2377 - precision_125: 0.2487\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.7031 - recall_125: 0.2189 - precision_125: 0.2477\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7132 - recall_125: 0.2070 - precision_125: 0.2529\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7162 - recall_125: 0.1990 - precision_125: 0.2532\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7272 - recall_125: 0.2025 - precision_125: 0.2642\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.7276 - recall_125: 0.1826 - precision_125: 0.2589\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7324 - recall_125: 0.1769 - precision_125: 0.2640\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7367 - recall_125: 0.1665 - precision_125: 0.2591\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7412 - recall_125: 0.1600 - precision_125: 0.2691\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7433 - recall_125: 0.1644 - precision_125: 0.2770\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.7504 - recall_125: 0.1486 - precision_125: 0.2799\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7457 - recall_125: 0.1444 - precision_125: 0.2722\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.7534 - recall_125: 0.1217 - precision_125: 0.2519\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7581 - recall_125: 0.1250 - precision_125: 0.2883\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.7606 - recall_125: 0.1182 - precision_125: 0.2792\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7631 - recall_125: 0.1162 - precision_125: 0.2922\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.7667 - recall_125: 0.1039 - precision_125: 0.2890\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5532 - accuracy: 0.7721 - recall_125: 0.1061 - precision_125: 0.3126\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.7698 - recall_125: 0.0975 - precision_125: 0.2945\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.7703 - recall_125: 0.0933 - precision_125: 0.2921\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.7718 - recall_125: 0.0827 - precision_125: 0.2919\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7800 - recall_125: 0.0800 - precision_125: 0.3058\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7767 - recall_125: 0.0749 - precision_125: 0.3067\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7824 - recall_125: 0.0694 - precision_125: 0.3116\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5410 - accuracy: 0.7819 - recall_125: 0.0678 - precision_125: 0.3234\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7825 - recall_125: 0.0726 - precision_125: 0.3444\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7861 - recall_125: 0.0704 - precision_125: 0.3536\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7806 - recall_125: 0.0587 - precision_125: 0.3356\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7851 - recall_125: 0.0545 - precision_125: 0.3200\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7859 - recall_125: 0.0559 - precision_125: 0.3428\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7867 - recall_125: 0.0524 - precision_125: 0.3422\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7854 - recall_125: 0.0472 - precision_125: 0.3224\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7898 - recall_125: 0.0523 - precision_125: 0.3690\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7887 - recall_125: 0.0466 - precision_125: 0.3391\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7921 - recall_125: 0.0487 - precision_125: 0.3665\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7863 - recall_125: 0.0449 - precision_125: 0.3524\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5202 - accuracy: 0.7920 - recall_125: 0.0435 - precision_125: 0.3850\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7900 - recall_125: 0.0352 - precision_125: 0.3456\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.7925 - recall_125: 0.0385 - precision_125: 0.3902\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7930 - recall_125: 0.0379 - precision_125: 0.4196\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7933 - recall_125: 0.0288 - precision_125: 0.3741\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5141 - accuracy: 0.7949 - recall_125: 0.0305 - precision_125: 0.4074\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7959 - recall_125: 0.0292 - precision_125: 0.4468\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7947 - recall_125: 0.0239 - precision_125: 0.4094\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.7971 - recall_125: 0.0290 - precision_125: 0.4681\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7983 - recall_125: 0.0277 - precision_125: 0.5324\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.8016 - recall_125: 0.0240 - precision_125: 0.4793\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7968 - recall_125: 0.0237 - precision_125: 0.5101\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7956 - recall_125: 0.0251 - precision_125: 0.5495\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7992 - recall_125: 0.0242 - precision_125: 0.5869\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7990 - recall_125: 0.0254 - precision_125: 0.5925\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.8000 - recall_125: 0.0263 - precision_125: 0.6098\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7983 - recall_125: 0.0236 - precision_125: 0.5813\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7996 - recall_125: 0.0225 - precision_125: 0.5766\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7997 - recall_125: 0.0215 - precision_125: 0.6460\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7953 - recall_125: 0.0219 - precision_125: 0.6391\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7980 - recall_125: 0.0160 - precision_125: 0.6310\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7982 - recall_125: 0.0222 - precision_125: 0.7207\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.7969 - recall_125: 0.0203 - precision_125: 0.6923\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.8025 - recall_125: 0.0218 - precision_125: 0.7412\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.8029 - recall_125: 0.0216 - precision_125: 0.7630\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.8017 - recall_125: 0.0186 - precision_125: 0.7537\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.8015 - recall_125: 0.0150 - precision_125: 0.750 - 0s 4ms/step - loss: 0.4924 - accuracy: 0.8012 - recall_125: 0.0173 - precision_125: 0.7594\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7997 - recall_125: 0.0193 - precision_125: 0.7731\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7996 - recall_125: 0.0171 - precision_125: 0.8003\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4879 - accuracy: 0.8011 - recall_125: 0.0167 - precision_125: 0.8170\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4902 - accuracy: 0.8017 - recall_125: 0.0168 - precision_125: 0.7822\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7993 - recall_125: 0.0150 - precision_125: 0.7942\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.8004 - recall_125: 0.0157 - precision_125: 0.7526\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65DA774C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.4891 - accuracy: 0.7994 - recall_125: 0.0191 - precision_125: 0.6429\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7212 - accuracy: 0.5550 - recall_126: 0.6779 - precision_126: 0.2680\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7204 - accuracy: 0.5511 - recall_126: 0.6683 - precision_126: 0.2587\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7113 - accuracy: 0.5581 - recall_126: 0.6705 - precision_126: 0.2649\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7000 - accuracy: 0.5683 - recall_126: 0.6654 - precision_126: 0.2729\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6955 - accuracy: 0.5683 - recall_126: 0.6644 - precision_126: 0.2680\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.5745 - recall_126: 0.6550 - precision_126: 0.2686\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.5805 - recall_126: 0.6571 - precision_126: 0.2722\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.5823 - recall_126: 0.6366 - precision_126: 0.2697\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.5882 - recall_126: 0.6415 - precision_126: 0.2747\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.5875 - recall_126: 0.6329 - precision_126: 0.2795\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.5940 - recall_126: 0.6300 - precision_126: 0.2760\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6544 - accuracy: 0.5972 - recall_126: 0.6126 - precision_126: 0.2706\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.6045 - recall_126: 0.6192 - precision_126: 0.2854\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6050 - recall_126: 0.6143 - precision_126: 0.2811\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.6115 - recall_126: 0.6067 - precision_126: 0.2829\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.6141 - recall_126: 0.6063 - precision_126: 0.2872\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6278 - accuracy: 0.6212 - recall_126: 0.6021 - precision_126: 0.2889\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6251 - accuracy: 0.6247 - recall_126: 0.5933 - precision_126: 0.2942\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6193 - accuracy: 0.6304 - recall_126: 0.5912 - precision_126: 0.2936\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.6342 - recall_126: 0.5746 - precision_126: 0.2924\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.6394 - recall_126: 0.5774 - precision_126: 0.2977\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6448 - recall_126: 0.5705 - precision_126: 0.2997\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6473 - recall_126: 0.5614 - precision_126: 0.3014\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.6542 - recall_126: 0.5624 - precision_126: 0.3079\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.6550 - recall_126: 0.5579 - precision_126: 0.3081\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.6640 - recall_126: 0.5504 - precision_126: 0.3152\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5895 - accuracy: 0.6686 - recall_126: 0.5478 - precision_126: 0.3153\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6698 - recall_126: 0.5406 - precision_126: 0.3154\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.6796 - recall_126: 0.5358 - precision_126: 0.3302\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.6789 - recall_126: 0.5224 - precision_126: 0.3237\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.6846 - recall_126: 0.5191 - precision_126: 0.3252\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.6888 - recall_126: 0.5179 - precision_126: 0.3254\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.6914 - recall_126: 0.5096 - precision_126: 0.3304\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.6954 - recall_126: 0.5069 - precision_126: 0.3374\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.6975 - recall_126: 0.4879 - precision_126: 0.3292\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.6967 - recall_126: 0.4756 - precision_126: 0.3259\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7058 - recall_126: 0.4906 - precision_126: 0.3466\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7059 - recall_126: 0.4720 - precision_126: 0.3373\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5420 - accuracy: 0.7330 - recall_126: 0.5240 - precision_126: 0.393 - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7183 - recall_126: 0.4858 - precision_126: 0.3590\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7207 - recall_126: 0.4685 - precision_126: 0.3485\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7216 - recall_126: 0.4596 - precision_126: 0.3525\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7176 - recall_126: 0.4512 - precision_126: 0.3464\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7243 - recall_126: 0.4504 - precision_126: 0.3566\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7254 - recall_126: 0.4362 - precision_126: 0.3547\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7307 - recall_126: 0.4226 - precision_126: 0.3619\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7328 - recall_126: 0.4227 - precision_126: 0.3590\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7381 - recall_126: 0.4107 - precision_126: 0.3654\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.7410 - recall_126: 0.4166 - precision_126: 0.3742\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7445 - recall_126: 0.4091 - precision_126: 0.3842\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7457 - recall_126: 0.3991 - precision_126: 0.3769\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7505 - recall_126: 0.3856 - precision_126: 0.3838\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7525 - recall_126: 0.3851 - precision_126: 0.3908\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7531 - recall_126: 0.3757 - precision_126: 0.3941\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7534 - recall_126: 0.3570 - precision_126: 0.3817\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5193 - accuracy: 0.7562 - recall_126: 0.3662 - precision_126: 0.3924\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7587 - recall_126: 0.3562 - precision_126: 0.3884\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7652 - recall_126: 0.3522 - precision_126: 0.4007\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7663 - recall_126: 0.3486 - precision_126: 0.3995\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7648 - recall_126: 0.3416 - precision_126: 0.4035\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7662 - recall_126: 0.3447 - precision_126: 0.4163\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7716 - recall_126: 0.3337 - precision_126: 0.4178\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7719 - recall_126: 0.3229 - precision_126: 0.4175\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7765 - recall_126: 0.3285 - precision_126: 0.4297\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7767 - recall_126: 0.3224 - precision_126: 0.4302\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7772 - recall_126: 0.3163 - precision_126: 0.4442\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7795 - recall_126: 0.3134 - precision_126: 0.4423\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5018 - accuracy: 0.7811 - recall_126: 0.2966 - precision_126: 0.4324\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7880 - recall_126: 0.3014 - precision_126: 0.4471\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7871 - recall_126: 0.2873 - precision_126: 0.4467\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7859 - recall_126: 0.2861 - precision_126: 0.4528\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7863 - recall_126: 0.2802 - precision_126: 0.4565\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7900 - recall_126: 0.2760 - precision_126: 0.4723\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7902 - recall_126: 0.2650 - precision_126: 0.4698\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4922 - accuracy: 0.7917 - recall_126: 0.2554 - precision_126: 0.4701\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7907 - recall_126: 0.2502 - precision_126: 0.4706\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7931 - recall_126: 0.2583 - precision_126: 0.4871\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7946 - recall_126: 0.2386 - precision_126: 0.4810\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7957 - recall_126: 0.2494 - precision_126: 0.4843\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7955 - recall_126: 0.2440 - precision_126: 0.4920\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.8004 - recall_126: 0.2426 - precision_126: 0.5003\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7948 - recall_126: 0.2266 - precision_126: 0.4936\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7980 - recall_126: 0.2403 - precision_126: 0.5174\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7995 - recall_126: 0.2362 - precision_126: 0.5121\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7997 - recall_126: 0.2199 - precision_126: 0.4904\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.8009 - recall_126: 0.2272 - precision_126: 0.5098\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7974 - recall_126: 0.2238 - precision_126: 0.5163\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7984 - recall_126: 0.2243 - precision_126: 0.4980\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.8005 - recall_126: 0.2091 - precision_126: 0.5141\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4811 - accuracy: 0.7977 - recall_126: 0.2099 - precision_126: 0.5218\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7969 - recall_126: 0.1904 - precision_126: 0.4960\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7991 - recall_126: 0.1984 - precision_126: 0.5131\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.8013 - recall_126: 0.2006 - precision_126: 0.5269\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8010 - recall_126: 0.1940 - precision_126: 0.5216\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.8024 - recall_126: 0.1958 - precision_126: 0.5335\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7998 - recall_126: 0.1855 - precision_126: 0.5331\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.8067 - recall_126: 0.1960 - precision_126: 0.5555\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.8030 - recall_126: 0.1723 - precision_126: 0.5200\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.8001 - recall_126: 0.1802 - precision_126: 0.5486\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.8047 - recall_126: 0.1820 - precision_126: 0.5505\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8042 - recall_126: 0.1803 - precision_126: 0.5548\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580329D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7883 - recall_126: 0.1522 - precision_126: 0.4364\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7135 - accuracy: 0.4624 - recall_127: 0.3744 - precision_127: 0.1547\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7132 - accuracy: 0.4604 - recall_127: 0.3664 - precision_127: 0.1509\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7122 - accuracy: 0.4664 - recall_127: 0.3717 - precision_127: 0.1600\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7099 - accuracy: 0.4728 - recall_127: 0.3705 - precision_127: 0.1579\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7100 - accuracy: 0.4704 - recall_127: 0.3538 - precision_127: 0.1553\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.4675 - recall_127: 0.3469 - precision_127: 0.1521\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7079 - accuracy: 0.4717 - recall_127: 0.3366 - precision_127: 0.1488\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7065 - accuracy: 0.4790 - recall_127: 0.3322 - precision_127: 0.1494\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.4786 - recall_127: 0.3240 - precision_127: 0.1462\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7052 - accuracy: 0.4854 - recall_127: 0.3308 - precision_127: 0.1493\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.4867 - recall_127: 0.3229 - precision_127: 0.1489\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7021 - accuracy: 0.4942 - recall_127: 0.3238 - precision_127: 0.1544\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7030 - accuracy: 0.4907 - recall_127: 0.3168 - precision_127: 0.1486\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7032 - accuracy: 0.4970 - recall_127: 0.3163 - precision_127: 0.160 - 0s 3ms/step - loss: 0.7017 - accuracy: 0.4980 - recall_127: 0.3137 - precision_127: 0.1524\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.5025 - recall_127: 0.3111 - precision_127: 0.1501\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.5010 - recall_127: 0.3039 - precision_127: 0.1481\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6986 - accuracy: 0.5041 - recall_127: 0.3030 - precision_127: 0.1490\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.5066 - recall_127: 0.3044 - precision_127: 0.1498\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6968 - accuracy: 0.5081 - recall_127: 0.3013 - precision_127: 0.1438\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.5158 - recall_127: 0.3080 - precision_127: 0.1544\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6944 - accuracy: 0.5198 - recall_127: 0.2967 - precision_127: 0.1532\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5261 - recall_127: 0.3067 - precision_127: 0.1583\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.5285 - recall_127: 0.3001 - precision_127: 0.1584\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5278 - recall_127: 0.2881 - precision_127: 0.1495\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.5351 - recall_127: 0.2843 - precision_127: 0.1516\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.5326 - recall_127: 0.2719 - precision_127: 0.1484\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.5403 - recall_127: 0.2818 - precision_127: 0.1549\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.5450 - recall_127: 0.2834 - precision_127: 0.1573\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.5439 - recall_127: 0.2719 - precision_127: 0.1490\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.5497 - recall_127: 0.2664 - precision_127: 0.1509\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.5465 - recall_127: 0.2553 - precision_127: 0.1472\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6847 - accuracy: 0.5544 - recall_127: 0.2663 - precision_127: 0.1515\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5617 - recall_127: 0.2537 - precision_127: 0.1510\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.5601 - recall_127: 0.2581 - precision_127: 0.1516\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.5637 - recall_127: 0.2547 - precision_127: 0.1528\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5678 - recall_127: 0.2475 - precision_127: 0.1502\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.5666 - recall_127: 0.2444 - precision_127: 0.1505\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6798 - accuracy: 0.5678 - recall_127: 0.2340 - precision_127: 0.1435\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.5741 - recall_127: 0.2267 - precision_127: 0.1495\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.5762 - recall_127: 0.2264 - precision_127: 0.1481\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.5754 - recall_127: 0.2252 - precision_127: 0.1493\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.5801 - recall_127: 0.2156 - precision_127: 0.1412\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6745 - accuracy: 0.5862 - recall_127: 0.2168 - precision_127: 0.1467\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.5868 - recall_127: 0.2153 - precision_127: 0.1442\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.5858 - recall_127: 0.2156 - precision_127: 0.1495\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.5893 - recall_127: 0.2080 - precision_127: 0.1425\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6719 - accuracy: 0.5929 - recall_127: 0.2118 - precision_127: 0.1495\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6705 - accuracy: 0.5961 - recall_127: 0.2030 - precision_127: 0.1428\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.5907 - recall_127: 0.2022 - precision_127: 0.1442\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.6033 - recall_127: 0.1948 - precision_127: 0.1410\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.6077 - recall_127: 0.2055 - precision_127: 0.1509\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.6102 - recall_127: 0.1941 - precision_127: 0.1430\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6690 - accuracy: 0.6028 - recall_127: 0.1857 - precision_127: 0.1447\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.6141 - recall_127: 0.1926 - precision_127: 0.1482\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6672 - accuracy: 0.6100 - recall_127: 0.1990 - precision_127: 0.148 - 0s 3ms/step - loss: 0.6660 - accuracy: 0.6123 - recall_127: 0.1915 - precision_127: 0.1472\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.6177 - recall_127: 0.1920 - precision_127: 0.1520\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.6207 - recall_127: 0.1913 - precision_127: 0.1518\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6632 - accuracy: 0.6220 - recall_127: 0.1783 - precision_127: 0.1455\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6632 - accuracy: 0.6256 - recall_127: 0.1793 - precision_127: 0.1519\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6607 - accuracy: 0.6325 - recall_127: 0.1789 - precision_127: 0.1499\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.6281 - recall_127: 0.1702 - precision_127: 0.1447\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.6306 - recall_127: 0.1623 - precision_127: 0.1426\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.6341 - recall_127: 0.1649 - precision_127: 0.1459\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.6379 - recall_127: 0.1606 - precision_127: 0.1440\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.6401 - recall_127: 0.1621 - precision_127: 0.1471\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.6400 - recall_127: 0.1523 - precision_127: 0.1421\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.6437 - recall_127: 0.1561 - precision_127: 0.1478\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6558 - accuracy: 0.6475 - recall_127: 0.1420 - precision_127: 0.1363\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.6491 - recall_127: 0.1385 - precision_127: 0.1354\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6539 - accuracy: 0.6551 - recall_127: 0.1474 - precision_127: 0.1461\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.6545 - recall_127: 0.1358 - precision_127: 0.1388\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6549 - recall_127: 0.1363 - precision_127: 0.1446\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6590 - recall_127: 0.1313 - precision_127: 0.1380\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.6594 - recall_127: 0.1246 - precision_127: 0.1299\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6634 - recall_127: 0.1301 - precision_127: 0.1383\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6495 - accuracy: 0.6643 - recall_127: 0.1248 - precision_127: 0.1380\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.6673 - recall_127: 0.1232 - precision_127: 0.1405\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6495 - accuracy: 0.6669 - recall_127: 0.1146 - precision_127: 0.1319\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.6701 - recall_127: 0.1207 - precision_127: 0.1394\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.6726 - recall_127: 0.1196 - precision_127: 0.1394\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.6706 - recall_127: 0.1162 - precision_127: 0.1395\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6812 - recall_127: 0.1092 - precision_127: 0.1383\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6826 - recall_127: 0.1136 - precision_127: 0.1393\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.6839 - recall_127: 0.1058 - precision_127: 0.1344\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6869 - recall_127: 0.1037 - precision_127: 0.1389\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6897 - recall_127: 0.1049 - precision_127: 0.1373\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.6930 - recall_127: 0.1071 - precision_127: 0.1461\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6925 - recall_127: 0.1002 - precision_127: 0.1395\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6419 - accuracy: 0.6924 - recall_127: 0.0990 - precision_127: 0.1385\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6410 - accuracy: 0.6954 - recall_127: 0.0957 - precision_127: 0.1390\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.7007 - recall_127: 0.0948 - precision_127: 0.1405\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6410 - accuracy: 0.6978 - recall_127: 0.0965 - precision_127: 0.1470\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.7044 - recall_127: 0.0950 - precision_127: 0.1522\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.7053 - recall_127: 0.0975 - precision_127: 0.1556\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.7124 - recall_127: 0.0933 - precision_127: 0.1516\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7095 - recall_127: 0.0931 - precision_127: 0.1486\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.7157 - recall_127: 0.0886 - precision_127: 0.1499\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7170 - recall_127: 0.0865 - precision_127: 0.1498\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.7202 - recall_127: 0.0881 - precision_127: 0.1495\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6356 - accuracy: 0.7150 - recall_127: 0.0795 - precision_127: 0.1416\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA13A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.6327 - accuracy: 0.7219 - recall_127: 0.0698 - precision_127: 0.1364\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6818 - accuracy: 0.5621 - recall_128: 0.6608 - precision_128: 0.2665\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.5682 - recall_128: 0.6647 - precision_128: 0.2714\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.5693 - recall_128: 0.6453 - precision_128: 0.2686\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.5787 - recall_128: 0.6364 - precision_128: 0.2723\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.5828 - recall_128: 0.6376 - precision_128: 0.2750\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6630 - accuracy: 0.5942 - recall_128: 0.6264 - precision_128: 0.2775\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.5962 - recall_128: 0.6199 - precision_128: 0.2770\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.6037 - recall_128: 0.6111 - precision_128: 0.2768\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.6046 - recall_128: 0.6033 - precision_128: 0.2797\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6532 - accuracy: 0.6115 - recall_128: 0.6117 - precision_128: 0.2862\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.6191 - recall_128: 0.6051 - precision_128: 0.2909\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6209 - recall_128: 0.5920 - precision_128: 0.2903\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.6227 - recall_128: 0.5708 - precision_128: 0.2868\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.6280 - recall_128: 0.5676 - precision_128: 0.2884\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.6370 - recall_128: 0.5720 - precision_128: 0.2953\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.6374 - recall_128: 0.5664 - precision_128: 0.2944\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.6450 - recall_128: 0.5452 - precision_128: 0.2919\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.6479 - recall_128: 0.5477 - precision_128: 0.2977\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.6516 - recall_128: 0.5478 - precision_128: 0.3017\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6576 - recall_128: 0.5302 - precision_128: 0.3019\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.6605 - recall_128: 0.5251 - precision_128: 0.3010\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.6701 - recall_128: 0.5255 - precision_128: 0.3115\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.6663 - recall_128: 0.5103 - precision_128: 0.3036\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.6709 - recall_128: 0.5108 - precision_128: 0.3072\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.6781 - recall_128: 0.5130 - precision_128: 0.3168\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.6821 - recall_128: 0.5024 - precision_128: 0.3203\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.6842 - recall_128: 0.4921 - precision_128: 0.3175\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.6922 - recall_128: 0.4883 - precision_128: 0.3263\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.6883 - recall_128: 0.4674 - precision_128: 0.3192\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.6982 - recall_128: 0.4676 - precision_128: 0.3301\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6010 - accuracy: 0.7045 - recall_128: 0.4709 - precision_128: 0.3340\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.7059 - recall_128: 0.4492 - precision_128: 0.3309\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5949 - accuracy: 0.7124 - recall_128: 0.4604 - precision_128: 0.3430\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.7138 - recall_128: 0.4550 - precision_128: 0.3450\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.7179 - recall_128: 0.4414 - precision_128: 0.3511\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.7249 - recall_128: 0.4449 - precision_128: 0.3558\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.7266 - recall_128: 0.4368 - precision_128: 0.3559\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.7303 - recall_128: 0.4301 - precision_128: 0.3567\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.7300 - recall_128: 0.4291 - precision_128: 0.3657\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5854 - accuracy: 0.7300 - recall_128: 0.4131 - precision_128: 0.348 - 0s 5ms/step - loss: 0.5833 - accuracy: 0.7349 - recall_128: 0.4179 - precision_128: 0.3616\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.7393 - recall_128: 0.4212 - precision_128: 0.3742\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5800 - accuracy: 0.7391 - recall_128: 0.4230 - precision_128: 0.3803\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7440 - recall_128: 0.4096 - precision_128: 0.3763\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.7511 - recall_128: 0.4140 - precision_128: 0.3853\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.7460 - recall_128: 0.4026 - precision_128: 0.3812\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.7534 - recall_128: 0.4015 - precision_128: 0.3881\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7554 - recall_128: 0.4107 - precision_128: 0.4003\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.7563 - recall_128: 0.3853 - precision_128: 0.4056\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5664 - accuracy: 0.7553 - recall_128: 0.3831 - precision_128: 0.3956\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5665 - accuracy: 0.7572 - recall_128: 0.3776 - precision_128: 0.3943\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7599 - recall_128: 0.3756 - precision_128: 0.3995\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.7666 - recall_128: 0.3682 - precision_128: 0.4165\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7661 - recall_128: 0.3635 - precision_128: 0.4148\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7667 - recall_128: 0.3567 - precision_128: 0.4223\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.7759 - recall_128: 0.3618 - precision_128: 0.4299\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.7796 - recall_128: 0.3573 - precision_128: 0.4409\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7724 - recall_128: 0.3412 - precision_128: 0.4292\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7785 - recall_128: 0.3351 - precision_128: 0.4339\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7799 - recall_128: 0.3452 - precision_128: 0.4389\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7806 - recall_128: 0.3423 - precision_128: 0.4456\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7845 - recall_128: 0.3382 - precision_128: 0.4538\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7825 - recall_128: 0.3209 - precision_128: 0.4590\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7808 - recall_128: 0.3120 - precision_128: 0.4524\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7881 - recall_128: 0.3066 - precision_128: 0.4586\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7863 - recall_128: 0.3055 - precision_128: 0.4612\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7898 - recall_128: 0.3056 - precision_128: 0.4684\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7883 - recall_128: 0.3108 - precision_128: 0.4640\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7897 - recall_128: 0.3008 - precision_128: 0.4857\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7910 - recall_128: 0.2951 - precision_128: 0.4863\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7934 - recall_128: 0.2895 - precision_128: 0.4897\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5367 - accuracy: 0.7947 - recall_128: 0.2806 - precision_128: 0.4737\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5365 - accuracy: 0.7938 - recall_128: 0.2772 - precision_128: 0.4867\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.7942 - recall_128: 0.2705 - precision_128: 0.4872\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5333 - accuracy: 0.7946 - recall_128: 0.2750 - precision_128: 0.4924\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7907 - recall_128: 0.2714 - precision_128: 0.4874\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7937 - recall_128: 0.2654 - precision_128: 0.4865\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7972 - recall_128: 0.2670 - precision_128: 0.4999\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7943 - recall_128: 0.2563 - precision_128: 0.4876\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5281 - accuracy: 0.7974 - recall_128: 0.2587 - precision_128: 0.4975\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.7958 - recall_128: 0.2543 - precision_128: 0.4989\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.7985 - recall_128: 0.2523 - precision_128: 0.5062\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7987 - recall_128: 0.2516 - precision_128: 0.4979\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7978 - recall_128: 0.2486 - precision_128: 0.5017\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7987 - recall_128: 0.2374 - precision_128: 0.5040\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5244 - accuracy: 0.7952 - recall_128: 0.2324 - precision_128: 0.5049\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7972 - recall_128: 0.2285 - precision_128: 0.5030\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.7976 - recall_128: 0.2289 - precision_128: 0.5000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7958 - recall_128: 0.2253 - precision_128: 0.5022\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7996 - recall_128: 0.2184 - precision_128: 0.4972\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7993 - recall_128: 0.2264 - precision_128: 0.5165\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7980 - recall_128: 0.2233 - precision_128: 0.5242\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5157 - accuracy: 0.7979 - recall_128: 0.2068 - precision_128: 0.4964\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7960 - recall_128: 0.1997 - precision_128: 0.5010\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7960 - recall_128: 0.2025 - precision_128: 0.4950\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7941 - recall_128: 0.1893 - precision_128: 0.4852\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7971 - recall_128: 0.2008 - precision_128: 0.5036\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5135 - accuracy: 0.7995 - recall_128: 0.2042 - precision_128: 0.5247\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.8038 - recall_128: 0.2088 - precision_128: 0.5324\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7950 - recall_128: 0.1885 - precision_128: 0.4986\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.8040 - recall_128: 0.2020 - precision_128: 0.5314\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C85F700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.8084 - recall_128: 0.1695 - precision_128: 0.5926\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7537 - accuracy: 0.4633 - recall_129: 0.3842 - precision_129: 0.1615\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7522 - accuracy: 0.4672 - recall_129: 0.3828 - precision_129: 0.1623\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7518 - accuracy: 0.4656 - recall_129: 0.3698 - precision_129: 0.1556\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7459 - accuracy: 0.4752 - recall_129: 0.3805 - precision_129: 0.1629\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7432 - accuracy: 0.4762 - recall_129: 0.3715 - precision_129: 0.1587\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7406 - accuracy: 0.4813 - recall_129: 0.3580 - precision_129: 0.1576\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7377 - accuracy: 0.4848 - recall_129: 0.3482 - precision_129: 0.1543\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7338 - accuracy: 0.4904 - recall_129: 0.3570 - precision_129: 0.1602\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.4903 - recall_129: 0.3395 - precision_129: 0.1538\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7318 - accuracy: 0.4905 - recall_129: 0.3399 - precision_129: 0.1582\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7275 - accuracy: 0.4971 - recall_129: 0.3449 - precision_129: 0.1582\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7234 - accuracy: 0.5049 - recall_129: 0.3436 - precision_129: 0.1601\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7224 - accuracy: 0.5052 - recall_129: 0.3262 - precision_129: 0.1568\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7196 - accuracy: 0.5118 - recall_129: 0.3380 - precision_129: 0.1631\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7196 - accuracy: 0.5084 - recall_129: 0.3266 - precision_129: 0.1571\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7143 - accuracy: 0.5172 - recall_129: 0.3331 - precision_129: 0.1616\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7151 - accuracy: 0.5149 - recall_129: 0.3250 - precision_129: 0.1612\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7108 - accuracy: 0.5238 - recall_129: 0.3355 - precision_129: 0.1651\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.5307 - recall_129: 0.3281 - precision_129: 0.1655\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7055 - accuracy: 0.5338 - recall_129: 0.3218 - precision_129: 0.1650\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7027 - accuracy: 0.5390 - recall_129: 0.3189 - precision_129: 0.1687\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7023 - accuracy: 0.5395 - recall_129: 0.2993 - precision_129: 0.1596\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6997 - accuracy: 0.5457 - recall_129: 0.3083 - precision_129: 0.1660\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.5502 - recall_129: 0.3085 - precision_129: 0.1709\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5560 - recall_129: 0.3119 - precision_129: 0.1737\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.5579 - recall_129: 0.2965 - precision_129: 0.1678\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5613 - recall_129: 0.3003 - precision_129: 0.1687\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6878 - accuracy: 0.5639 - recall_129: 0.2854 - precision_129: 0.1627\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5665 - recall_129: 0.2958 - precision_129: 0.1745\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.5711 - recall_129: 0.2787 - precision_129: 0.1686\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5781 - recall_129: 0.2860 - precision_129: 0.1715\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.5778 - recall_129: 0.2788 - precision_129: 0.1704\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.5839 - recall_129: 0.2761 - precision_129: 0.1717\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.5882 - recall_129: 0.2879 - precision_129: 0.1772\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.5848 - recall_129: 0.2757 - precision_129: 0.1709\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.5937 - recall_129: 0.2780 - precision_129: 0.1799\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.5962 - recall_129: 0.2786 - precision_129: 0.1787\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.5974 - recall_129: 0.2695 - precision_129: 0.1794\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.6040 - recall_129: 0.2652 - precision_129: 0.1766\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.6117 - recall_129: 0.2655 - precision_129: 0.1799\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.6141 - recall_129: 0.2594 - precision_129: 0.1804\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.6143 - recall_129: 0.2477 - precision_129: 0.1764\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.6192 - recall_129: 0.2543 - precision_129: 0.1807\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.6183 - recall_129: 0.2372 - precision_129: 0.1759\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6290 - recall_129: 0.2471 - precision_129: 0.1882\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6323 - recall_129: 0.2360 - precision_129: 0.1819\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.6301 - recall_129: 0.2404 - precision_129: 0.1858\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6342 - recall_129: 0.2302 - precision_129: 0.1760\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.6371 - recall_129: 0.2246 - precision_129: 0.1815\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.6431 - recall_129: 0.2250 - precision_129: 0.1859\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.6451 - recall_129: 0.2297 - precision_129: 0.1861\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6460 - recall_129: 0.2154 - precision_129: 0.1831\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6524 - recall_129: 0.2162 - precision_129: 0.1903\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.6585 - recall_129: 0.2146 - precision_129: 0.1905\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6630 - recall_129: 0.2054 - precision_129: 0.1859\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.6614 - recall_129: 0.2057 - precision_129: 0.1910\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6350 - accuracy: 0.6669 - recall_129: 0.2093 - precision_129: 0.1948\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6323 - accuracy: 0.6688 - recall_129: 0.2072 - precision_129: 0.1972\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.6712 - recall_129: 0.1963 - precision_129: 0.1950\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.6753 - recall_129: 0.1978 - precision_129: 0.1979\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6287 - accuracy: 0.6747 - recall_129: 0.1947 - precision_129: 0.1981\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.6791 - recall_129: 0.1911 - precision_129: 0.2016\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.6799 - recall_129: 0.1769 - precision_129: 0.1891\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6846 - recall_129: 0.1768 - precision_129: 0.1929\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.6870 - recall_129: 0.1806 - precision_129: 0.2025\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6239 - accuracy: 0.6853 - recall_129: 0.1814 - precision_129: 0.1992\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.6931 - recall_129: 0.1829 - precision_129: 0.2078\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.6885 - recall_129: 0.1800 - precision_129: 0.2048\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6163 - accuracy: 0.6949 - recall_129: 0.1762 - precision_129: 0.2069\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.6928 - recall_129: 0.1743 - precision_129: 0.2082\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.6997 - recall_129: 0.1767 - precision_129: 0.2048\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6135 - accuracy: 0.7014 - recall_129: 0.1773 - precision_129: 0.2179\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.7029 - recall_129: 0.1738 - precision_129: 0.2164\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6108 - accuracy: 0.7054 - recall_129: 0.1774 - precision_129: 0.2220\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.7044 - recall_129: 0.1676 - precision_129: 0.2090\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.7087 - recall_129: 0.1605 - precision_129: 0.2111\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.7146 - recall_129: 0.1663 - precision_129: 0.2189\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.7093 - recall_129: 0.1587 - precision_129: 0.2087\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.7122 - recall_129: 0.1596 - precision_129: 0.2198\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6019 - accuracy: 0.7175 - recall_129: 0.1602 - precision_129: 0.2196\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6020 - accuracy: 0.7191 - recall_129: 0.1583 - precision_129: 0.2256\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6002 - accuracy: 0.7203 - recall_129: 0.1549 - precision_129: 0.2229\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.7216 - recall_129: 0.1494 - precision_129: 0.2200\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6001 - accuracy: 0.7222 - recall_129: 0.1454 - precision_129: 0.2227\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.7280 - recall_129: 0.1560 - precision_129: 0.2344\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5966 - accuracy: 0.7280 - recall_129: 0.1516 - precision_129: 0.2400\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5940 - accuracy: 0.7294 - recall_129: 0.1425 - precision_129: 0.2298\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5917 - accuracy: 0.7338 - recall_129: 0.1473 - precision_129: 0.2370\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.7273 - recall_129: 0.1401 - precision_129: 0.2267\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7337 - recall_129: 0.1464 - precision_129: 0.2347\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.7323 - recall_129: 0.1327 - precision_129: 0.2233\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.7323 - recall_129: 0.1307 - precision_129: 0.2228\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.7330 - recall_129: 0.1272 - precision_129: 0.2251\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7297 - recall_129: 0.1275 - precision_129: 0.2175\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5844 - accuracy: 0.7367 - recall_129: 0.1337 - precision_129: 0.2326\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.7342 - recall_129: 0.1194 - precision_129: 0.2123\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7370 - recall_129: 0.1261 - precision_129: 0.2337\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7374 - recall_129: 0.1180 - precision_129: 0.2232\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7401 - recall_129: 0.1241 - precision_129: 0.2390\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.7385 - recall_129: 0.1144 - precision_129: 0.2173\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C9F30D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5849 - accuracy: 0.7270 - recall_129: 0.1268 - precision_129: 0.2113\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5100 - accuracy: 0.7977 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7986 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7941 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7997 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7993 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7967 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7969 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7977 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7965 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7936 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7978 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.8001 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7990 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7984 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7993 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7983 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7981 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7935 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7959 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5125 - accuracy: 0.7949 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7979 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7999 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7959 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7981 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7930 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7975 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7943 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7951 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7994 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7980 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7960 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7989 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7987 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7969 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7980 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7973 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7986 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7972 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7999 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7989 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.8016 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7993 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5043 - accuracy: 0.7994 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7946 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5093 - accuracy: 0.7960 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.8004 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7981 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7992 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7986 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7980 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7977 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.8000 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5120 - accuracy: 0.7939 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7986 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7976 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7970 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7980 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7990 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7974 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7950 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7939 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.7942 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5050 - accuracy: 0.7989 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5039 - accuracy: 0.8000 - recall_130: 0.0000e+00 - precision_130: 0.0000e+0 - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7978 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7980 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7945 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7977 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5140 - accuracy: 0.7923 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7974 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.8019 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.8008 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7962 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7982 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.7963 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7989 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7968 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5087 - accuracy: 0.7960 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7995 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.7973 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7977 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7941 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7958 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7948 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7980 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7977 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.7957 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5022 - accuracy: 0.8004 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7950 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7964 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7952 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.8000 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7999 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5084 - accuracy: 0.7957 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5041 - accuracy: 0.7988 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.7953 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.7954 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.8017 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5080 - accuracy: 0.7961 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7932 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7952 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D658032B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 0.5055 - accuracy: 0.7973 - recall_130: 0.0000e+00 - precision_130: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.0516 - accuracy: 0.2026 - recall_131: 1.0000 - precision_131: 0.2026\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0174 - accuracy: 0.2012 - recall_131: 1.0000 - precision_131: 0.2012\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9813 - accuracy: 0.2044 - recall_131: 1.0000 - precision_131: 0.2044\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9529 - accuracy: 0.2005 - recall_131: 1.0000 - precision_131: 0.2005\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9245 - accuracy: 0.1986 - recall_131: 1.0000 - precision_131: 0.1986\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8952 - accuracy: 0.2025 - recall_131: 1.0000 - precision_131: 0.2025\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8705 - accuracy: 0.2001 - recall_131: 1.0000 - precision_131: 0.2001\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8464 - accuracy: 0.2015 - recall_131: 1.0000 - precision_131: 0.2015\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8235 - accuracy: 0.2028 - recall_131: 1.0000 - precision_131: 0.2028\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8034 - accuracy: 0.2020 - recall_131: 1.0000 - precision_131: 0.2020\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7837 - accuracy: 0.2025 - recall_131: 1.0000 - precision_131: 0.2025\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7665 - accuracy: 0.2008 - recall_131: 1.0000 - precision_131: 0.2008\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7494 - accuracy: 0.2021 - recall_131: 0.9995 - precision_131: 0.2016\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7329 - accuracy: 0.2207 - recall_131: 0.9753 - precision_131: 0.2065\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7186 - accuracy: 0.2946 - recall_131: 0.8408 - precision_131: 0.2023\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7048 - accuracy: 0.3885 - recall_131: 0.6039 - precision_131: 0.1876\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5017 - recall_131: 0.4061 - precision_131: 0.1804\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.6278 - recall_131: 0.2078 - precision_131: 0.1635\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.7332 - recall_131: 0.0786 - precision_131: 0.1622\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.7848 - recall_131: 0.0230 - precision_131: 0.1902\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.7980 - recall_131: 0.0038 - precision_131: 0.3214\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.7986 - recall_131: 0.0015 - precision_131: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.7977 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7990 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.7950 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.7994 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7999 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.7987 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7950 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.7947 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5838 - accuracy: 0.7972 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.7978 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.7976 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7944 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7929 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7977 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7952 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7997 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7997 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.8045 - recall_131: 0.0000e+00 - precision_131: 0.0000e+0 - 0s 3ms/step - loss: 0.5501 - accuracy: 0.8000 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.8003 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7960 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7983 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7957 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7983 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.8006 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7977 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7993 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.8029 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7965 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7962 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.8019 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7956 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7958 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7972 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7948 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7957 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7993 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5240 - accuracy: 0.7955 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7997 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7952 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7996 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7967 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7997 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.7978 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7973 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7954 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7973 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7981 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7995 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7971 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7983 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5127 - accuracy: 0.7983 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7952 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.8000 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7972 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7988 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7952 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7965 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7925 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7963 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7980 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7998 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7961 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7968 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7988 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7987 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7985 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7960 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7973 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.8008 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7971 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7963 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7970 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7950 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7955 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7967 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7981 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7981 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7952 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A54A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5072 - accuracy: 0.7977 - recall_131: 0.0000e+00 - precision_131: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.8245 - accuracy: 0.2047 - recall_132: 1.0000 - precision_132: 0.2047\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7993 - accuracy: 0.2030 - recall_132: 1.0000 - precision_132: 0.2030\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7772 - accuracy: 0.2009 - recall_132: 1.0000 - precision_132: 0.2006\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.2076 - recall_132: 0.9973 - precision_132: 0.2020\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.2326 - recall_132: 0.9580 - precision_132: 0.2041\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7178 - accuracy: 0.2996 - recall_132: 0.8737 - precision_132: 0.2090\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7011 - accuracy: 0.4154 - recall_132: 0.6821 - precision_132: 0.2116\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.5684 - recall_132: 0.4498 - precision_132: 0.2233\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.7041 - recall_132: 0.2148 - precision_132: 0.2470\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.7694 - recall_132: 0.0674 - precision_132: 0.2512\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.7905 - recall_132: 0.0132 - precision_132: 0.2431\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.7980 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7953 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7979 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7994 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.7962 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7950 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7961 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.7966 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.8009 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7977 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7987 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7962 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7995 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7987 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7958 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7947 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7959 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.7962 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.8034 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7983 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7961 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7978 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7960 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7975 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.7986 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7988 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7974 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7956 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7998 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7981 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7960 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7983 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7953 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.7890 - recall_132: 0.0000e+00 - precision_132: 0.0000e+0 - 0s 3ms/step - loss: 0.5180 - accuracy: 0.7942 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7961 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.7974 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7955 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7963 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7976 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7964 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7949 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7968 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7990 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7986 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7990 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7980 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7994 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7989 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7991 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7968 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7976 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7969 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7996 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.7961 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.7950 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7966 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7956 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.8027 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7951 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7995 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7979 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7954 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7973 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7998 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7967 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7973 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.8003 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7970 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7971 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7978 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7969 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7966 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7936 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7964 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7973 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7967 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.8009 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7990 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.8004 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.8003 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7945 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7967 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7976 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.8016 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7962 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7961 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7972 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7988 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7978 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.7973 - recall_132: 0.0000e+00 - precision_132: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7889 - accuracy: 0.4920 - recall_133: 0.4558 - precision_133: 0.1890\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7777 - accuracy: 0.4986 - recall_133: 0.4457 - precision_133: 0.1867\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7629 - accuracy: 0.5123 - recall_133: 0.4437 - precision_133: 0.1952\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7537 - accuracy: 0.5210 - recall_133: 0.4238 - precision_133: 0.1910\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7397 - accuracy: 0.5372 - recall_133: 0.4177 - precision_133: 0.1945\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7285 - accuracy: 0.5432 - recall_133: 0.4044 - precision_133: 0.1955\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7192 - accuracy: 0.5529 - recall_133: 0.3973 - precision_133: 0.1994\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7098 - accuracy: 0.5591 - recall_133: 0.3763 - precision_133: 0.1940\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5767 - recall_133: 0.3957 - precision_133: 0.2076\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.5790 - recall_133: 0.3541 - precision_133: 0.1974\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.5906 - recall_133: 0.3543 - precision_133: 0.2070\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5950 - recall_133: 0.3288 - precision_133: 0.1998\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6035 - recall_133: 0.3093 - precision_133: 0.2000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6186 - recall_133: 0.3179 - precision_133: 0.2136\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6237 - recall_133: 0.3066 - precision_133: 0.2132\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.6382 - recall_133: 0.2985 - precision_133: 0.2141\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6338 - accuracy: 0.6463 - recall_133: 0.2898 - precision_133: 0.2202\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.6477 - recall_133: 0.2692 - precision_133: 0.2102\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6542 - recall_133: 0.2545 - precision_133: 0.2092\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.6632 - recall_133: 0.2387 - precision_133: 0.2044\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6083 - accuracy: 0.6770 - recall_133: 0.2363 - precision_133: 0.2196\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6818 - recall_133: 0.2288 - precision_133: 0.2227\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.6898 - recall_133: 0.2211 - precision_133: 0.2260\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.6948 - recall_133: 0.2216 - precision_133: 0.2360\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7000 - recall_133: 0.2029 - precision_133: 0.2342\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.7045 - recall_133: 0.1872 - precision_133: 0.2301\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.7157 - recall_133: 0.1862 - precision_133: 0.2398\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7199 - recall_133: 0.1807 - precision_133: 0.2386\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7237 - recall_133: 0.1805 - precision_133: 0.2526\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7309 - recall_133: 0.1703 - precision_133: 0.2464\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7332 - recall_133: 0.1641 - precision_133: 0.2509\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7358 - recall_133: 0.1576 - precision_133: 0.2594\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7409 - recall_133: 0.1504 - precision_133: 0.2639\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7501 - recall_133: 0.1474 - precision_133: 0.2723\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7524 - recall_133: 0.1382 - precision_133: 0.2660\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7581 - recall_133: 0.1376 - precision_133: 0.2748\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7562 - recall_133: 0.1274 - precision_133: 0.2769\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7644 - recall_133: 0.1248 - precision_133: 0.2958\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7676 - recall_133: 0.1188 - precision_133: 0.3052\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7671 - recall_133: 0.1145 - precision_133: 0.3126\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7678 - recall_133: 0.1056 - precision_133: 0.2959\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7724 - recall_133: 0.1048 - precision_133: 0.2997\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7759 - recall_133: 0.0983 - precision_133: 0.3111\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7807 - recall_133: 0.0973 - precision_133: 0.3454\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7779 - recall_133: 0.0826 - precision_133: 0.3044\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7794 - recall_133: 0.0866 - precision_133: 0.3353\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7835 - recall_133: 0.0883 - precision_133: 0.3522\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7827 - recall_133: 0.0822 - precision_133: 0.3563\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7831 - recall_133: 0.0787 - precision_133: 0.3568\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7834 - recall_133: 0.0689 - precision_133: 0.3563\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7854 - recall_133: 0.0602 - precision_133: 0.3406\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7863 - recall_133: 0.0600 - precision_133: 0.3257\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7868 - recall_133: 0.0667 - precision_133: 0.3662\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7872 - recall_133: 0.0578 - precision_133: 0.3617\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7912 - recall_133: 0.0634 - precision_133: 0.3873\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7918 - recall_133: 0.0574 - precision_133: 0.3684\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7940 - recall_133: 0.0590 - precision_133: 0.3911\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7890 - recall_133: 0.0548 - precision_133: 0.3906\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7906 - recall_133: 0.0496 - precision_133: 0.3924\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7928 - recall_133: 0.0496 - precision_133: 0.4122\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7930 - recall_133: 0.0490 - precision_133: 0.4129\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7916 - recall_133: 0.0472 - precision_133: 0.4329\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7956 - recall_133: 0.0472 - precision_133: 0.4523\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7960 - recall_133: 0.0458 - precision_133: 0.4491\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7932 - recall_133: 0.0521 - precision_133: 0.5006\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7975 - recall_133: 0.0434 - precision_133: 0.4570\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7943 - recall_133: 0.0494 - precision_133: 0.5047\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.8026 - recall_133: 0.0505 - precision_133: 0.5001\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7998 - recall_133: 0.0511 - precision_133: 0.5339\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7998 - recall_133: 0.0504 - precision_133: 0.5396\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7997 - recall_133: 0.0543 - precision_133: 0.5746\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8009 - recall_133: 0.0516 - precision_133: 0.5645\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7992 - recall_133: 0.0458 - precision_133: 0.5576\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.8005 - recall_133: 0.0484 - precision_133: 0.5373\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.8040 - recall_133: 0.0484 - precision_133: 0.5855\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8040 - recall_133: 0.0473 - precision_133: 0.6386\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.8018 - recall_133: 0.0483 - precision_133: 0.5956\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8005 - recall_133: 0.0481 - precision_133: 0.6156\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8029 - recall_133: 0.0468 - precision_133: 0.6169\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.7990 - recall_133: 0.0627 - precision_133: 0.666 - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8003 - recall_133: 0.0515 - precision_133: 0.6367\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7996 - recall_133: 0.0444 - precision_133: 0.6192\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8020 - recall_133: 0.0450 - precision_133: 0.6173\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.8044 - recall_133: 0.0461 - precision_133: 0.6340\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8041 - recall_133: 0.0437 - precision_133: 0.6132\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.8001 - recall_133: 0.0445 - precision_133: 0.6301\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8009 - recall_133: 0.0486 - precision_133: 0.6980\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.8048 - recall_133: 0.0485 - precision_133: 0.6672\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.8033 - recall_133: 0.0521 - precision_133: 0.6821\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.8009 - recall_133: 0.0468 - precision_133: 0.6529\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8026 - recall_133: 0.0545 - precision_133: 0.6701\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8018 - recall_133: 0.0532 - precision_133: 0.6570\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.8059 - recall_133: 0.0475 - precision_133: 0.7064\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.8065 - recall_133: 0.0521 - precision_133: 0.7203\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.8056 - recall_133: 0.0500 - precision_133: 0.6731\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.8064 - recall_133: 0.0572 - precision_133: 0.7177\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.8069 - recall_133: 0.0619 - precision_133: 0.7417\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8071 - recall_133: 0.0572 - precision_133: 0.7127\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.8060 - recall_133: 0.0590 - precision_133: 0.7043\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.8036 - recall_133: 0.0568 - precision_133: 0.7361\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8038 - recall_133: 0.0554 - precision_133: 0.6819\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C85FE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.4493 - accuracy: 0.8072 - recall_133: 0.0613 - precision_133: 0.8286\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 2ms/step - loss: 0.7108 - accuracy: 0.5205 - recall_134: 0.5510 - precision_134: 0.2246\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.5301 - recall_134: 0.5428 - precision_134: 0.2296\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5414 - recall_134: 0.5284 - precision_134: 0.2284\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5586 - recall_134: 0.5175 - precision_134: 0.2333\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.5712 - recall_134: 0.4982 - precision_134: 0.2374\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.5802 - recall_134: 0.4856 - precision_134: 0.2401\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.5995 - recall_134: 0.4758 - precision_134: 0.2466\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.6080 - recall_134: 0.4633 - precision_134: 0.2497\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.6198 - recall_134: 0.4509 - precision_134: 0.2598\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.6271 - recall_134: 0.4391 - precision_134: 0.2577\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.6433 - recall_134: 0.4293 - precision_134: 0.2596\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6538 - recall_134: 0.4048 - precision_134: 0.2648\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.6618 - recall_134: 0.3945 - precision_134: 0.2639\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.6675 - recall_134: 0.3759 - precision_134: 0.2711\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.6821 - recall_134: 0.3735 - precision_134: 0.2795\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.6885 - recall_134: 0.3587 - precision_134: 0.2924\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6963 - recall_134: 0.3347 - precision_134: 0.2857\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6025 - accuracy: 0.7052 - recall_134: 0.3284 - precision_134: 0.2976\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7160 - recall_134: 0.3275 - precision_134: 0.3122\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7171 - recall_134: 0.3175 - precision_134: 0.3085\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7243 - recall_134: 0.3003 - precision_134: 0.2998\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.7311 - recall_134: 0.2941 - precision_134: 0.3217\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.7345 - recall_134: 0.2804 - precision_134: 0.3277\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7413 - recall_134: 0.2852 - precision_134: 0.3287\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7442 - recall_134: 0.2673 - precision_134: 0.3276\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7478 - recall_134: 0.2605 - precision_134: 0.3367\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7450 - recall_134: 0.2433 - precision_134: 0.3367\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7548 - recall_134: 0.2394 - precision_134: 0.3435\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7599 - recall_134: 0.2288 - precision_134: 0.3557\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7590 - recall_134: 0.2182 - precision_134: 0.3570\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7617 - recall_134: 0.2111 - precision_134: 0.3626\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7660 - recall_134: 0.2085 - precision_134: 0.3633\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7648 - recall_134: 0.1917 - precision_134: 0.3599\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7768 - recall_134: 0.1965 - precision_134: 0.3789\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7785 - recall_134: 0.1961 - precision_134: 0.3935\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7738 - recall_134: 0.1836 - precision_134: 0.3835\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7766 - recall_134: 0.1867 - precision_134: 0.4050\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7822 - recall_134: 0.1812 - precision_134: 0.4078\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7787 - recall_134: 0.1695 - precision_134: 0.4005\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7864 - recall_134: 0.1770 - precision_134: 0.4274\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7813 - recall_134: 0.1564 - precision_134: 0.3952\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7859 - recall_134: 0.1706 - precision_134: 0.4335\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7880 - recall_134: 0.1692 - precision_134: 0.4345\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7827 - recall_134: 0.1541 - precision_134: 0.4082\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7943 - recall_134: 0.1708 - precision_134: 0.4443\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7875 - recall_134: 0.1583 - precision_134: 0.4403\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7925 - recall_134: 0.1567 - precision_134: 0.4309\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7897 - recall_134: 0.1557 - precision_134: 0.4565\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7934 - recall_134: 0.1541 - precision_134: 0.4608\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7896 - recall_134: 0.1409 - precision_134: 0.4499\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7919 - recall_134: 0.1446 - precision_134: 0.4708\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7937 - recall_134: 0.1416 - precision_134: 0.4749\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7981 - recall_134: 0.1392 - precision_134: 0.4989\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7943 - recall_134: 0.1337 - precision_134: 0.4857\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7977 - recall_134: 0.1324 - precision_134: 0.4942\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7953 - recall_134: 0.1270 - precision_134: 0.4959\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8000 - recall_134: 0.1290 - precision_134: 0.5221\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7976 - recall_134: 0.1268 - precision_134: 0.5159\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7986 - recall_134: 0.1258 - precision_134: 0.5326\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7976 - recall_134: 0.1213 - precision_134: 0.5179\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.8015 - recall_134: 0.1216 - precision_134: 0.5159\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7954 - recall_134: 0.1143 - precision_134: 0.5111\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.8016 - recall_134: 0.1210 - precision_134: 0.5436\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.8023 - recall_134: 0.1221 - precision_134: 0.5319\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7995 - recall_134: 0.1220 - precision_134: 0.5329\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.8038 - recall_134: 0.1154 - precision_134: 0.5378\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8023 - recall_134: 0.1168 - precision_134: 0.5582\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8020 - recall_134: 0.1148 - precision_134: 0.5554\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.8037 - recall_134: 0.1127 - precision_134: 0.5334\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7997 - recall_134: 0.1147 - precision_134: 0.5344\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.8015 - recall_134: 0.1130 - precision_134: 0.5429\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.8032 - recall_134: 0.1137 - precision_134: 0.5343\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.8014 - recall_134: 0.1110 - precision_134: 0.5273\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8040 - recall_134: 0.1172 - precision_134: 0.5634\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.8020 - recall_134: 0.1158 - precision_134: 0.5428\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8017 - recall_134: 0.1126 - precision_134: 0.5549\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.8031 - recall_134: 0.1185 - precision_134: 0.5668\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.8009 - recall_134: 0.1132 - precision_134: 0.5495\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.8023 - recall_134: 0.1159 - precision_134: 0.5624\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.8044 - recall_134: 0.1116 - precision_134: 0.5549\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7998 - recall_134: 0.1115 - precision_134: 0.5661\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.8037 - recall_134: 0.1190 - precision_134: 0.5559\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.8040 - recall_134: 0.1108 - precision_134: 0.5587\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7992 - recall_134: 0.1114 - precision_134: 0.5545\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.8074 - recall_134: 0.1161 - precision_134: 0.5835\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.8027 - recall_134: 0.1133 - precision_134: 0.5823\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8015 - recall_134: 0.1117 - precision_134: 0.5680\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7999 - recall_134: 0.1074 - precision_134: 0.5547\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.8029 - recall_134: 0.1038 - precision_134: 0.5586\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.8036 - recall_134: 0.1088 - precision_134: 0.5829\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8053 - recall_134: 0.1157 - precision_134: 0.5947\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.8063 - recall_134: 0.1145 - precision_134: 0.5931\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.8037 - recall_134: 0.1040 - precision_134: 0.5684\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8049 - recall_134: 0.1098 - precision_134: 0.5885\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.8044 - recall_134: 0.1064 - precision_134: 0.5941\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.8062 - recall_134: 0.1167 - precision_134: 0.6134\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.8063 - recall_134: 0.1146 - precision_134: 0.6168\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8053 - recall_134: 0.1159 - precision_134: 0.6211\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8053 - recall_134: 0.1126 - precision_134: 0.6258\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.8051 - recall_134: 0.1153 - precision_134: 0.6198\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C85FC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.8127 - recall_134: 0.1271 - precision_134: 0.7059\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 2ms/step - loss: 0.7336 - accuracy: 0.5068 - recall_135: 0.5061 - precision_135: 0.2078\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7249 - accuracy: 0.5207 - recall_135: 0.5014 - precision_135: 0.2090\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7139 - accuracy: 0.5262 - recall_135: 0.4876 - precision_135: 0.2101\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7085 - accuracy: 0.5324 - recall_135: 0.4772 - precision_135: 0.2119\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6997 - accuracy: 0.5427 - recall_135: 0.4713 - precision_135: 0.2125\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5574 - recall_135: 0.4687 - precision_135: 0.2228\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6882 - accuracy: 0.5551 - recall_135: 0.4489 - precision_135: 0.2140\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5727 - recall_135: 0.4469 - precision_135: 0.2226\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6739 - accuracy: 0.5725 - recall_135: 0.4326 - precision_135: 0.2176\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.5873 - recall_135: 0.4354 - precision_135: 0.2317\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.5948 - recall_135: 0.4193 - precision_135: 0.2264\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.5969 - recall_135: 0.4078 - precision_135: 0.2258\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.6090 - recall_135: 0.4027 - precision_135: 0.2283\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6123 - recall_135: 0.3957 - precision_135: 0.2306\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.6229 - recall_135: 0.3871 - precision_135: 0.2373\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.6287 - recall_135: 0.3788 - precision_135: 0.2381\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6351 - recall_135: 0.3628 - precision_135: 0.2383\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.6412 - recall_135: 0.3634 - precision_135: 0.2430\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6164 - accuracy: 0.6506 - recall_135: 0.3552 - precision_135: 0.2449\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6541 - recall_135: 0.3404 - precision_135: 0.2464\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6665 - recall_135: 0.3315 - precision_135: 0.2555\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.6724 - recall_135: 0.3188 - precision_135: 0.2543\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6760 - recall_135: 0.3045 - precision_135: 0.2498\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.6858 - recall_135: 0.3009 - precision_135: 0.2580\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.6919 - recall_135: 0.2798 - precision_135: 0.2607\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.7020 - recall_135: 0.2858 - precision_135: 0.2663\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7016 - recall_135: 0.2721 - precision_135: 0.2609\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7095 - recall_135: 0.2490 - precision_135: 0.2627\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7086 - recall_135: 0.2468 - precision_135: 0.2616\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.7097 - recall_135: 0.2351 - precision_135: 0.2676\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.7212 - recall_135: 0.2309 - precision_135: 0.2723\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7251 - recall_135: 0.2288 - precision_135: 0.2783\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7270 - recall_135: 0.2215 - precision_135: 0.2812\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7288 - recall_135: 0.2190 - precision_135: 0.2820\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.7286 - recall_135: 0.2124 - precision_135: 0.2751\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7381 - recall_135: 0.2060 - precision_135: 0.2846\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7401 - recall_135: 0.2045 - precision_135: 0.2991\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7517 - recall_135: 0.2022 - precision_135: 0.3211\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7499 - recall_135: 0.2054 - precision_135: 0.3175\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7497 - recall_135: 0.1816 - precision_135: 0.3030\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7517 - recall_135: 0.1846 - precision_135: 0.3208\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7554 - recall_135: 0.1763 - precision_135: 0.3158\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7608 - recall_135: 0.1724 - precision_135: 0.3278\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7604 - recall_135: 0.1714 - precision_135: 0.3165\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7606 - recall_135: 0.1607 - precision_135: 0.3034\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7610 - recall_135: 0.1597 - precision_135: 0.3150\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7613 - recall_135: 0.1561 - precision_135: 0.3216\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7665 - recall_135: 0.1436 - precision_135: 0.3036\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7623 - recall_135: 0.1435 - precision_135: 0.3133\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7677 - recall_135: 0.1460 - precision_135: 0.3275\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7688 - recall_135: 0.1429 - precision_135: 0.3231\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7717 - recall_135: 0.1454 - precision_135: 0.3423\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7706 - recall_135: 0.1391 - precision_135: 0.3374\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7722 - recall_135: 0.1402 - precision_135: 0.3351\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7724 - recall_135: 0.1349 - precision_135: 0.3475\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7782 - recall_135: 0.1338 - precision_135: 0.3509\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7784 - recall_135: 0.1293 - precision_135: 0.3556\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7772 - recall_135: 0.1194 - precision_135: 0.3453\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7752 - recall_135: 0.1190 - precision_135: 0.3536\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7763 - recall_135: 0.1106 - precision_135: 0.3436\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7798 - recall_135: 0.1130 - precision_135: 0.3557\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7771 - recall_135: 0.1090 - precision_135: 0.3673\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7800 - recall_135: 0.1063 - precision_135: 0.3627\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7863 - recall_135: 0.1060 - precision_135: 0.3622\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7840 - recall_135: 0.1018 - precision_135: 0.3580\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7834 - recall_135: 0.1025 - precision_135: 0.3705\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.7862 - recall_135: 0.0978 - precision_135: 0.3852\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7868 - recall_135: 0.0966 - precision_135: 0.3867\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7816 - recall_135: 0.0988 - precision_135: 0.3970\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7892 - recall_135: 0.1023 - precision_135: 0.4172\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7880 - recall_135: 0.0924 - precision_135: 0.3933\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7913 - recall_135: 0.0890 - precision_135: 0.4077\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7871 - recall_135: 0.0802 - precision_135: 0.3710\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7885 - recall_135: 0.0839 - precision_135: 0.3942\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7886 - recall_135: 0.0860 - precision_135: 0.4138\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7891 - recall_135: 0.0854 - precision_135: 0.4250\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7906 - recall_135: 0.0864 - precision_135: 0.4270\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7881 - recall_135: 0.0862 - precision_135: 0.4427\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7900 - recall_135: 0.0781 - precision_135: 0.4316\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7953 - recall_135: 0.0850 - precision_135: 0.4438\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7952 - recall_135: 0.0836 - precision_135: 0.4433\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7949 - recall_135: 0.0824 - precision_135: 0.4657\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7951 - recall_135: 0.0833 - precision_135: 0.4645\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7926 - recall_135: 0.0774 - precision_135: 0.4465\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7941 - recall_135: 0.0737 - precision_135: 0.4394\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7918 - recall_135: 0.0683 - precision_135: 0.4173\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7939 - recall_135: 0.0662 - precision_135: 0.4027\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7929 - recall_135: 0.0686 - precision_135: 0.4303\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7941 - recall_135: 0.0728 - precision_135: 0.4500\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7913 - recall_135: 0.0651 - precision_135: 0.4323\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7954 - recall_135: 0.0630 - precision_135: 0.4230\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7934 - recall_135: 0.0658 - precision_135: 0.4394\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7966 - recall_135: 0.0671 - precision_135: 0.4476\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7929 - recall_135: 0.0645 - precision_135: 0.4698\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7962 - recall_135: 0.0608 - precision_135: 0.4359\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7945 - recall_135: 0.0674 - precision_135: 0.4566\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7966 - recall_135: 0.0664 - precision_135: 0.4808\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7941 - recall_135: 0.0627 - precision_135: 0.4775\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7983 - recall_135: 0.0543 - precision_135: 0.4341\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7951 - recall_135: 0.0587 - precision_135: 0.4511\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65C564040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.4713 - accuracy: 0.7951 - recall_135: 0.0655 - precision_135: 0.4627\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5870 - accuracy: 0.7953 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.7987 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.7965 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7964 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7984 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7985 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7977 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.7985 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.7952 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.7964 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.7955 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7980 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7939 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.7966 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.7946 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7992 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7971 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.8004 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.7973 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7964 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.7962 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7985 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7976 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7984 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7942 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7933 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7987 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7969 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7979 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.7998 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.8008 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7939 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7959 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7972 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7972 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7974 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5650 - accuracy: 0.7920 - recall_136: 0.0000e+00 - precision_136: 0.0000e+0 - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7957 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7975 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7960 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7982 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7986 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7987 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.8005 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5551 - accuracy: 0.8025 - recall_136: 0.0000e+00 - precision_136: 0.0000e+0 - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7993 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7972 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7980 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7989 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.8007 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7960 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.8007 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7984 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7979 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7970 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7981 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7954 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7967 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7982 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7964 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7984 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7979 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7980 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7970 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7964 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7999 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.8004 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.8007 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7973 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7978 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7962 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7967 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7956 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7996 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7993 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7986 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7973 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7975 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.8002 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7992 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7975 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7986 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7983 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7969 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7969 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7956 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7984 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7959 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7965 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7949 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5389 - accuracy: 0.7979 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7988 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5388 - accuracy: 0.7972 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5388 - accuracy: 0.7967 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5378 - accuracy: 0.7975 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7981 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7989 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7997 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7994 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.8014 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7958 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7986 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580A5DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7973 - recall_136: 0.0000e+00 - precision_136: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7387 - accuracy: 0.2008 - recall_137: 1.0000 - precision_137: 0.2008\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.2070 - recall_137: 1.0000 - precision_137: 0.2070\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7343 - accuracy: 0.2043 - recall_137: 1.0000 - precision_137: 0.2043\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7328 - accuracy: 0.2002 - recall_137: 1.0000 - precision_137: 0.2002\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7308 - accuracy: 0.2015 - recall_137: 1.0000 - precision_137: 0.2015\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7286 - accuracy: 0.2040 - recall_137: 1.0000 - precision_137: 0.2040\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7266 - accuracy: 0.2057 - recall_137: 1.0000 - precision_137: 0.2057\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7247 - accuracy: 0.2067 - recall_137: 1.0000 - precision_137: 0.2067\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7231 - accuracy: 0.2045 - recall_137: 1.0000 - precision_137: 0.2045\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7213 - accuracy: 0.2038 - recall_137: 1.0000 - precision_137: 0.2038\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7195 - accuracy: 0.2045 - recall_137: 1.0000 - precision_137: 0.2045\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7178 - accuracy: 0.2045 - recall_137: 1.0000 - precision_137: 0.2045\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7162 - accuracy: 0.2034 - recall_137: 1.0000 - precision_137: 0.2034\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7145 - accuracy: 0.2017 - recall_137: 1.0000 - precision_137: 0.2017\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7128 - accuracy: 0.2012 - recall_137: 1.0000 - precision_137: 0.2012\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.2049 - recall_137: 1.0000 - precision_137: 0.2049\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7090 - accuracy: 0.2068 - recall_137: 0.9995 - precision_137: 0.2063\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7075 - accuracy: 0.2058 - recall_137: 0.9955 - precision_137: 0.2036\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7061 - accuracy: 0.2095 - recall_137: 0.9906 - precision_137: 0.2017\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7042 - accuracy: 0.2180 - recall_137: 0.9802 - precision_137: 0.2044\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7027 - accuracy: 0.2278 - recall_137: 0.9534 - precision_137: 0.2010\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7011 - accuracy: 0.2522 - recall_137: 0.9084 - precision_137: 0.2012\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.2777 - recall_137: 0.8582 - precision_137: 0.1945\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6978 - accuracy: 0.3208 - recall_137: 0.7901 - precision_137: 0.2007\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.3633 - recall_137: 0.7112 - precision_137: 0.1986\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.4198 - recall_137: 0.6394 - precision_137: 0.2031\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4840 - recall_137: 0.5338 - precision_137: 0.2048\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5448 - recall_137: 0.4090 - precision_137: 0.2030\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.6195 - recall_137: 0.2863 - precision_137: 0.1952\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.6840 - recall_137: 0.2019 - precision_137: 0.2127\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.7190 - recall_137: 0.1175 - precision_137: 0.183 - 0s 4ms/step - loss: 0.6871 - accuracy: 0.7289 - recall_137: 0.1168 - precision_137: 0.2045\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.7669 - recall_137: 0.0622 - precision_137: 0.2261\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.7853 - recall_137: 0.0229 - precision_137: 0.2204\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.7928 - recall_137: 0.0137 - precision_137: 0.3094\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.7968 - recall_137: 8.3491e-04 - precision_137: 0.0813\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7974 - recall_137: 0.0015 - precision_137: 0.2333\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.7976 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.7972 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.7978 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.7987 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.7989 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.7983 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.7985 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.7956 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.7942 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.7978 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.7953 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.7952 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.7981 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.7992 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.7988 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.7989 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.7955 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.7978 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.7967 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.7964 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.7996 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.7989 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.7980 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.7950 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.7985 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.7983 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.7964 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.7969 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.7972 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.7980 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.7962 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.7952 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6378 - accuracy: 0.8020 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.7976 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7949 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7997 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.7955 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.6338 - accuracy: 0.7965 - recall_137: 0.0000e+00 - precision_137: 0.0000e+0 - 0s 3ms/step - loss: 0.6336 - accuracy: 0.7970 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.7965 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.7991 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.7995 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.7949 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.7985 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.7972 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.7958 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.7978 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.7927 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6238 - accuracy: 0.7968 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7983 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.7965 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.7954 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.7975 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.7990 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.7986 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.7945 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.7985 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.7967 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.7992 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.7923 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.7962 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7990 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.7973 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.7961 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.7983 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D657FE74C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.7977 - recall_137: 0.0000e+00 - precision_137: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.5670 - accuracy: 0.7991 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7960 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.8001 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7921 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7988 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7974 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7944 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7961 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.8005 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7973 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7991 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7956 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7973 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7963 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7984 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7999 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7976 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5610 - accuracy: 0.7950 - recall_138: 0.0000e+00 - precision_138: 0.0000e+0 - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7971 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7991 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7978 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7961 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7959 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7991 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7980 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7976 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7993 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7993 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7991 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7974 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7921 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7958 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7996 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7976 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7931 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7978 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7981 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7988 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.8011 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7987 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.8000 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.8043 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.8001 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7964 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7983 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5454 - accuracy: 0.8017 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7958 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7969 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7972 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7998 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7986 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7996 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7981 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7972 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7980 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7983 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7969 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.7961 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.8013 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7994 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7928 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7940 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7957 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7989 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7972 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7978 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7973 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7975 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7982 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7942 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7988 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7968 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7978 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7959 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7963 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7989 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7964 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.8000 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.8003 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7997 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7965 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7986 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7976 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7991 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7944 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7987 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7956 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7955 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7934 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7950 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7937 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.8004 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7943 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.8006 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7969 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.8007 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7963 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7978 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7993 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7994 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7956 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D658032940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5321 - accuracy: 0.7973 - recall_138: 0.0000e+00 - precision_138: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7164 - accuracy: 0.4810 - recall_139: 0.3734 - precision_139: 0.1623\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.4926 - recall_139: 0.3495 - precision_139: 0.1578\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7051 - accuracy: 0.5095 - recall_139: 0.3428 - precision_139: 0.1633\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7010 - accuracy: 0.5127 - recall_139: 0.3240 - precision_139: 0.1551\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.5237 - recall_139: 0.3133 - precision_139: 0.1563\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.5294 - recall_139: 0.2941 - precision_139: 0.1544\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.5441 - recall_139: 0.2806 - precision_139: 0.1561\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5558 - recall_139: 0.2655 - precision_139: 0.1522\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5620 - recall_139: 0.2524 - precision_139: 0.1501\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.5711 - recall_139: 0.2377 - precision_139: 0.1500\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.5801 - recall_139: 0.2263 - precision_139: 0.1510\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.5922 - recall_139: 0.2073 - precision_139: 0.1454\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.5997 - recall_139: 0.1976 - precision_139: 0.1441\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.6100 - recall_139: 0.1940 - precision_139: 0.1513\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.6179 - recall_139: 0.1736 - precision_139: 0.1405\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.6276 - recall_139: 0.1669 - precision_139: 0.1419\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6306 - recall_139: 0.1587 - precision_139: 0.1441\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.6379 - recall_139: 0.1372 - precision_139: 0.1300\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6438 - recall_139: 0.1263 - precision_139: 0.1259\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.6528 - recall_139: 0.1167 - precision_139: 0.1245\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.6619 - recall_139: 0.1090 - precision_139: 0.1230\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.6686 - recall_139: 0.1041 - precision_139: 0.1240\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6776 - recall_139: 0.0957 - precision_139: 0.1231\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6817 - recall_139: 0.0830 - precision_139: 0.1152\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.6902 - recall_139: 0.0841 - precision_139: 0.1177\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.7004 - recall_139: 0.0777 - precision_139: 0.1245\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.7000 - recall_139: 0.0716 - precision_139: 0.1182\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.7006 - recall_139: 0.0621 - precision_139: 0.1046\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.7119 - recall_139: 0.0632 - precision_139: 0.1131\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.7179 - recall_139: 0.0583 - precision_139: 0.1072\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7227 - recall_139: 0.0505 - precision_139: 0.1053\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.7212 - recall_139: 0.0439 - precision_139: 0.0934\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.7261 - recall_139: 0.0402 - precision_139: 0.0924\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7274 - recall_139: 0.0380 - precision_139: 0.0918\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7320 - recall_139: 0.0352 - precision_139: 0.0926\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6042 - accuracy: 0.7392 - recall_139: 0.0385 - precision_139: 0.1071\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.7418 - recall_139: 0.0344 - precision_139: 0.1045\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.7486 - recall_139: 0.0295 - precision_139: 0.0962\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.7462 - recall_139: 0.0263 - precision_139: 0.0863\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7533 - recall_139: 0.0249 - precision_139: 0.0889\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7575 - recall_139: 0.0223 - precision_139: 0.0919\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7616 - recall_139: 0.0207 - precision_139: 0.0911\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5921 - accuracy: 0.7600 - recall_139: 0.0191 - precision_139: 0.0855\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.7653 - recall_139: 0.0162 - precision_139: 0.0818\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7682 - recall_139: 0.0178 - precision_139: 0.0995\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7674 - recall_139: 0.0142 - precision_139: 0.0833\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.7704 - recall_139: 0.0129 - precision_139: 0.0829\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.7715 - recall_139: 0.0119 - precision_139: 0.0843\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.7722 - recall_139: 0.0109 - precision_139: 0.0824\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.7804 - recall_139: 0.0113 - precision_139: 0.0984\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.7805 - recall_139: 0.0103 - precision_139: 0.0876\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.7800 - recall_139: 0.0069 - precision_139: 0.0678\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.7801 - recall_139: 0.0057 - precision_139: 0.0589\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7802 - recall_139: 0.0054 - precision_139: 0.0588\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7834 - recall_139: 0.0023 - precision_139: 0.0293\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7842 - recall_139: 0.0023 - precision_139: 0.0317\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7845 - recall_139: 0.0029 - precision_139: 0.0403\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7830 - recall_139: 0.0020 - precision_139: 0.0312\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.7851 - recall_139: 0.0023 - precision_139: 0.0391\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7901 - recall_139: 0.0014 - precision_139: 0.0265    \n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7894 - recall_139: 0.0017 - precision_139: 0.0352    \n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7872 - recall_139: 0.0023 - precision_139: 0.0582\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.7917 - recall_139: 0.0029 - precision_139: 0.0843\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7928 - recall_139: 0.0017 - precision_139: 0.0519    \n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7947 - recall_139: 0.0023 - precision_139: 0.0728\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7911 - recall_139: 0.0017 - precision_139: 0.0579    \n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7931 - recall_139: 0.0029 - precision_139: 0.0945\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7952 - recall_139: 0.0023 - precision_139: 0.0964\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7943 - recall_139: 8.3472e-04 - precision_139: 0.0505\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7940 - recall_139: 8.3889e-04 - precision_139: 0.0774\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7975 - recall_139: 0.0015 - precision_139: 0.1098\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7971 - recall_139: 5.2910e-04 - precision_139: 0.0455\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7926 - recall_139: 0.0014 - precision_139: 0.1313\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7986 - recall_139: 0.0015 - precision_139: 0.1190\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7937 - recall_139: 0.0014 - precision_139: 0.1696\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7999 - recall_139: 0.0015 - precision_139: 0.2333\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7998 - recall_139: 0.0015 - precision_139: 0.3333\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7963 - recall_139: 8.4082e-04 - precision_139: 0.2500\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7973 - recall_139: 0.0015 - precision_139: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7972 - recall_139: 0.0014 - precision_139: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7971 - recall_139: 0.0014 - precision_139: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7995 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7956 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7957 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7934 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7954 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.8004 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7985 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7987 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.8021 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.8060 - recall_139: 0.0000e+00 - precision_139: 0.0000e+0 - 0s 3ms/step - loss: 0.5368 - accuracy: 0.8000 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7962 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7950 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7946 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7958 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7946 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7982 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7978 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5372 - accuracy: 0.7950 - recall_139: 0.0000e+00 - precision_139: 0.0000e+0 - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7968 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7997 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D65AFA1670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 3ms/step - loss: 0.5317 - accuracy: 0.7973 - recall_139: 0.0000e+00 - precision_139: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.7124 - accuracy: 0.5581 - recall_140: 0.6516 - precision_140: 0.2626\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7044 - accuracy: 0.5609 - recall_140: 0.6366 - precision_140: 0.2586\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5730 - recall_140: 0.6255 - precision_140: 0.2669\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.5747 - recall_140: 0.6150 - precision_140: 0.2675\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.5833 - recall_140: 0.6093 - precision_140: 0.2690\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.5918 - recall_140: 0.6097 - precision_140: 0.2756\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.5992 - recall_140: 0.5919 - precision_140: 0.2736\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6082 - recall_140: 0.5730 - precision_140: 0.2818\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6134 - recall_140: 0.5565 - precision_140: 0.2753\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.6246 - recall_140: 0.5551 - precision_140: 0.2839\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6317 - recall_140: 0.5418 - precision_140: 0.2818\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.6438 - recall_140: 0.5332 - precision_140: 0.2936\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6472 - recall_140: 0.5178 - precision_140: 0.2882\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6558 - recall_140: 0.5108 - precision_140: 0.3011\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.6676 - recall_140: 0.4893 - precision_140: 0.2967\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.6738 - recall_140: 0.4868 - precision_140: 0.3078\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.6850 - recall_140: 0.4775 - precision_140: 0.3158\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.6874 - recall_140: 0.4528 - precision_140: 0.3162\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.6869 - recall_140: 0.4413 - precision_140: 0.3151\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.6981 - recall_140: 0.4248 - precision_140: 0.3134\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.7023 - recall_140: 0.4263 - precision_140: 0.3260\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7121 - recall_140: 0.4134 - precision_140: 0.3251\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7172 - recall_140: 0.4006 - precision_140: 0.3319\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7195 - recall_140: 0.3867 - precision_140: 0.3345\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7255 - recall_140: 0.3851 - precision_140: 0.3399\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7323 - recall_140: 0.3765 - precision_140: 0.3487\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7327 - recall_140: 0.3704 - precision_140: 0.3571\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7380 - recall_140: 0.3429 - precision_140: 0.3476\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7440 - recall_140: 0.3364 - precision_140: 0.3542\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7450 - recall_140: 0.3295 - precision_140: 0.3637\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7487 - recall_140: 0.3174 - precision_140: 0.3642\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7513 - recall_140: 0.3056 - precision_140: 0.3677\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7533 - recall_140: 0.2896 - precision_140: 0.3633\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7592 - recall_140: 0.2744 - precision_140: 0.3665\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7610 - recall_140: 0.2766 - precision_140: 0.3861\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7624 - recall_140: 0.2623 - precision_140: 0.3769\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7681 - recall_140: 0.2521 - precision_140: 0.3826\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7713 - recall_140: 0.2428 - precision_140: 0.3924\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7735 - recall_140: 0.2374 - precision_140: 0.4019\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7726 - recall_140: 0.2316 - precision_140: 0.3966\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7724 - recall_140: 0.2170 - precision_140: 0.3971\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7735 - recall_140: 0.2106 - precision_140: 0.3896\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7735 - recall_140: 0.1977 - precision_140: 0.3901\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.7758 - recall_140: 0.1964 - precision_140: 0.3944\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7787 - recall_140: 0.1901 - precision_140: 0.4090\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7813 - recall_140: 0.1905 - precision_140: 0.4103\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7841 - recall_140: 0.1774 - precision_140: 0.4122\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7846 - recall_140: 0.1710 - precision_140: 0.4184\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7851 - recall_140: 0.1743 - precision_140: 0.4439\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7915 - recall_140: 0.1713 - precision_140: 0.4578\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7924 - recall_140: 0.1644 - precision_140: 0.4559\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7925 - recall_140: 0.1616 - precision_140: 0.4637\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7920 - recall_140: 0.1506 - precision_140: 0.4625\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7919 - recall_140: 0.1394 - precision_140: 0.4581\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7935 - recall_140: 0.1354 - precision_140: 0.4588\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7917 - recall_140: 0.1314 - precision_140: 0.4597\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7939 - recall_140: 0.1343 - precision_140: 0.4635\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7941 - recall_140: 0.1282 - precision_140: 0.4794\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7967 - recall_140: 0.1242 - precision_140: 0.4780\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7959 - recall_140: 0.1184 - precision_140: 0.4808\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7977 - recall_140: 0.1065 - precision_140: 0.4485\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7923 - recall_140: 0.1025 - precision_140: 0.4690\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7945 - recall_140: 0.1022 - precision_140: 0.5043\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.8017 - recall_140: 0.1105 - precision_140: 0.5237\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7991 - recall_140: 0.1014 - precision_140: 0.5250\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8007 - recall_140: 0.0949 - precision_140: 0.5417\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8012 - recall_140: 0.0909 - precision_140: 0.5294\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.8026 - recall_140: 0.0895 - precision_140: 0.5538\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.8004 - recall_140: 0.0887 - precision_140: 0.5621\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.8027 - recall_140: 0.0819 - precision_140: 0.5791\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.8034 - recall_140: 0.0837 - precision_140: 0.5841\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.8036 - recall_140: 0.0828 - precision_140: 0.5844\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.8004 - recall_140: 0.0771 - precision_140: 0.5749\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.8021 - recall_140: 0.0702 - precision_140: 0.5864\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.8044 - recall_140: 0.0712 - precision_140: 0.6076\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.8010 - recall_140: 0.0648 - precision_140: 0.6252\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.8039 - recall_140: 0.0656 - precision_140: 0.6568\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8044 - recall_140: 0.0601 - precision_140: 0.6535\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.8029 - recall_140: 0.0592 - precision_140: 0.6452\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8059 - recall_140: 0.0588 - precision_140: 0.6794\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.8044 - recall_140: 0.0536 - precision_140: 0.6621\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.8080 - recall_140: 0.0577 - precision_140: 0.6993\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.8032 - recall_140: 0.0565 - precision_140: 0.7184\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.8025 - recall_140: 0.0549 - precision_140: 0.7233\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8043 - recall_140: 0.0524 - precision_140: 0.7462\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.8061 - recall_140: 0.0520 - precision_140: 0.7450\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.8010 - recall_140: 0.0483 - precision_140: 0.7283\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.8035 - recall_140: 0.0488 - precision_140: 0.7582\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.8055 - recall_140: 0.0512 - precision_140: 0.7491\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.8035 - recall_140: 0.0495 - precision_140: 0.7345\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8021 - recall_140: 0.0475 - precision_140: 0.7136\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8022 - recall_140: 0.0409 - precision_140: 0.7337\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8013 - recall_140: 0.0447 - precision_140: 0.7373\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.8045 - recall_140: 0.0464 - precision_140: 0.7523\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.8023 - recall_140: 0.0389 - precision_140: 0.6952\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8006 - recall_140: 0.0406 - precision_140: 0.7121\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7989 - recall_140: 0.0395 - precision_140: 0.7190\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.8020 - recall_140: 0.0391 - precision_140: 0.7187\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.8035 - recall_140: 0.0403 - precision_140: 0.7169\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.8024 - recall_140: 0.0394 - precision_140: 0.7563\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A5C550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.8028 - recall_140: 0.0360 - precision_140: 0.7727\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6988 - accuracy: 0.4809 - recall_141: 0.4363 - precision_141: 0.1773\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.4958 - recall_141: 0.4028 - precision_141: 0.1768\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5116 - recall_141: 0.3810 - precision_141: 0.1742\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5190 - recall_141: 0.3464 - precision_141: 0.1698\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.5374 - recall_141: 0.3166 - precision_141: 0.1665\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5510 - recall_141: 0.3012 - precision_141: 0.1662\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6835 - accuracy: 0.5684 - recall_141: 0.2776 - precision_141: 0.1609\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.5814 - recall_141: 0.2622 - precision_141: 0.1680\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.5952 - recall_141: 0.2337 - precision_141: 0.1600\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.6077 - recall_141: 0.2213 - precision_141: 0.1590\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.6179 - recall_141: 0.1954 - precision_141: 0.1507\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6286 - recall_141: 0.1804 - precision_141: 0.1505\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.6347 - recall_141: 0.1682 - precision_141: 0.1506\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.6450 - recall_141: 0.1396 - precision_141: 0.1377\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.6598 - recall_141: 0.1313 - precision_141: 0.1415\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6728 - recall_141: 0.1208 - precision_141: 0.1409\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6931 - recall_141: 0.1251 - precision_141: 0.1570\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.7001 - recall_141: 0.1059 - precision_141: 0.1570\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.7120 - recall_141: 0.0906 - precision_141: 0.1458\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.7222 - recall_141: 0.0790 - precision_141: 0.1465\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.7309 - recall_141: 0.0715 - precision_141: 0.1561\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.7416 - recall_141: 0.0616 - precision_141: 0.1522\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.7490 - recall_141: 0.0533 - precision_141: 0.1573\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.7585 - recall_141: 0.0396 - precision_141: 0.1429\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.7670 - recall_141: 0.0335 - precision_141: 0.1535\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.7743 - recall_141: 0.0241 - precision_141: 0.1358\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.7785 - recall_141: 0.0181 - precision_141: 0.1462\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.7841 - recall_141: 0.0135 - precision_141: 0.1365\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.7855 - recall_141: 0.0087 - precision_141: 0.1057\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.7847 - recall_141: 0.0022 - precision_141: 0.0425    \n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.7890 - recall_141: 0.0020 - precision_141: 0.0465\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7925 - recall_141: 0.0015 - precision_141: 0.0506\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.7968 - recall_141: 0.0015 - precision_141: 0.0862\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.7977 - recall_141: 0.0015 - precision_141: 0.1571\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.8001 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.7986 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.7979 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.7992 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.7989 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.7963 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6201 - accuracy: 0.7941 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.7975 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.7998 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.7998 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.7938 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.7962 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.7988 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.7984 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7948 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.7972 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7993 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.7944 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7984 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.8001 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5993 - accuracy: 0.7986 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.7999 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7967 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7977 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7954 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.7965 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.7974 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.7993 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7989 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.7976 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7933 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7965 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7975 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.8005 - recall_141: 0.0000e+00 - precision_141: 0.0000e+0 - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7978 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.7971 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.7951 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.8000 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7951 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.7972 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5774 - accuracy: 0.7994 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.8003 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7984 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5769 - accuracy: 0.7953 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7971 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7974 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7971 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.8011 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7969 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7973 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7988 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7958 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7975 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7981 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.8023 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7977 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7984 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7974 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5636 - accuracy: 0.7948 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7934 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7955 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7968 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.8021 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7973 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7978 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7978 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7966 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6599AC820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7973 - recall_141: 0.0000e+00 - precision_141: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6381 - accuracy: 0.7957 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.8004 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.7980 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7909 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.7959 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.7979 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.7942 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.7993 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.7998 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.7984 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.8002 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.7954 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7979 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.7995 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6081 - accuracy: 0.7988 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.7958 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.7970 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7958 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.7989 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.7960 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5980 - accuracy: 0.7981 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.8005 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.7945 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7997 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.7975 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5895 - accuracy: 0.8000 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7984 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.8007 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.7973 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7993 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.7965 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7972 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.7975 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.7985 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7976 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.7977 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7992 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5747 - accuracy: 0.7979 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7992 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7967 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7979 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.7996 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7983 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.7969 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7976 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7974 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7969 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7985 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5623 - accuracy: 0.7990 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7959 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.8014 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7970 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7957 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5593 - accuracy: 0.7962 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5576 - accuracy: 0.7975 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.7969 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7976 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7980 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7971 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5555 - accuracy: 0.7943 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.7933 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.7957 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7978 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7999 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7976 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7992 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7964 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7987 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7960 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.8000 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7959 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7984 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7979 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7984 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.8000 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7979 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7969 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7971 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7975 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7974 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.8006 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7964 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7970 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.7954 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7986 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7994 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7972 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7997 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7950 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7985 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.8004 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.8004 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7970 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7922 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7959 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.8025 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5322 - accuracy: 0.7969 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7931 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7986 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5291 - accuracy: 0.7992 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580329D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7973 - recall_142: 0.0000e+00 - precision_142: 0.0000e+00\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 1.4242 - accuracy: 0.2016 - recall_143: 1.0000 - precision_143: 0.2016\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.4020 - accuracy: 0.2067 - recall_143: 1.0000 - precision_143: 0.2067\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3913 - accuracy: 0.2042 - recall_143: 1.0000 - precision_143: 0.2042\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3796 - accuracy: 0.2028 - recall_143: 1.0000 - precision_143: 0.2028\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3653 - accuracy: 0.2031 - recall_143: 1.0000 - precision_143: 0.2031\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3559 - accuracy: 0.2002 - recall_143: 1.0000 - precision_143: 0.2002\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3394 - accuracy: 0.2022 - recall_143: 1.0000 - precision_143: 0.2022\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3235 - accuracy: 0.2041 - recall_143: 1.0000 - precision_143: 0.2041\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3132 - accuracy: 0.2020 - recall_143: 1.0000 - precision_143: 0.2020\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3000 - accuracy: 0.2023 - recall_143: 1.0000 - precision_143: 0.2023\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.2899 - accuracy: 0.2002 - recall_143: 1.0000 - precision_143: 0.2002\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2732 - accuracy: 0.2033 - recall_143: 1.0000 - precision_143: 0.2033\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2599 - accuracy: 0.2041 - recall_143: 1.0000 - precision_143: 0.2041\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2493 - accuracy: 0.2028 - recall_143: 1.0000 - precision_143: 0.2028\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2358 - accuracy: 0.2041 - recall_143: 1.0000 - precision_143: 0.2041\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.2263 - accuracy: 0.2023 - recall_143: 1.0000 - precision_143: 0.2023\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2153 - accuracy: 0.2019 - recall_143: 1.0000 - precision_143: 0.2019\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2021 - accuracy: 0.2032 - recall_143: 1.0000 - precision_143: 0.2032\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1926 - accuracy: 0.2019 - recall_143: 1.0000 - precision_143: 0.2019\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1813 - accuracy: 0.2020 - recall_143: 1.0000 - precision_143: 0.2020\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1668 - accuracy: 0.2053 - recall_143: 1.0000 - precision_143: 0.2053\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1624 - accuracy: 0.1995 - recall_143: 1.0000 - precision_143: 0.1995\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1462 - accuracy: 0.2047 - recall_143: 1.0000 - precision_143: 0.2047\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1361 - accuracy: 0.2045 - recall_143: 1.0000 - precision_143: 0.2045\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1304 - accuracy: 0.2002 - recall_143: 1.0000 - precision_143: 0.2002\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1175 - accuracy: 0.2030 - recall_143: 1.0000 - precision_143: 0.2030\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1037 - accuracy: 0.2068 - recall_143: 1.0000 - precision_143: 0.2068\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0953 - accuracy: 0.2055 - recall_143: 1.0000 - precision_143: 0.2055\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0902 - accuracy: 0.2008 - recall_143: 1.0000 - precision_143: 0.2008\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0819 - accuracy: 0.1996 - recall_143: 1.0000 - precision_143: 0.1996\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0707 - accuracy: 0.2018 - recall_143: 1.0000 - precision_143: 0.2018\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0616 - accuracy: 0.2017 - recall_143: 1.0000 - precision_143: 0.2017\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0503 - accuracy: 0.2044 - recall_143: 1.0000 - precision_143: 0.2044\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0420 - accuracy: 0.2036 - recall_143: 1.0000 - precision_143: 0.2036\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0346 - accuracy: 0.2022 - recall_143: 1.0000 - precision_143: 0.2022\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0279 - accuracy: 0.2000 - recall_143: 1.0000 - precision_143: 0.2000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0176 - accuracy: 0.2023 - recall_143: 1.0000 - precision_143: 0.2023\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0079 - accuracy: 0.2042 - recall_143: 1.0000 - precision_143: 0.2042\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0001 - accuracy: 0.2035 - recall_143: 1.0000 - precision_143: 0.2035\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9937 - accuracy: 0.2018 - recall_143: 1.0000 - precision_143: 0.2018\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.9864 - accuracy: 0.2025 - recall_143: 1.0000 - precision_143: 0.202 - 0s 3ms/step - loss: 0.9852 - accuracy: 0.2025 - recall_143: 1.0000 - precision_143: 0.2025\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9782 - accuracy: 0.2016 - recall_143: 1.0000 - precision_143: 0.2016\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9705 - accuracy: 0.2016 - recall_143: 1.0000 - precision_143: 0.2016\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9608 - accuracy: 0.2048 - recall_143: 1.0000 - precision_143: 0.2048\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9566 - accuracy: 0.2003 - recall_143: 1.0000 - precision_143: 0.2003\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9476 - accuracy: 0.2029 - recall_143: 1.0000 - precision_143: 0.2029\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9395 - accuracy: 0.2045 - recall_143: 1.0000 - precision_143: 0.2045\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9334 - accuracy: 0.2032 - recall_143: 1.0000 - precision_143: 0.2032\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9280 - accuracy: 0.2008 - recall_143: 1.0000 - precision_143: 0.2008\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9188 - accuracy: 0.2047 - recall_143: 1.0000 - precision_143: 0.2047\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9140 - accuracy: 0.2017 - recall_143: 1.0000 - precision_143: 0.2017\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9059 - accuracy: 0.2045 - recall_143: 1.0000 - precision_143: 0.2045\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8998 - accuracy: 0.2038 - recall_143: 1.0000 - precision_143: 0.2038\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8936 - accuracy: 0.2038 - recall_143: 1.0000 - precision_143: 0.2038\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8881 - accuracy: 0.2024 - recall_143: 1.0000 - precision_143: 0.2024\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8802 - accuracy: 0.2057 - recall_143: 1.0000 - precision_143: 0.2057\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8766 - accuracy: 0.2010 - recall_143: 1.0000 - precision_143: 0.2010\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8695 - accuracy: 0.2035 - recall_143: 1.0000 - precision_143: 0.2035\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8639 - accuracy: 0.2030 - recall_143: 1.0000 - precision_143: 0.2030\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8585 - accuracy: 0.2023 - recall_143: 1.0000 - precision_143: 0.2023\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8526 - accuracy: 0.2029 - recall_143: 1.0000 - precision_143: 0.2029\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8458 - accuracy: 0.2058 - recall_143: 1.0000 - precision_143: 0.2058\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8408 - accuracy: 0.2049 - recall_143: 1.0000 - precision_143: 0.2049\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8359 - accuracy: 0.2040 - recall_143: 1.0000 - precision_143: 0.2040\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8317 - accuracy: 0.2013 - recall_143: 1.0000 - precision_143: 0.2013\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8263 - accuracy: 0.2019 - recall_143: 1.0000 - precision_143: 0.2019\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8219 - accuracy: 0.2002 - recall_143: 1.0000 - precision_143: 0.2002\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8156 - accuracy: 0.2039 - recall_143: 1.0000 - precision_143: 0.2039\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8105 - accuracy: 0.2043 - recall_143: 1.0000 - precision_143: 0.2043\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8064 - accuracy: 0.2025 - recall_143: 1.0000 - precision_143: 0.2025\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8014 - accuracy: 0.2033 - recall_143: 1.0000 - precision_143: 0.2033\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7965 - accuracy: 0.2044 - recall_143: 1.0000 - precision_143: 0.2044\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7929 - accuracy: 0.2012 - recall_143: 1.0000 - precision_143: 0.2012\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7878 - accuracy: 0.2033 - recall_143: 1.0000 - precision_143: 0.2033\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7834 - accuracy: 0.2032 - recall_143: 1.0000 - precision_143: 0.2032\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7789 - accuracy: 0.2038 - recall_143: 1.0000 - precision_143: 0.2038\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7747 - accuracy: 0.2037 - recall_143: 1.0000 - precision_143: 0.2037\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7710 - accuracy: 0.2020 - recall_143: 1.0000 - precision_143: 0.2020\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7667 - accuracy: 0.2023 - recall_143: 1.0000 - precision_143: 0.2023\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7630 - accuracy: 0.2010 - recall_143: 1.0000 - precision_143: 0.2010\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7583 - accuracy: 0.2048 - recall_143: 1.0000 - precision_143: 0.2048\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7547 - accuracy: 0.2034 - recall_143: 1.0000 - precision_143: 0.2034\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7511 - accuracy: 0.2019 - recall_143: 1.0000 - precision_143: 0.2019\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7476 - accuracy: 0.2007 - recall_143: 1.0000 - precision_143: 0.2007\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7432 - accuracy: 0.2045 - recall_143: 1.0000 - precision_143: 0.2045\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7397 - accuracy: 0.2032 - recall_143: 1.0000 - precision_143: 0.2032\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.2032 - recall_143: 1.0000 - precision_143: 0.2032\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7328 - accuracy: 0.2022 - recall_143: 1.0000 - precision_143: 0.2022\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7293 - accuracy: 0.2019 - recall_143: 1.0000 - precision_143: 0.2019\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7261 - accuracy: 0.2008 - recall_143: 1.0000 - precision_143: 0.2008\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7227 - accuracy: 0.2007 - recall_143: 1.0000 - precision_143: 0.2007\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7191 - accuracy: 0.2050 - recall_143: 1.0000 - precision_143: 0.2050\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7160 - accuracy: 0.2019 - recall_143: 1.0000 - precision_143: 0.2019\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7129 - accuracy: 0.2030 - recall_143: 1.0000 - precision_143: 0.2030\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7098 - accuracy: 0.2001 - recall_143: 1.0000 - precision_143: 0.2001\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7067 - accuracy: 0.2024 - recall_143: 1.0000 - precision_143: 0.2024\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.7045 - accuracy: 0.1950 - recall_143: 1.0000 - precision_143: 0.195 - 0s 3ms/step - loss: 0.7038 - accuracy: 0.1998 - recall_143: 1.0000 - precision_143: 0.1998\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7007 - accuracy: 0.2045 - recall_143: 1.0000 - precision_143: 0.2045\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.2118 - recall_143: 0.9981 - precision_143: 0.2058\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6948 - accuracy: 0.3483 - recall_143: 0.9609 - precision_143: 0.2339\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D659A540D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6924 - accuracy: 0.5902 - recall_143: 0.7458 - precision_143: 0.2963\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 0.6510 - accuracy: 0.7983 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.7929 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.7969 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.7974 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.7969 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.8001 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.7950 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.7953 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7964 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.7969 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.7976 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.7996 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6273 - accuracy: 0.7968 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6260 - accuracy: 0.7949 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6238 - accuracy: 0.7969 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6215 - accuracy: 0.7987 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.7986 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.8024 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6175 - accuracy: 0.7951 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6148 - accuracy: 0.7988 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.8008 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.7984 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7976 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6082 - accuracy: 0.7999 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.7977 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7993 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.7991 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.7970 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7976 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.7992 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7956 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7969 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7933 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.8026 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.7979 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.8006 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.7969 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5903 - accuracy: 0.7965 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5883 - accuracy: 0.7984 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5871 - accuracy: 0.7984 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7980 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.7942 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7995 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.8006 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.7966 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.8013 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.7963 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7957 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7961 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7957 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.8001 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7956 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7949 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7985 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5720 - accuracy: 0.7966 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7968 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7962 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5702 - accuracy: 0.7947 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7974 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7966 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7995 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7939 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7936 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.7983 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7962 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7998 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.8031 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7964 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7993 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.8001 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7956 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7992 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7987 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.7971 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7984 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7957 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.8023 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7961 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7991 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7998 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7991 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.8001 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7965 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7991 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7993 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7976 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7987 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7958 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7938 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7987 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7981 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.8023 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7988 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7976 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7964 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7984 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7947 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7974 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.8000 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7984 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D6580A55E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.7973 - recall_144: 0.0000e+00 - precision_144: 0.0000e+00\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 0.7189 - accuracy: 0.4896 - recall_145: 0.4792 - precision_145: 0.1922\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7098 - accuracy: 0.5124 - recall_145: 0.4569 - precision_145: 0.1970\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.5325 - recall_145: 0.4334 - precision_145: 0.1987\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.5439 - recall_145: 0.3970 - precision_145: 0.1931\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6873 - accuracy: 0.5547 - recall_145: 0.3692 - precision_145: 0.1922\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.5775 - recall_145: 0.3553 - precision_145: 0.1981\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.5866 - recall_145: 0.3154 - precision_145: 0.1878\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.6077 - recall_145: 0.3114 - precision_145: 0.2040\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.6150 - recall_145: 0.2710 - precision_145: 0.1879\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6398 - recall_145: 0.2520 - precision_145: 0.1914\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6489 - recall_145: 0.2355 - precision_145: 0.1930\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6576 - recall_145: 0.2196 - precision_145: 0.1959\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6701 - recall_145: 0.2054 - precision_145: 0.1943\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.6825 - recall_145: 0.1908 - precision_145: 0.1970\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.6941 - recall_145: 0.1729 - precision_145: 0.2027\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.6986 - recall_145: 0.1521 - precision_145: 0.1897\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.7083 - recall_145: 0.1484 - precision_145: 0.1998\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.7176 - recall_145: 0.1271 - precision_145: 0.2014\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.7226 - recall_145: 0.1196 - precision_145: 0.1984\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6025 - accuracy: 0.7293 - recall_145: 0.1076 - precision_145: 0.2017\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.7351 - recall_145: 0.0888 - precision_145: 0.1794\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5933 - accuracy: 0.7438 - recall_145: 0.0936 - precision_145: 0.2033\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5919 - accuracy: 0.7458 - recall_145: 0.0723 - precision_145: 0.1846\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5860 - accuracy: 0.7541 - recall_145: 0.0733 - precision_145: 0.2009\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7585 - recall_145: 0.0676 - precision_145: 0.1992\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7589 - recall_145: 0.0639 - precision_145: 0.2102\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.7683 - recall_145: 0.0619 - precision_145: 0.2289\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7721 - recall_145: 0.0493 - precision_145: 0.2054\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7730 - recall_145: 0.0427 - precision_145: 0.2125\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7748 - recall_145: 0.0401 - precision_145: 0.2135\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7781 - recall_145: 0.0358 - precision_145: 0.2187\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.7854 - recall_145: 0.0287 - precision_145: 0.2018\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7825 - recall_145: 0.0311 - precision_145: 0.2268\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7829 - recall_145: 0.0261 - precision_145: 0.2288\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7872 - recall_145: 0.0243 - precision_145: 0.2232\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5534 - accuracy: 0.7877 - recall_145: 0.0188 - precision_145: 0.2240\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7869 - recall_145: 0.0183 - precision_145: 0.2338\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7943 - recall_145: 0.0183 - precision_145: 0.2632\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7857 - recall_145: 0.0168 - precision_145: 0.2749\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7914 - recall_145: 0.0127 - precision_145: 0.2290\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7913 - recall_145: 0.0125 - precision_145: 0.2353\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7961 - recall_145: 0.0150 - precision_145: 0.3355\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7992 - recall_145: 0.0132 - precision_145: 0.3342\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7950 - recall_145: 0.0136 - precision_145: 0.3533\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7952 - recall_145: 0.0109 - precision_145: 0.3068\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7944 - recall_145: 0.0117 - precision_145: 0.3538\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7944 - recall_145: 0.0088 - precision_145: 0.3581\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7950 - recall_145: 0.0098 - precision_145: 0.4222\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7954 - recall_145: 0.0064 - precision_145: 0.3311\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7983 - recall_145: 0.0074 - precision_145: 0.3505\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7969 - recall_145: 0.0078 - precision_145: 0.3923\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5256 - accuracy: 0.7964 - recall_145: 0.0072 - precision_145: 0.4175\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7992 - recall_145: 0.0077 - precision_145: 0.5102\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.8014 - recall_145: 0.0080 - precision_145: 0.5013\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7951 - recall_145: 0.0056 - precision_145: 0.3975\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7945 - recall_145: 0.0047 - precision_145: 0.6254\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.7960 - recall_145: 0.0042 - precision_145: 0.4434\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.8011 - recall_145: 0.0057 - precision_145: 0.5924\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5188 - accuracy: 0.7968 - recall_145: 0.0043 - precision_145: 0.5068    \n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.8001 - recall_145: 0.0031 - precision_145: 0.4810    \n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7959 - recall_145: 0.0032 - precision_145: 0.8286\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7954 - recall_145: 0.0021 - precision_145: 0.4867    \n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7990 - recall_145: 0.0021 - precision_145: 0.6700    \n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7973 - recall_145: 0.0026 - precision_145: 0.9000\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7980 - recall_145: 0.0016 - precision_145: 0.7000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7988 - recall_145: 0.0015 - precision_145: 0.7667\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7981 - recall_145: 4.4509e-04 - precision_145: 0.3000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7962 - recall_145: 6.9120e-04 - precision_145: 0.8000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.8001 - recall_145: 6.9995e-04 - precision_145: 0.8000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7985 - recall_145: 0.0012 - precision_145: 1.0000\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.7865 - recall_145: 0.0000e+00 - precision_145: 0.0000e+0 - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7947 - recall_145: 2.8209e-04 - precision_145: 0.4000\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7983 - recall_145: 4.4724e-04 - precision_145: 0.6000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7972 - recall_145: 6.8656e-04 - precision_145: 0.8000\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7979 - recall_145: 0.0012 - precision_145: 1.0000\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.7948 - recall_145: 0.0012 - precision_145: 1.0000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7979 - recall_145: 0.0012 - precision_145: 1.0000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.7971 - recall_145: 6.9066e-04 - precision_145: 0.8000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7948 - recall_145: 0.0012 - precision_145: 1.0000\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7966 - recall_145: 6.9162e-04 - precision_145: 0.8000\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7994 - recall_145: 6.9675e-04 - precision_145: 0.8000\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7946 - recall_145: 4.4351e-04 - precision_145: 0.6000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7946 - recall_145: 2.8209e-04 - precision_145: 0.4000\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7996 - recall_145: 7.0403e-04 - precision_145: 0.8000\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7984 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7961 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7968 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7958 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7965 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7977 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7979 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7970 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.7999 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7954 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7971 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7953 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7936 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7993 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8031 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7988 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7978 - recall_145: 0.0000e+00 - precision_145: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=3, shuffle=True),\n",
       "                   estimator=Pipeline(steps=[('powTransY', PowerTransformer()),\n",
       "                                             ('kerClass',\n",
       "                                              <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x000001D6580B5A30>)]),\n",
       "                   n_iter=48,\n",
       "                   param_distributions={'kerClass__activ1': ['sigmoid', 'tanh'],\n",
       "                                        'kerClass__l_rate': [0.002, 0.004,\n",
       "                                                             0.006, 0.008,\n",
       "                                                             0.01],\n",
       "                                        'kerClass__n_hidden_layer': [2, 3, 4],\n",
       "                                        'kerClass__neuFrac': [0.5, 0.66666],\n",
       "                                        'kerClass__neuronMult': [1.5],\n",
       "                                        'kerClass__optim': ['SGD']})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_distribs = {'kerClass__n_hidden_layer': [2, 3, 4], \n",
    "                  'kerClass__neuronMult': [1.5],\n",
    "                  'kerClass__optim': ['SGD'],\n",
    "                  'kerClass__activ1': ['sigmoid', 'tanh'],\n",
    "                  'kerClass__l_rate': np.arange(0.002,0.012,0.002).tolist(),\n",
    "                  'kerClass__neuFrac': [0.5, 0.66666]\n",
    "                 }\n",
    "rnd_search_cv = RandomizedSearchCV(annPipeL, param_distribs, n_iter=48, cv=kf3)\n",
    "rnd_search_cv.fit(X1_train, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kerClass__optim': 'SGD',\n",
       " 'kerClass__neuronMult': 1.5,\n",
       " 'kerClass__neuFrac': 0.5,\n",
       " 'kerClass__n_hidden_layer': 3,\n",
       " 'kerClass__l_rate': 0.01,\n",
       " 'kerClass__activ1': 'tanh'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction at 0.5 Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Tweaked by RandomizedSearchCV results comparison with base model\n",
    "1. Use RandomizedSearchCV Best Parameters for final model\n",
    "2. Cater for imbalanced Exited class distribution with weight adjustments weights = {0:1, 1:5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0:1, 1:5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim='SGD'\n",
    "neuronMult=1.5\n",
    "neuFrac=0.5\n",
    "n_hidden_layer=3\n",
    "l_rate=0.01\n",
    "activ1='tanh'\n",
    "rand1=0.5\n",
    "rand2=0.0\n",
    "\n",
    "# Create model\n",
    "annClass = tf.keras.Sequential()\n",
    "annClass.add(tf.keras.Input(shape=(trape,)))\n",
    "\n",
    "init0 = False\n",
    "for layer in range(1, n_hidden_layer+1):\n",
    "    if init0 == False:\n",
    "        annClass.add(tf.keras.layers.Dense(int(neuronMult*trape), activation=activ1))\n",
    "        init0 = True\n",
    "    else:\n",
    "        annClass.add(tf.keras.layers.Dense(int(neuronMult*trape*(np.power(neuFrac, layer-1))), activation=activ1))\n",
    "\n",
    "annClass.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Optimizer for model\n",
    "optimiz = tf.keras.optimizers.Optimizer\n",
    "if optim == 'SGD':\n",
    "    optimiz = tf.keras.optimizers.SGD(learning_rate=l_rate, momentum=rand2, name='SGD')# nesterov=False, \n",
    "if optim == 'RMSprop':\n",
    "    optimiz = tf.keras.optimizers.RMSprop(learning_rate=l_rate, rho=0.9, momentum=rand2, name='RMSprop')#, epsilon=1e-07, centered=False,\n",
    "\n",
    "# Compile model\n",
    "annClass.compile(optimizer=optimiz, loss='binary_crossentropy', metrics=['accuracy',\n",
    "                                                                        tf.keras.metrics.BinaryCrossentropy(),\n",
    "                                                                        tf.keras.metrics.Recall(thresholds=0.5),\n",
    "                                                                        tf.keras.metrics.Precision(thresholds=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_583 (Dense)            (None, 18)                234       \n",
      "_________________________________________________________________\n",
      "dense_584 (Dense)            (None, 9)                 171       \n",
      "_________________________________________________________________\n",
      "dense_585 (Dense)            (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "dense_586 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 450\n",
      "Trainable params: 450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print model summary\n",
    "annClass.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Tweaked by RandomizedSearchCV validation metrics \"annHist\" comparison with base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "137/154 [=========================>....] - ETA: 0s - loss: 1.2381 - accuracy: 0.5306 - binary_crossentropy: 0.7288 - recall_146: 0.6679 - precision_146: 0.2520WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001D655258DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "154/154 [==============================] - 2s 6ms/step - loss: 1.2274 - accuracy: 0.5350 - binary_crossentropy: 0.7246 - recall_146: 0.6757 - precision_146: 0.2553 - val_loss: 0.6578 - val_accuracy: 0.6200 - val_binary_crossentropy: 0.6578 - val_recall_146: 0.7650 - val_precision_146: 0.3230\n",
      "Epoch 2/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 1.0559 - accuracy: 0.6274 - binary_crossentropy: 0.6563 - recall_146: 0.8144 - precision_146: 0.3381 - val_loss: 0.6244 - val_accuracy: 0.6605 - val_binary_crossentropy: 0.6244 - val_recall_146: 0.7327 - val_precision_146: 0.3475\n",
      "Epoch 3/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.9961 - accuracy: 0.6731 - binary_crossentropy: 0.6124 - recall_146: 0.7729 - precision_146: 0.3499 - val_loss: 0.6136 - val_accuracy: 0.6681 - val_binary_crossentropy: 0.6136 - val_recall_146: 0.7120 - val_precision_146: 0.3507\n",
      "Epoch 4/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.9927 - accuracy: 0.6849 - binary_crossentropy: 0.6108 - recall_146: 0.7921 - precision_146: 0.3682 - val_loss: 0.6080 - val_accuracy: 0.6838 - val_binary_crossentropy: 0.6080 - val_recall_146: 0.7212 - val_precision_146: 0.3657\n",
      "Epoch 5/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.9796 - accuracy: 0.6898 - binary_crossentropy: 0.5982 - recall_146: 0.7729 - precision_146: 0.3690 - val_loss: 0.6192 - val_accuracy: 0.6743 - val_binary_crossentropy: 0.6192 - val_recall_146: 0.7373 - val_precision_146: 0.3596\n",
      "Epoch 6/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.9786 - accuracy: 0.6918 - binary_crossentropy: 0.6003 - recall_146: 0.7905 - precision_146: 0.3856 - val_loss: 0.5922 - val_accuracy: 0.6919 - val_binary_crossentropy: 0.5922 - val_recall_146: 0.7143 - val_precision_146: 0.3721\n",
      "Epoch 7/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.9533 - accuracy: 0.7117 - binary_crossentropy: 0.5760 - recall_146: 0.7970 - precision_146: 0.3954 - val_loss: 0.5850 - val_accuracy: 0.6976 - val_binary_crossentropy: 0.5850 - val_recall_146: 0.7166 - val_precision_146: 0.3779\n",
      "Epoch 8/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.9372 - accuracy: 0.7169 - binary_crossentropy: 0.5665 - recall_146: 0.7979 - precision_146: 0.3929 - val_loss: 0.5943 - val_accuracy: 0.6914 - val_binary_crossentropy: 0.5943 - val_recall_146: 0.7373 - val_precision_146: 0.3747\n",
      "Epoch 9/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.9298 - accuracy: 0.7138 - binary_crossentropy: 0.5672 - recall_146: 0.8073 - precision_146: 0.4024 - val_loss: 0.5754 - val_accuracy: 0.7029 - val_binary_crossentropy: 0.5754 - val_recall_146: 0.7189 - val_precision_146: 0.3833\n",
      "Epoch 10/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.9477 - accuracy: 0.7134 - binary_crossentropy: 0.5750 - recall_146: 0.8112 - precision_146: 0.4106 - val_loss: 0.5592 - val_accuracy: 0.7167 - val_binary_crossentropy: 0.5592 - val_recall_146: 0.7166 - val_precision_146: 0.3972\n",
      "Epoch 11/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8850 - accuracy: 0.7433 - binary_crossentropy: 0.5304 - recall_146: 0.8008 - precision_146: 0.4283 - val_loss: 0.5545 - val_accuracy: 0.7186 - val_binary_crossentropy: 0.5545 - val_recall_146: 0.7143 - val_precision_146: 0.3990\n",
      "Epoch 12/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8856 - accuracy: 0.7438 - binary_crossentropy: 0.5319 - recall_146: 0.7867 - precision_146: 0.4182 - val_loss: 0.5562 - val_accuracy: 0.7252 - val_binary_crossentropy: 0.5562 - val_recall_146: 0.7465 - val_precision_146: 0.4096\n",
      "Epoch 13/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8772 - accuracy: 0.7462 - binary_crossentropy: 0.5323 - recall_146: 0.8130 - precision_146: 0.4374 - val_loss: 0.5420 - val_accuracy: 0.7333 - val_binary_crossentropy: 0.5420 - val_recall_146: 0.7304 - val_precision_146: 0.4171\n",
      "Epoch 14/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8638 - accuracy: 0.7500 - binary_crossentropy: 0.5261 - recall_146: 0.8162 - precision_146: 0.4253 - val_loss: 0.5686 - val_accuracy: 0.7100 - val_binary_crossentropy: 0.5686 - val_recall_146: 0.7581 - val_precision_146: 0.3950\n",
      "Epoch 15/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8721 - accuracy: 0.7352 - binary_crossentropy: 0.5392 - recall_146: 0.8277 - precision_146: 0.4184 - val_loss: 0.5327 - val_accuracy: 0.7362 - val_binary_crossentropy: 0.5327 - val_recall_146: 0.7442 - val_precision_146: 0.4217\n",
      "Epoch 16/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8748 - accuracy: 0.7493 - binary_crossentropy: 0.5248 - recall_146: 0.8217 - precision_146: 0.4483 - val_loss: 0.5276 - val_accuracy: 0.7400 - val_binary_crossentropy: 0.5276 - val_recall_146: 0.7396 - val_precision_146: 0.4257\n",
      "Epoch 17/100\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.8395 - accuracy: 0.7538 - binary_crossentropy: 0.5044 - recall_146: 0.8156 - precision_146: 0.4331 - val_loss: 0.5615 - val_accuracy: 0.7186 - val_binary_crossentropy: 0.5615 - val_recall_146: 0.7765 - val_precision_146: 0.4055\n",
      "Epoch 18/100\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.8351 - accuracy: 0.7464 - binary_crossentropy: 0.5205 - recall_146: 0.8349 - precision_146: 0.4283 - val_loss: 0.5984 - val_accuracy: 0.6910 - val_binary_crossentropy: 0.5984 - val_recall_146: 0.8018 - val_precision_146: 0.3820\n",
      "Epoch 19/100\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.8418 - accuracy: 0.7368 - binary_crossentropy: 0.5300 - recall_146: 0.8420 - precision_146: 0.4213 - val_loss: 0.5822 - val_accuracy: 0.7014 - val_binary_crossentropy: 0.5822 - val_recall_146: 0.7834 - val_precision_146: 0.3895\n",
      "Epoch 20/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8143 - accuracy: 0.7489 - binary_crossentropy: 0.5114 - recall_146: 0.8395 - precision_146: 0.4292 - val_loss: 0.5492 - val_accuracy: 0.7186 - val_binary_crossentropy: 0.5492 - val_recall_146: 0.7765 - val_precision_146: 0.4055\n",
      "Epoch 21/100\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.8424 - accuracy: 0.7563 - binary_crossentropy: 0.5131 - recall_146: 0.8244 - precision_146: 0.4328 - val_loss: 0.5189 - val_accuracy: 0.7333 - val_binary_crossentropy: 0.5189 - val_recall_146: 0.7373 - val_precision_146: 0.4178\n",
      "Epoch 22/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8157 - accuracy: 0.7675 - binary_crossentropy: 0.4881 - recall_146: 0.8212 - precision_146: 0.4534 - val_loss: 0.5183 - val_accuracy: 0.7357 - val_binary_crossentropy: 0.5183 - val_recall_146: 0.7558 - val_precision_146: 0.4221\n",
      "Epoch 23/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8282 - accuracy: 0.7508 - binary_crossentropy: 0.5083 - recall_146: 0.8161 - precision_146: 0.4332 - val_loss: 0.5184 - val_accuracy: 0.7414 - val_binary_crossentropy: 0.5184 - val_recall_146: 0.7512 - val_precision_146: 0.4284\n",
      "Epoch 24/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8135 - accuracy: 0.7701 - binary_crossentropy: 0.4862 - recall_146: 0.8192 - precision_146: 0.4517 - val_loss: 0.5796 - val_accuracy: 0.7052 - val_binary_crossentropy: 0.5796 - val_recall_146: 0.8041 - val_precision_146: 0.3952\n",
      "Epoch 25/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7963 - accuracy: 0.7642 - binary_crossentropy: 0.5053 - recall_146: 0.8510 - precision_146: 0.4467 - val_loss: 0.5358 - val_accuracy: 0.7248 - val_binary_crossentropy: 0.5358 - val_recall_146: 0.7581 - val_precision_146: 0.4102\n",
      "Epoch 26/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8093 - accuracy: 0.7665 - binary_crossentropy: 0.4986 - recall_146: 0.8367 - precision_146: 0.4532 - val_loss: 0.4943 - val_accuracy: 0.7567 - val_binary_crossentropy: 0.4943 - val_recall_146: 0.7235 - val_precision_146: 0.4454\n",
      "Epoch 27/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8308 - accuracy: 0.7636 - binary_crossentropy: 0.4901 - recall_146: 0.8053 - precision_146: 0.4537 - val_loss: 0.5158 - val_accuracy: 0.7376 - val_binary_crossentropy: 0.5158 - val_recall_146: 0.7442 - val_precision_146: 0.4233\n",
      "Epoch 28/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7934 - accuracy: 0.7723 - binary_crossentropy: 0.4770 - recall_146: 0.8168 - precision_146: 0.4525 - val_loss: 0.5163 - val_accuracy: 0.7343 - val_binary_crossentropy: 0.5163 - val_recall_146: 0.7512 - val_precision_146: 0.4201\n",
      "Epoch 29/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8033 - accuracy: 0.7772 - binary_crossentropy: 0.4848 - recall_146: 0.8348 - precision_146: 0.4821 - val_loss: 0.5511 - val_accuracy: 0.7181 - val_binary_crossentropy: 0.5511 - val_recall_146: 0.7995 - val_precision_146: 0.4073\n",
      "Epoch 30/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8000 - accuracy: 0.7572 - binary_crossentropy: 0.4969 - recall_146: 0.8226 - precision_146: 0.4257 - val_loss: 0.5347 - val_accuracy: 0.7276 - val_binary_crossentropy: 0.5347 - val_recall_146: 0.7719 - val_precision_146: 0.4146\n",
      "Epoch 31/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7972 - accuracy: 0.7735 - binary_crossentropy: 0.4893 - recall_146: 0.8304 - precision_146: 0.4672 - val_loss: 0.5026 - val_accuracy: 0.7471 - val_binary_crossentropy: 0.5026 - val_recall_146: 0.7442 - val_precision_146: 0.4347\n",
      "Epoch 32/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7981 - accuracy: 0.7725 - binary_crossentropy: 0.4863 - recall_146: 0.8356 - precision_146: 0.4756 - val_loss: 0.4709 - val_accuracy: 0.7738 - val_binary_crossentropy: 0.4709 - val_recall_146: 0.7051 - val_precision_146: 0.4686\n",
      "Epoch 33/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7924 - accuracy: 0.7842 - binary_crossentropy: 0.4675 - recall_146: 0.8185 - precision_146: 0.4749 - val_loss: 0.5320 - val_accuracy: 0.7305 - val_binary_crossentropy: 0.5320 - val_recall_146: 0.7696 - val_precision_146: 0.4175\n",
      "Epoch 34/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7994 - accuracy: 0.7727 - binary_crossentropy: 0.4766 - recall_146: 0.8279 - precision_146: 0.4567 - val_loss: 0.4936 - val_accuracy: 0.7543 - val_binary_crossentropy: 0.4936 - val_recall_146: 0.7304 - val_precision_146: 0.4427\n",
      "Epoch 35/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7906 - accuracy: 0.7751 - binary_crossentropy: 0.4778 - recall_146: 0.8450 - precision_146: 0.4779 - val_loss: 0.4883 - val_accuracy: 0.7586 - val_binary_crossentropy: 0.4883 - val_recall_146: 0.7396 - val_precision_146: 0.4490\n",
      "Epoch 36/100\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.7449 - accuracy: 0.7927 - binary_crossentropy: 0.4483 - recall_146: 0.8428 - precision_146: 0.4898 - val_loss: 0.5095 - val_accuracy: 0.7433 - val_binary_crossentropy: 0.5095 - val_recall_146: 0.7650 - val_precision_146: 0.4317\n",
      "Epoch 37/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7747 - accuracy: 0.7793 - binary_crossentropy: 0.4746 - recall_146: 0.8369 - precision_146: 0.4708 - val_loss: 0.4859 - val_accuracy: 0.7610 - val_binary_crossentropy: 0.4859 - val_recall_146: 0.7350 - val_precision_146: 0.4518\n",
      "Epoch 38/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7635 - accuracy: 0.7885 - binary_crossentropy: 0.4551 - recall_146: 0.8304 - precision_146: 0.4790 - val_loss: 0.5023 - val_accuracy: 0.7495 - val_binary_crossentropy: 0.5023 - val_recall_146: 0.7465 - val_precision_146: 0.4378\n",
      "Epoch 39/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.7792 - binary_crossentropy: 0.4608 - recall_146: 0.8377 - precision_146: 0.4679 - val_loss: 0.4763 - val_accuracy: 0.7648 - val_binary_crossentropy: 0.4763 - val_recall_146: 0.7396 - val_precision_146: 0.4573\n",
      "Epoch 40/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7484 - accuracy: 0.7914 - binary_crossentropy: 0.4534 - recall_146: 0.8390 - precision_146: 0.4865 - val_loss: 0.4851 - val_accuracy: 0.7643 - val_binary_crossentropy: 0.4851 - val_recall_146: 0.7373 - val_precision_146: 0.4565\n",
      "Epoch 41/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8061 - accuracy: 0.7714 - binary_crossentropy: 0.4823 - recall_146: 0.8280 - precision_146: 0.4781 - val_loss: 0.4571 - val_accuracy: 0.7829 - val_binary_crossentropy: 0.4571 - val_recall_146: 0.7028 - val_precision_146: 0.4826\n",
      "Epoch 42/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7799 - accuracy: 0.7847 - binary_crossentropy: 0.4588 - recall_146: 0.8206 - precision_146: 0.4913 - val_loss: 0.5206 - val_accuracy: 0.7448 - val_binary_crossentropy: 0.5206 - val_recall_146: 0.7535 - val_precision_146: 0.4325\n",
      "Epoch 43/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7654 - accuracy: 0.7807 - binary_crossentropy: 0.4724 - recall_146: 0.8278 - precision_146: 0.4644 - val_loss: 0.5452 - val_accuracy: 0.7290 - val_binary_crossentropy: 0.5452 - val_recall_146: 0.7650 - val_precision_146: 0.4155\n",
      "Epoch 44/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7709 - accuracy: 0.7696 - binary_crossentropy: 0.4728 - recall_146: 0.8439 - precision_146: 0.4663 - val_loss: 0.4981 - val_accuracy: 0.7538 - val_binary_crossentropy: 0.4981 - val_recall_146: 0.7442 - val_precision_146: 0.4431\n",
      "Epoch 45/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7525 - accuracy: 0.7850 - binary_crossentropy: 0.4643 - recall_146: 0.8232 - precision_146: 0.4566 - val_loss: 0.4841 - val_accuracy: 0.7667 - val_binary_crossentropy: 0.4841 - val_recall_146: 0.7419 - val_precision_146: 0.4600\n",
      "Epoch 46/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7302 - accuracy: 0.7997 - binary_crossentropy: 0.4429 - recall_146: 0.8341 - precision_146: 0.4969 - val_loss: 0.5658 - val_accuracy: 0.7162 - val_binary_crossentropy: 0.5658 - val_recall_146: 0.8157 - val_precision_146: 0.4069\n",
      "Epoch 47/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7287 - accuracy: 0.7811 - binary_crossentropy: 0.4639 - recall_146: 0.8507 - precision_146: 0.4734 - val_loss: 0.4757 - val_accuracy: 0.7729 - val_binary_crossentropy: 0.4757 - val_recall_146: 0.7373 - val_precision_146: 0.4685\n",
      "Epoch 48/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7274 - accuracy: 0.7925 - binary_crossentropy: 0.4415 - recall_146: 0.8415 - precision_146: 0.4812 - val_loss: 0.4971 - val_accuracy: 0.7595 - val_binary_crossentropy: 0.4971 - val_recall_146: 0.7512 - val_precision_146: 0.4509\n",
      "Epoch 49/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.7989 - binary_crossentropy: 0.4347 - recall_146: 0.8548 - precision_146: 0.4935 - val_loss: 0.5021 - val_accuracy: 0.7557 - val_binary_crossentropy: 0.5021 - val_recall_146: 0.7535 - val_precision_146: 0.4461\n",
      "Epoch 50/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7205 - accuracy: 0.8003 - binary_crossentropy: 0.4394 - recall_146: 0.8372 - precision_146: 0.4974 - val_loss: 0.5054 - val_accuracy: 0.7524 - val_binary_crossentropy: 0.5054 - val_recall_146: 0.7719 - val_precision_146: 0.4431\n",
      "Epoch 51/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7306 - accuracy: 0.7945 - binary_crossentropy: 0.4426 - recall_146: 0.8345 - precision_146: 0.4931 - val_loss: 0.4702 - val_accuracy: 0.7700 - val_binary_crossentropy: 0.4702 - val_recall_146: 0.7235 - val_precision_146: 0.4638\n",
      "Epoch 52/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7424 - accuracy: 0.7954 - binary_crossentropy: 0.4485 - recall_146: 0.8365 - precision_146: 0.4941 - val_loss: 0.5346 - val_accuracy: 0.7386 - val_binary_crossentropy: 0.5346 - val_recall_146: 0.7880 - val_precision_146: 0.4280\n",
      "Epoch 53/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7424 - accuracy: 0.7819 - binary_crossentropy: 0.4637 - recall_146: 0.8375 - precision_146: 0.4685 - val_loss: 0.4839 - val_accuracy: 0.7719 - val_binary_crossentropy: 0.4839 - val_recall_146: 0.7419 - val_precision_146: 0.4673\n",
      "Epoch 54/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7780 - accuracy: 0.7789 - binary_crossentropy: 0.4660 - recall_146: 0.8168 - precision_146: 0.4741 - val_loss: 0.5170 - val_accuracy: 0.7519 - val_binary_crossentropy: 0.5170 - val_recall_146: 0.7673 - val_precision_146: 0.4422\n",
      "Epoch 55/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7715 - accuracy: 0.7839 - binary_crossentropy: 0.4641 - recall_146: 0.8227 - precision_146: 0.4760 - val_loss: 0.5190 - val_accuracy: 0.7452 - val_binary_crossentropy: 0.5190 - val_recall_146: 0.7696 - val_precision_146: 0.4343\n",
      "Epoch 56/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7596 - accuracy: 0.7797 - binary_crossentropy: 0.4688 - recall_146: 0.8270 - precision_146: 0.4702 - val_loss: 0.4925 - val_accuracy: 0.7610 - val_binary_crossentropy: 0.4925 - val_recall_146: 0.7396 - val_precision_146: 0.4521\n",
      "Epoch 57/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7589 - accuracy: 0.7910 - binary_crossentropy: 0.4506 - recall_146: 0.8356 - precision_146: 0.4881 - val_loss: 0.4845 - val_accuracy: 0.7695 - val_binary_crossentropy: 0.4845 - val_recall_146: 0.7396 - val_precision_146: 0.4639\n",
      "Epoch 58/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7378 - accuracy: 0.7978 - binary_crossentropy: 0.4428 - recall_146: 0.8281 - precision_146: 0.5007 - val_loss: 0.4751 - val_accuracy: 0.7729 - val_binary_crossentropy: 0.4751 - val_recall_146: 0.7419 - val_precision_146: 0.4687\n",
      "Epoch 59/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7276 - accuracy: 0.8048 - binary_crossentropy: 0.4381 - recall_146: 0.8362 - precision_146: 0.5103 - val_loss: 0.4995 - val_accuracy: 0.7529 - val_binary_crossentropy: 0.4995 - val_recall_146: 0.7581 - val_precision_146: 0.4428\n",
      "Epoch 60/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.8003 - accuracy: 0.7742 - binary_crossentropy: 0.4819 - recall_146: 0.8124 - precision_146: 0.4641 - val_loss: 0.5012 - val_accuracy: 0.7581 - val_binary_crossentropy: 0.5012 - val_recall_146: 0.7512 - val_precision_146: 0.4490\n",
      "Epoch 61/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7439 - accuracy: 0.7949 - binary_crossentropy: 0.4514 - recall_146: 0.8410 - precision_146: 0.4914 - val_loss: 0.4833 - val_accuracy: 0.7705 - val_binary_crossentropy: 0.4833 - val_recall_146: 0.7604 - val_precision_146: 0.4661\n",
      "Epoch 62/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7280 - accuracy: 0.7894 - binary_crossentropy: 0.4421 - recall_146: 0.8171 - precision_146: 0.4809 - val_loss: 0.4882 - val_accuracy: 0.7695 - val_binary_crossentropy: 0.4882 - val_recall_146: 0.7558 - val_precision_146: 0.4646\n",
      "Epoch 63/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7607 - accuracy: 0.7786 - binary_crossentropy: 0.4593 - recall_146: 0.8257 - precision_146: 0.4785 - val_loss: 0.5058 - val_accuracy: 0.7576 - val_binary_crossentropy: 0.5058 - val_recall_146: 0.7742 - val_precision_146: 0.4498\n",
      "Epoch 64/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7684 - accuracy: 0.7811 - binary_crossentropy: 0.4638 - recall_146: 0.8087 - precision_146: 0.4681 - val_loss: 0.5349 - val_accuracy: 0.7429 - val_binary_crossentropy: 0.5349 - val_recall_146: 0.7742 - val_precision_146: 0.4319\n",
      "Epoch 65/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7433 - accuracy: 0.7855 - binary_crossentropy: 0.4591 - recall_146: 0.8358 - precision_146: 0.4798 - val_loss: 0.4857 - val_accuracy: 0.7710 - val_binary_crossentropy: 0.4857 - val_recall_146: 0.7581 - val_precision_146: 0.4667\n",
      "Epoch 66/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7208 - accuracy: 0.7933 - binary_crossentropy: 0.4425 - recall_146: 0.8399 - precision_146: 0.4839 - val_loss: 0.5169 - val_accuracy: 0.7500 - val_binary_crossentropy: 0.5169 - val_recall_146: 0.7696 - val_precision_146: 0.4401\n",
      "Epoch 67/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7191 - accuracy: 0.7961 - binary_crossentropy: 0.4456 - recall_146: 0.8559 - precision_146: 0.4978 - val_loss: 0.4881 - val_accuracy: 0.7714 - val_binary_crossentropy: 0.4881 - val_recall_146: 0.7512 - val_precision_146: 0.4670\n",
      "Epoch 68/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7265 - accuracy: 0.7932 - binary_crossentropy: 0.4441 - recall_146: 0.8272 - precision_146: 0.4814 - val_loss: 0.4779 - val_accuracy: 0.7733 - val_binary_crossentropy: 0.4779 - val_recall_146: 0.7512 - val_precision_146: 0.4697\n",
      "Epoch 69/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7597 - accuracy: 0.7977 - binary_crossentropy: 0.4423 - recall_146: 0.8095 - precision_146: 0.5038 - val_loss: 0.4798 - val_accuracy: 0.7719 - val_binary_crossentropy: 0.4798 - val_recall_146: 0.7442 - val_precision_146: 0.4674\n",
      "Epoch 70/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7093 - accuracy: 0.8035 - binary_crossentropy: 0.4314 - recall_146: 0.8419 - precision_146: 0.4999 - val_loss: 0.5237 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5237 - val_recall_146: 0.7719 - val_precision_146: 0.4306\n",
      "Epoch 71/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7200 - accuracy: 0.7914 - binary_crossentropy: 0.4455 - recall_146: 0.8354 - precision_146: 0.4833 - val_loss: 0.5592 - val_accuracy: 0.7338 - val_binary_crossentropy: 0.5592 - val_recall_146: 0.7995 - val_precision_146: 0.4237\n",
      "Epoch 72/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7370 - accuracy: 0.7926 - binary_crossentropy: 0.4573 - recall_146: 0.8476 - precision_146: 0.4947 - val_loss: 0.5379 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5379 - val_recall_146: 0.7903 - val_precision_146: 0.4320\n",
      "Epoch 73/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7457 - accuracy: 0.7828 - binary_crossentropy: 0.4670 - recall_146: 0.8431 - precision_146: 0.4816 - val_loss: 0.4634 - val_accuracy: 0.7843 - val_binary_crossentropy: 0.4634 - val_recall_146: 0.7143 - val_precision_146: 0.4851\n",
      "Epoch 74/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.8108 - binary_crossentropy: 0.4196 - recall_146: 0.8398 - precision_146: 0.5054 - val_loss: 0.4924 - val_accuracy: 0.7610 - val_binary_crossentropy: 0.4924 - val_recall_146: 0.7512 - val_precision_146: 0.4528\n",
      "Epoch 75/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7343 - accuracy: 0.7889 - binary_crossentropy: 0.4466 - recall_146: 0.8445 - precision_146: 0.4854 - val_loss: 0.4944 - val_accuracy: 0.7657 - val_binary_crossentropy: 0.4944 - val_recall_146: 0.7465 - val_precision_146: 0.4589\n",
      "Epoch 76/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7682 - accuracy: 0.7812 - binary_crossentropy: 0.4647 - recall_146: 0.8181 - precision_146: 0.4624 - val_loss: 0.4823 - val_accuracy: 0.7686 - val_binary_crossentropy: 0.4823 - val_recall_146: 0.7442 - val_precision_146: 0.4628\n",
      "Epoch 77/100\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.7986 - binary_crossentropy: 0.4304 - recall_146: 0.8530 - precision_146: 0.5036 - val_loss: 0.4759 - val_accuracy: 0.7748 - val_binary_crossentropy: 0.4759 - val_recall_146: 0.7419 - val_precision_146: 0.4714\n",
      "Epoch 78/100\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.7412 - accuracy: 0.7974 - binary_crossentropy: 0.4418 - recall_146: 0.8477 - precision_146: 0.5064 - val_loss: 0.5112 - val_accuracy: 0.7486 - val_binary_crossentropy: 0.5112 - val_recall_146: 0.7581 - val_precision_146: 0.4375\n",
      "Epoch 79/100\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.7083 - accuracy: 0.8056 - binary_crossentropy: 0.4365 - recall_146: 0.8546 - precision_146: 0.5016 - val_loss: 0.5185 - val_accuracy: 0.7529 - val_binary_crossentropy: 0.5185 - val_recall_146: 0.7488 - val_precision_146: 0.4422\n",
      "Epoch 80/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.7756 - binary_crossentropy: 0.4669 - recall_146: 0.8333 - precision_146: 0.4551 - val_loss: 0.5167 - val_accuracy: 0.7495 - val_binary_crossentropy: 0.5167 - val_recall_146: 0.7788 - val_precision_146: 0.4401\n",
      "Epoch 81/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7406 - accuracy: 0.7800 - binary_crossentropy: 0.4594 - recall_146: 0.8443 - precision_146: 0.4694 - val_loss: 0.4922 - val_accuracy: 0.7671 - val_binary_crossentropy: 0.4922 - val_recall_146: 0.7535 - val_precision_146: 0.4612\n",
      "Epoch 82/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7143 - accuracy: 0.8036 - binary_crossentropy: 0.4299 - recall_146: 0.8495 - precision_146: 0.5156 - val_loss: 0.4938 - val_accuracy: 0.7624 - val_binary_crossentropy: 0.4938 - val_recall_146: 0.7581 - val_precision_146: 0.4550\n",
      "Epoch 83/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.8047 - binary_crossentropy: 0.4344 - recall_146: 0.8493 - precision_146: 0.5040 - val_loss: 0.5949 - val_accuracy: 0.7067 - val_binary_crossentropy: 0.5949 - val_recall_146: 0.8111 - val_precision_146: 0.3973\n",
      "Epoch 84/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7470 - accuracy: 0.7719 - binary_crossentropy: 0.4767 - recall_146: 0.8513 - precision_146: 0.4617 - val_loss: 0.4670 - val_accuracy: 0.7795 - val_binary_crossentropy: 0.4670 - val_recall_146: 0.7235 - val_precision_146: 0.4779\n",
      "Epoch 85/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.8064 - binary_crossentropy: 0.4197 - recall_146: 0.8445 - precision_146: 0.5191 - val_loss: 0.4822 - val_accuracy: 0.7705 - val_binary_crossentropy: 0.4822 - val_recall_146: 0.7350 - val_precision_146: 0.4650\n",
      "Epoch 86/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.8052 - binary_crossentropy: 0.4243 - recall_146: 0.8420 - precision_146: 0.4995 - val_loss: 0.4727 - val_accuracy: 0.7776 - val_binary_crossentropy: 0.4727 - val_recall_146: 0.7396 - val_precision_146: 0.4756\n",
      "Epoch 87/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7029 - accuracy: 0.8022 - binary_crossentropy: 0.4252 - recall_146: 0.8482 - precision_146: 0.5036 - val_loss: 0.5292 - val_accuracy: 0.7410 - val_binary_crossentropy: 0.5292 - val_recall_146: 0.7811 - val_precision_146: 0.4302\n",
      "Epoch 88/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.7939 - binary_crossentropy: 0.4465 - recall_146: 0.8504 - precision_146: 0.4938 - val_loss: 0.5298 - val_accuracy: 0.7429 - val_binary_crossentropy: 0.5298 - val_recall_146: 0.7811 - val_precision_146: 0.4324\n",
      "Epoch 89/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.7926 - binary_crossentropy: 0.4391 - recall_146: 0.8744 - precision_146: 0.4978 - val_loss: 0.5130 - val_accuracy: 0.7562 - val_binary_crossentropy: 0.5130 - val_recall_146: 0.7650 - val_precision_146: 0.4474\n",
      "Epoch 90/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7487 - accuracy: 0.7910 - binary_crossentropy: 0.4569 - recall_146: 0.8430 - precision_146: 0.4983 - val_loss: 0.4758 - val_accuracy: 0.7814 - val_binary_crossentropy: 0.4758 - val_recall_146: 0.7350 - val_precision_146: 0.4811\n",
      "Epoch 91/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.6816 - accuracy: 0.8135 - binary_crossentropy: 0.4105 - recall_146: 0.8486 - precision_146: 0.5212 - val_loss: 0.4569 - val_accuracy: 0.7805 - val_binary_crossentropy: 0.4569 - val_recall_146: 0.6959 - val_precision_146: 0.4786\n",
      "Epoch 92/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7041 - accuracy: 0.8081 - binary_crossentropy: 0.4146 - recall_146: 0.8362 - precision_146: 0.5161 - val_loss: 0.5059 - val_accuracy: 0.7552 - val_binary_crossentropy: 0.5059 - val_recall_146: 0.7650 - val_precision_146: 0.4462\n",
      "Epoch 93/100\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.7203 - accuracy: 0.7998 - binary_crossentropy: 0.4378 - recall_146: 0.8505 - precision_146: 0.4986 - val_loss: 0.4697 - val_accuracy: 0.7743 - val_binary_crossentropy: 0.4697 - val_recall_146: 0.7097 - val_precision_146: 0.4695\n",
      "Epoch 94/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7364 - accuracy: 0.7986 - binary_crossentropy: 0.4359 - recall_146: 0.8459 - precision_146: 0.5015 - val_loss: 0.4964 - val_accuracy: 0.7643 - val_binary_crossentropy: 0.4964 - val_recall_146: 0.7558 - val_precision_146: 0.4575\n",
      "Epoch 95/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.8069 - binary_crossentropy: 0.4259 - recall_146: 0.8541 - precision_146: 0.5237 - val_loss: 0.4995 - val_accuracy: 0.7576 - val_binary_crossentropy: 0.4995 - val_recall_146: 0.7488 - val_precision_146: 0.4483\n",
      "Epoch 96/100\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.7044 - accuracy: 0.8087 - binary_crossentropy: 0.4347 - recall_146: 0.8676 - precision_146: 0.5183 - val_loss: 0.5108 - val_accuracy: 0.7519 - val_binary_crossentropy: 0.5108 - val_recall_146: 0.7581 - val_precision_146: 0.4416\n",
      "Epoch 97/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7294 - accuracy: 0.7890 - binary_crossentropy: 0.4528 - recall_146: 0.8520 - precision_146: 0.4892 - val_loss: 0.4891 - val_accuracy: 0.7710 - val_binary_crossentropy: 0.4891 - val_recall_146: 0.7373 - val_precision_146: 0.4658\n",
      "Epoch 98/100\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.7092 - accuracy: 0.8065 - binary_crossentropy: 0.4327 - recall_146: 0.8543 - precision_146: 0.5015 - val_loss: 0.5235 - val_accuracy: 0.7443 - val_binary_crossentropy: 0.5235 - val_recall_146: 0.7650 - val_precision_146: 0.4329\n",
      "Epoch 99/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.7074 - accuracy: 0.8121 - binary_crossentropy: 0.4399 - recall_146: 0.8681 - precision_146: 0.5169 - val_loss: 0.5147 - val_accuracy: 0.7576 - val_binary_crossentropy: 0.5147 - val_recall_146: 0.7696 - val_precision_146: 0.4495\n",
      "Epoch 100/100\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.6848 - accuracy: 0.8062 - binary_crossentropy: 0.4284 - recall_146: 0.8587 - precision_146: 0.5001 - val_loss: 0.4880 - val_accuracy: 0.7719 - val_binary_crossentropy: 0.4880 - val_recall_146: 0.7442 - val_precision_146: 0.4674\n"
     ]
    }
   ],
   "source": [
    "annHist = annClass.fit(X0_train1, y0_train.values, epochs=100, validation_data=(X0_valid1, y0_valid.values), class_weight=weights, verbose=True) #, batch_size = 1000, callbacks=[tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'binary_crossentropy', 'recall_146', 'precision_146', 'val_loss', 'val_accuracy', 'val_binary_crossentropy', 'val_recall_146', 'val_precision_146'])\n"
     ]
    }
   ],
   "source": [
    "# List all data in history\n",
    "print(annHist.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(annHist.history['accuracy'])\n",
    "plt.plot(annHist.history['val_accuracy'])\n",
    "plt.title('Model Tweaked by RandomizedSearchCV Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(annHist.history['recall_146'])\n",
    "plt.plot(annHist.history['val_recall_146'])\n",
    "plt.title('Model Tweaked by RandomizedSearchCV Recall')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(annHist.history['binary_crossentropy'])\n",
    "plt.plot(annHist.history['val_binary_crossentropy'])\n",
    "plt.title('Model Tweaked by RandomizedSearchCV Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>binary_crossentropy</th>\n",
       "      <th>recall_146</th>\n",
       "      <th>precision_146</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.362071</td>\n",
       "      <td>0.855667</td>\n",
       "      <td>0.362071</td>\n",
       "      <td>0.466882</td>\n",
       "      <td>0.737245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  binary_crossentropy  recall_146  precision_146\n",
       "0  0.362071  0.855667             0.362071    0.466882       0.737245"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_DF = pd.DataFrame(columns=annClass.metrics_names)\n",
    "res_DF.loc[0] = np.array(results)\n",
    "res_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 978us/step - loss: 0.4901 - accuracy: 0.7750 - binary_crossentropy: 0.4901 - recall_146: 0.7431 - precision_146: 0.4713\n"
     ]
    }
   ],
   "source": [
    "results = annClass.evaluate(X1_test, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[1865,  516],\n",
       "       [ 159,  460]])>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (annClass.predict(X1_test) > 0.5).astype('int32')\n",
    "tf.math.confusion_matrix(y_test, y_pred, num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ANN Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEECAYAAAAxqm/oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df3RU1b338ffkx8Q4mQApyqWVKBECWIwkCGiBKFqeINZWciUho1NBy72lFiUqhB/hR1UEBAJcKFhSrI8hJBMavULx1qtIiSJSGoUID/FHUBBURECYGWUSkvP8YTuW1pJJmGTmMJ8Xa6/FObOz93dYiy9f9tnnHIthGAYiImI6UaEOQEREWkcJXETEpJTARURMSglcRMSklMBFREwqJtQB/KOGz/eHOgQJQzkZD4Q6BAlDzx3ceN5jtCTnxHZOOe/5gkkVuIiISYVdBS4i0q6aGkMdQaspgYtIZGs8E+oIWk0JXEQimmE0hTqEVlMCF5HI1mTeBK6LmCIS2YymwFsAdu/ejdPpBGDfvn3k5OSQl5fHtGnTaPrrPxYVFRVkZ2eTk5PDli1bADh9+jQTJ07E4XAwfvx4jh8/3uxcSuAiEtmaGgNvzSguLqawsBCfzwfAihUruO+++ygrK6O+vp4//elPHD16lJKSEsrLy1mzZg1FRUXU19dTVlZGamoq69at4/bbb2flypXNzqcELiKRLYgVeHJyMsuXL/cf9+nThy+++ALDMPB6vcTExFBTU0N6ejpWqxW73U5ycjK1tbVUV1czdOhQADIzM9m+fXuz8ymBi0hEMxrPBNxcLhfZ2dn+5nK5zhorKyuLmJhvLi1eccUVzJ07l1tuuYVjx44xaNAgPB4Pdrvd38dms+HxeM46b7PZcLvdzcaui5giEtlacBEzNzeX3NzcgPvPnTuX0tJSevbsSWlpKfPnz2fIkCF4vV5/H6/Xi91uJyEhwX/e6/WSmJjY7PiqwEUksgX5Iubf69ChAwkJCQBceumlnDp1irS0NKqrq/H5fLjdburq6khNTSUjI4OtW7cCUFVVRf/+/ZsdXxW4iES2NrwT87HHHiM/P5+YmBhiY2N59NFHueSSS3A6nTgcDgzDID8/n7i4OPLy8igoKCAvL4/Y2FgWL17c7PiWcHulmh5mJd9GD7OSbxOMh1n59m0JuG9cn2HnPV8wqQIXkcimW+lFREzKxHdiKoGLSEQzDD2NUETEnPQwKxERk9ISioiISakCFxExqcaGUEfQakrgIhLZtIQiImJSWkIRETEpVeAiIialBC4iYk6GLmKKiJiU1sBFRExKSygiIialClxExKRUgYuImJSJK3C9E1NEItuZM4G3AOzevRun0wnAsWPHmDBhAnfeeSdjxozh4MGDAFRUVJCdnU1OTg5btnz9RqDTp08zceJEHA4H48eP5/jx483OpQpcRCJbECvw4uJiNmzYQHx8PAALFy7ktttuY+TIkbzxxhvs37+f+Ph4SkpKqKysxOfz4XA4GDx4MGVlZaSmpjJx4kQ2bdrEypUrKSwsPOd8qsBFJLI1NQXempGcnMzy5cv9x2+++SZHjhxh7NixbNy4kYEDB1JTU0N6ejpWqxW73U5ycjK1tbVUV1czdOhQADIzM9m+fXuz8ymBi0hkM5oCbi6Xi+zsbH9zuVxnDZWVlUVMzDcLG4cPHyYxMZGnn36arl27UlxcjMfjwW63+/vYbDY8Hs9Z5202G263u9nQtYQiIpGtBbtQcnNzyc3NDbh/x44duemmmwC46aabWLJkCX379sXr9fr7eL1e7HY7CQkJ/vNer5fExMRmx1cFLiKRrQUVeEv179+frVu3ArBz50569OhBWloa1dXV+Hw+3G43dXV1pKamkpGR4e9bVVVF//79mx1fFbiIRLYAd5e0RkFBAYWFhZSXl5OQkMDixYvp0KEDTqcTh8OBYRjk5+cTFxdHXl4eBQUF5OXlERsby+LFi5sd32IYhtFm0bdCw+f7Qx2ChKGcjAdCHYKEoecObjzvMb5y/SrgvvG5s897vmBSBS4ikU13YoqImJQSuIiISZn4VnolcBGJbI2NoY6g1ZTARSSyaQlFRMSklMBFRExKa+AiIuZkNIXVrTAtogQuIpFNSygiIialXSgiIialClxExKSUwKWlavbWUrTqKZ5e8QS179bxyMLlRMdEc3m37/HI1ElERUXx6vadrHqqFIA+vXpQ+NB9ANx8u5Pkbt8F4Jrv9yF/wriQfQ9pG4tfWMqX7i8BOPLREVY8vAyAcbN+xsf7D/Hi2j8CkHFjf3ImjQFg/579rC5cFZqAzSy8nufXIkrgIfBU6Xo2/vEV4i+KA2Dl70r5+TgHmT8YSMGcBVS9/mcGpKex+Ndr+N2KBXTq2IGnStdz4ouTeLxf0qfXlfz6icCfoCbmEhsXC8DM3On+c4lJiTyw5EG+m/Jd/vs3hwC4yBbP3TPGUZgzHfeJU9z+82wSkxI5dfxUSOI2LRNX4G36QocmE//BtKVu3+3K0se/eVlpn55XctLtwTAMvF9+RUxMDLv27KPnlVewcHkxP53wMN/p1JGkTh3ZW/senx09xrhfFjDhoZl8cOBQCL+JtIUr+nQnLj6O2Wsf4ZGyx0hN78VFtnjKl6zjT89u8ffr3b83B2o/ZNzMe5j7+/mc/PwLJe/WaDICb2Em6BX4Rx99xLx589izZw8xMTE0NTWRmprKtGnT6N69e7CnM6Xhw4Zw+JMj/uPLu32Pxxb/mtVPl5GQYGNAehov/ek1/vxmDZVPr+Di+Hh++ouHuaZvHy7pnMTPnLlk3TSUN3fvYeojT+Ba818h/DYSbL6vfDy/+jleKvtfvtv9u8x8Zg733fhzPvvoCBnDvnlLS2JSIn2vT+PBW+7ntPc0c38/n3eqa/n4g49DGL0JaRfKN2bMmMFDDz3ENddc4z+3a9cupk2bRnl5ebCnuyDMX/okz6xcRI+Uyymr3MjCFcXcOHgQffv0pPN3kgDo3+9qat/bzw2DBxITHQ1AxjV9+ezoMQzDwGKxhPIrSBB9/MFhPv3wk7/+/mPcJ9x0ujSJY598flY/9wk379e8xxdHvwDg//15L1d8P0UJvIUME68UBH0Jpb6+/qzkDdCvX79gT3NB6ZBox2a7GIBLOidxyu3hql49eH//AU58cZIzZxqp2VvLld2TWfVUKSUV/w1A7Xv76drlEiXvC8zNOcMZO/NeADp1SSI+4WJOfHb8n/rVvf0+yamXY++USFR0FKnpvTj07sH2Dtf8tITyjV69ejFt2jSGDh2K3W7H6/WydetWevXqFeypLhi/mvoAk2fPJyY6ipiYWH419QGSOnXkgZ+P5T8f/HqtPOumofRMuYJ778ph6iMLqXr9z0RHR/NY4UMhjl6CbbPrJSYunsTjlQswDIMVk5fR1PjPVeKp46dYu+D/Mnvt1xe0t/3hNQ4qgbdckJ+Fsnv3bhYtWkRJSYn/3MaNG1m7di0ulwuAiooKysvLiYmJYcKECQwbNozTp08zefJkjh07hs1mY8GCBSQlJZ1zrqC/E9MwDF5++WWqq6vxeDwkJCSQkZHB8OHDA6oU9U5M+TZ6J6Z8m2C8E9P7yJ0B97XNKj3n58XFxWzYsIH4+HgqKioA2LdvH/Pnz+err76ioqKCo0ePcs8991BZWYnP58PhcFBZWUlpaSkej4eJEyeyadMm3nrrLQoLC885X9ArcIvFwvDhwxk+fHiwhxYRCb4zwbuImZyczPLly5kyZQoAJ06cYNGiRUyfPp2ZM2cCUFNTQ3p6OlarFavVSnJyMrW1tVRXV/Ozn/0MgMzMTFauXNnsfNoHLiKRrQVLKC6Xy78MApCbm0tubq7/OCsri0OHvt7a29jYyIwZM5g+fTpxcXH+Ph6PB7vd7j+22Wx4PJ6zzttsNtxud7PxKIGLSGRrwcXJf0zY57J3714OHDjAnDlz8Pl8vP/++8ydO5frrrsOr9fr7+f1erHb7SQkJPjPe71eEhMTm51DCVxEIlpbbSNMS0tj06ZNABw6dIgHH3yQGTNmcPToUZYuXYrP56O+vp66ujpSU1PJyMhg69atpKWlUVVVRf/+/ZuZQQlcRCJdO28PvOSSS3A6nTgcDgzDID8/n7i4OPLy8igoKCAvL4/Y2FgWL17c7FhB34VyvrQLRb6NdqHItwnGLhTP5FEB901Y+Nx5zxdMqsBFJLLpVnoREXPSOzFFRMxKCVxExKRM/DArJXARiWyqwEVETEoJXETEnIxvedKjWSiBi0hkUwUuImJO2kYoImJWSuAiIiZl3iVwJXARiWzGGfNmcCVwEYls5s3fSuAiEtl0EVNExKxUgYuImJMqcBERszJxBR4V6gBERELJOBN4C8Tu3btxOp0A7Nu3D4fDgdPp5N577+Xzzz8HoKKiguzsbHJyctiyZQsAp0+fZuLEiTgcDsaPH8/x48ebnUsJXEQimtEUeGtOcXExhYWF+Hw+AObOncvMmTMpKSlh+PDhFBcXc/ToUUpKSigvL2fNmjUUFRVRX19PWVkZqamprFu3jttvv52VK1c2O58SuIhEtqYWtGYkJyezfPly/3FRURF9+vQBoLGxkbi4OGpqakhPT8dqtWK320lOTqa2tpbq6mqGDh0KQGZmJtu3b292Pq2Bi0hEC6Sy/huXy4XL5fIf5+bmkpub6z/Oysri0KFD/uNLL70UgDfffJO1a9dSWlrKq6++it1u9/ex2Wx4PB48Ho//vM1mw+12NxuPEriIRLSWJPB/TNiBeOGFF1i1ahWrV68mKSmJhIQEvF6v/3Ov14vdbj/rvNfrJTExsdmxtYQiIhHNaLQE3Frq+eefZ+3atZSUlNCtWzcA0tLSqK6uxufz4Xa7qaurIzU1lYyMDLZu3QpAVVUV/fv3b3Z8VeAiEtFaUoG3RGNjI3PnzqVr165MnDgRgAEDBnD//ffjdDpxOBwYhkF+fj5xcXHk5eVRUFBAXl4esbGxLF68uNk5LIZhhNUu9obP94c6BAlDORkPhDoECUPPHdx43mN8MmRYwH27vrblvOcLJlXgIhLR2qoCbw/nTODTpk37l5/Nmzcv6MGIiLQ3w2j52na4OOdFzJEjRzJy5EhOnjxJSkoKd9xxB7169aK+vr694hMRaVPBvJGnvZ2zAv/bpvLf/e53jB8/HoD+/fszbty4to9MRKQdNLVid0m4CGgb4Zdffsn27dvxeDy8+uqrNDQ0tHVcIiLtwmiyBNzCTUAXMefOncuyZct47LHHSElJYcmSJW0dl4hIuwjHxByogBL4lVdeSX5+PgcPHqRXr1507ty5reMSEWkX4bWRumUCSuBr167lpZde4uTJk4waNYoDBw4wa9asto5NRKTNmbkCD2gNfNOmTTz99NPY7Xbuvvtudu/e3dZxiYi0C8OwBNzCTUAV+N9u1rRYvv4CVqu17SISEWlHjSbehRJQAr/11lu58847+fjjjxk/fjw//OEP2zouEZF2EY6VdaACSuB5eXn84Ac/4N1336V79+707t27reMSEWkXF/wa+G233UZlZSW9e/dW8haRC4phBN7CTUAV+PPPP88rr7zC/Pnz8fl8ZGdn8+Mf/7itYxMRaXMXfAVutVoZMWIE48ePJzExkVWrVrV1XCIi7aKxKSrgFm4CqsBXrFjBiy++SJ8+fXA6nQwYMKCt4xIRaRfhuDQSqIASeIcOHSgtLQ3oHW0iImbSZOJdKAH9n+CFF15Q8haRC9IFfyPPxRdfzOOPP0737t2Jivo657f0zcwiIuEo2Esou3fvZtGiRZSUlHDgwAGmTp2KxWKhZ8+ezJ49m6ioKCoqKigvLycmJoYJEyYwbNgwTp8+zeTJkzl27Bg2m40FCxaQlJR0zrkCSuDp6ekAHDt27Py/XTPivzu0zecQ87mxS99QhyAXqGAuoRQXF7Nhwwbi4+OBr99cNmnSJAYNGsSsWbPYvHkz/fr1o6SkhMrKSnw+Hw6Hg8GDB1NWVkZqaioTJ05k06ZNrFy5ksLCwnPOF9ASyi9/+UsyMjK49NJL+eEPf+h/uYOIiNkFcxdKcnIyy5cv9x/v3buXgQMHApCZmcnrr79OTU0N6enpWK1W7HY7ycnJ1NbWUl1d7X+JTmZmJtu3b292voAq8KKiIj799FPq6uqIjY1l9erVFBUVBfKjIiJhrSUrKC6XC5fL5T/Ozc09azk5KyuLQ4cOfTO2YfifIWWz2XC73Xg8Hux2u7+PzWbD4/Gcdf5vfZsTUAKvrq6mtLQUp9PJqFGjKCsrC+THRETCXkuWUP4xYTfnb9cMAbxeL4mJiSQkJOD1es86b7fbzzr/t77Njh9IEI2Njfh8PiwWC42NjWcFJSJiZm25C+Wqq65ix44dAFRVVXHttdeSlpZGdXU1Pp8Pt9tNXV0dqampZGRksHXrVn/f/v37Nzt+QBX43XffTXZ2NsePH2f06NGMHTu2xV9ERCQcteXL5gsKCpg5cyZFRUWkpKSQlZVFdHQ0TqcTh8OBYRjk5+cTFxdHXl4eBQUF5OXlERsby+LFi5sd32IYgW2iOXnyJAcOHKBbt2506tTpvL/YvxJj/V6bjS3mpV0o8m1e/ujF8x6j6t9GB9w389P15z1fMAW0FrJz5052797NiRMnGD16NBs3bmzruERE2sUZwxJwCzcBJfCFCxdyxRVX8Mwzz1BWVkZ5eXlbxyUi0i4MLAG3cBPQGnhcXBzf+c53iImJ4ZJLLqG+vr6t4xIRaRdtuQbe1gKqwBMSEhg3bhy33HILpaWldO3ata3jEhFpFxd8Bb5s2TIOHjxIjx49eO+99xg9OvBFfxGRcGbmCjygBH7kyBGWLVvGhx9+SM+ePZk8ebKqcBG5IDSGYWUdqICWUKZPn84dd9zBunXr+NGPfsT06dPbOi4RkXbRZAm8hZuAEnh0dDQ33HADdrudm266iaYmM/+nQ0TkG01YAm7h5pxLKK+99hoA8fHxFBcXM2DAAGpqaujcuXO7BCci0tZM/Ea1cyfwTZs2AZCYmEh5eTl1dXVYLBasVmu7BCci0tbMvJ5wziWUwsJCTpw4wYcffki/fv147733OHbsGDNmzGiv+ERE2lSTxRJwCzfnrMAXL17MiBEjuP322/3n1q9fzxNPPMEjjzzS5sGJiLS1xlAHcB7OWYHX1taelbwBRo8ezTvvvNOmQYmItBcz70I5ZwUeE/PtH0dHR7dJMCIi7S0cd5cE6pwVeMeOHXn77bfPOvf222/ToUOHNg1KRKS9GC1o4eacFfiUKVOYMGECgwYNolu3bhw6dIjt27ezatWq9opPRKRNhePSSKDOWYFfdtll/P73v2fAgAE0NDSQlpZGRUUF3bp1a6/4RETaVFMLWrhp9lkocXFxZGVltUcsIiLtrjFIFXhDQwNTp07l8OHDREVF8eijjxITE8PUqVOxWCz07NmT2bNnExUVRUVFBeXl5cTExDBhwgSGDRvWqjkDepiViMiFKliV9datWzlz5gzl5eVs27aNpUuX0tDQwKRJkxg0aBCzZs1i8+bN9OvXj5KSEiorK/H5fDgcDgYPHtyqGySVwEUkogUrgXfv3p3GxkaamprweDzExMSwa9cuBg4cCEBmZibbtm0jKiqK9PR0rFYrVquV5ORkamtrSUtLa/GcSuAiEtFa8qpLl8uFy+XyH+fm5pKbmwvAxRdfzOHDh7nllls4ceIETz75JDt37sTy1zs4bTYbbrcbj8eD3W73j2Gz2fB4PK2KXQlcRCJaSyrwv0/Y/+jpp59myJAhPPTQQ3zyySfcfffdNDQ0+D/3er0kJiaSkJCA1+s96/zfJ/SWCOhxsiIiF6rGFrRzSUxM9CfiDh06cObMGa666ip27NgBQFVVFddeey1paWlUV1fj8/lwu93U1dWRmpraqthVgYtIRAvWPvCxY8cyffp0HA4HDQ0N5Ofn07dvX2bOnElRUREpKSlkZWURHR2N0+nE4XBgGAb5+fnExcW1ak6LYRhhdYNRjPV7oQ5BwtCNXfqGOgQJQy9/9OJ5j7Ek+a6A++YfXHve8wWTKnARiWjheINOoJTARSSihdUSRAspgYtIRDPzs1CUwEUkopn5hQ5K4CIS0ZpMvIiiBC4iEU0XMUVETMq89bcSuIhEOFXgIiImdcZi3hpcCVxEIpp507cSuIhEOC2hiIiYlLYRioiYlHnTtxK4iEQ4LaGIiJhUo4lrcCVwEYloqsBFREzKUAUuImJOqsBFREwqmNsIf/Ob3/DKK6/Q0NBAXl4eAwcOZOrUqVgsFnr27Mns2bOJioqioqKC8vJyYmJimDBhAsOGDWvVfHorfRgYOCCdzS+tByC9X18OfPAXNr+0ns0vrWf06B8DMPnhX/CXnf/Lls2V3Dryh6EMV9pJx+90YN2OtXS7shsdv9OBR9bMoej3i1j6bBFdL+8KwMi8W/j1puUsf34pg24eFOKIzcloQTuXHTt28NZbb1FWVkZJSQmffvop8+bNY9KkSaxbtw7DMNi8eTNHjx6lpKSE8vJy1qxZQ1FREfX19a2KXRV4iD380ATuvPPf+dL7FQDp6VezdFkxS5b+xt+nb9/ejBkzih8M/hEAr1Y9zytbXuOrr06HJGZpe9Ex0Uya/wD1p30AjJ/xMzY/9wpb/1DFNddfQ/KV3Tj95WlG3fMTfnHrRKxxsSx9tog3X32ThvqGEEdvLmeCVIG/9tprpKamct999+HxeJgyZQoVFRUMHDgQgMzMTLZt20ZUVBTp6elYrVasVivJycnU1taSlpbW4jlVgYdY3f4DjM4Z7z/OyEhj5C03s2VzJat/s4iEBBu9e/dk69bX8fl8+Hw+3n//A9KuviqEUUtb+8/C8fxh7SaOHTkGwPev/T6du3bmiXXzuXnUMHZv303vfr3Ys/P/0VDfgNf9JYc//JiUPt1DHLn5GC345XK5yM7O9jeXy+Uf58SJE+zZs4dly5bxq1/9iocffhjDMLBYvn5nm81mw+124/F4sNvt/p+z2Wx4PJ5Wxa4EHmLPPfcCDQ3fVEw7d75FwdRHGXbzv/PBBweZVfgge/bsY+jQ60hIsJGU1Inrr7sWm+3iEEYtben/jB7OyeMn+cvWav+5f7usC56THqY4pvLZ4aPk/iKXixMuxuv2+vt85fkKm90WipBNrakFLTc3l2effdbfcnNz/eN07NiRIUOGYLVaSUlJIS4uDrfb7f/c6/WSmJhIQkICXq/3rPN/n9BbIuhLKE6n86yEBPj/FSovLw/2dBec/37+j5w8eeqvv/8fli15jNra91m58nds2riW9+s+5M873+LzY8dDHKm0lRG5WRiGQcaQdK686koKlk6mqbGJ7f+7HYA3Xn6DcVPG8m7Nu1ycEO//ufiEeDynWlfJRbJgbSPs378/zzzzDOPGjeOzzz7jq6++4vrrr2fHjh0MGjSIqqoqrrvuOtLS0li6dCk+n4/6+nrq6upITU1t1ZxBT+APP/wwhYWF/PrXvyY6OjrYw1/w/mdTKQ9MmsnOv+zipmFDePOtGjp3TqJz5yRuGDaKxEQ7f3xhHXv21IY6VGkjD97xsP/3iyueYOm05YybfDcDbxrIy89u5upBV3Pg3QPU7nqHe6aMJTYuFqs1luQeyXzwzoehC9ykgrWNcNiwYezcuZM77rgDwzCYNWsWl112GTNnzqSoqIiUlBSysrKIjo7G6XTicDgwDIP8/Hzi4uJaNWfQE/g111zDT37yE9555x2GDx8e7OEvePf9chr/tWwu9fX1fHrkKD+fMAW320P37pez/fVNNNQ3UDD1MZqazLx7VVrqyUdX89AT+dzm/BFet5fHJ87Hc9LDc089z9LKxVgsUfzuiadp8OkCZks1GsHbRjhlypR/Ord27dp/OpeTk0NOTs55z2cxjCBGHwQx1u+FOgQJQzd26RvqECQMvfzRi+c9huPyUQH3XXfgufOeL5i0jVBEIppupRcRMSkzL0YqgYtIRNMbeURETEpLKCIiJhXMXSjtTQlcRCKallBERExKFzFFRExKa+AiIialJRQREZMKs5vRW0QJXEQiWqMqcBERc9ISioiISWkJRUTEpFSBi4iYlLYRioiYlJlvpddLjUUkojVhBNwCcezYMW644Qbq6uo4cOAAeXl5OBwOZs+e7X+TVkVFBdnZ2eTk5LBly5ZWx64ELiIRLZgJvKGhgVmzZnHRRRcBMG/ePCZNmsS6deswDIPNmzdz9OhRSkpKKC8vZ82aNRQVFVFfX9+q2JXARSSiGYYRcGvOggULGDNmDJdeeikAe/fuZeDAgQBkZmby+uuvU1NTQ3p6OlarFbvdTnJyMrW1rXtJuRK4iES0llTgLpeL7Oxsf3O5XP5xnn32WZKSkhg6dKj/nGEYWCwWAGw2G263G4/Hg91u9/ex2Wx4PJ5Wxa6LmCIS0VqyCyU3N5fc3Nxv/ayyshKLxcL27dvZt28fBQUFHD9+3P+51+slMTGRhIQEvF7vWef/PqG3hCpwEYlojUZTwO1cSktLWbt2LSUlJfTp04cFCxaQmZnJjh07AKiqquLaa68lLS2N6upqfD4fbreburo6UlNTWxW7KnARiWhteSdmQUEBM2fOpKioiJSUFLKysoiOjsbpdOJwODAMg/z8fOLi4lo1vsUIs/tIY6zfC3UIEoZu7NI31CFIGHr5oxfPe4xr/u0HAffd/enr5z1fMKkCF5GIpjsxRURMqim8FiFaRAlcRCKaKnAREZNqbndJOFMCF5GIpiUUERGT0hKKiIhJqQIXETEpVeAiIibVaDSGOoRWUwIXkYgWZjejt4gSuIhENL3UWETEpFSBi4iYlHahiIiYlHahiIiYlG6lFxExKa2Bi4iYlNbARURMShW4iIhJBWsfeENDA9OnT+fw4cPU19czYcIEevTowdSpU7FYLPTs2ZPZs2cTFRVFRUUF5eXlxMTEMGHCBIYNG9aqOZXARSSiBasC37BhAx07dmThwoWcOHGCUaNG0bt3byZNmsSgQYOYNWsWmzdvpl+/fpSUlFBZWYnP58PhcDB48GCsVmuL51QCF5GIFqxdKCNGjCArK8t/HB0dzd69exk4cCAAmZmZbNu2jaioKNLT07FarVitVpKTk78PD2wAAAVOSURBVKmtrSUtLa3Fc0YFJXIREZNqMoyAm8vlIjs7299cLpd/HJvNRkJCAh6Ph/vvv59JkyZhGAYWi8X/udvtxuPxYLfbz/o5j8fTqthVgYtIRGvJEkpubi65ubn/8vNPPvmE++67D4fDwW233cbChQv9n3m9XhITE0lISMDr9Z51/u8TekuoAheRiGa04Ne5fP7559xzzz1MnjyZO+64A4CrrrqKHTt2AFBVVcW1115LWloa1dXV+Hw+3G43dXV1pKamtip2VeAiEtGCdRHzySef5NSpU6xcuZKVK1cCMGPGDB577DGKiopISUkhKyuL6OhonE4nDocDwzDIz88nLi6uVXNajDDbBBlj/V6oQ5AwdGOXvqEOQcLQyx+9eN5jtCTnnKk/fN7zBVPYJXAREQmM1sBFRExKCVxExKSUwEVETEoJXETEpJTARURMSglcRMSklMBFRExKCTwMNTU1MWvWLHJzc3E6nRw4cCDUIUmY2L17N06nM9RhSJjQrfRh6OWXX6a+vh6Xy8WuXbuYP38+q1atCnVYEmLFxcVs2LCB+Pj4UIciYUIVeBiqrq5m6NChAPTr1489e/aEOCIJB8nJySxfvjzUYUgYUQIPQx6Ph4SEBP9xdHQ0Z86cCWFEEg6ysrKIidF/muUbSuBh6B+fF9zU1KS/uCLyT5TAw1BGRgZVVVUA7Nq1q9XPChaRC5vKujA0fPhwtm3bxpgxYzAMg8cffzzUIYlIGNLjZEVETEpLKCIiJqUELiJiUkrgIiImpQQuImJSSuAiIialBC5tYseOHVx//fU4nU6cTic5OTmUlJS0eJxFixbx7LPPsm/fPlasWPEv+7300kscOXIkoDGrqqqYOnVqi2MRCTfaBy5t5rrrrmPJkiUA1NfXM2LECH7yk5+QmJjY4rH69OlDnz59/uXnzzzzDHPmzKFLly6tjlfEbJTApV14PB6ioqIYO3Ysl112GadOnWL16tXMmTOHAwcO0NTUxKRJkxg0aBAvvvgiq1atIikpiYaGBlJSUtixYwfl5eUsWbKE9evXU1ZWRlNTEzfffDNXX301+/bto6CggHXr1uFyufjDH/6AxWJh5MiR/PSnP6Wuro7p06cTHx9PfHw8HTp0CPUfich5UwKXNvPGG2/gdDqxWCzExsYyc+ZMfvvb33LbbbcxfPhw1q1bR6dOnXj88cc5ceIEd911F5s2bWLhwoWsX7+ejh078h//8R9njXns2DH/Y1WtVivz589nwIAB9OnThzlz5nDw4EFeeOEF1q1bh8ViYezYsQwZMoRly5Zx//33M3jwYFavXs3+/ftD9KciEjxK4NJm/n4J5W9++9vf0r17dwDeffddqqurqampAeDMmTN8/vnnJCQk0KlTJwDS09PP+vmPPvqInj17ctFFFwEwffr0sz5/9913+fjjjxk7diwAJ0+e5ODBg7z33nukpaUBXz9rRglcLgS6iCntzmKxAJCSksKtt95KSUkJxcXFjBgxgsTERNxuN8ePHwfg7bffPutnk5OT2b9/P/X19QDcf//9HDlyBIvFgmEYpKSk0KNHD5555hlKSkrIzs4mNTWVlJQU3nrrLQA9X10uGKrAJWTGjBlDYWEhd911Fx6PB4fDgdVqZd68edx777106NDhnx6jm5SUxPjx47nrrruwWCwMGzaMLl26kJ6ezpQpU3jqqae4/vrrycvLo76+nrS0NLp06cLs2bPJz89nzZo1JCUlERcXF6JvLRI8epiViIhJaQlFRMSklMBFRExKCVxExKSUwEVETEoJXETEpJTARURMSglcRMSk/j9OucbVH9agjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('           ANN Confusion Matrix')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True,  fmt='.0f', xticklabels = [0,1] , yticklabels = [0,1] )\n",
    "plt.ylabel('Observed')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall [TP/(TP+FN)] for ANN Model = 0.74\n",
      "Precision [TP/(TP+FP)] for ANN Model = 0.47\n",
      "F1 Score [2.Precision.Recall / (Precision + Recall)] for ANN Model = 0.58\n",
      "Accuracy [(TP+TN)/(TP+TN+FP+FN)] for ANN Model = 0.78\n"
     ]
    }
   ],
   "source": [
    "TP = 460\n",
    "FP = 516\n",
    "FN = 159\n",
    "TN = 1865\n",
    "\n",
    "Recall = TP/(TP+FN)\n",
    "Precision = TP/(TP+FP)\n",
    "print('Recall [TP/(TP+FN)] for ANN Model = {0:.2f}'.format(Recall))\n",
    "print('Precision [TP/(TP+FP)] for ANN Model = {0:.2f}'.format(Precision))\n",
    "print('F1 Score [2.Precision.Recall / (Precision + Recall)] for ANN Model = {0:.2f}'.format((2*Recall*Precision)/(Recall+Precision)))\n",
    "print('Accuracy [(TP+TN)/(TP+TN+FP+FN)] for ANN Model = {0:.2f}'.format((TP+TN)/(TP+TN+FP+FN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FInal Model Evaluation\n",
    "1. The Final Model Accuracy based on 3 Fold cross validation of hyperparameters has produced:\n",
    "    - Recall score of 0.74 on test data, which is good as Exited customers are identified pretty well. A better score can be achieved with greater amount of data, which results in better neural network model performance\n",
    "    - Accuracy of 0.78 on test data, which is good because the model classifed correctly 78% of customers that Exited and those who stayed\n",
    "    - 3 hidden layers, resulting in it learning some complex relationships in parameters\n",
    "    - 1st hidden layer with 1.5 times the number of neurons compared to input layer, thereby creating equivalent of polynomial features to learn better\n",
    "2. Base Model Accuracy on validation data appears better than Final Model on validation data, however:\n",
    "    - Balancing the Exited class distribution with weight adjustments weights {0:1, 1:5} led to the Final Model having a better Recall value on validation data\n",
    "    - Final Model is expedted to generalise well in production, due to cross validation exercise\n",
    "    - Final Model Accuracy converges faster at about 40 epochs, compared to 60 epochs of the Base Model, which means faster learning of the cross validated & weight balanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
